{
  "cache_state": "hit",
  "components": [
    "[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
    "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
    "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
    "[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]",
    "[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}",
    "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
    "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
    "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
    "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
    "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
    "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
    "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
    "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
    "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
    "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
    "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
    "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
    "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
    "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
    "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
    "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
    "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
    "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
    "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
    "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
    "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
    "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
    "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
    "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
    "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
    "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
    "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
    "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
    "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
    "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
    "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
    "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
    "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
    "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
    "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
    "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
    "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
    "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
    "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
    "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
    "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
    "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
    "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
    "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
    "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
    "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
    "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
    "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
    "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
    "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
    "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
    "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
    "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
    "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
    "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
    "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
    "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
    "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
    "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
    "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
    "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
    "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
    "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
    "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
    "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
    "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
    "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
    "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
    "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
    "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
    "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
    "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
    "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
    "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
  ],
  "key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a",
  "time_saved_ns": 9358179354
}