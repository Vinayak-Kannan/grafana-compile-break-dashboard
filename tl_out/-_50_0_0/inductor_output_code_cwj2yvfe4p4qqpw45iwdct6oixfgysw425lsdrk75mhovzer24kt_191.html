<pre style="background-color:#ffffff;">
<span style="font-style:italic;color:#969896;"># AOT ID: [&#39;23_forward&#39;]
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">ctypes </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">c_void_p, c_long, c_int
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">torch
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">math
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">random
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">os
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">tempfile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">math </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">inf, nan
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.hooks </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">run_intermediate_hooks
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">maybe_profile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.memory_planning </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">_align </span><span style="font-weight:bold;color:#a71d5d;">as </span><span style="color:#323232;">align
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">device, empty_strided
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.async_compile </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">AsyncCompile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.select_algorithm </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">extern_kernels
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.multi_kernel </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">MultiKernelCall
</span><span style="color:#323232;">
</span><span style="color:#323232;">aten </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.aten
</span><span style="color:#323232;">inductor_ops </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor
</span><span style="color:#323232;">_quantized </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops._quantized
</span><span style="color:#323232;">assert_size_stride </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards.assert_size_stride
</span><span style="color:#323232;">empty_strided_cpu </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cpu
</span><span style="color:#323232;">empty_strided_cuda </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cuda
</span><span style="color:#323232;">empty_strided_xpu </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_xpu
</span><span style="color:#323232;">reinterpret_tensor </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._reinterpret_tensor
</span><span style="color:#323232;">alloc_from_pool </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor._alloc_from_pool
</span><span style="color:#323232;">async_compile </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">AsyncCompile()
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const int64_t* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const int64_t* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       const int64_t* in_ptr4,
</span><span style="color:#183691;">                       const float* in_ptr5,
</span><span style="color:#183691;">                       const float* in_ptr6,
</span><span style="color:#183691;">                       const float* in_ptr7,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4,
</span><span style="color:#183691;">                       float* out_ptr5,
</span><span style="color:#183691;">                       float* out_ptr6)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                Welford&lt;float&gt; tmp_acc0 = Welford&lt;float&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; masked_tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                static WeightRecp&lt;at::vec::Vectorized&lt;float&gt;&gt; wrecps0(static_cast&lt;int64_t&gt;(16L));
</span><span style="color:#183691;">                for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp10 = in_ptr2[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp21 = in_ptr4[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp1 = 30522L;
</span><span style="color:#183691;">                    auto tmp2 = c10::convert&lt;int64_t&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
</span><span style="color:#183691;">                    auto tmp4 = tmp0 &lt; 0;
</span><span style="color:#183691;">                    auto tmp5 = tmp4 ? tmp3 : tmp0;
</span><span style="color:#183691;">                    auto tmp6 = tmp5;
</span><span style="color:#183691;">                    auto tmp7 = c10::convert&lt;int64_t&gt;(tmp6);
</span><span style="color:#183691;">                    TORCH_CHECK((0 &lt;= tmp7) &amp; (tmp7 &lt; 30522L), &quot;index out of bounds: 0 &lt;= tmp7 &lt; 30522L&quot;);
</span><span style="color:#183691;">                    auto tmp9 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*tmp5)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp11 = 2L;
</span><span style="color:#183691;">                    auto tmp12 = c10::convert&lt;int64_t&gt;(tmp11);
</span><span style="color:#183691;">                    auto tmp13 = decltype(tmp10)(tmp10 + tmp12);
</span><span style="color:#183691;">                    auto tmp14 = tmp10 &lt; 0;
</span><span style="color:#183691;">                    auto tmp15 = tmp14 ? tmp13 : tmp10;
</span><span style="color:#183691;">                    auto tmp16 = tmp15;
</span><span style="color:#183691;">                    auto tmp17 = c10::convert&lt;int64_t&gt;(tmp16);
</span><span style="color:#183691;">                    TORCH_CHECK((0 &lt;= tmp17) &amp; (tmp17 &lt; 2L), &quot;index out of bounds: 0 &lt;= tmp17 &lt; 2L&quot;);
</span><span style="color:#183691;">                    auto tmp19 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;int64_t&gt;(x1 + (128L*tmp15)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp20 = tmp9 + tmp19;
</span><span style="color:#183691;">                    auto tmp22 = 512L;
</span><span style="color:#183691;">                    auto tmp23 = c10::convert&lt;int64_t&gt;(tmp22);
</span><span style="color:#183691;">                    auto tmp24 = decltype(tmp21)(tmp21 + tmp23);
</span><span style="color:#183691;">                    auto tmp25 = tmp21 &lt; 0;
</span><span style="color:#183691;">                    auto tmp26 = tmp25 ? tmp24 : tmp21;
</span><span style="color:#183691;">                    auto tmp27 = tmp26;
</span><span style="color:#183691;">                    auto tmp28 = c10::convert&lt;int64_t&gt;(tmp27);
</span><span style="color:#183691;">                    TORCH_CHECK((0 &lt;= tmp28) &amp; (tmp28 &lt; 512L), &quot;index out of bounds: 0 &lt;= tmp28 &lt; 512L&quot;);
</span><span style="color:#183691;">                    auto tmp30 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr5 + static_cast&lt;int64_t&gt;(x1 + (128L*tmp26)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp31 = tmp20 + tmp30;
</span><span style="color:#183691;">                    tmp31.store(out_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp31, &amp;wrecps0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
</span><span style="color:#183691;">                out_ptr1[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.mean);
</span><span style="color:#183691;">                out_ptr2[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.m2);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp1 = out_ptr1[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp4 = out_ptr2[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp12 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr6 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp14 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr7 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">                auto tmp3 = tmp0 - tmp2;
</span><span style="color:#183691;">                auto tmp5 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">                auto tmp6 = tmp4 / tmp5;
</span><span style="color:#183691;">                auto tmp7 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">                auto tmp8 = decltype(tmp6)(tmp6 + tmp7);
</span><span style="color:#183691;">                auto tmp9 = 1 / std::sqrt(tmp8);
</span><span style="color:#183691;">                auto tmp10 = at::vec::Vectorized&lt;float&gt;(tmp9);
</span><span style="color:#183691;">                auto tmp11 = tmp3 * tmp10;
</span><span style="color:#183691;">                auto tmp13 = tmp11 * tmp12;
</span><span style="color:#183691;">                auto tmp15 = tmp13 + tmp14;
</span><span style="color:#183691;">                tmp11.store(out_ptr3 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">                tmp15.store(out_ptr4 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(8L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr2 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr5 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(8L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(2L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr2 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr5 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(96L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = static_cast&lt;float&gt;(0.0);
</span><span style="color:#183691;">            auto tmp1 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">            tmp1.store(out_ptr6 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(96L); x0&lt;static_cast&lt;int64_t&gt;(100L); x0+=static_cast&lt;int64_t&gt;(4L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = static_cast&lt;float&gt;(0.0);
</span><span style="color:#183691;">            auto tmp1 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">            tmp1.store(out_ptr6 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(4L));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_add_native_layer_norm_native_layer_norm_backward_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const float* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                Welford&lt;float&gt; tmp_acc0 = Welford&lt;float&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; masked_tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                static WeightRecp&lt;at::vec::Vectorized&lt;float&gt;&gt; wrecps0(static_cast&lt;int64_t&gt;(16L));
</span><span style="color:#183691;">                for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &amp;wrecps0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
</span><span style="color:#183691;">                out_ptr0[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.mean);
</span><span style="color:#183691;">                out_ptr1[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.m2);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp3 = out_ptr0[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp6 = out_ptr1[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp14 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr2 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp16 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                auto tmp4 = at::vec::Vectorized&lt;float&gt;(tmp3);
</span><span style="color:#183691;">                auto tmp5 = tmp2 - tmp4;
</span><span style="color:#183691;">                auto tmp7 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">                auto tmp8 = tmp6 / tmp7;
</span><span style="color:#183691;">                auto tmp9 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
</span><span style="color:#183691;">                auto tmp11 = 1 / std::sqrt(tmp10);
</span><span style="color:#183691;">                auto tmp12 = at::vec::Vectorized&lt;float&gt;(tmp11);
</span><span style="color:#183691;">                auto tmp13 = tmp5 * tmp12;
</span><span style="color:#183691;">                auto tmp15 = tmp13 * tmp14;
</span><span style="color:#183691;">                auto tmp17 = tmp15 + tmp16;
</span><span style="color:#183691;">                tmp13.store(out_ptr2 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">                tmp17.store(out_ptr3 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(8L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(8L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(2L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_gelu_2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       float* out_ptr0)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(5120L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(0.5);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 * tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(0.7071067811865476);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp0 * tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.erf();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 + tmp9;
</span><span style="color:#183691;">            auto tmp11 = tmp3 * tmp10;
</span><span style="color:#183691;">            tmp11.store(out_ptr0 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_add_native_layer_norm_native_layer_norm_backward_3 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const float* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                Welford&lt;float&gt; tmp_acc0 = Welford&lt;float&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; masked_tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                static WeightRecp&lt;at::vec::Vectorized&lt;float&gt;&gt; wrecps0(static_cast&lt;int64_t&gt;(16L));
</span><span style="color:#183691;">                for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &amp;wrecps0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
</span><span style="color:#183691;">                out_ptr0[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.mean);
</span><span style="color:#183691;">                out_ptr1[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.m2);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp3 = out_ptr0[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp6 = out_ptr1[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp14 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr2 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp16 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                auto tmp4 = at::vec::Vectorized&lt;float&gt;(tmp3);
</span><span style="color:#183691;">                auto tmp5 = tmp2 - tmp4;
</span><span style="color:#183691;">                auto tmp7 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">                auto tmp8 = tmp6 / tmp7;
</span><span style="color:#183691;">                auto tmp9 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
</span><span style="color:#183691;">                auto tmp11 = 1 / std::sqrt(tmp10);
</span><span style="color:#183691;">                auto tmp12 = at::vec::Vectorized&lt;float&gt;(tmp11);
</span><span style="color:#183691;">                auto tmp13 = tmp5 * tmp12;
</span><span style="color:#183691;">                auto tmp15 = tmp13 * tmp14;
</span><span style="color:#183691;">                auto tmp17 = tmp15 + tmp16;
</span><span style="color:#183691;">                tmp13.store(out_ptr2 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">                tmp17.store(out_ptr3 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(8L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(8L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(2L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_add_native_layer_norm_native_layer_norm_backward_4 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const float* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                Welford&lt;float&gt; tmp_acc0 = Welford&lt;float&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; masked_tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                static WeightRecp&lt;at::vec::Vectorized&lt;float&gt;&gt; wrecps0(static_cast&lt;int64_t&gt;(16L));
</span><span style="color:#183691;">                for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &amp;wrecps0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
</span><span style="color:#183691;">                out_ptr0[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.mean);
</span><span style="color:#183691;">                out_ptr1[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.m2);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp3 = out_ptr0[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp6 = out_ptr1[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp14 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr2 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp16 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                auto tmp4 = at::vec::Vectorized&lt;float&gt;(tmp3);
</span><span style="color:#183691;">                auto tmp5 = tmp2 - tmp4;
</span><span style="color:#183691;">                auto tmp7 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">                auto tmp8 = tmp6 / tmp7;
</span><span style="color:#183691;">                auto tmp9 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
</span><span style="color:#183691;">                auto tmp11 = 1 / std::sqrt(tmp10);
</span><span style="color:#183691;">                auto tmp12 = at::vec::Vectorized&lt;float&gt;(tmp11);
</span><span style="color:#183691;">                auto tmp13 = tmp5 * tmp12;
</span><span style="color:#183691;">                auto tmp15 = tmp13 * tmp14;
</span><span style="color:#183691;">                auto tmp17 = tmp15 + tmp16;
</span><span style="color:#183691;">                tmp13.store(out_ptr2 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">                tmp17.store(out_ptr3 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(8L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(8L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(2L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_gelu_5 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       float* out_ptr0)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(5120L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(0.5);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 * tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(0.7071067811865476);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp0 * tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.erf();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 + tmp9;
</span><span style="color:#183691;">            auto tmp11 = tmp3 * tmp10;
</span><span style="color:#183691;">            tmp11.store(out_ptr0 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_add_native_layer_norm_native_layer_norm_backward_6 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const float* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                Welford&lt;float&gt; tmp_acc0 = Welford&lt;float&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                Welford&lt;at::vec::Vectorized&lt;float&gt;&gt; masked_tmp_acc0_vec = Welford&lt;at::vec::Vectorized&lt;float&gt;&gt;();
</span><span style="color:#183691;">                static WeightRecp&lt;at::vec::Vectorized&lt;float&gt;&gt; wrecps0(static_cast&lt;int64_t&gt;(16L));
</span><span style="color:#183691;">                for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                    auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &amp;wrecps0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
</span><span style="color:#183691;">                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
</span><span style="color:#183691;">                out_ptr0[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.mean);
</span><span style="color:#183691;">                out_ptr1[static_cast&lt;int64_t&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0.m2);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(int64_t x1=static_cast&lt;int64_t&gt;(0L); x1&lt;static_cast&lt;int64_t&gt;(128L); x1+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp1 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp3 = out_ptr0[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp6 = out_ptr1[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">                auto tmp14 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr2 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp16 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;int64_t&gt;(x1), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">                auto tmp2 = tmp0 + tmp1;
</span><span style="color:#183691;">                auto tmp4 = at::vec::Vectorized&lt;float&gt;(tmp3);
</span><span style="color:#183691;">                auto tmp5 = tmp2 - tmp4;
</span><span style="color:#183691;">                auto tmp7 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">                auto tmp8 = tmp6 / tmp7;
</span><span style="color:#183691;">                auto tmp9 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
</span><span style="color:#183691;">                auto tmp11 = 1 / std::sqrt(tmp10);
</span><span style="color:#183691;">                auto tmp12 = at::vec::Vectorized&lt;float&gt;(tmp11);
</span><span style="color:#183691;">                auto tmp13 = tmp5 * tmp12;
</span><span style="color:#183691;">                auto tmp15 = tmp13 * tmp14;
</span><span style="color:#183691;">                auto tmp17 = tmp15 + tmp16;
</span><span style="color:#183691;">                tmp13.store(out_ptr2 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">                tmp17.store(out_ptr3 + static_cast&lt;int64_t&gt;(x1 + (128L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(8L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(8L); x0&lt;static_cast&lt;int64_t&gt;(10L); x0+=static_cast&lt;int64_t&gt;(2L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">            auto tmp1 = static_cast&lt;float&gt;(128.0);
</span><span style="color:#183691;">            auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">            auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">            auto tmp4 = static_cast&lt;float&gt;(1e-12);
</span><span style="color:#183691;">            auto tmp5 = at::vec::Vectorized&lt;float&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp3 + tmp5;
</span><span style="color:#183691;">            auto tmp7 = tmp6.rsqrt();
</span><span style="color:#183691;">            auto tmp8 = static_cast&lt;float&gt;(0.0078125);
</span><span style="color:#183691;">            auto tmp9 = at::vec::Vectorized&lt;float&gt;(tmp8);
</span><span style="color:#183691;">            auto tmp10 = tmp7 * tmp9;
</span><span style="color:#183691;">            tmp10.store(out_ptr4 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(2L));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_tanh_7 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(float* in_out_ptr0)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(128L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_out_ptr0 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp1 = decltype(tmp0)(2) / (decltype(tmp0)(1) + (decltype(tmp0)(-2) * tmp0).exp()) - decltype(tmp0)(1);
</span><span style="color:#183691;">            tmp1.store(in_out_ptr0 + static_cast&lt;int64_t&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">async_compile.wait(</span><span style="color:#62a35c;">globals</span><span style="color:#323232;">())
</span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">async_compile
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">call</span><span style="color:#323232;">(args):
</span><span style="color:#323232;">    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">args
</span><span style="color:#323232;">    args.clear()
</span><span style="color:#323232;">    assert_size_stride(primals_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_2, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_3, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_4, (</span><span style="color:#0086b3;">30522</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_5, (</span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_6, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_7, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_8, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_9, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_10, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_11, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_12, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_13, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_14, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_15, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_16, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_17, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_18, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_19, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_20, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_21, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_22, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_23, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_24, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_25, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_26, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_27, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_28, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_29, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_30, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_31, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_32, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_33, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_34, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_35, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_36, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_37, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_38, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_39, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_40, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(primals_41, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(primals_42, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    buf0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf4 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf6 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf53 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf5 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">100</span><span style="color:#323232;">, </span><span style="color:#0086b3;">100</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0(primals_1, primals_4, primals_2, primals_5, primals_3, primals_6, primals_7, primals_8, buf0, buf1, buf2, buf4, buf6, buf53, buf5)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_4
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_5
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_6
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_8
</span><span style="color:#323232;">    buf7 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf0, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf0  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_10, reinterpret_tensor(buf6, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_9, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf7)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_10
</span><span style="color:#323232;">    buf8 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [linear_1], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_12, reinterpret_tensor(buf6, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_11, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf8)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_12
</span><span style="color:#323232;">    buf9 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_14, reinterpret_tensor(buf6, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_13, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf9)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_14
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [attn_output], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
</span><span style="color:#323232;">    buf10 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf7, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf8, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf9, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), attn_mask</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf5)
</span><span style="color:#323232;">    buf11 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf10[</span><span style="color:#0086b3;">0</span><span style="color:#323232;">]
</span><span style="color:#323232;">    buf12 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf10[</span><span style="color:#0086b3;">1</span><span style="color:#323232;">]
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf10
</span><span style="color:#323232;">    buf13 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [hidden_states], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_16, reinterpret_tensor(buf11, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_15, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf13)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_16
</span><span style="color:#323232;">    buf14 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf2; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf2  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf15 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf1; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf1  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf17 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf18 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf52 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_add_native_layer_norm_native_layer_norm_backward_1(buf13, buf6, primals_17, primals_18, buf14, buf15, buf17, buf18, buf52)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_18
</span><span style="color:#323232;">    buf19 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [hidden_states_3], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_20, reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_19, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf19)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_20
</span><span style="color:#323232;">    buf20 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">5120</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_gelu_2(buf19, buf20)
</span><span style="color:#323232;">    buf21 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf13; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf13  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [hidden_states_5], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_22, reinterpret_tensor(buf20, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_21, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf21)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_22
</span><span style="color:#323232;">    buf22 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf15; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf15  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf23 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf14; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf14  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf25 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf26 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf51 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_add_native_layer_norm_native_layer_norm_backward_3(buf21, buf18, primals_23, primals_24, buf22, buf23, buf25, buf26, buf51)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_24
</span><span style="color:#323232;">    buf27 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf21; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf21  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_26, reinterpret_tensor(buf26, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_25, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf27)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_26
</span><span style="color:#323232;">    buf28 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [linear_7], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_28, reinterpret_tensor(buf26, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_27, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf28)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_28
</span><span style="color:#323232;">    buf29 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_30, reinterpret_tensor(buf26, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_29, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf29)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_30
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [attn_output_3], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
</span><span style="color:#323232;">    buf30 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf27, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf28, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf29, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), attn_mask</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf5)
</span><span style="color:#323232;">    buf31 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf30[</span><span style="color:#0086b3;">0</span><span style="color:#323232;">]
</span><span style="color:#323232;">    buf32 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf30[</span><span style="color:#0086b3;">1</span><span style="color:#323232;">]
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf30
</span><span style="color:#323232;">    buf33 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [hidden_states_8], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_32, reinterpret_tensor(buf31, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_31, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf33)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_32
</span><span style="color:#323232;">    buf34 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf23; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf23  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf35 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf22; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf22  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf37 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf38 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf50 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_add_native_layer_norm_native_layer_norm_backward_4(buf33, buf26, primals_33, primals_34, buf34, buf35, buf37, buf38, buf50)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_34
</span><span style="color:#323232;">    buf39 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [hidden_states_11], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_36, reinterpret_tensor(buf38, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_35, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf39)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_36
</span><span style="color:#323232;">    buf40 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">5120</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_gelu_5(buf39, buf40)
</span><span style="color:#323232;">    buf41 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf33; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf33  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [hidden_states_13], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_38, reinterpret_tensor(buf40, (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_37, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf41)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_38
</span><span style="color:#323232;">    buf42 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf35; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf35  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf43 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf34; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf34  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf45 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf46 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf49 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    cpp_fused_add_native_layer_norm_native_layer_norm_backward_6(buf41, buf38, primals_39, primals_40, buf42, buf43, buf45, buf46, buf49)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf41
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf42
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf43
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_40
</span><span style="color:#323232;">    buf47 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Topologically Sorted Source Nodes: [pooled_output], Original ATen: [aten.addmm]
</span><span style="color:#323232;">    extern_kernels.addmm(primals_42, reinterpret_tensor(buf46, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_41, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), alpha</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, beta</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf47)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">primals_42
</span><span style="color:#323232;">    buf48 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf47; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf47  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    cpp_fused_tanh_7(buf48)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">(buf46, buf48, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, reinterpret_tensor(primals_2, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(primals_3, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), buf4, buf5, reinterpret_tensor(buf7, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf8, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf9, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), buf11, buf12, buf17, buf19, buf25, reinterpret_tensor(buf27, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf28, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf29, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1280</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), buf31, buf32, buf37, buf39, buf45, buf48, primals_41, reinterpret_tensor(buf46, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1280</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), buf49, primals_37, reinterpret_tensor(buf40, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), primals_35, reinterpret_tensor(buf38, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), buf50, primals_31, primals_29, reinterpret_tensor(buf26, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), primals_27, primals_25, buf51, primals_21, reinterpret_tensor(buf20, (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), primals_19, reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), buf52, primals_15, primals_13, reinterpret_tensor(buf6, (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), primals_11, primals_9, buf53, )
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">benchmark_compiled_module</span><span style="color:#323232;">(times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">):
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._dynamo.testing </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">rand_strided
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">print_performance
</span><span style="color:#323232;">    primals_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">10</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int64)
</span><span style="color:#323232;">    primals_2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int64)
</span><span style="color:#323232;">    primals_3 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int64)
</span><span style="color:#323232;">    primals_4 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">30522</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_5 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">2</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_6 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_7 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_8 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_9 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_10 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_11 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_12 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_13 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_14 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_15 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_16 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_17 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_18 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_19 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_20 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_21 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_22 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_23 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_24 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_25 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_26 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_27 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_28 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_29 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_30 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_31 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_32 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_33 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_34 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_35 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_36 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">512</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_37 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_38 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_39 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_40 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_41 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">128</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    primals_42 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">128</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    fn </span><span style="font-weight:bold;color:#a71d5d;">= lambda</span><span style="color:#323232;">: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42])
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">print_performance(fn, times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">times, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">repeat)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">if </span><span style="color:#323232;">__name__ </span><span style="font-weight:bold;color:#a71d5d;">== </span><span style="color:#183691;">&quot;__main__&quot;</span><span style="color:#323232;">:
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.wrapper_benchmark </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">compiled_module_main
</span><span style="color:#323232;">    compiled_module_main(</span><span style="color:#183691;">&#39;None&#39;</span><span style="color:#323232;">, benchmark_compiled_module)
</span></pre>
