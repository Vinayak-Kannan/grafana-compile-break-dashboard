class <lambda>(torch.nn.Module):
    def forward(self, arg0_1: "f64[2][1]cpu"):
         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
        full: "b8[2][1]cpu" = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
        logical_not: "b8[2][1]cpu" = torch.ops.aten.logical_not.default(full);  full = None
        any_1: "b8[][]cpu" = torch.ops.aten.any.dims(logical_not);  logical_not = None
        logical_not_1: "b8[][]cpu" = torch.ops.aten.logical_not.default(any_1);  any_1 = None
        return (logical_not_1,)
        