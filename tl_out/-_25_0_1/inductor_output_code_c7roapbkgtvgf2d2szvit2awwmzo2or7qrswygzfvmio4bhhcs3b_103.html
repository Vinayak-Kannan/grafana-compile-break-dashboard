<pre style="background-color:#ffffff;">
<span style="font-style:italic;color:#969896;"># AOT ID: [&#39;14_inference&#39;]
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">ctypes </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">c_void_p, c_long, c_int
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">torch
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">math
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">random
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">os
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">tempfile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">math </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">inf, nan
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.hooks </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">run_intermediate_hooks
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">maybe_profile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.memory_planning </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">_align </span><span style="font-weight:bold;color:#a71d5d;">as </span><span style="color:#323232;">align
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">device, empty_strided
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.async_compile </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">AsyncCompile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.select_algorithm </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">extern_kernels
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.multi_kernel </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">MultiKernelCall
</span><span style="color:#323232;">
</span><span style="color:#323232;">aten </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.aten
</span><span style="color:#323232;">inductor_ops </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor
</span><span style="color:#323232;">_quantized </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops._quantized
</span><span style="color:#323232;">assert_size_stride </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards.assert_size_stride
</span><span style="color:#323232;">empty_strided_cpu </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cpu
</span><span style="color:#323232;">empty_strided_cuda </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cuda
</span><span style="color:#323232;">empty_strided_xpu </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_xpu
</span><span style="color:#323232;">reinterpret_tensor </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._reinterpret_tensor
</span><span style="color:#323232;">alloc_from_pool </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor._alloc_from_pool
</span><span style="color:#323232;">async_compile </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">AsyncCompile()
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_add_clone_div_lift_fresh_mul_pow_sub_0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const double*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const double*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const double*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;double*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;double*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot;  void kernel(const double* in_ptr0,
</span><span style="color:#183691;">                       const double* in_ptr1,
</span><span style="color:#183691;">                       const double* in_ptr2,
</span><span style="color:#183691;">                       double* out_ptr0,
</span><span style="color:#183691;">                       double* out_ptr1)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(2L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">            out_ptr0[static_cast&lt;int64_t&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(0L); x0&lt;static_cast&lt;int64_t&gt;(296L); x0+=static_cast&lt;int64_t&gt;(8L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
</span><span style="color:#183691;">            auto tmp1 = at::vec::VectorizedN&lt;double,2&gt;::loadu(in_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp2 = in_ptr0[static_cast&lt;int64_t&gt;(1L)];
</span><span style="color:#183691;">            auto tmp13 = at::vec::VectorizedN&lt;double,2&gt;::loadu(in_ptr2 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">            auto tmp3 = static_cast&lt;double&gt;(2.0);
</span><span style="color:#183691;">            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
</span><span style="color:#183691;">            auto tmp5 = at::vec::VectorizedN&lt;double,2&gt;(tmp4);
</span><span style="color:#183691;">            auto tmp6 = tmp1.pow(tmp5);
</span><span style="color:#183691;">            auto tmp7 = at::vec::VectorizedN&lt;double,2&gt;(tmp0);
</span><span style="color:#183691;">            auto tmp8 = tmp7 * tmp6;
</span><span style="color:#183691;">            auto tmp9 = static_cast&lt;double&gt;(1.0);
</span><span style="color:#183691;">            auto tmp10 = at::vec::VectorizedN&lt;double,2&gt;(tmp9);
</span><span style="color:#183691;">            auto tmp11 = tmp10 + tmp8;
</span><span style="color:#183691;">            auto tmp12 = tmp10 / tmp11;
</span><span style="color:#183691;">            auto tmp14 = tmp12 - tmp13;
</span><span style="color:#183691;">            tmp14.store(out_ptr1 + static_cast&lt;int64_t&gt;(x0), static_cast&lt;int64_t&gt;(8));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(4) 
</span><span style="color:#183691;">        for(int64_t x0=static_cast&lt;int64_t&gt;(296L); x0&lt;static_cast&lt;int64_t&gt;(300L); x0+=static_cast&lt;int64_t&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
</span><span style="color:#183691;">            auto tmp1 = in_ptr1[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">            auto tmp2 = in_ptr0[static_cast&lt;int64_t&gt;(1L)];
</span><span style="color:#183691;">            auto tmp10 = in_ptr2[static_cast&lt;int64_t&gt;(x0)];
</span><span style="color:#183691;">            auto tmp3 = static_cast&lt;double&gt;(2.0);
</span><span style="color:#183691;">            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
</span><span style="color:#183691;">            auto tmp5 = std::pow(tmp1, tmp4);
</span><span style="color:#183691;">            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
</span><span style="color:#183691;">            auto tmp7 = static_cast&lt;double&gt;(1.0);
</span><span style="color:#183691;">            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
</span><span style="color:#183691;">            auto tmp9 = tmp7 / tmp8;
</span><span style="color:#183691;">            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
</span><span style="color:#183691;">            out_ptr1[static_cast&lt;int64_t&gt;(x0)] = tmp11;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">async_compile.wait(</span><span style="color:#62a35c;">globals</span><span style="color:#323232;">())
</span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">async_compile
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">call</span><span style="color:#323232;">(args):
</span><span style="color:#323232;">    arg0_1, arg1_1, arg2_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">args
</span><span style="color:#323232;">    args.clear()
</span><span style="color:#323232;">    assert_size_stride(arg0_1, (</span><span style="color:#0086b3;">300</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(arg1_1, (</span><span style="color:#0086b3;">300</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    assert_size_stride(arg2_1, (</span><span style="color:#0086b3;">2</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ))
</span><span style="color:#323232;">    buf0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">2</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), torch.float64)
</span><span style="color:#323232;">    buf1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">300</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), torch.float64)
</span><span style="color:#323232;">    cpp_fused_add_clone_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0, buf1)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg0_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg1_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg2_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">(buf0, buf1, )
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">benchmark_compiled_module</span><span style="color:#323232;">(times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">):
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._dynamo.testing </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">rand_strided
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">print_performance
</span><span style="color:#323232;">    arg0_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">300</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float64)
</span><span style="color:#323232;">    arg1_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">300</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float64)
</span><span style="color:#323232;">    arg2_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">2</span><span style="color:#323232;">, ), (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, ), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float64)
</span><span style="color:#323232;">    fn </span><span style="font-weight:bold;color:#a71d5d;">= lambda</span><span style="color:#323232;">: call([arg0_1, arg1_1, arg2_1])
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">print_performance(fn, times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">times, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">repeat)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">if </span><span style="color:#323232;">__name__ </span><span style="font-weight:bold;color:#a71d5d;">== </span><span style="color:#183691;">&quot;__main__&quot;</span><span style="color:#323232;">:
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.wrapper_benchmark </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">compiled_module_main
</span><span style="color:#323232;">    compiled_module_main(</span><span style="color:#183691;">&#39;None&#39;</span><span style="color:#323232;">, benchmark_compiled_module)
</span></pre>
