V0331 22:12:39.939000 6798 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", 0]}
V0331 22:12:39.940000 6798 torch/_logging/structured.py:22] {"str": ["/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", 1]}
V0331 22:12:39.940000 6798 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", 2]}
V0331 22:12:39.941000 6798 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", 3]}
V0331 22:12:39.941000 6798 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", 4]}
V0331 22:12:39.942000 6798 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 14, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1001, "name": "forward", "filename": 4}]}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:39.943000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "d670563da2032b9c1076a3c41dd00733"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743459159943101.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:39.944000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "eba9119ad67a983686b275c6fdc47759"}
	{
	"name": "entire_frame_compile",
	"ts": 1743459159943101.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:39.972000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 0, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:39.973000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7b8f81201ae0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:39.973000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 0, "source": "L['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.075000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 0, "size": 4096}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.076000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "stride": [512, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7b8f4f278aa0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.076000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 1, "source": "L['self']._modules['embeddings']._buffers['token_type_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.087000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 0, "size": 4096}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.088000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7b8f4f26acb0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.089000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "is_view": true, "stride": [512, 1], "storage": 2, "base": 6, "creation_meta": "CreationMeta.DEFAULT", "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7b8f4fa9e440>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.089000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 5, "source": "L['self']._modules['embeddings']._buffers['position_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.094000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 0, "size": 15627264}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.095000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [30522, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27ba20>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.096000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 8, "source": "L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.107000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 0, "size": 1024}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.108000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 9, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [2, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27b340>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.108000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 9, "source": "L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.117000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 0, "size": 262144}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.118000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 11, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27b930>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.118000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 11, "source": "L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.126000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.126000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 12, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27b890>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.127000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 12, "source": "L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.129000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 7, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.130000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 13, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 7, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f2682d0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.131000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 13, "source": "L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.192000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 8, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.193000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 25, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 8, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27ba70>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.194000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 25, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.196000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 9, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.196000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 26, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 9, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27bbb0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.197000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 26, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.216000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 10, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.217000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 36, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 10, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27b840>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.218000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 36, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.219000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 11, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.220000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 37, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 11, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278230>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.221000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 37, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.232000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 12, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.232000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 38, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 12, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278b40>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.233000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 38, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.235000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 13, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.236000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 39, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 13, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278b90>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.236000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 39, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.258000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 14, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.259000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 45, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 14, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278be0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.259000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 45, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.261000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 15, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.262000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 46, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 15, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278c30>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.263000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 46, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.274000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 16, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.274000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 47, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 16, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278cd0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.275000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 47, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.278000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 17, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.279000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 48, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 17, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278c80>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.279000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 48, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.295000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 18, "describer_id": 0, "size": 262144}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.296000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 52, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 18, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278dc0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.297000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 52, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.298000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 19, "describer_id": 0, "size": 2048}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.299000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 53, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 19, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27bde0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.300000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 53, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.315000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 20, "describer_id": 0, "size": 262144}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.316000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 61, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 20, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278d70>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.317000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 61, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.318000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 21, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.319000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 62, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 21, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278d20>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.319000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 62, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.328000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 22, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.329000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 66, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 22, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278eb0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.330000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 66, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.331000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 23, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.332000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 67, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 23, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278e60>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.332000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 67, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.348000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 24, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.349000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 71, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 24, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f27b980>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.350000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 71, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.352000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 25, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.352000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 72, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 25, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278e10>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.353000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 72, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.363000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 26, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.364000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 73, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 26, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278f50>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.365000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 73, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.366000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 27, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.367000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 74, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 27, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278ff0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.368000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 74, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.378000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 28, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.379000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 75, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 28, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279040>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.379000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 75, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.381000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 29, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.382000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 76, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 29, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279090>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.382000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 76, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.399000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 30, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.400000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 79, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 30, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f2790e0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.401000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 79, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.402000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 31, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.403000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 80, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 31, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279130>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.404000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 80, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.416000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 32, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.417000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 81, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 32, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f2791d0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.418000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 81, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.419000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 33, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.420000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 82, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 33, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279180>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.420000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 82, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.437000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 34, "describer_id": 0, "size": 262144}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.438000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 86, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 34, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f2792c0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.438000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 86, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.440000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 35, "describer_id": 0, "size": 2048}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.440000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 87, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 35, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f278f00>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.441000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 87, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.449000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 36, "describer_id": 0, "size": 262144}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.449000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 88, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 36, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279270>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.450000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 88, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.451000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 37, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.452000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 89, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 37, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279220>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.453000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 89, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.459000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 38, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.460000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 90, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 38, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f2793b0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.461000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 90, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.462000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 39, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.463000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 91, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 39, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f279360>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.463000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 91, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.485000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 40, "describer_id": 0, "size": 65536}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.485000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 97, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 40, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f268320>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.486000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 97, "source": "L['self']._modules['pooler']._modules['dense']._parameters['weight']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.488000 6798 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 41, "describer_id": 0, "size": 512}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.489000 6798 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 98, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 41, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7b8f4f268280>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.490000 6798 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 98, "source": "L['self']._modules['pooler']._modules['dense']._parameters['bias']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:12:40.530000 6798 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_input_ids_": [1, 10], "l_self_modules_embeddings_buffers_token_type_ids_": [1, 512], "l_self_modules_embeddings_buffers_position_ids_": [1, 512], "l_self_modules_embeddings_modules_word_embeddings_parameters_weight_": [30522, 128], "l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_": [2, 128], "l_self_modules_embeddings_modules_position_embeddings_parameters_weight_": [512, 128], "l_self_modules_embeddings_modules_layer_norm_parameters_weight_": [128], "l_self_modules_embeddings_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_": [512], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_": [128, 512], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_": [512], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_": [128, 512], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_pooler_modules_dense_parameters_weight_": [128, 128], "l_self_modules_pooler_modules_dense_parameters_bias_": [128], "buffered_token_type_ids": [1, 10], "buffered_token_type_ids_expanded": [1, 10], "position_ids": [1, 10], "inputs_embeds": [1, 10, 128], "token_type_embeddings": [1, 10, 128], "embeddings": [1, 10, 128], "position_embeddings": [1, 10, 128], "embeddings_1": [1, 10, 128], "embeddings_2": [1, 10, 128], "embeddings_3": [1, 10, 128], "attention_mask": [1, 10], "getitem_2": [1, 1, 1, 10], "expand_1": [1, 1, 10, 10], "expanded_mask": [1, 1, 10, 10], "inverted_mask": [1, 1, 10, 10], "to_1": [1, 1, 10, 10], "extended_attention_mask": [1, 1, 10, 10], "linear": [1, 10, 128], "x": [1, 10, 2, 64], "query_layer": [1, 2, 10, 64], "linear_1": [1, 10, 128], "x_1": [1, 10, 2, 64], "key_layer": [1, 2, 10, 64], "linear_2": [1, 10, 128], "x_2": [1, 10, 2, 64], "value_layer": [1, 2, 10, 64], "attn_output": [1, 2, 10, 64], "attn_output_1": [1, 10, 2, 64], "attn_output_2": [1, 10, 128], "hidden_states": [1, 10, 128], "hidden_states_1": [1, 10, 128], "add_1": [1, 10, 128], "hidden_states_2": [1, 10, 128], "hidden_states_3": [1, 10, 512], "hidden_states_4": [1, 10, 512], "hidden_states_5": [1, 10, 128], "hidden_states_6": [1, 10, 128], "add_2": [1, 10, 128], "hidden_states_7": [1, 10, 128], "linear_6": [1, 10, 128], "x_3": [1, 10, 2, 64], "query_layer_1": [1, 2, 10, 64], "linear_7": [1, 10, 128], "x_4": [1, 10, 2, 64], "key_layer_1": [1, 2, 10, 64], "linear_8": [1, 10, 128], "x_5": [1, 10, 2, 64], "value_layer_1": [1, 2, 10, 64], "attn_output_3": [1, 2, 10, 64], "attn_output_4": [1, 10, 2, 64], "attn_output_5": [1, 10, 128], "hidden_states_8": [1, 10, 128], "hidden_states_9": [1, 10, 128], "add_3": [1, 10, 128], "hidden_states_10": [1, 10, 128], "hidden_states_11": [1, 10, 512], "hidden_states_12": [1, 10, 512], "hidden_states_13": [1, 10, 128], "hidden_states_14": [1, 10, 128], "add_4": [1, 10, 128], "hidden_states_15": [1, 10, 128], "first_token_tensor": [1, 128], "pooled_output": [1, 128], "pooled_output_1": [1, 128]}}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "ab467e954c31af9f03b0e717a844571c"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_input_ids_: "i64[1, 10][10, 1]cpu", L_self_modules_embeddings_buffers_token_type_ids_: "i64[1, 512][512, 1]cpu", L_self_modules_embeddings_buffers_position_ids_: "i64[1, 512][512, 1]cpu", L_self_modules_embeddings_modules_word_embeddings_parameters_weight_: "f32[30522, 128][128, 1]cpu", L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_: "f32[2, 128][128, 1]cpu", L_self_modules_embeddings_modules_position_embeddings_parameters_weight_: "f32[512, 128][128, 1]cpu", L_self_modules_embeddings_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_embeddings_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_pooler_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_pooler_modules_dense_parameters_bias_: "f32[128][1]cpu"):
	        l_input_ids_ = L_input_ids_
	        l_self_modules_embeddings_buffers_token_type_ids_ = L_self_modules_embeddings_buffers_token_type_ids_
	        l_self_modules_embeddings_buffers_position_ids_ = L_self_modules_embeddings_buffers_position_ids_
	        l_self_modules_embeddings_modules_word_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_word_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_position_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_position_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_layer_norm_parameters_weight_ = L_self_modules_embeddings_modules_LayerNorm_parameters_weight_
	        l_self_modules_embeddings_modules_layer_norm_parameters_bias_ = L_self_modules_embeddings_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_pooler_modules_dense_parameters_weight_ = L_self_modules_pooler_modules_dense_parameters_weight_
	        l_self_modules_pooler_modules_dense_parameters_bias_ = L_self_modules_pooler_modules_dense_parameters_bias_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        buffered_token_type_ids: "i64[1, 10][512, 1]cpu" = l_self_modules_embeddings_buffers_token_type_ids_[(slice(None, None, None), slice(None, 10, None))];  l_self_modules_embeddings_buffers_token_type_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        buffered_token_type_ids_expanded: "i64[1, 10][512, 1]cpu" = buffered_token_type_ids.expand(1, 10);  buffered_token_type_ids = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        position_ids: "i64[1, 10][512, 1]cpu" = l_self_modules_embeddings_buffers_position_ids_[(slice(None, None, None), slice(0, 10, None))];  l_self_modules_embeddings_buffers_position_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        inputs_embeds: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(l_input_ids_, l_self_modules_embeddings_modules_word_embeddings_parameters_weight_, 0, None, 2.0, False, False);  l_input_ids_ = l_self_modules_embeddings_modules_word_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        token_type_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(buffered_token_type_ids_expanded, l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_, None, None, 2.0, False, False);  buffered_token_type_ids_expanded = l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = inputs_embeds + token_type_embeddings;  inputs_embeds = token_type_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        position_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(position_ids, l_self_modules_embeddings_modules_position_embeddings_parameters_weight_, None, None, 2.0, False, False);  position_ids = l_self_modules_embeddings_modules_position_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        embeddings += position_embeddings;  embeddings_1: "f32[1, 10, 128][1280, 128, 1]cpu" = embeddings;  embeddings = position_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        embeddings_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(embeddings_1, (128,), l_self_modules_embeddings_modules_layer_norm_parameters_weight_, l_self_modules_embeddings_modules_layer_norm_parameters_bias_, 1e-12);  embeddings_1 = l_self_modules_embeddings_modules_layer_norm_parameters_weight_ = l_self_modules_embeddings_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        embeddings_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(embeddings_2, 0.1, False, False);  embeddings_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        attention_mask: "f32[1, 10][10, 1]cpu" = torch.ones((1, 10), device = device(type='cpu'))
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        getitem_2: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = attention_mask[(slice(None, None, None), None, None, slice(None, None, None))];  attention_mask = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = getitem_2.expand(1, 1, 10, 10);  getitem_2 = None
	        expanded_mask: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = expand_1.to(torch.float32);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        inverted_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = 1.0 - expanded_mask;  expanded_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        to_1: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.to(torch.bool)
	        extended_attention_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.masked_fill(to_1, -3.4028234663852886e+38);  inverted_mask = to_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear.view((1, 10, 2, 64));  linear = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x.permute(0, 2, 1, 3);  x = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_1.view((1, 10, 2, 64));  linear_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_1.permute(0, 2, 1, 3);  x_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_2.view((1, 10, 2, 64));  linear_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_2.permute(0, 2, 1, 3);  x_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer, key_layer, value_layer, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer = key_layer = value_layer = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output.transpose(1, 2);  attn_output = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_2: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_1.reshape(1, 10, 128);  attn_output_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_2, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_2 = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states, 0.1, False, False);  hidden_states = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_1 + embeddings_3;  hidden_states_1 = embeddings_3 = None
	        hidden_states_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_1, (128,), l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_1 = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_2, l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_3);  hidden_states_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_4, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_);  hidden_states_4 = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_5, 0.1, False, False);  hidden_states_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_2: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_6 + hidden_states_2;  hidden_states_6 = hidden_states_2 = None
	        hidden_states_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_2, (128,), l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_2 = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_3: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_6.view((1, 10, 2, 64));  linear_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_3.permute(0, 2, 1, 3);  x_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_7.view((1, 10, 2, 64));  linear_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_4.permute(0, 2, 1, 3);  x_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_8.view((1, 10, 2, 64));  linear_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_5.permute(0, 2, 1, 3);  x_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer_1, key_layer_1, value_layer_1, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer_1 = key_layer_1 = value_layer_1 = extended_attention_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output_3.transpose(1, 2);  attn_output_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_5: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_4.reshape(1, 10, 128);  attn_output_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_5, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_5 = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_8, 0.1, False, False);  hidden_states_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_9 + hidden_states_7;  hidden_states_9 = hidden_states_7 = None
	        hidden_states_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_3, (128,), l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_3 = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_10, l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_11);  hidden_states_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_12, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_);  hidden_states_12 = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_13, 0.1, False, False);  hidden_states_13 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_14 + hidden_states_10;  hidden_states_14 = hidden_states_10 = None
	        hidden_states_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_4, (128,), l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_4 = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        first_token_tensor: "f32[1, 128][1280, 1]cpu" = hidden_states_15[(slice(None, None, None), 0)]
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        pooled_output: "f32[1, 128][128, 1]cpu" = torch._C._nn.linear(first_token_tensor, l_self_modules_pooler_modules_dense_parameters_weight_, l_self_modules_pooler_modules_dense_parameters_bias_);  first_token_tensor = l_self_modules_pooler_modules_dense_parameters_weight_ = l_self_modules_pooler_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        pooled_output_1: "f32[1, 128][128, 1]cpu" = torch.tanh(pooled_output);  pooled_output = None
	        return (hidden_states_15, pooled_output_1)
	        
V0331 22:12:40.532000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "f33d79ac9eed7ad619ccb1a5ad4d74f9"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743459160532065.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:40.532000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "33063a50305c83ba557f639f293f0078"}
	{
	"name": "backend_compile",
	"ts": 1743459160532065.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:40.575000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "da10a55aa1ff96a9f4bd1bc12c28f7ca"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743459160575764.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:41.495000 6798 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:352] {"aot_joint_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcb09d2e1a88d319c9f911a929a3e77d"}
	class joint_helper(torch.nn.Module):
	    def forward(self, primals, tangents):
	        primals_1: "i64[1, 10][10, 1]cpu"; primals_2: "i64[1, 512][512, 1]cpu"; primals_3: "i64[1, 512][512, 1]cpu"; primals_4: "f32[30522, 128][128, 1]cpu"; primals_5: "f32[2, 128][128, 1]cpu"; primals_6: "f32[512, 128][128, 1]cpu"; primals_7: "f32[128][1]cpu"; primals_8: "f32[128][1]cpu"; primals_9: "f32[128, 128][1, 128]cpu"; primals_10: "f32[128][1]cpu"; primals_11: "f32[128, 128][1, 128]cpu"; primals_12: "f32[128][1]cpu"; primals_13: "f32[128, 128][1, 128]cpu"; primals_14: "f32[128][1]cpu"; primals_15: "f32[128, 128][1, 128]cpu"; primals_16: "f32[128][1]cpu"; primals_17: "f32[128][1]cpu"; primals_18: "f32[128][1]cpu"; primals_19: "f32[512, 128][1, 512]cpu"; primals_20: "f32[512][1]cpu"; primals_21: "f32[128, 512][1, 128]cpu"; primals_22: "f32[128][1]cpu"; primals_23: "f32[128][1]cpu"; primals_24: "f32[128][1]cpu"; primals_25: "f32[128, 128][1, 128]cpu"; primals_26: "f32[128][1]cpu"; primals_27: "f32[128, 128][1, 128]cpu"; primals_28: "f32[128][1]cpu"; primals_29: "f32[128, 128][1, 128]cpu"; primals_30: "f32[128][1]cpu"; primals_31: "f32[128, 128][1, 128]cpu"; primals_32: "f32[128][1]cpu"; primals_33: "f32[128][1]cpu"; primals_34: "f32[128][1]cpu"; primals_35: "f32[512, 128][1, 512]cpu"; primals_36: "f32[512][1]cpu"; primals_37: "f32[128, 512][1, 128]cpu"; primals_38: "f32[128][1]cpu"; primals_39: "f32[128][1]cpu"; primals_40: "f32[128][1]cpu"; primals_41: "f32[128, 128][1, 128]cpu"; primals_42: "f32[128][1]cpu"; tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu"; tangents_2: "f32[1, 128][128, 1]cpu"; 
	    
	        primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, tangents_1, tangents_2, = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_1: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 0, 0, 9223372036854775807);  primals_2 = None
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 10);  slice_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_3: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 0, 0, 9223372036854775807);  primals_3 = None
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_3, 1, 0, 10);  slice_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1)
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7);  mul = None
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        clone: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(add_3);  add_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        full: "f32[1, 10][10, 1]cpu" = torch.ops.aten.full.default([1, 10], 1, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        slice_5: "f32[1, 10][10, 1]cpu" = torch.ops.aten.slice.Tensor(full, 0, 0, 9223372036854775807);  full = None
	        unsqueeze: "f32[1, 1, 10][10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(slice_5, 1);  slice_5 = None
	        unsqueeze_1: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
	        slice_6: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.slice.Tensor(unsqueeze_1, 3, 0, 9223372036854775807);  unsqueeze_1 = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = torch.ops.aten.expand.default(slice_6, [1, 1, 10, 10]);  slice_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        sub_1: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.sub.Tensor(1.0, expand_1);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        convert_element_type: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.prims.convert_element_type.default(sub_1, torch.bool)
	        scalar_tensor: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(-3.4028234663852886e+38, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.where.self(convert_element_type, scalar_tensor, sub_1);  convert_element_type = scalar_tensor = sub_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view_3, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view_6, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = where)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        alias: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_2)
	        alias_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias);  alias = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3]);  getitem_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_11);  view_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_1, clone);  clone_1 = clone = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5)
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17);  mul_2 = None
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_15);  view_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_2, add_6);  clone_2 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7)
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23);  mul_7 = None
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_19: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_19, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_22, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = where)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        alias_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_8)
	        alias_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_2);  alias_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3]);  getitem_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_27);  view_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_3, add_10);  clone_3 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11)
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33);  mul_9 = None
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_31);  view_31 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_4, add_13);  clone_4 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13)
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39);  mul_14 = None
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        slice_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice.Tensor(add_17, 0, 0, 9223372036854775807)
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(slice_7, 1, 0);  slice_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        alias_4: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(tanh)
	        alias_5: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_4);  alias_4 = None
	        alias_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_5);  alias_5 = None
	        alias_7: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_6);  alias_6 = None
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(alias_7, alias_7);  alias_7 = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_1, mm, 1, 0);  full_1 = mm = None
	        full_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        slice_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice_scatter.default(full_2, select_scatter, 0, 0, 9223372036854775807);  full_2 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, slice_scatter);  tangents_1 = slice_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_7, rsqrt_4);  sub_7 = None
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_18);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_18, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_18);  mul_18 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_2: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_25);  mul_25 = None
	        add_19: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_2, 1);  erf_2 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_19, 0.5);  add_19 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_32: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_10, rsqrt_3);  sub_10 = None
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_32);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_32, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_32);  mul_32 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_3);  alias_3 = None
	        alias_9: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_8);  alias_8 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, alias_9, getitem_9, 0.0, False, attn_mask = where);  permute_33 = permute_11 = permute_13 = permute_15 = alias_9 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_22, [1, 0]);  view_22 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44);  permute_36 = None
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        permute_40: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_19, [1, 0]);  view_19 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_40, view_48);  permute_40 = None
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        permute_44: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_44, view_52);  permute_44 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_39: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_13, rsqrt_2);  sub_13 = None
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_39);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_39, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_39);  mul_39 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_46: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_46);  mul_46 = None
	        add_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_3, 1);  erf_3 = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_25, 0.5);  add_25 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_16: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_53: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_16, rsqrt_1);  sub_16 = None
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_53);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_53, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_53);  mul_53 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_10: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_1);  alias_1 = None
	        alias_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_10);  alias_10 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, alias_11, getitem_3, 0.0, False, attn_mask = where);  permute_55 = permute_1 = permute_3 = permute_5 = alias_11 = getitem_3 = where = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_6, [1, 0]);  view_6 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66);  permute_58 = None
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        permute_62: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_3, [1, 0]);  view_3 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_62, view_70);  permute_62 = None
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        permute_66: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_66, view_74);  permute_66 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        sub_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_19, rsqrt);  sub_19 = None
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul_60);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_60, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul_60);  mul_60 = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        scalar_tensor_1: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, scalar_tensor_1, mul_65);  unsqueeze_2 = scalar_tensor_1 = None
	        full_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_3, [slice_4], where_1, True);  full_3 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        scalar_tensor_2: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, scalar_tensor_2, mul_65);  unsqueeze_3 = scalar_tensor_2 = None
	        full_4: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_4, [expand], where_2, True);  full_4 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        scalar_tensor_3: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, scalar_tensor_3, mul_65);  unsqueeze_4 = scalar_tensor_3 = mul_65 = None
	        full_5: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_5, [primals_1], where_3, True);  full_5 = primals_1 = where_3 = None
	        return pytree.tree_unflatten([add_17, tanh, None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32], self._out_spec)
	        
V0331 22:12:42.229000 6798 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:545] {"aot_forward_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "79ae68c5ee14a8aca5626a97bbc2e0b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_2: "i64[1, 512][512, 1]cpu", primals_3: "i64[1, 512][512, 1]cpu", primals_4: "f32[30522, 128][128, 1]cpu", primals_5: "f32[2, 128][128, 1]cpu", primals_6: "f32[512, 128][128, 1]cpu", primals_7: "f32[128][1]cpu", primals_8: "f32[128][1]cpu", primals_9: "f32[128, 128][1, 128]cpu", primals_10: "f32[128][1]cpu", primals_11: "f32[128, 128][1, 128]cpu", primals_12: "f32[128][1]cpu", primals_13: "f32[128, 128][1, 128]cpu", primals_14: "f32[128][1]cpu", primals_15: "f32[128, 128][1, 128]cpu", primals_16: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_18: "f32[128][1]cpu", primals_19: "f32[512, 128][1, 512]cpu", primals_20: "f32[512][1]cpu", primals_21: "f32[128, 512][1, 128]cpu", primals_22: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_24: "f32[128][1]cpu", primals_25: "f32[128, 128][1, 128]cpu", primals_26: "f32[128][1]cpu", primals_27: "f32[128, 128][1, 128]cpu", primals_28: "f32[128][1]cpu", primals_29: "f32[128, 128][1, 128]cpu", primals_30: "f32[128][1]cpu", primals_31: "f32[128, 128][1, 128]cpu", primals_32: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_34: "f32[128][1]cpu", primals_35: "f32[512, 128][1, 512]cpu", primals_36: "f32[512][1]cpu", primals_37: "f32[128, 512][1, 128]cpu", primals_38: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", primals_40: "f32[128][1]cpu", primals_41: "f32[128, 128][1, 128]cpu", primals_42: "f32[128][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_3, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17)
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23)
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33)
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39)
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(add_17, 1, 0)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)
	        
V0331 22:12:42.239000 6798 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] {"aot_backward_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8ef2f550890c1bc6143556bd01aa3cc0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_7: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", expand: "i64[1, 10][512, 1]cpu", slice_4: "i64[1, 10][512, 1]cpu", mul: "f32[1, 10, 128][1280, 128, 1]cpu", full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu", permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_3: "f32[1, 2, 10][20, 1, 2]cpu", mul_2: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_4: "f32[10, 512][512, 1]cpu", mul_7: "f32[1, 10, 128][1280, 128, 1]cpu", permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_9: "f32[1, 2, 10][20, 1, 2]cpu", mul_9: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_10: "f32[10, 512][512, 1]cpu", mul_14: "f32[1, 10, 128][1280, 128, 1]cpu", tanh: "f32[1, 128][128, 1]cpu", permute_21: "f32[128, 128][1, 128]cpu", permute_22: "f32[128, 1][1, 1280]cpu", div: "f32[1, 10, 1][10, 1, 1]cpu", permute_24: "f32[128, 512][1, 128]cpu", permute_25: "f32[512, 10][1, 512]cpu", permute_27: "f32[512, 128][1, 512]cpu", permute_28: "f32[128, 10][1, 128]cpu", div_1: "f32[1, 10, 1][10, 1, 1]cpu", permute_30: "f32[128, 128][1, 128]cpu", permute_35: "f32[128, 128][1, 128]cpu", permute_36: "f32[128, 10][1, 128]cpu", permute_39: "f32[128, 128][1, 128]cpu", permute_43: "f32[128, 128][1, 128]cpu", div_2: "f32[1, 10, 1][10, 1, 1]cpu", permute_46: "f32[128, 512][1, 128]cpu", permute_47: "f32[512, 10][1, 512]cpu", permute_49: "f32[512, 128][1, 512]cpu", permute_50: "f32[128, 10][1, 128]cpu", div_3: "f32[1, 10, 1][10, 1, 1]cpu", permute_52: "f32[128, 128][1, 128]cpu", permute_57: "f32[128, 128][1, 128]cpu", permute_58: "f32[128, 10][1, 128]cpu", permute_61: "f32[128, 128][1, 128]cpu", permute_65: "f32[128, 128][1, 128]cpu", div_4: "f32[1, 10, 1][10, 1, 1]cpu", tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu", tangents_2: "f32[1, 128][128, 1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tanh, tanh);  tanh = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_default_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_default_1, mm, 1, 0);  full_default_1 = mm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, select_scatter);  tangents_1 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_14);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_14);  mul_14 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_14, 0.5);  add_14 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_9);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_9);  mul_9 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, getitem_8, getitem_9, 0.0, False, attn_mask = full_default);  permute_33 = permute_11 = permute_13 = permute_15 = getitem_8 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44)
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_48)
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_52);  permute_36 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_7);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_7);  mul_7 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_7, 0.5);  add_7 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_2);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_2);  mul_2 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, getitem_2, getitem_3, 0.0, False, attn_mask = full_default);  permute_55 = permute_1 = permute_3 = permute_5 = getitem_2 = getitem_3 = full_default = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66)
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_70)
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_74);  permute_58 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul);  mul = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        full_default_3: "f32[][]cpu" = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, full_default_3, mul_65);  unsqueeze_2 = None
	        full_default_4: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_4, [slice_4], where_1, True);  full_default_4 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, full_default_3, mul_65);  unsqueeze_3 = None
	        full_default_6: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_6, [expand], where_2, True);  full_default_6 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, full_default_3, mul_65);  unsqueeze_4 = full_default_3 = mul_65 = None
	        full_default_8: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_8, [primals_1], where_3, True);  full_default_8 = primals_1 = where_3 = None
	        return (None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32)
	        
V0331 22:12:42.241000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8d3500b62369283b9e526bbcd61ec57d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743459162240612.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:42.241000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "16962e36c86bd5c9fd24d93564f902aa"}
	{
	"name": "compile_fx_inner",
	"ts": 1743459162241836.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:42.242000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "301d5f335d5537de55f1bcf709a4ff1c"}
	{
	"name": "inductor_compile",
	"ts": 1743459162241836.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:42.982000 6798 torch/_inductor/compile_fx.py:742] {"artifact": {"name": "fx_graph_runnable", "encoding": "string"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "0c11fad184ab43943b3b5b2d5d5f1098"}
	
	import torch
	from torch import tensor, device
	import torch.fx as fx
	from torch._dynamo.testing import rand_strided
	from math import inf
	import torch._inductor.inductor_prims
	
	import torch._dynamo.config
	import torch._inductor.config
	import torch._functorch.config
	import torch.fx.experimental._config
	
	
	torch._functorch.config.unlift_effect_tokens = True
	
	
	
	isolate_fails_code_str = None
	
	
	
	# torch version: 2.5.1+cpu
	# torch cuda version: None
	# torch git version: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
	
	
	# torch.cuda.is_available()==False, no GPU info collected
	
	from torch.nn import *
	class Repro(torch.nn.Module):
	    def __init__(self) -> None:
	        super().__init__()
	
	    
	    
	    def forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):
	        slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None
	        expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None
	        embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem = var_mean[0]
	        getitem_1 = var_mean[1];  var_mean = None
	        add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)
	        add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        view = torch.ops.aten.view.default(add_3, [10, 128])
	        permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None
	        view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None
	        view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)
	        getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None
	        view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4 = var_mean_1[0]
	        getitem_5 = var_mean_1[1];  var_mean_1 = None
	        add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)
	        add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        view_12 = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])
	        mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None
	        erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6 = var_mean_2[0]
	        getitem_7 = var_mean_2[1];  var_mean_2 = None
	        add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)
	        add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        view_16 = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None
	        view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None
	        view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)
	        getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None
	        view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10 = var_mean_3[0]
	        getitem_11 = var_mean_3[1];  var_mean_3 = None
	        add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)
	        add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        view_28 = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])
	        mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None
	        erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12 = var_mean_4[0]
	        getitem_13 = var_mean_4[1];  var_mean_4 = None
	        add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)
	        add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        select = torch.ops.aten.select.int(add_17, 1, 0)
	        permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)
	        
	def load_args(reader):
	    buf0 = reader.storage(None, 80, dtype_hint=torch.int64)
	    reader.tensor(buf0, (1, 10), dtype=torch.int64, is_leaf=True)  # primals_1
	    buf1 = reader.storage(None, 4096, dtype_hint=torch.int64)
	    reader.tensor(buf1, (1, 512), dtype=torch.int64, is_leaf=True)  # primals_2
	    buf2 = reader.storage(None, 4096, dtype_hint=torch.int64)
	    reader.tensor(buf2, (1, 512), dtype=torch.int64, is_leaf=True)  # primals_3
	    buf3 = reader.storage(None, 15627264)
	    reader.tensor(buf3, (30522, 128), is_leaf=True)  # primals_4
	    buf4 = reader.storage(None, 1024)
	    reader.tensor(buf4, (2, 128), is_leaf=True)  # primals_5
	    buf5 = reader.storage(None, 262144)
	    reader.tensor(buf5, (512, 128), is_leaf=True)  # primals_6
	    buf6 = reader.storage(None, 512)
	    reader.tensor(buf6, (128,), is_leaf=True)  # primals_7
	    buf7 = reader.storage(None, 512)
	    reader.tensor(buf7, (128,), is_leaf=True)  # primals_8
	    buf8 = reader.storage(None, 65536)
	    reader.tensor(buf8, (128, 128), (1, 128), is_leaf=True)  # primals_9
	    buf9 = reader.storage(None, 512)
	    reader.tensor(buf9, (128,), is_leaf=True)  # primals_10
	    buf10 = reader.storage(None, 65536)
	    reader.tensor(buf10, (128, 128), (1, 128), is_leaf=True)  # primals_11
	    buf11 = reader.storage(None, 512)
	    reader.tensor(buf11, (128,), is_leaf=True)  # primals_12
	    buf12 = reader.storage(None, 65536)
	    reader.tensor(buf12, (128, 128), (1, 128), is_leaf=True)  # primals_13
	    buf13 = reader.storage(None, 512)
	    reader.tensor(buf13, (128,), is_leaf=True)  # primals_14
	    buf14 = reader.storage(None, 65536)
	    reader.tensor(buf14, (128, 128), (1, 128), is_leaf=True)  # primals_15
	    buf15 = reader.storage(None, 512)
	    reader.tensor(buf15, (128,), is_leaf=True)  # primals_16
	    buf16 = reader.storage(None, 512)
	    reader.tensor(buf16, (128,), is_leaf=True)  # primals_17
	    buf17 = reader.storage(None, 512)
	    reader.tensor(buf17, (128,), is_leaf=True)  # primals_18
	    buf18 = reader.storage(None, 262144)
	    reader.tensor(buf18, (512, 128), (1, 512), is_leaf=True)  # primals_19
	    buf19 = reader.storage(None, 2048)
	    reader.tensor(buf19, (512,), is_leaf=True)  # primals_20
	    buf20 = reader.storage(None, 262144)
	    reader.tensor(buf20, (128, 512), (1, 128), is_leaf=True)  # primals_21
	    buf21 = reader.storage(None, 512)
	    reader.tensor(buf21, (128,), is_leaf=True)  # primals_22
	    buf22 = reader.storage(None, 512)
	    reader.tensor(buf22, (128,), is_leaf=True)  # primals_23
	    buf23 = reader.storage(None, 512)
	    reader.tensor(buf23, (128,), is_leaf=True)  # primals_24
	    buf24 = reader.storage(None, 65536)
	    reader.tensor(buf24, (128, 128), (1, 128), is_leaf=True)  # primals_25
	    buf25 = reader.storage(None, 512)
	    reader.tensor(buf25, (128,), is_leaf=True)  # primals_26
	    buf26 = reader.storage(None, 65536)
	    reader.tensor(buf26, (128, 128), (1, 128), is_leaf=True)  # primals_27
	    buf27 = reader.storage(None, 512)
	    reader.tensor(buf27, (128,), is_leaf=True)  # primals_28
	    buf28 = reader.storage(None, 65536)
	    reader.tensor(buf28, (128, 128), (1, 128), is_leaf=True)  # primals_29
	    buf29 = reader.storage(None, 512)
	    reader.tensor(buf29, (128,), is_leaf=True)  # primals_30
	    buf30 = reader.storage(None, 65536)
	    reader.tensor(buf30, (128, 128), (1, 128), is_leaf=True)  # primals_31
	    buf31 = reader.storage(None, 512)
	    reader.tensor(buf31, (128,), is_leaf=True)  # primals_32
	    buf32 = reader.storage(None, 512)
	    reader.tensor(buf32, (128,), is_leaf=True)  # primals_33
	    buf33 = reader.storage(None, 512)
	    reader.tensor(buf33, (128,), is_leaf=True)  # primals_34
	    buf34 = reader.storage(None, 262144)
	    reader.tensor(buf34, (512, 128), (1, 512), is_leaf=True)  # primals_35
	    buf35 = reader.storage(None, 2048)
	    reader.tensor(buf35, (512,), is_leaf=True)  # primals_36
	    buf36 = reader.storage(None, 262144)
	    reader.tensor(buf36, (128, 512), (1, 128), is_leaf=True)  # primals_37
	    buf37 = reader.storage(None, 512)
	    reader.tensor(buf37, (128,), is_leaf=True)  # primals_38
	    buf38 = reader.storage(None, 512)
	    reader.tensor(buf38, (128,), is_leaf=True)  # primals_39
	    buf39 = reader.storage(None, 512)
	    reader.tensor(buf39, (128,), is_leaf=True)  # primals_40
	    buf40 = reader.storage(None, 65536)
	    reader.tensor(buf40, (128, 128), (1, 128), is_leaf=True)  # primals_41
	    buf41 = reader.storage(None, 512)
	    reader.tensor(buf41, (128,), is_leaf=True)  # primals_42
	load_args._version = 0
	mod = Repro()
	if __name__ == '__main__':
	    from torch._dynamo.repro.after_aot import run_repro
	    with torch.no_grad():
	        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='real', check_str=None)
	        # To run it separately, do 
	        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='real', check_str=None)
	        # mod(*args)
V0331 22:12:43.087000 6798 torch/_inductor/compile_fx.py:801] {"inductor_post_grad_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3603c34bcc64fc1036f331ca428bd3e8"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_2: "i64[1, 512][512, 1]cpu", primals_3: "i64[1, 512][512, 1]cpu", primals_4: "f32[30522, 128][128, 1]cpu", primals_5: "f32[2, 128][128, 1]cpu", primals_6: "f32[512, 128][128, 1]cpu", primals_7: "f32[128][1]cpu", primals_8: "f32[128][1]cpu", primals_9: "f32[128, 128][1, 128]cpu", primals_10: "f32[128][1]cpu", primals_11: "f32[128, 128][1, 128]cpu", primals_12: "f32[128][1]cpu", primals_13: "f32[128, 128][1, 128]cpu", primals_14: "f32[128][1]cpu", primals_15: "f32[128, 128][1, 128]cpu", primals_16: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_18: "f32[128][1]cpu", primals_19: "f32[512, 128][1, 512]cpu", primals_20: "f32[512][1]cpu", primals_21: "f32[128, 512][1, 128]cpu", primals_22: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_24: "f32[128][1]cpu", primals_25: "f32[128, 128][1, 128]cpu", primals_26: "f32[128][1]cpu", primals_27: "f32[128, 128][1, 128]cpu", primals_28: "f32[128][1]cpu", primals_29: "f32[128, 128][1, 128]cpu", primals_30: "f32[128][1]cpu", primals_31: "f32[128, 128][1, 128]cpu", primals_32: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_34: "f32[128][1]cpu", primals_35: "f32[512, 128][1, 512]cpu", primals_36: "f32[512][1]cpu", primals_37: "f32[128, 512][1, 128]cpu", primals_38: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", primals_40: "f32[128][1]cpu", primals_41: "f32[128, 128][1, 128]cpu", primals_42: "f32[128][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.reshape.default(add_3, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.reshape.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.reshape.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.reshape.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.reshape.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17)
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.reshape.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.reshape.default(addmm_4, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.reshape.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23)
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.reshape.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.reshape.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.reshape.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.reshape.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.reshape.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33)
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.reshape.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.reshape.default(addmm_10, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.reshape.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.reshape.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39)
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(add_17, 1, 0)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)
	        
V0331 22:12:43.094000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "8f33f47692a5f72147d6c9b6c3ad4959"}
	{
	"name": "GraphLowering.run",
	"ts": 1743459163094566.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.255000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "af7e4f5105bbe3166167d85140b20611"}
	{
	"name": "GraphLowering.run",
	"ts": 1743459163255575.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.257000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "5eb68cf5b7dfd1f0579e04f905689dcb"}
	{
	"name": "GraphLowering.compile_to_module",
	"ts": 1743459163257224.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.257000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "c08575b2a4da495d8015e0d89545ab27"}
	{
	"name": "code_gen",
	"ts": 1743459163257224.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.261000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "fdfd2171caf8593eca3bfa5f10e74ad8"}
	{
	"name": "Scheduler.__init__",
	"ts": 1743459163261686.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.431000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "b57b8c08ff348ddf2be3ee0e479cf9a1"}
	{
	"name": "Scheduler.__init__",
	"ts": 1743459163430902.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.431000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "de4d8fc4806e17502ea7a22386dd17fa"}
	{
	"name": "Scheduler.codegen",
	"ts": 1743459163431718.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:43.591000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a4a0545757259627bb62a7402a061e28"}
	{
	"name": "compile_file",
	"ts": 1743459163590825.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:45.825000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "019a66e6f465a022bfe61082aaf1c216"}
	{
	"name": "compile_file",
	"ts": 1743459165825761.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:48.544000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "3088558e441ca58497a7179ee559fd67"}
	{
	"name": "Scheduler.codegen",
	"ts": 1743459168544035.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:48.544000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "fb008a42995ec3ceb34b502a7b9e26df"}
	{
	"name": "WrapperCodeGen.generate",
	"ts": 1743459168544804.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:48.553000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "aa9538ccd43e10b90e8fec03320ea5b1"}
	{
	"name": "WrapperCodeGen.generate",
	"ts": 1743459168553828.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:48.555000 6798 torch/_inductor/graph.py:1861] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/kb/ckb7rafd2axgx3svqabknxiadoamlwfrjac5wn435h7nnf25khqd.py"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "d41660e2a5bd76f896de5d8724a7cc08"}
	# AOT ID: ['0_forward']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0 = async_compile.cpp_pybinding(['const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       const float* in_ptr1,
	                       const int64_t* in_ptr2,
	                       const float* in_ptr3,
	                       const int64_t* in_ptr4,
	                       const float* in_ptr5,
	                       const float* in_ptr6,
	                       const float* in_ptr7,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4,
	                       float* out_ptr5,
	                       float* out_ptr6)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                    auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	                    auto tmp21 = in_ptr4[static_cast<int64_t>(x0)];
	                    auto tmp1 = 30522L;
	                    auto tmp2 = c10::convert<int64_t>(tmp1);
	                    auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
	                    auto tmp4 = tmp0 < 0;
	                    auto tmp5 = tmp4 ? tmp3 : tmp0;
	                    auto tmp6 = tmp5;
	                    auto tmp7 = c10::convert<int64_t>(tmp6);
	                    TORCH_CHECK((0 <= tmp7) & (tmp7 < 30522L), "index out of bounds: 0 <= tmp7 < 30522L");
	                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*tmp5)), static_cast<int64_t>(8));
	                    auto tmp11 = 2L;
	                    auto tmp12 = c10::convert<int64_t>(tmp11);
	                    auto tmp13 = decltype(tmp10)(tmp10 + tmp12);
	                    auto tmp14 = tmp10 < 0;
	                    auto tmp15 = tmp14 ? tmp13 : tmp10;
	                    auto tmp16 = tmp15;
	                    auto tmp17 = c10::convert<int64_t>(tmp16);
	                    TORCH_CHECK((0 <= tmp17) & (tmp17 < 2L), "index out of bounds: 0 <= tmp17 < 2L");
	                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1 + (128L*tmp15)), static_cast<int64_t>(8));
	                    auto tmp20 = tmp9 + tmp19;
	                    auto tmp22 = 512L;
	                    auto tmp23 = c10::convert<int64_t>(tmp22);
	                    auto tmp24 = decltype(tmp21)(tmp21 + tmp23);
	                    auto tmp25 = tmp21 < 0;
	                    auto tmp26 = tmp25 ? tmp24 : tmp21;
	                    auto tmp27 = tmp26;
	                    auto tmp28 = c10::convert<int64_t>(tmp27);
	                    TORCH_CHECK((0 <= tmp28) & (tmp28 < 512L), "index out of bounds: 0 <= tmp28 < 512L");
	                    auto tmp30 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x1 + (128L*tmp26)), static_cast<int64_t>(8));
	                    auto tmp31 = tmp20 + tmp30;
	                    tmp31.store(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)));
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp31, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr2[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp4 = out_ptr2[static_cast<int64_t>(x0)];
	                auto tmp12 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = at::vec::Vectorized<float>(tmp1);
	                auto tmp3 = tmp0 - tmp2;
	                auto tmp5 = static_cast<float>(128.0);
	                auto tmp6 = tmp4 / tmp5;
	                auto tmp7 = static_cast<float>(1e-12);
	                auto tmp8 = decltype(tmp6)(tmp6 + tmp7);
	                auto tmp9 = 1 / std::sqrt(tmp8);
	                auto tmp10 = at::vec::Vectorized<float>(tmp9);
	                auto tmp11 = tmp3 * tmp10;
	                auto tmp13 = tmp11 * tmp12;
	                auto tmp15 = tmp13 + tmp14;
	                tmp11.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp15.store(out_ptr4 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(96L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(96L); x0<static_cast<int64_t>(100L); x0+=static_cast<int64_t>(4L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0), static_cast<int64_t>(4L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_1 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_2 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_3 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_4 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_5 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_6 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_tanh_7 = async_compile.cpp_pybinding(['float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(float* in_out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(128L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = decltype(tmp0)(2) / (decltype(tmp0)(1) + (decltype(tmp0)(-2) * tmp0).exp()) - decltype(tmp0)(1);
	            tmp1.store(in_out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42 = args
	    args.clear()
	    assert_size_stride(primals_1, (1, 10), (10, 1))
	    assert_size_stride(primals_2, (1, 512), (512, 1))
	    assert_size_stride(primals_3, (1, 512), (512, 1))
	    assert_size_stride(primals_4, (30522, 128), (128, 1))
	    assert_size_stride(primals_5, (2, 128), (128, 1))
	    assert_size_stride(primals_6, (512, 128), (128, 1))
	    assert_size_stride(primals_7, (128, ), (1, ))
	    assert_size_stride(primals_8, (128, ), (1, ))
	    assert_size_stride(primals_9, (128, 128), (1, 128))
	    assert_size_stride(primals_10, (128, ), (1, ))
	    assert_size_stride(primals_11, (128, 128), (1, 128))
	    assert_size_stride(primals_12, (128, ), (1, ))
	    assert_size_stride(primals_13, (128, 128), (1, 128))
	    assert_size_stride(primals_14, (128, ), (1, ))
	    assert_size_stride(primals_15, (128, 128), (1, 128))
	    assert_size_stride(primals_16, (128, ), (1, ))
	    assert_size_stride(primals_17, (128, ), (1, ))
	    assert_size_stride(primals_18, (128, ), (1, ))
	    assert_size_stride(primals_19, (512, 128), (1, 512))
	    assert_size_stride(primals_20, (512, ), (1, ))
	    assert_size_stride(primals_21, (128, 512), (1, 128))
	    assert_size_stride(primals_22, (128, ), (1, ))
	    assert_size_stride(primals_23, (128, ), (1, ))
	    assert_size_stride(primals_24, (128, ), (1, ))
	    assert_size_stride(primals_25, (128, 128), (1, 128))
	    assert_size_stride(primals_26, (128, ), (1, ))
	    assert_size_stride(primals_27, (128, 128), (1, 128))
	    assert_size_stride(primals_28, (128, ), (1, ))
	    assert_size_stride(primals_29, (128, 128), (1, 128))
	    assert_size_stride(primals_30, (128, ), (1, ))
	    assert_size_stride(primals_31, (128, 128), (1, 128))
	    assert_size_stride(primals_32, (128, ), (1, ))
	    assert_size_stride(primals_33, (128, ), (1, ))
	    assert_size_stride(primals_34, (128, ), (1, ))
	    assert_size_stride(primals_35, (512, 128), (1, 512))
	    assert_size_stride(primals_36, (512, ), (1, ))
	    assert_size_stride(primals_37, (128, 512), (1, 128))
	    assert_size_stride(primals_38, (128, ), (1, ))
	    assert_size_stride(primals_39, (128, ), (1, ))
	    assert_size_stride(primals_40, (128, ), (1, ))
	    assert_size_stride(primals_41, (128, 128), (1, 128))
	    assert_size_stride(primals_42, (128, ), (1, ))
	    buf0 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf1 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf2 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf4 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf6 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf53 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    buf5 = empty_strided_cpu((1, 1, 10, 10), (100, 100, 10, 1), torch.float32)
	    cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0(primals_1, primals_4, primals_2, primals_5, primals_3, primals_6, primals_7, primals_8, buf0, buf1, buf2, buf4, buf6, buf53, buf5)
	    del primals_4
	    del primals_5
	    del primals_6
	    del primals_8
	    buf7 = reinterpret_tensor(buf0, (10, 128), (128, 1), 0); del buf0  # reuse
	    # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_10, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_9, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf7)
	    del primals_10
	    buf8 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_1], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_12, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_11, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf8)
	    del primals_12
	    buf9 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_14, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_13, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf9)
	    del primals_14
	    # Topologically Sorted Source Nodes: [attn_output], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf10 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf11 = buf10[0]
	    buf12 = buf10[1]
	    del buf10
	    buf13 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_16, reinterpret_tensor(buf11, (10, 128), (128, 1), 0), reinterpret_tensor(primals_15, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf13)
	    del primals_16
	    buf14 = buf2; del buf2  # reuse
	    buf15 = buf1; del buf1  # reuse
	    buf17 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf18 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf52 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_1(buf13, buf6, primals_17, primals_18, buf14, buf15, buf17, buf18, buf52)
	    del primals_18
	    buf19 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_3], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_20, reinterpret_tensor(buf18, (10, 128), (128, 1), 0), reinterpret_tensor(primals_19, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf19)
	    del primals_20
	    buf20 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_2(buf19, buf20)
	    buf21 = buf13; del buf13  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_5], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_22, reinterpret_tensor(buf20, (10, 512), (512, 1), 0), reinterpret_tensor(primals_21, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf21)
	    del primals_22
	    buf22 = buf15; del buf15  # reuse
	    buf23 = buf14; del buf14  # reuse
	    buf25 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf26 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf51 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_3(buf21, buf18, primals_23, primals_24, buf22, buf23, buf25, buf26, buf51)
	    del primals_24
	    buf27 = buf21; del buf21  # reuse
	    # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_26, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_25, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf27)
	    del primals_26
	    buf28 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_7], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_28, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_27, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf28)
	    del primals_28
	    buf29 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_30, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_29, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf29)
	    del primals_30
	    # Topologically Sorted Source Nodes: [attn_output_3], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf30 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf31 = buf30[0]
	    buf32 = buf30[1]
	    del buf30
	    buf33 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_32, reinterpret_tensor(buf31, (10, 128), (128, 1), 0), reinterpret_tensor(primals_31, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf33)
	    del primals_32
	    buf34 = buf23; del buf23  # reuse
	    buf35 = buf22; del buf22  # reuse
	    buf37 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf38 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf50 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_4(buf33, buf26, primals_33, primals_34, buf34, buf35, buf37, buf38, buf50)
	    del primals_34
	    buf39 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_11], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_36, reinterpret_tensor(buf38, (10, 128), (128, 1), 0), reinterpret_tensor(primals_35, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf39)
	    del primals_36
	    buf40 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_5(buf39, buf40)
	    buf41 = buf33; del buf33  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_13], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_38, reinterpret_tensor(buf40, (10, 512), (512, 1), 0), reinterpret_tensor(primals_37, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf41)
	    del primals_38
	    buf42 = buf35; del buf35  # reuse
	    buf43 = buf34; del buf34  # reuse
	    buf45 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf46 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf49 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_6(buf41, buf38, primals_39, primals_40, buf42, buf43, buf45, buf46, buf49)
	    del buf41
	    del buf42
	    del buf43
	    del primals_40
	    buf47 = empty_strided_cpu((1, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [pooled_output], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_42, reinterpret_tensor(buf46, (1, 128), (128, 1), 0), reinterpret_tensor(primals_41, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf47)
	    del primals_42
	    buf48 = buf47; del buf47  # reuse
	    cpp_fused_tanh_7(buf48)
	    return (buf46, buf48, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, reinterpret_tensor(primals_2, (1, 10), (512, 1), 0), reinterpret_tensor(primals_3, (1, 10), (512, 1), 0), buf4, buf5, reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf11, buf12, buf17, buf19, buf25, reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf31, buf32, buf37, buf39, buf45, buf48, primals_41, reinterpret_tensor(buf46, (128, 1), (1, 1280), 0), buf49, primals_37, reinterpret_tensor(buf40, (512, 10), (1, 512), 0), primals_35, reinterpret_tensor(buf38, (128, 10), (1, 128), 0), buf50, primals_31, primals_29, reinterpret_tensor(buf26, (128, 10), (1, 128), 0), primals_27, primals_25, buf51, primals_21, reinterpret_tensor(buf20, (512, 10), (1, 512), 0), primals_19, reinterpret_tensor(buf18, (128, 10), (1, 128), 0), buf52, primals_15, primals_13, reinterpret_tensor(buf6, (128, 10), (1, 128), 0), primals_11, primals_9, buf53, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    primals_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    primals_2 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_3 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_4 = rand_strided((30522, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_5 = rand_strided((2, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_6 = rand_strided((512, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_7 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_8 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_9 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_10 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_11 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_12 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_13 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_14 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_15 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_16 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_17 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_18 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_19 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_20 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_21 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_22 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_23 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_24 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_25 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_26 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_27 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_28 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_29 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_30 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_31 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_32 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_33 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_34 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_35 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_36 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_37 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_38 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_39 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_40 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_41 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_42 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0331 22:12:48.569000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "03350b70200d71b25a84d92c37692518"}
	{
	"name": "compile_file",
	"ts": 1743459168569230.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:48.623000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "77218d3275cf9e7c8713953162ee2d36"}
	{
	"name": "compile_file",
	"ts": 1743459168623418.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:52.832000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "7112285d81314ebd49267cff38ef602e"}
	{
	"name": "compile_file",
	"ts": 1743459172832069.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:52.833000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "a8937d9c61e397196ba42bf1c19429ef"}
	{
	"name": "compile_file",
	"ts": 1743459172833661.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:52.876000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "0acd10a7a69d2a3b5b44b8e4112cae15"}
	{
	"name": "compile_file",
	"ts": 1743459172875851.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:52.877000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "6f2189885c23a4d766f1d2d7228c5d6b"}
	{
	"name": "compile_file",
	"ts": 1743459172877696.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.816000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "65e65beaa9bf10141e19b0906e48e102"}
	{
	"name": "compile_file",
	"ts": 1743459176816730.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.825000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "has_payload": "dadf115fa9c90f73092efb5105232344"}
	{
	"name": "compile_file",
	"ts": 1743459176824895.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.826000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "2efae7be99afc7e889ecfc5de52aaa34"}
	{
	"name": "code_gen",
	"ts": 1743459176826790.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.827000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "ee96c501711243dec01868faf46afcb5"}
	{
	"name": "GraphLowering.compile_to_module",
	"ts": 1743459176827495.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.832000 6798 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "25cd499479359fd5fa50a475eba88765"}
	{
	"name": "fx_graph_cache_miss",
	"ts": 1743459162979705.2,
	"args": {
	"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a",
	"components": [
	"[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]",
	"[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_taken_ns": 13851574116,
	"cache_state": "miss"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0331 22:12:56.833000 6798 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "412cf82c7bc663d9a8aa539894255794"}
	{"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a", "components": ["[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]", "[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_taken_ns": 13851574116, "cache_state": "miss"}
V0331 22:12:56.835000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "c491d06dba8acf13427d2e6cce9c02fb"}
	{
	"name": "inductor_compile",
	"ts": 1743459176835377.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.836000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "e50b4de615024f8e4384e52fae75bc42"}
	{
	"name": "compile_fx_inner",
	"ts": 1743459176835987.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.837000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "7c9991425b3ec79ba6392e7dfafcc703"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743459176837018.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.840000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "a80d9a1fe30a5872a964f1d480617ec2"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743459176840477.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.841000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "b29f7f372f3c2d0b002912f7d2cc085e"}
	{
	"name": "backend_compile",
	"ts": 1743459176841329.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:56.841000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "80b4e5ea6a80bfa93625d0e4239380d0"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743459176841905.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:57.042000 6798 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "23d404d214d66266e4087119d932bf88"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 97967545447424)                 
	| | +- GuardManager: source=L['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | +- GuardManager: source=L['self'].config, accessed_by=DictGetItemGuardAccessor(config)
	| | | | +- TYPE_MATCH: ___check_type_id(L['self'].config, 97967540258080)          
	| | | | +- GuardManager: source=L['self'].config.is_decoder, accessed_by=GetAttrGuardAccessor(is_decoder)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.is_decoder, 97966799356864)
	| | | | +- GuardManager: source=L['self'].config.use_return_dict, accessed_by=GetAttrGuardAccessor(use_return_dict)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.use_return_dict, 97966799356832)
	| | | | +- GuardManager: source=L['self'].config.num_hidden_layers, accessed_by=GetAttrGuardAccessor(num_hidden_layers)
	| | | | | +- EQUALS_MATCH: L['self'].config.num_hidden_layers == 2                     
	| | | | +- GuardManager: source=L['self'].config.output_attentions, accessed_by=GetAttrGuardAccessor(output_attentions)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.output_attentions, 97966799356864)
	| | | | +- GuardManager: source=L['self'].config.output_hidden_states, accessed_by=GetAttrGuardAccessor(output_hidden_states)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.output_hidden_states, 97966799356864)
	| | | +- GuardManager: source=L['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | +- DICT_LENGTH: len(L['self']._modules) == 3                                
	| | | | +- GuardManager: source=L['self']._modules['embeddings'], accessed_by=DictGetItemGuardAccessor(embeddings)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings'], 97967544690480)
	| | | | | +- GuardManager: source=L['self']._modules['embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers, accessed_by=DictGetItemGuardAccessor(_buffers)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._buffers) == 2         
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._buffers['position_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['input_ids'], L['self']._modules['embeddings']._buffers['position_ids'], L['self']._modules['embeddings']._buffers['token_type_ids'], L['self']._modules['pooler']._modules['dense']._parameters['bias'], L['self']._modules['pooler']._modules['dense']._parameters['weight'], L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'])
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._buffers['token_type_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules) == 5         
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'], accessed_by=DictGetItemGuardAccessor(word_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['word_embeddings'], 97967474931328)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['word_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].sparse, 97966799356864)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].max_norm, 97966799449824)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['word_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['word_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[30522, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['word_embeddings'].padding_idx == 0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, 97966799356864)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'], accessed_by=DictGetItemGuardAccessor(position_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['position_embeddings'], 97967474931328)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['position_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].sparse, 97966799356864)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].max_norm, 97966799449824)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['position_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['position_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].padding_idx, 97966799449824)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, 97966799356864)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'], accessed_by=DictGetItemGuardAccessor(token_type_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['token_type_embeddings'], 97967474931328)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['token_type_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].sparse, 97966799356864)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].max_norm, 97966799449824)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['token_type_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[2, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].padding_idx, 97966799449824)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, 97966799356864)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['LayerNorm'], 97967474409040)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['LayerNorm'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape, 97966799458368)
	| | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['dropout'], 97967474004320)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['dropout'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['dropout'].p == 0.1
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['dropout'].inplace, 97966799356864)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['dropout'].training, 97966799356864)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._parameters            
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['embeddings']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._backward_hooks        
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['embeddings']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._backward_pre_hooks    
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings'].position_embedding_type == 'absolute'
	| | | | +- GuardManager: source=L['self']._modules['encoder'], accessed_by=DictGetItemGuardAccessor(encoder)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder'], 97967545467488)
	| | | | | +- GuardManager: source=L['self']._modules['encoder'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules) == 1            
	| | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer'], accessed_by=DictGetItemGuardAccessor(layer)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer'], 97967473018592)
	| | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']) == 2   
	| | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DictGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | +- KeyValueManager pair at index=0
	| | | | | | | | | | | +- KeyManager: GuardManager: source=list(L['self']._modules['encoder']._modules['layer']._modules.keys())[0]
	| | | | | | | | | | | | +- EQUALS_MATCH: list(L['self']._modules['encoder']._modules['layer']._modules.keys())[0] == '0'
	| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0'], 97967545213424)
	| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0'].__dict__)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules) == 3
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'], 97967545182624)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], 97967545128784)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], 97967545130560)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], 97967474409040)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 97966799458368)
	| | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], 97967474004320)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, 97966799356864)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], 97966799449824)
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], 97967545184400)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], 97967473627488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], 97967544639584)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, 135855779300512)
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'], 97967545211648)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], 97967473627488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], 97967474409040)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, 97966799458368)
	| | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], 97967474004320)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, 97966799356864)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0'].is_decoder, 97966799356864)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._parameters
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._backward_hooks
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward == 0
	| | | | | | | | | | +- KeyValueManager pair at index=1
	| | | | | | | | | | | +- KeyManager: GuardManager: source=list(L['self']._modules['encoder']._modules['layer']._modules.keys())[1]
	| | | | | | | | | | | | +- EQUALS_MATCH: list(L['self']._modules['encoder']._modules['layer']._modules.keys())[1] == '1'
	| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1'], 97967545213424)
	| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1'].__dict__)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules) == 3
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'], 97967545182624)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], 97967545128784)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], 97967545130560)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], 97967473627488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], 97967474409040)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 97966799458368)
	| | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], 97967474004320)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, 97966799356864)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], 97966799449824)
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], 97967545184400)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], 97967473627488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], 97967544639584)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, 135855779300512)
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'], 97967545211648)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], 97967473627488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], 97967474409040)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, 97966799458368)
	| | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], 97967474004320)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, 97966799356864)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, 97966799356864)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1'].is_decoder, 97966799356864)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._parameters
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._backward_hooks
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward == 0
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._parameters               
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._backward_hooks           
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._backward_pre_hooks       
	| | | | | | +- GuardManager: source=L['self']._modules['encoder'].gradient_checkpointing, accessed_by=DictGetItemGuardAccessor(gradient_checkpointing)
	| | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder'].gradient_checkpointing, 97966799356864)
	| | | | +- GuardManager: source=L['self']._modules['pooler'], accessed_by=DictGetItemGuardAccessor(pooler)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler'], 97967545469264)
	| | | | | +- GuardManager: source=L['self']._modules['pooler'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['pooler']._modules) == 2             
	| | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler']._modules['dense'], 97967473627488)
	| | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler']._modules['dense'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['pooler']._modules['dense']._parameters) == 2
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['pooler']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['pooler']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['activation'], accessed_by=DictGetItemGuardAccessor(activation)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler']._modules['activation'], 97967473231440)
	| | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['activation'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler']._modules['activation'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._parameters                
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['pooler']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._backward_hooks            
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['pooler']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._backward_pre_hooks        
	| | | +- GuardManager: source=L['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | +- DICT_LENGTH: not L['self']._parameters                                   
	| | | +- GuardManager: source=L['self'].attn_implementation, accessed_by=DictGetItemGuardAccessor(attn_implementation)
	| | | | +- EQUALS_MATCH: L['self'].attn_implementation == 'sdpa'                     
	| | | +- GuardManager: source=L['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | +- EQUALS_MATCH: L['self'].position_embedding_type == 'absolute'             
	| +- GuardManager: source=L['head_mask'], accessed_by=DictGetItemGuardAccessor(head_mask)
	| | +- ID_MATCH: ___check_obj_id(L['head_mask'], 97966799449824)             
	| +- GuardManager: source=L['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False 
	| | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['return_dict'], accessed_by=DictGetItemGuardAccessor(return_dict)
	| | +- ID_MATCH: ___check_obj_id(L['return_dict'], 97966799449824)           
	| +- GuardManager: source=L['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | +- ID_MATCH: ___check_obj_id(L['position_ids'], 97966799449824)          
	| +- GuardManager: source=L['inputs_embeds'], accessed_by=DictGetItemGuardAccessor(inputs_embeds)
	| | +- ID_MATCH: ___check_obj_id(L['inputs_embeds'], 97966799449824)         
	| +- GuardManager: source=L['attention_mask'], accessed_by=DictGetItemGuardAccessor(attention_mask)
	| | +- ID_MATCH: ___check_obj_id(L['attention_mask'], 97966799449824)        
	| +- GuardManager: source=L['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | +- ID_MATCH: ___check_obj_id(L['token_type_ids'], 97966799449824)        
	| +- GuardManager: source=L['past_key_values'], accessed_by=DictGetItemGuardAccessor(past_key_values)
	| | +- ID_MATCH: ___check_obj_id(L['past_key_values'], 97966799449824)       
	| +- GuardManager: source=L['output_attentions'], accessed_by=DictGetItemGuardAccessor(output_attentions)
	| | +- ID_MATCH: ___check_obj_id(L['output_attentions'], 97966799449824)     
	| +- GuardManager: source=L['output_hidden_states'], accessed_by=DictGetItemGuardAccessor(output_hidden_states)
	| | +- ID_MATCH: ___check_obj_id(L['output_hidden_states'], 97966799449824)  
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__import_torch'], accessed_by=DictGetItemGuardAccessor(__import_torch)
	| | | +- GuardManager: source=G['__import_torch'].fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx, 135855756408240)    
	| | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | | +- GuardManager: source=G['__import_torch'].fx.Proxy, accessed_by=GetAttrGuardAccessor(Proxy)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx.Proxy, 97967480054976)
	| | | +- GuardManager: source=G['__import_torch'].compiler, accessed_by=GetAttrGuardAccessor(compiler)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler, 135855741213552)
	| | | | +- GuardManager: source=G['__import_torch'].compiler.is_compiling, accessed_by=GetAttrGuardAccessor(is_compiling)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler.is_compiling, 135855739547584)
	| | +- GuardManager: source=G['apply_chunking_to_forward'], accessed_by=DictGetItemGuardAccessor(apply_chunking_to_forward)
	| | | +- GuardManager: source=G['apply_chunking_to_forward'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['apply_chunking_to_forward'].__code__, 97967516469408)
	| | +- GuardManager: source=G['__builtins_dict___0'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___0)
	| | | +- GuardManager: source=G['__builtins_dict___0']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['int'], 97966799430368)
	| | | +- GuardManager: source=G['__builtins_dict___0']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['len'], 135856278938192)
	| | | +- GuardManager: source=G['__builtins_dict___0']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['str'], 97966799475648)
	| | | +- GuardManager: source=G['__builtins_dict___0']['dict'], accessed_by=DictGetItemGuardAccessor(dict)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['dict'], 97966799436000)
	| | | +- GuardManager: source=G['__builtins_dict___0']['iter'], accessed_by=DictGetItemGuardAccessor(iter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['iter'], 135856278938032)
	| | | +- GuardManager: source=G['__builtins_dict___0']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['tuple'], 97966799458368)
	| | | +- GuardManager: source=G['__builtins_dict___0']['hasattr'], accessed_by=DictGetItemGuardAccessor(hasattr)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['hasattr'], 135856278937472)
	| | | +- GuardManager: source=G['__builtins_dict___0']['enumerate'], accessed_by=DictGetItemGuardAccessor(enumerate)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['enumerate'], 97966799378848)
	| | | +- GuardManager: source=G['__builtins_dict___0']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___0']['isinstance'], 135856278937872)
	| | +- GuardManager: source=G['_prepare_4d_attention_mask_for_sdpa'], accessed_by=DictGetItemGuardAccessor(_prepare_4d_attention_mask_for_sdpa)
	| | | +- GuardManager: source=G['_prepare_4d_attention_mask_for_sdpa'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_prepare_4d_attention_mask_for_sdpa'].__code__, 135855440979504)
	| | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_pytorch_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'], 135855674116832)
	| | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect, accessed_by=GetAttrGuardAccessor(inspect)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect, 135856277856048)
	| | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature, accessed_by=GetAttrGuardAccessor(signature)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, 135856275676976)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'], 135855441065312)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch, 135856277016864)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['torch']
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn, accessed_by=GetAttrGuardAccessor(nn)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.nn, 135855776682672)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn.functional, accessed_by=GetAttrGuardAccessor(functional)
	| | | | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit, accessed_by=GetAttrGuardAccessor(jit)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit, 135855762996448)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, accessed_by=GetAttrGuardAccessor(is_tracing)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, 135855761793856)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.bool, accessed_by=GetAttrGuardAccessor(bool)
	| | | | | +- EQUALS_MATCH: G['__import_transformers_dot_modeling_utils'].torch.bool == torch.bool
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.ones, accessed_by=GetAttrGuardAccessor(ones)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.ones, 135856271104960)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.tanh, accessed_by=GetAttrGuardAccessor(tanh)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.tanh, 135856271167376)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.finfo, accessed_by=GetAttrGuardAccessor(finfo)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.finfo, 135856268189984)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy, accessed_by=GetAttrGuardAccessor(is_torch_fx_proxy)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, 135855694160368)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, 135855694652448)
	| | +- GuardManager: source=G['BaseModelOutputWithPastAndCrossAttentions'], accessed_by=DictGetItemGuardAccessor(BaseModelOutputWithPastAndCrossAttentions)
	| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPastAndCrossAttentions'], 97967516672800)
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_generic'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_generic)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_generic'], 135855691030480)
	| | +- GuardManager: source=G['BaseModelOutputWithPoolingAndCrossAttentions'], accessed_by=DictGetItemGuardAccessor(BaseModelOutputWithPoolingAndCrossAttentions)
	| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPoolingAndCrossAttentions'], 97967516702048)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_linear)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 135855767746128)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_module)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 135855776688272)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_sparse)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'], 135855765288128)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, 135855767746288)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, accessed_by=GetAttrGuardAccessor(linear)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, 135855779301632)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, accessed_by=GetAttrGuardAccessor(dropout)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, 135855765872352)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, accessed_by=GetAttrGuardAccessor(embedding)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, 135855765877152)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, 135855765878112)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, accessed_by=GetAttrGuardAccessor(scaled_dot_product_attention)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, 135855779304192)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_dropout)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_dropout'], 135855764624688)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_container)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'], 135855766447872)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_activation)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_activation'], 135855766386736)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_import_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'], 135855692752960)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_available, accessed_by=GetAttrGuardAccessor(_torch_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_available, 97966799356832)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available, accessed_by=GetAttrGuardAccessor(is_torch_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, 135855694736608)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, accessed_by=GetAttrGuardAccessor(_torch_fx_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, 97966799356832)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available, accessed_by=GetAttrGuardAccessor(is_torch_fx_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, 135855694739520)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_attn_mask_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'], 135855439123120)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, accessed_by=GetAttrGuardAccessor(AttentionMaskConverter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, 97967544661456)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask, accessed_by=GetAttrGuardAccessor(_expand_mask)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, 135855440978480)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, 135855694652448)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_normalization)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 135855764725152)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | +- GuardManager: source=G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot__dynamo_dot_polyfills_dot_builtins)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], 135855702374288)
	| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor(torch)
	| | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['torch']
	
V0331 22:12:57.043000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "ea7752341e6e285b0f07bd13fcd2cad0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743459177043851.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:57.044000 6798 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "43a6ebef199ee92ff174f81c6875f164"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743459177044532.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 0,
	"fxgraph_cache_miss": 1,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:12:57.045000 6798 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "0/0", "frame_key": "1", "co_name": "forward", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", "co_firstlineno": 1001, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 642, "shape_env_guard_count": 0, "graph_op_count": 64, "graph_node_count": 107, "graph_input_count": 42, "start_time": 1743459159.943079, "entire_frame_compile_time_s": 17.1004056930542, "backend_compile_time_s": 16.30918049812317, "inductor_compile_time_s": 14.593415260314941, "code_gen_time_s": 13.569451332092285, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
