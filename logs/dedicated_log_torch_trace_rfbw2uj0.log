V0401 21:31:19.530000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", 0]}
V0401 21:31:19.535000 13296 torch/_logging/structured.py:22] {"str": ["/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", 1]}
V0401 21:31:19.538000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", 2]}
V0401 21:31:19.539000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", 3]}
V0401 21:31:19.541000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}]}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:19.543000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "7ba7c19bc75bc7930d5ed9f80daf48da"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543079542915.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.544000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "22cd9ba9efb6cce2d3e3b690fa856d2c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543079542915.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.607000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 0, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:19.608000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70026fcd92c0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:19.609000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 0, "source": "L['kwargs']['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:19.621000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 1, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:19.622000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70026fcd92c0>", "describer_id": 1}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:19.623000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 1, "id": 0, "source": "L['kwargs']['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:19.637000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_kwargs_input_ids_": [1, 10], "modified_input_ids": [1, 10], "getitem": [], "iadd": [], "getitem_1": []}}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "6c0020aaeb7d7d3760b62c08f9f2bfed"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_kwargs_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_kwargs_input_ids_ = L_kwargs_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:27 in forward_refined, code: modified_input_ids = input_ids.clone()
	        modified_input_ids: "i64[1, 10][10, 1]cpu" = l_kwargs_input_ids_.clone()
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:31 in forward_refined, code: modified_input_ids[0, 0] += seq_length
	        getitem: "i64[][]cpu" = modified_input_ids[(0, 0)]
	        getitem += 10;  iadd: "i64[][]cpu" = getitem;  getitem = None
	        modified_input_ids[(0, 0)] = iadd;  setitem = modified_input_ids;  iadd = setitem = None
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:34 in forward_refined, code: print(f"Original first element: {input_ids[0, 0]}")
	        getitem_1: "i64[][]cpu" = l_kwargs_input_ids_[(0, 0)];  l_kwargs_input_ids_ = None
	        return (getitem_1, modified_input_ids)
	        
V0401 21:31:19.638000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "5d1346a051af2a955a11d72c1d42dd3a"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543079638744.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.639000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "a2398fe98e7f3f702a22127acbe630a8"}
	{
	"name": "backend_compile",
	"ts": 1743543079638744.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.648000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "b6f51b73315ee076b7475752cddd4da9"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543079648697.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.684000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "9f707f30b1279384c519811dad0b9552"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:27 in forward_refined, code: modified_input_ids = input_ids.clone()
	        clone: "i64[1, 10][10, 1]cpu" = torch.ops.aten.clone.default(arg0_1)
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:31 in forward_refined, code: modified_input_ids[0, 0] += seq_length
	        select: "i64[10][1]cpu" = torch.ops.aten.select.int(clone, 0, 0)
	        select_1: "i64[][]cpu" = torch.ops.aten.select.int(select, 0, 0);  select = None
	        add: "i64[][]cpu" = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None
	        select_2: "i64[10][1]cpu" = torch.ops.aten.select.int(clone, 0, 0)
	        select_scatter: "i64[10][1]cpu" = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None
	        select_scatter_1: "i64[1, 10][10, 1]cpu" = torch.ops.aten.select_scatter.default(clone, select_scatter, 0, 0);  clone = select_scatter = None
	        select_3: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_4: "i64[][]cpu" = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None
	        select_7: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_8: "i64[][]cpu" = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = None
	        copy: "i64[][]cpu" = torch.ops.aten.copy.default(select_8, select_4);  select_8 = select_4 = None
	        select_9: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_scatter_2: "i64[10][1]cpu" = torch.ops.aten.select_scatter.default(select_9, copy, 0, 0);  select_9 = copy = None
	        select_scatter_3: "i64[1, 10][10, 1]cpu" = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:34 in forward_refined, code: print(f"Original first element: {input_ids[0, 0]}")
	        select_12: "i64[10][1]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None
	        select_13: "i64[][]cpu" = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None
	        return (select_13, select_scatter_3)
	        
V0401 21:31:19.686000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "0be22a83e34d0b7ce6fa34bdd969f07d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543079685658.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.855000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "aa6c1e2773923360bf0614401596276b"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543079855360.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:19.856000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "dd19113ce09de44edf2c8b59b0749c20"}
	{
	"name": "inductor_compile",
	"ts": 1743543079855360.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.533000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/za/cza42ezs6wdnqo3b4nlw4kwua42vqcv5gso47esdzicghfon3frt.py"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "b03204725a32a1e8cfe9a86df64c4b5d"}
	# AOT ID: ['0_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_0 = async_compile.cpp_pybinding(['const int64_t*', 'int64_t*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       int64_t* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp7 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp12 = at::vec::VectorizedN<int64_t,2>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp0 = static_cast<int32_t>(0);
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = x0;
	            auto tmp3 = c10::convert<int32_t>(tmp2);
	            auto tmp4 = at::vec::Vectorized<int32_t>::arange(tmp3, 1);
	            auto tmp5 = at::vec::Vectorized<int32_t>(tmp0);
	            auto tmp6 = at::vec::VecMask<int32_t,1>(tmp4 == tmp5);
	            auto tmp8 = static_cast<int64_t>(10);
	            auto tmp9 = decltype(tmp7)(tmp7 + tmp8);
	            auto tmp10 = tmp1 ? tmp9 : tmp7;
	            auto tmp11 = tmp1 ? tmp10 : tmp7;
	            auto tmp13 = at::vec::VectorizedN<int64_t,2>(tmp9);
	            auto tmp14 = decltype(tmp13)::blendv(tmp12, tmp13, tmp6.template cast<int64_t,2>());
	            auto tmp15 = at::vec::VecMask<float,1>::from(tmp1);
	            auto tmp16 = decltype(tmp14)::blendv(tmp12, tmp14, tmp15.template cast<int64_t,2>());
	            auto tmp17 = at::vec::VectorizedN<int64_t,2>(tmp11);
	            auto tmp18 = decltype(tmp17)::blendv(tmp16, tmp17, tmp6.template cast<int64_t,2>());
	            auto tmp19 = decltype(tmp18)::blendv(tmp16, tmp18, tmp15.template cast<int64_t,2>());
	            tmp19.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp5 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp10 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp0 = static_cast<int32_t>(0);
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = x0;
	            auto tmp3 = c10::convert<int32_t>(tmp2);
	            auto tmp4 = tmp3 == tmp0;
	            auto tmp6 = static_cast<int64_t>(10);
	            auto tmp7 = decltype(tmp5)(tmp5 + tmp6);
	            auto tmp8 = tmp1 ? tmp7 : tmp5;
	            auto tmp9 = tmp1 ? tmp8 : tmp5;
	            auto tmp11 = tmp4 ? tmp7 : tmp10;
	            auto tmp12 = tmp1 ? tmp11 : tmp10;
	            auto tmp13 = tmp4 ? tmp9 : tmp12;
	            auto tmp14 = tmp1 ? tmp13 : tmp12;
	            out_ptr0[static_cast<int64_t>(x0)] = tmp14;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    buf0 = empty_strided_cpu((1, 10), (10, 1), torch.int64)
	    cpp_fused_add_0(arg0_1, buf0)
	    return (reinterpret_tensor(arg0_1, (), (), 0), buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:22.535000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "bb2d60550c8d1f6bd74afd6fd2ec9e24"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543082534669.2,
	"args": {
	"key": "f45yeswqixng4eyeijdmgdg6qxts7wnacm33wctqnuimy5akgqsg",
	"components": [
	"[lhff6jmwhay6uafbrkejb2az4bylpedd2xot6tiu6smleylsdao] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    add = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None\n    select_2 = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_scatter = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None\n    select_scatter_1 = torch.ops.aten.select_scatter.default(arg0_1, select_scatter, 0, 0);  select_scatter = None\n    select_3 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_4 = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None\n    select_7 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_8 = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = select_8 = None\n    select_9 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_scatter_2 = torch.ops.aten.select_scatter.default(select_9, select_4, 0, 0);  select_9 = select_4 = None\n    select_scatter_3 = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None\n    select_12 = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_13 = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None\n    return (select_13, select_scatter_3)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xakmu6hsswqogysgn56movvhqlw4wodj3bhszmkotgxxv3ro4uw] fx_kwargs[user_visible_outputs]: {'select_13': None, 'select_scatter_3': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 6573314886,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:22.536000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "8142b1e4e0519319e771637003402f44"}
	{"key": "f45yeswqixng4eyeijdmgdg6qxts7wnacm33wctqnuimy5akgqsg", "components": ["[lhff6jmwhay6uafbrkejb2az4bylpedd2xot6tiu6smleylsdao] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    add = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None\n    select_2 = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_scatter = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None\n    select_scatter_1 = torch.ops.aten.select_scatter.default(arg0_1, select_scatter, 0, 0);  select_scatter = None\n    select_3 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_4 = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None\n    select_7 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_8 = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = select_8 = None\n    select_9 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_scatter_2 = torch.ops.aten.select_scatter.default(select_9, select_4, 0, 0);  select_9 = select_4 = None\n    select_scatter_3 = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None\n    select_12 = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_13 = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None\n    return (select_13, select_scatter_3)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xakmu6hsswqogysgn56movvhqlw4wodj3bhszmkotgxxv3ro4uw] fx_kwargs[user_visible_outputs]: {'select_13': None, 'select_scatter_3': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 6573314886, "cache_state": "hit"}
V0401 21:31:22.538000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "7ea4b2e054065271e6494bee077a5e13"}
	{
	"name": "inductor_compile",
	"ts": 1743543082538246.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.538000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "2ed6e64c9b46041e2de9f438d9f66b97"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543082538898.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.540000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "d74ce2701371313ceab0ed3f913fb32b"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543082540384.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.543000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "56af18504f397afcb37d4b0e992a631f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543082543708.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.544000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "788fd64b9055b553725647c505606e9c"}
	{
	"name": "backend_compile",
	"ts": 1743543082544607.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.545000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "12381ef34bd7538b26258b2d588e8083"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543082545333.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.556000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "16765dd640e7829a14c57c8c63c0b889"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: len(L['kwargs']) == 1                                       
	| | +- GuardManager: source=L['kwargs']['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | | +- TENSOR_MATCH: check_tensor(L['kwargs']['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(L['kwargs']['input_ids'], '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___1'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___1)
	| | | +- GuardManager: source=G['__builtins_dict___1']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___1']['print'], 123155769910560)
	
V0401 21:31:22.557000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "16a8523d7dfb70c50c1db38b6ed7d80d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082557181.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.558000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "777d63f35bdb78a991096f5d1b509ea1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082558223.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.559000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "0/0", "frame_key": "1", "co_name": "forward_refined", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 19, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 7, "graph_input_count": 1, "start_time": 1743543079.5428905, "entire_frame_compile_time_s": 3.014023780822754, "backend_compile_time_s": 2.9057743549346924, "inductor_compile_time_s": 2.6826012134552, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.misc.StringFormatVariable'>] False"], "dynamo_time_before_restart_s": 0.07354521751403809, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.562000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}]}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.563000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0, "has_payload": "4a31a3ef96db6cd56a838af0241aa4f7"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082563227.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.564000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0, "has_payload": "9b8c7dd4b47a24acf51a832fa870fb3d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082563227.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.569000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 5, "size": 80}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.569000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022fe97980>", "describer_id": 5}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.570000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 5, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.575000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 6, "size": 80}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.576000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022fe97980>", "describer_id": 6}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.577000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 6, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.581000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_modified_input_ids_": [1, 10], "getitem": []}}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "37c5f5824b4dd3725b99b1c5447f0161"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_modified_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_modified_input_ids_ = L_modified_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:35 in torch_dynamo_resume_in_forward_refined_at_34, code: print(f"Modified first element: {modified_input_ids[0, 0]}")
	        getitem: "i64[][]cpu" = l_modified_input_ids_[(0, 0)];  l_modified_input_ids_ = None
	        return (getitem,)
	        
V0401 21:31:22.582000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "11d4ab2933d3d5512bf08f7cdb207fac"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543082582181.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.582000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "63d030a65846859b8a96781845682985"}
	{
	"name": "backend_compile",
	"ts": 1743543082582181.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.585000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "221e67c6544e29519f41f173c6a46895"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543082585423.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.596000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "1cd4c8f6fa09852cb5f89469b8223930"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:35 in torch_dynamo_resume_in_forward_refined_at_34, code: print(f"Modified first element: {modified_input_ids[0, 0]}")
	        select: "i64[10][1]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None
	        select_1: "i64[][]cpu" = torch.ops.aten.select.int(select, 0, 0);  select = None
	        return (select_1,)
	        
V0401 21:31:22.597000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "8aebe209cb606ec987bf1a3840c08893"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543082597171.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.599000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "dbb3a5f326167e565391f3a0f2f0e80d"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543082599285.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.600000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "7a6e423ff938982babdcdbe4ab453de3"}
	{
	"name": "inductor_compile",
	"ts": 1743543082599285.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.608000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/mf/cmfwsynimsavisgwplg33qd33nmpeiz6yigdbqzhgwumgq5l7im3.py"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "02aa93543631a1582a9db906672174f8"}
	# AOT ID: ['1_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    return (reinterpret_tensor(arg0_1, (), (), 0), )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:22.609000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "5e28da12752ea964f938fb80900e8e61"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543082608624.8,
	"args": {
	"key": "fjjuflzqe3xa3bki3hrdezh2yb7fcvpr5a7vabgq2eqgcfqqmqpa",
	"components": [
	"[fl2wa3duqskceg3a4tsvilaaejxeh5hx5joo6yg7wnyjgjtwpfr] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    return (select_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[vnytv4vvduj2micgs6fvhtgyftmyf4tv24dcsrt3c2rpsdyaevy] fx_kwargs[user_visible_outputs]: {'select_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 17118202,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:22.610000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "6ff4022008a9b440da7b9a59ac7c88f4"}
	{"key": "fjjuflzqe3xa3bki3hrdezh2yb7fcvpr5a7vabgq2eqgcfqqmqpa", "components": ["[fl2wa3duqskceg3a4tsvilaaejxeh5hx5joo6yg7wnyjgjtwpfr] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    return (select_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[vnytv4vvduj2micgs6fvhtgyftmyf4tv24dcsrt3c2rpsdyaevy] fx_kwargs[user_visible_outputs]: {'select_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 17118202, "cache_state": "hit"}
V0401 21:31:22.611000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "9043d93ccb905a2f876fa5853d210cd4"}
	{
	"name": "inductor_compile",
	"ts": 1743543082611202.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.612000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "081d0d887b5b0aede57ea3dc123442b0"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543082612092.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.613000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "baf50f23098a59e3e240524857dd2753"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543082613516.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.616000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "d5b4b7002bbeab4665803a237610eb1b"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543082616765.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.617000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "8b278f85705173536e32afca0f400405"}
	{
	"name": "backend_compile",
	"ts": 1743543082617579.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.618000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "09e5e7c1e51311cfee387966c3316c88"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543082618408.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.631000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "d0fb8f5f1ad17a0fb214e345a34bb159"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['modified_input_ids'], accessed_by=DictGetItemGuardAccessor(modified_input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['modified_input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['modified_input_ids'], '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___5'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___5)
	| | | +- GuardManager: source=G['__builtins_dict___5']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___5']['print'], 123155769910560)
	
V0401 21:31:22.632000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "3a587a9a652229981c4944baed021248"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082632221.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.633000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "d4dd00c62f4938b61e7b8c1836aa0654"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082633109.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.634000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "1/0", "frame_key": "2", "co_name": "torch_dynamo_resume_in_forward_refined_at_34", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 34, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 1, "graph_node_count": 3, "graph_input_count": 1, "start_time": 1743543082.5632136, "entire_frame_compile_time_s": 0.06891441345214844, "backend_compile_time_s": 0.035299062728881836, "inductor_compile_time_s": 0.011819839477539062, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.misc.StringFormatVariable'>] False"], "dynamo_time_before_restart_s": 0.008287191390991211, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.635000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}]}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.636000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0, "has_payload": "1e4eef63cdb8b92547b3a4fbedf230b2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082636525.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.637000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0, "has_payload": "f2494d4bf5501b43471b58f331582f90"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082636525.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.657000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "fe84aec992292e2da915b7bdd74f01ab"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['seq_length'], accessed_by=DictGetItemGuardAccessor(seq_length)
	| | +- EQUALS_MATCH: L['seq_length'] == 10                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___9'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___9)
	| | | +- GuardManager: source=G['__builtins_dict___9']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___9']['print'], 123155769910560)
	
V0401 21:31:22.658000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "c3c75bfe414651ec642eb695a79b393c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082658487.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.659000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "ea38a23d0b55e70be3a1ae3dcc58fa2b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082659498.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.660000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "2/0", "frame_key": "3", "co_name": "torch_dynamo_resume_in_forward_refined_at_35", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 35, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543082.6365142, "entire_frame_compile_time_s": 0.021854877471923828, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.constant.ConstantVariable'>] False"], "dynamo_time_before_restart_s": 0.0027959346771240234, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.662000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 36, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}]}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.663000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "dc7dc9c3a0f958ec0ec39b431cb04e25"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082663092.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.664000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "9bb68e90fcbb0728dc3cabba93befa04"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082663092.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.667000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 10, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.668000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70026fcd92c0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.669000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 0, "source": "L['input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.749000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 11, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.750000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70026fcd92c0>", "describer_id": 11}, "frame_id": 3, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.751000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 11, "id": 0, "source": "L['input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.760000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 12, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:31:22.761000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70026fcd92c0>", "describer_id": 12}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:31:22.762000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 12, "id": 0, "source": "L['input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:31:22.771000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_input_ids_": [1, 10], "cpu": [1, 10], "input_ids_np": [1, 10]}}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "c74eb8f1fcfac94e6d35f9dd4236f6ca"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_input_ids_ = L_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:40 in torch_dynamo_resume_in_forward_refined_at_36, code: input_ids_np = input_ids.cpu().numpy()
	        cpu: "i64[1, 10][10, 1]cpu" = l_input_ids_.cpu();  l_input_ids_ = None
	        input_ids_np: "i64[1, 10][10, 1]cpu" = cpu.view_as(cpu);  cpu = None
	        return (input_ids_np,)
	        
V0401 21:31:22.772000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "f0d3c8e4000e867babeddcd88360f4ed"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543082772138.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.772000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "69dba61aec9709f5ad32988366f35c3d"}
	{
	"name": "backend_compile",
	"ts": 1743543082772138.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.775000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "e022649f4d23a8ee91c358264424f43e"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543082775386.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.785000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "e6e59f19e0b541b9e36bef4b4d515d57"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:40 in torch_dynamo_resume_in_forward_refined_at_36, code: input_ids_np = input_ids.cpu().numpy()
	        view: "i64[1, 10][10, 1]cpu" = torch.ops.aten.view.default(arg0_1, [1, 10]);  arg0_1 = None
	        return (view,)
	        
V0401 21:31:22.786000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "419e11f0c0cb7be9eb7afd65bb420bf7"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543082786638.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.789000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "46652eba8fa2b0ece6c1bc5d723b58e7"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543082788828.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.789000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "9a46b6a6748a8d731004a5f4530bd1ab"}
	{
	"name": "inductor_compile",
	"ts": 1743543082788828.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.791000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "d3d968ebb3bc0a032edff3b23a3a3c16"}
	{
	"name": "inductor_compile",
	"ts": 1743543082791212.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.791000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "45a1493370f3997f3e81a64267812d05"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543082791838.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.793000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "d2071035a390da8ccf9e9d0f8dc30b05"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543082793068.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.796000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "0bf843ac6b10916a92c6877ad389702a"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543082796151.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.797000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "387ac375312e746d35af0f2acf9da661"}
	{
	"name": "backend_compile",
	"ts": 1743543082797142.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.798000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "a443eb7c86554dd5efd757fb294db207"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543082797941.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.804000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "207c02aa8dd504f02459c6c4e52e11c5"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False 
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['umap'], accessed_by=DictGetItemGuardAccessor(umap)
	| | | +- ID_MATCH: ___check_obj_id(G['umap'], 123155225140320)                 
	| | | +- GuardManager: source=G['umap'].UMAP, accessed_by=GetAttrGuardAccessor(UMAP)
	| | | | +- ID_MATCH: ___check_obj_id(G['umap'].UMAP, 105251536270224)            
	
V0401 21:31:22.804000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "8964b99c425362a2c7f1e85d9259be09"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082804874.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.806000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "36d2c58da2802cb7d491a8350119232c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082805959.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.807000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "3/0", "frame_key": "4", "co_name": "torch_dynamo_resume_in_forward_refined_at_36", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 36, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 8, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543082.6630805, "entire_frame_compile_time_s": 0.14170360565185547, "backend_compile_time_s": 0.024917125701904297, "inductor_compile_time_s": 0.0023107528686523438, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["'skip function check_array in file /home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py'", "Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.0933537483215332, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:31:22.809000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", 4]}
V0401 21:31:22.809000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 2890, "name": "fit_transform", "filename": 4}]}, "frame_id": 4, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.810000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 0, "has_payload": "8e35b29bdf319ea6a02ef407119b31bf"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082810874.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.811000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 0, "has_payload": "b2ec54587486207b38f6aee12450a33e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082810874.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.833000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 15, "size": 80}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.833000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022fe975c0>", "describer_id": 15}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.834000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 15, "id": 0, "source": "___from_numpy(L['X'])"}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.843000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1, "has_payload": "e59e51dd26701e45c1ecefd191c18d72"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=L['X'], accessed_by=DictGetItemGuardAccessor(X)
	| | +- GuardManager: source=___from_numpy(L['X']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['X']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['X']), '_dynamo_dynamic_indices') == False
	
V0401 21:31:22.844000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1, "has_payload": "af7c091f61d2c9bf2d62cf08daa07efd"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082844260.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.845000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1, "has_payload": "41d4013873cd08dbff0855a6f03a32f6"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082845207.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.846000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "4/0", "frame_key": "5", "co_name": "fit_transform", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2890, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543082.8108623, "entire_frame_compile_time_s": 0.03328299522399902, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["'skip function check_array in file /home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py'"], "dynamo_time_before_restart_s": 0.017703533172607422, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.849000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2339, "name": "fit", "filename": 4}]}, "frame_id": 5, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.849000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 0, "has_payload": "eba28fb71e9056a3a626750c213170b0"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082849743.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.850000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 0, "has_payload": "7388d3cd51b889d8fd26081cd64a9d00"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082849743.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.885000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 17, "size": 80}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.886000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14fb60>", "describer_id": 17}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.887000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 17, "id": 0, "source": "___from_numpy(L['X'])"}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.955000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1, "has_payload": "12fb2188757f60c6076c62b25e72fae0"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].metric, accessed_by=GetAttrGuardAccessor(metric)
	| | | +- EQUALS_MATCH: L['self'].metric == 'euclidean'                             
	| +- GuardManager: source=L['force_all_finite'], accessed_by=DictGetItemGuardAccessor(force_all_finite)
	| | +- ID_MATCH: ___check_obj_id(L['force_all_finite'], 105251315000224)     
	| +- GuardManager: source=L['X'], accessed_by=DictGetItemGuardAccessor(X)
	| | +- GuardManager: source=___from_numpy(L['X']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['X']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['X']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].float32, accessed_by=GetAttrGuardAccessor(float32)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].float32, 123155389871904)           
	| | +- GuardManager: source=G['check_array'], accessed_by=DictGetItemGuardAccessor(check_array)
	| | | +- ID_MATCH: ___check_obj_id(G['check_array'], 123154980229248)          
	
V0401 21:31:22.956000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1, "has_payload": "4288f9150eee0f084692309027a18688"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082955913.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.957000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1, "has_payload": "1363fb1c9ef7d76dc5c7a5a50ba1bb3e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082956930.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.957000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "5/0", "frame_key": "6", "co_name": "fit", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2339, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543082.8497322, "entire_frame_compile_time_s": 0.10606098175048828, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["'skip function check_array in file /home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py'"], "dynamo_time_before_restart_s": 0.01622176170349121, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:22.964000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/sparse/_base.py", 5]}
V0401 21:31:22.965000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 1335, "name": "issparse", "filename": 5}]}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.966000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "b0f13458d3200bd75b53b500694a611f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082966304.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.967000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "a5fe6fc5dc8dad91ab39a30668e04765"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082966304.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.971000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 18, "size": 80}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.975000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1ea120>", "describer_id": 18}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.977000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 18, "id": 0, "source": "___from_numpy(L['x'])"}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.979000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "0519376d5e8810fbf1b1bcfe0ea4a9d7"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082979185.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.980000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "c1c316b30c743eada03ebbec5d618921"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082980069.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.981000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "6/0", "frame_key": "15", "co_name": "issparse", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/sparse/_base.py", "co_firstlineno": 1335, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543082.966291, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.014680147171020508, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.987000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}]}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:22.987000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0, "has_payload": "afa61e5ee8a20f5c1d46acfcfde934b2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543082987802.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:22.988000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0, "has_payload": "d28b4fc00f2c6931c489635756458ea1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543082987802.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.004000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 19, "size": 40}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.005000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f147390>", "describer_id": 19}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.005000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 19, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.036000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 20, "size": 40}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.037000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f653ed0>", "describer_id": 20}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.038000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 20, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.174000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1, "has_payload": "ed2346f58aa8c3baa8c3ec899bef89a6"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].a, accessed_by=GetAttrGuardAccessor(a)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].a, 105251315093216)               
	| | +- GuardManager: source=L['self'].spread, accessed_by=GetAttrGuardAccessor(spread)
	| | | +- EQUALS_MATCH: L['self'].spread == 1.0                                     
	| | +- GuardManager: source=L['self'].min_dist, accessed_by=GetAttrGuardAccessor(min_dist)
	| | | +- EQUALS_MATCH: L['self'].min_dist == 0.1                                   
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['find_ab_params'], accessed_by=DictGetItemGuardAccessor(find_ab_params)
	| | | +- GuardManager: source=G['find_ab_params'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['find_ab_params'].__code__, 123154972028288)
	
V0401 21:31:23.175000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1, "has_payload": "38cd59902cadf7c46c4e1436af5bac12"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083175606.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.176000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1, "has_payload": "5629aa3333214fdb0c83bdd398caa6a3"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083176601.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.177000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "7/0", "frame_key": "21", "co_name": "torch_dynamo_resume_in_fit_at_2372", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2372, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543082.9877908, "entire_frame_compile_time_s": 0.18768310546875, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.0312800407409668, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.179000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 1393, "name": "find_ab_params", "filename": 4}]}, "frame_id": 8, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.180000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 0, "has_payload": "ce38d61de2722ded77a86f4a3feb914b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083180210.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.181000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 0, "has_payload": "7c3287fe12b8ec668079633de9857178"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083180210.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.208000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"xv": [300], "yv": [300], "wrapped_lt": [300], "wrapped_ge": [300]}}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "55f47d9e0bf1af31c29501dfe1fba563"}
	class GraphModule(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1403 in find_ab_params, code: xv = np.linspace(0, spread * 3, 300)
	        xv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_linspace(0, 3.0, 300)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1404 in find_ab_params, code: yv = np.zeros(xv.shape)
	        yv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_zeros((300,))
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1405 in find_ab_params, code: yv[xv < min_dist] = 1.0
	        wrapped_lt: "b8[300][1]cpu" = torch__dynamo_utils_wrapped_lt(xv, 0.1)
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(yv, wrapped_lt, 1.0);  wrapped_lt = wrapped___setitem__ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in find_ab_params, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        wrapped_ge: "b8[300][1]cpu" = torch__dynamo_utils_wrapped_ge(xv, 0.1)
	        return (xv, wrapped_ge, yv)
	        
V0401 21:31:23.209000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "8f5d413dced5cf6a1d1743ab444f2e45"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083209479.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.210000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "bb5089f906c333919cec1fa1f148e9e7"}
	{
	"name": "backend_compile",
	"ts": 1743543083209479.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.213000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "8a0735324c7a35dd531f69f6262517eb"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083213423.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.267000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "884d6c6132cd21993a3f7096f47aa4c0"}
	class <lambda>(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1403 in find_ab_params, code: xv = np.linspace(0, spread * 3, 300)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "i64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        _tensor_constant1 = self._tensor_constant1
	        lift_fresh_copy_1: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None
	        convert_element_type: "f64[][]cpu" = torch.ops.prims.convert_element_type.default(lift_fresh_copy, torch.float64);  lift_fresh_copy = None
	        iota: "i64[300][1]cpu" = torch.ops.prims.iota.default(300, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)
	        sub: "f64[][]cpu" = torch.ops.aten.sub.Tensor(lift_fresh_copy_1, convert_element_type)
	        div: "f64[][]cpu" = torch.ops.aten.div.Tensor(sub, 299);  sub = None
	        lt: "b8[300][1]cpu" = torch.ops.aten.lt.Scalar(iota, 150.0)
	        convert_element_type_1: "f64[300][1]cpu" = torch.ops.prims.convert_element_type.default(iota, torch.float64)
	        mul: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(div, convert_element_type_1);  convert_element_type_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(convert_element_type, mul);  convert_element_type = mul = None
	        sub_1: "i64[300][1]cpu" = torch.ops.aten.sub.Tensor(299, iota);  iota = None
	        convert_element_type_2: "f64[300][1]cpu" = torch.ops.prims.convert_element_type.default(sub_1, torch.float64);  sub_1 = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(div, convert_element_type_2);  div = convert_element_type_2 = None
	        sub_2: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(lift_fresh_copy_1, mul_1);  lift_fresh_copy_1 = mul_1 = None
	        where: "f64[300][1]cpu" = torch.ops.aten.where.self(lt, add, sub_2);  lt = add = sub_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1404 in find_ab_params, code: yv = np.zeros(xv.shape)
	        full: "f64[300][1]cpu" = torch.ops.aten.full.default([300], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1405 in find_ab_params, code: yv[xv < min_dist] = 1.0
	        _tensor_constant2 = self._tensor_constant2
	        lift_fresh_copy_2: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant2);  _tensor_constant2 = None
	        lt_1: "b8[300][1]cpu" = torch.ops.aten.lt.Tensor(where, lift_fresh_copy_2);  lift_fresh_copy_2 = None
	        _tensor_constant3 = self._tensor_constant3
	        lift_fresh_copy_3: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant3);  _tensor_constant3 = None
	        index_put: "f64[300][1]cpu" = torch.ops.aten.index_put.default(full, [lt_1], lift_fresh_copy_3);  full = lt_1 = lift_fresh_copy_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in find_ab_params, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        _tensor_constant4 = self._tensor_constant4
	        lift_fresh_copy_4: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant4);  _tensor_constant4 = None
	        ge: "b8[300][1]cpu" = torch.ops.aten.ge.Tensor(where, lift_fresh_copy_4);  lift_fresh_copy_4 = None
	        return (where, ge, index_put)
	        
V0401 21:31:23.268000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "e301c3def64e7c87baac3d213cde0997"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083267957.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.276000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "72cdf4512c3d3609a4fd348ae7e9293d"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083276428.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.279000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "a5de0fc15182f0e52c10d0749a528a56"}
	{
	"name": "inductor_compile",
	"ts": 1743543083276428.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.297000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/nt/cntbgzb2vnymycik6kg4ylecrpu5yugftj55begun2ly3v6e4hki.py"}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "7d18f30503b2495a7d180c4f4a95ff5c"}
	# AOT ID: ['3_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_ge_index_put_lift_fresh_linspace_zeros_0 = async_compile.cpp_pybinding(['double*', 'bool*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(double* out_ptr0,
	                       bool* out_ptr1,
	                       double* out_ptr2)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = at::vec::Vectorized<float>::arange(tmp1, 1);
	            auto tmp3 = static_cast<float>(150.0);
	            auto tmp4 = at::vec::Vectorized<float>(tmp3);
	            auto tmp5 = at::vec::VecMask<float,1>(tmp2 < tmp4);
	            auto tmp6 = static_cast<double>(0.010033444816053512);
	            auto tmp7 = c10::convert<double>(tmp0);
	            auto tmp8 = at::vec::VectorizedN<double,2>::arange(tmp7, 1);
	            auto tmp9 = at::vec::VectorizedN<double,2>(tmp6);
	            auto tmp10 = tmp9 * tmp8;
	            auto tmp11 = 299L + ((-1L)*x0);
	            auto tmp12 = c10::convert<double>(tmp11);
	            auto tmp13 = at::vec::VectorizedN<double,2>::arange(tmp12, -1);
	            auto tmp14 = tmp9 * tmp13;
	            auto tmp15 = static_cast<double>(3.0);
	            auto tmp16 = at::vec::VectorizedN<double,2>(tmp15);
	            auto tmp17 = tmp16 - tmp14;
	            auto tmp18 = decltype(tmp10)::blendv(tmp17, tmp10, tmp5.template cast<double,2>());
	            tmp18.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = static_cast<float>(150.0);
	            auto tmp3 = tmp1 < tmp2;
	            auto tmp4 = static_cast<double>(0.010033444816053512);
	            auto tmp5 = c10::convert<double>(tmp0);
	            auto tmp6 = decltype(tmp4)(tmp4 * tmp5);
	            auto tmp7 = 299L + ((-1L)*x0);
	            auto tmp8 = c10::convert<double>(tmp7);
	            auto tmp9 = decltype(tmp4)(tmp4 * tmp8);
	            auto tmp10 = static_cast<double>(3.0);
	            auto tmp11 = decltype(tmp10)(tmp10 - tmp9);
	            auto tmp12 = tmp3 ? tmp6 : tmp11;
	            out_ptr0[static_cast<int64_t>(x0)] = tmp12;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = at::vec::Vectorized<float>::arange(tmp1, 1);
	            auto tmp3 = static_cast<float>(150.0);
	            auto tmp4 = at::vec::Vectorized<float>(tmp3);
	            auto tmp5 = at::vec::VecMask<float,1>(tmp2 < tmp4);
	            auto tmp6 = static_cast<double>(0.010033444816053512);
	            auto tmp7 = c10::convert<double>(tmp0);
	            auto tmp8 = at::vec::VectorizedN<double,2>::arange(tmp7, 1);
	            auto tmp9 = at::vec::VectorizedN<double,2>(tmp6);
	            auto tmp10 = tmp9 * tmp8;
	            auto tmp11 = 299L + ((-1L)*x0);
	            auto tmp12 = c10::convert<double>(tmp11);
	            auto tmp13 = at::vec::VectorizedN<double,2>::arange(tmp12, -1);
	            auto tmp14 = tmp9 * tmp13;
	            auto tmp15 = static_cast<double>(3.0);
	            auto tmp16 = at::vec::VectorizedN<double,2>(tmp15);
	            auto tmp17 = tmp16 - tmp14;
	            auto tmp18 = decltype(tmp10)::blendv(tmp17, tmp10, tmp5.template cast<double,2>());
	            auto tmp19 = static_cast<double>(0.1);
	            auto tmp20 = at::vec::VectorizedN<double,2>(tmp19);
	            auto tmp21 = at::vec::VecMask<double,2>(tmp18 >= tmp20);
	            tmp21.store(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = static_cast<float>(150.0);
	            auto tmp3 = tmp1 < tmp2;
	            auto tmp4 = static_cast<double>(0.010033444816053512);
	            auto tmp5 = c10::convert<double>(tmp0);
	            auto tmp6 = decltype(tmp4)(tmp4 * tmp5);
	            auto tmp7 = 299L + ((-1L)*x0);
	            auto tmp8 = c10::convert<double>(tmp7);
	            auto tmp9 = decltype(tmp4)(tmp4 * tmp8);
	            auto tmp10 = static_cast<double>(3.0);
	            auto tmp11 = decltype(tmp10)(tmp10 - tmp9);
	            auto tmp12 = tmp3 ? tmp6 : tmp11;
	            auto tmp13 = static_cast<double>(0.1);
	            auto tmp14 = tmp12 >= tmp13;
	            out_ptr1[static_cast<int64_t>(x0)] = tmp14;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = at::vec::Vectorized<float>::arange(tmp1, 1);
	            auto tmp3 = static_cast<float>(150.0);
	            auto tmp4 = at::vec::Vectorized<float>(tmp3);
	            auto tmp5 = at::vec::VecMask<float,1>(tmp2 < tmp4);
	            auto tmp6 = static_cast<double>(0.010033444816053512);
	            auto tmp7 = c10::convert<double>(tmp0);
	            auto tmp8 = at::vec::VectorizedN<double,2>::arange(tmp7, 1);
	            auto tmp9 = at::vec::VectorizedN<double,2>(tmp6);
	            auto tmp10 = tmp9 * tmp8;
	            auto tmp11 = 299L + ((-1L)*x0);
	            auto tmp12 = c10::convert<double>(tmp11);
	            auto tmp13 = at::vec::VectorizedN<double,2>::arange(tmp12, -1);
	            auto tmp14 = tmp9 * tmp13;
	            auto tmp15 = static_cast<double>(3.0);
	            auto tmp16 = at::vec::VectorizedN<double,2>(tmp15);
	            auto tmp17 = tmp16 - tmp14;
	            auto tmp18 = decltype(tmp10)::blendv(tmp17, tmp10, tmp5.template cast<double,2>());
	            auto tmp19 = static_cast<double>(0.1);
	            auto tmp20 = at::vec::VectorizedN<double,2>(tmp19);
	            auto tmp21 = at::vec::VecMask<double,2>(tmp18 < tmp20);
	            auto tmp22 = static_cast<double>(1.0);
	            auto tmp23 = static_cast<double>(0.0);
	            auto tmp24 = at::vec::VectorizedN<double,2>(tmp22);
	            auto tmp25 = at::vec::VectorizedN<double,2>(tmp23);
	            auto tmp26 = decltype(tmp24)::blendv(tmp25, tmp24, tmp21.template cast<double,2>());
	            tmp26.store(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = static_cast<float>(150.0);
	            auto tmp3 = tmp1 < tmp2;
	            auto tmp4 = static_cast<double>(0.010033444816053512);
	            auto tmp5 = c10::convert<double>(tmp0);
	            auto tmp6 = decltype(tmp4)(tmp4 * tmp5);
	            auto tmp7 = 299L + ((-1L)*x0);
	            auto tmp8 = c10::convert<double>(tmp7);
	            auto tmp9 = decltype(tmp4)(tmp4 * tmp8);
	            auto tmp10 = static_cast<double>(3.0);
	            auto tmp11 = decltype(tmp10)(tmp10 - tmp9);
	            auto tmp12 = tmp3 ? tmp6 : tmp11;
	            auto tmp13 = static_cast<double>(0.1);
	            auto tmp14 = tmp12 < tmp13;
	            auto tmp15 = static_cast<double>(1.0);
	            auto tmp16 = static_cast<double>(0.0);
	            auto tmp17 = tmp14 ? tmp15 : tmp16;
	            out_ptr2[static_cast<int64_t>(x0)] = tmp17;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    buf0 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((300, ), (1, ), torch.bool)
	    buf2 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_ge_index_put_lift_fresh_linspace_zeros_0(buf0, buf1, buf2)
	    return (buf0, buf1, buf2, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    fn = lambda: call([])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:23.298000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "862943ecd7d81ddbd305450055dc1789"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543083298576.8,
	"args": {
	"key": "fzl5qjtrd5cithub2slqbdncrkoutl6amq6o3cvtjbteozwxhueh",
	"components": [
	"[tonr2mrgdlu2nen3ozhu3ijdxmfcg2rjrzqzmvblwymuszvx3sd] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = lift_fresh_copy = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default = torch.ops.aten.full.default([], 3.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False);  full_default_1 = None\n    iota = torch.ops.prims.iota.default(300, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    full_default_2 = torch.ops.aten.full.default([], 0.010033444816053512, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Scalar(iota, 150.0)\n    convert_element_type_1 = torch.ops.prims.convert_element_type.default(iota, torch.float64)\n    mul = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_1);  convert_element_type_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(299, iota);  iota = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(sub_1, torch.float64);  sub_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_2);  full_default_2 = convert_element_type_2 = None\n    sub_2 = torch.ops.aten.sub.Tensor(full_default, mul_1);  full_default = mul_1 = None\n    where = torch.ops.aten.where.self(lt, mul, sub_2);  lt = mul = sub_2 = None\n    full_default_3 = torch.ops.aten.full.default([300], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    _tensor_constant2 = self._tensor_constant2;  _tensor_constant2 = None\n    full_default_4 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt_1 = torch.ops.aten.lt.Tensor(where, full_default_4);  full_default_4 = None\n    _tensor_constant3 = self._tensor_constant3;  _tensor_constant3 = None\n    full_default_5 = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    index_put = torch.ops.aten.index_put.default(full_default_3, [lt_1], full_default_5);  full_default_3 = lt_1 = full_default_5 = None\n    _tensor_constant4 = self._tensor_constant4;  _tensor_constant4 = None\n    full_default_6 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(where, full_default_6);  full_default_6 = None\n    return (where, ge, index_put)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[4pgrl5wuvi6oqmjehmimwaduhxq6rrasw6f65kiwgepz2acoxp2] fx_kwargs[user_visible_outputs]: {'where': None, 'ge': None, 'index_put': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 3291860166,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:23.300000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "ec3523ba2c99e5b67ac979a96345da4f"}
	{"key": "fzl5qjtrd5cithub2slqbdncrkoutl6amq6o3cvtjbteozwxhueh", "components": ["[tonr2mrgdlu2nen3ozhu3ijdxmfcg2rjrzqzmvblwymuszvx3sd] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = lift_fresh_copy = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default = torch.ops.aten.full.default([], 3.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False);  full_default_1 = None\n    iota = torch.ops.prims.iota.default(300, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    full_default_2 = torch.ops.aten.full.default([], 0.010033444816053512, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Scalar(iota, 150.0)\n    convert_element_type_1 = torch.ops.prims.convert_element_type.default(iota, torch.float64)\n    mul = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_1);  convert_element_type_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(299, iota);  iota = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(sub_1, torch.float64);  sub_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_2);  full_default_2 = convert_element_type_2 = None\n    sub_2 = torch.ops.aten.sub.Tensor(full_default, mul_1);  full_default = mul_1 = None\n    where = torch.ops.aten.where.self(lt, mul, sub_2);  lt = mul = sub_2 = None\n    full_default_3 = torch.ops.aten.full.default([300], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    _tensor_constant2 = self._tensor_constant2;  _tensor_constant2 = None\n    full_default_4 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt_1 = torch.ops.aten.lt.Tensor(where, full_default_4);  full_default_4 = None\n    _tensor_constant3 = self._tensor_constant3;  _tensor_constant3 = None\n    full_default_5 = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    index_put = torch.ops.aten.index_put.default(full_default_3, [lt_1], full_default_5);  full_default_3 = lt_1 = full_default_5 = None\n    _tensor_constant4 = self._tensor_constant4;  _tensor_constant4 = None\n    full_default_6 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(where, full_default_6);  full_default_6 = None\n    return (where, ge, index_put)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[4pgrl5wuvi6oqmjehmimwaduhxq6rrasw6f65kiwgepz2acoxp2] fx_kwargs[user_visible_outputs]: {'where': None, 'ge': None, 'index_put': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 3291860166, "cache_state": "hit"}
V0401 21:31:23.302000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "fb71a17c92b592636fa7e0c43d8c3d5b"}
	{
	"name": "inductor_compile",
	"ts": 1743543083301924.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.304000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "e41b8464f423fbf9550e26c976d568f2"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083304269.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.307000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "f806612c4211485f439ad192d1dce0a8"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083307201.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.311000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "5bb52e6c42feca47ff094eba0378c487"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083311152.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.312000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "55bb7f81e62259a56438661c357b9972"}
	{
	"name": "backend_compile",
	"ts": 1743543083311976.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.312000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "68bc79f80513206824fc935ad3428669"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083312808.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.320000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "be4b18bb97dd216be39f7e740b6cab04"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['spread'], accessed_by=DictGetItemGuardAccessor(spread)
	| | +- EQUALS_MATCH: L['spread'] == 1.0                                          
	| +- GuardManager: source=L['min_dist'], accessed_by=DictGetItemGuardAccessor(min_dist)
	| | +- EQUALS_MATCH: L['min_dist'] == 0.1                                        
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].exp, accessed_by=GetAttrGuardAccessor(exp)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].exp, 123155762880576)               
	| | | +- GuardManager: source=G['np'].zeros, accessed_by=GetAttrGuardAccessor(zeros)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].zeros, 123155762228624)             
	| | | +- GuardManager: source=G['np'].linspace, accessed_by=GetAttrGuardAccessor(linspace)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].linspace, 123155306899184)          
	
V0401 21:31:23.321000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "a51a14169ba0de7668d716aab3a38f4b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083321371.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.322000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "9e1ac0e580b4ca355b6509708a811495"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083322334.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.323000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "8/0", "frame_key": "22", "co_name": "find_ab_params", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1393, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 6, "graph_input_count": 0, "start_time": 1743543083.1801999, "entire_frame_compile_time_s": 0.14107608795166016, "backend_compile_time_s": 0.1024167537689209, "inductor_compile_time_s": 0.025390625, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.010972261428833008, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.326000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}]}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.327000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0, "has_payload": "1712fef389953bb0fd2edfbcfc00e8f4"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083326960.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.327000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0, "has_payload": "7d8c59081275c2e1b946b98580fd3b36"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083326960.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.330000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 24, "size": 2320}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.332000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [290], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6cd900>", "describer_id": 24}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.333000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 24, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.349000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 24, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.351000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022feacb40>", "describer_id": 24}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.356000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 24, "id": 5, "source": "___from_numpy(L['xv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.363000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 24, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.366000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6af750>", "describer_id": 24}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.369000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 24, "id": 8, "source": "___from_numpy(L['yv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.441000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 25, "size": 2320}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.442000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [290], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f7f4550>", "describer_id": 25}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.444000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 25, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.452000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 25, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.455000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6d55e0>", "describer_id": 25}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.458000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 25, "id": 1, "source": "___from_numpy(L['xv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.464000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 25, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.466000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6d5810>", "describer_id": 25}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.469000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 25, "id": 4, "source": "___from_numpy(L['yv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.475000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack1_": [290], "l_xv_": [300], "l_yv_": [300], "wrapped_sub": [290], "wrapped_neg": [290], "wrapped_truediv": [290], "wrapped_exp": [290], "wrapped_ge": [300]}}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "c480bb8f9ce479ebbca554f41be8f641"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack1_: "f64[290][1]cpu", L_xv_: "f64[300][1]cpu", L_yv_: "f64[300][1]cpu"):
	        l_stack1_ = L_stack1_
	        l_xv_ = L_xv_
	        l_yv_ = L_yv_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in torch_dynamo_resume_in_find_ab_params_at_1406, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        wrapped_sub: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_sub(l_stack1_, 0.1);  l_stack1_ = None
	        wrapped_neg: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_neg(wrapped_sub);  wrapped_sub = None
	        wrapped_truediv: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_truediv(wrapped_neg, 1.0);  wrapped_neg = None
	        wrapped_exp: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_exp(wrapped_truediv);  wrapped_truediv = None
	        wrapped_ge: "b8[300][1]cpu" = torch__dynamo_utils_wrapped_ge(l_xv_, 0.1);  l_xv_ = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_yv_, wrapped_ge, wrapped_exp);  l_yv_ = wrapped_ge = wrapped_exp = wrapped___setitem__ = None
	        return ()
	        
V0401 21:31:23.476000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "4db74c7980a234757560024a4d53fa98"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083476194.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.477000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "dd1874e1bd0dd50aacb3c7a3d1d944e7"}
	{
	"name": "backend_compile",
	"ts": 1743543083476194.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.481000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "968dfca8c13413579bf7fca28bebabf8"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083481234.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.514000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "9fb4be2f26b589c77f4084b871f6897a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[290][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[300][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in torch_dynamo_resume_in_find_ab_params_at_1406, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        sub: "f64[290][1]cpu" = torch.ops.aten.sub.Tensor(arg0_1, 0.1);  arg0_1 = None
	        neg: "f64[290][1]cpu" = torch.ops.aten.neg.default(sub);  sub = None
	        div: "f64[290][1]cpu" = torch.ops.aten.div.Tensor(neg, 1.0);  neg = None
	        exp: "f64[290][1]cpu" = torch.ops.aten.exp.default(div);  div = None
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        ge: "b8[300][1]cpu" = torch.ops.aten.ge.Tensor(arg1_1, lift_fresh_copy);  arg1_1 = lift_fresh_copy = None
	        index_put: "f64[300][1]cpu" = torch.ops.aten.index_put.default(arg2_1, [ge], exp);  ge = exp = None
	        copy_: "f64[300][1]cpu" = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None
	        return ()
	        
V0401 21:31:23.516000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "f70dce2a129c72b3e8c415d9c6f1df05"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083515749.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.521000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "39b970f54d93fb0d036dad840f8a7e8e"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083520985.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.521000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "c833d465adb1a28cbf29da65a7a84af6"}
	{
	"name": "inductor_compile",
	"ts": 1743543083520985.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.533000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/dk/cdk6qhze7a7o4zdrvtlr5ny5lhfq4ej3ylypq7rudzh2emcmthg2.py"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "4aa7b9ddca4abb04bcd64a9ecd07eed1"}
	# AOT ID: ['4_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_div_exp_ge_lift_fresh_neg_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'double*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       double* out_ptr0,
	                       bool* out_ptr1)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(288L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::VectorizedN<double,2>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = at::vec::VectorizedN<double,2>(tmp1);
	            auto tmp3 = tmp0 - tmp2;
	            auto tmp4 = tmp3.neg();
	            auto tmp5 = static_cast<double>(1.0);
	            auto tmp6 = at::vec::VectorizedN<double,2>(tmp5);
	            auto tmp7 = tmp4 * tmp6;
	            auto tmp8 = tmp7.exp();
	            tmp8.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(288L); x0<static_cast<int64_t>(290L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = decltype(tmp0)(tmp0 - tmp1);
	            auto tmp3 = decltype(tmp2)(-tmp2);
	            auto tmp4 = static_cast<double>(1.0);
	            auto tmp5 = decltype(tmp3)(tmp3 * tmp4);
	            auto tmp6 = std::exp(tmp5);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp6;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = at::vec::VectorizedN<double,2>(tmp1);
	            auto tmp3 = at::vec::VecMask<double,2>(tmp0 >= tmp2);
	            tmp3.store(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = tmp0 >= tmp1;
	            out_ptr1[static_cast<int64_t>(x0)] = tmp2;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (290, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (300, ), (1, ))
	    buf0 = empty_strided_cpu((290, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((300, ), (1, ), torch.bool)
	    cpp_fused_div_exp_ge_lift_fresh_neg_sub_0(arg0_1, arg1_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    aten.index_put_(arg2_1, [buf1], buf0, False)
	    del arg2_1
	    return ()
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((290, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:23.534000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "797aeb6e29bffc8de6f5a62713f7d7e1"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543083534424.0,
	"args": {
	"key": "fcxeq3o3h62scxy65dfbtk4okqddemndlldvrlhugjurxh2kuiqa",
	"components": [
	"[jfat3osakyvxfe2j5x7i25ax7olumljfj3r2xjzwijgqcmz3fql] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    sub = torch.ops.aten.sub.Tensor(arg0_1, 0.1);  arg0_1 = None\n    neg = torch.ops.aten.neg.default(sub);  sub = None\n    div = torch.ops.aten.div.Tensor(neg, 1.0);  neg = None\n    exp = torch.ops.aten.exp.default(div);  div = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [ge], exp);  ge = exp = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qq3r6iutttyrup346b5hoj3iunplzowinx4le3dezhua3jyjejs] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([290]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2333674778,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:23.536000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "2e09640378612dd3288af906c8c47102"}
	{"key": "fcxeq3o3h62scxy65dfbtk4okqddemndlldvrlhugjurxh2kuiqa", "components": ["[jfat3osakyvxfe2j5x7i25ax7olumljfj3r2xjzwijgqcmz3fql] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    sub = torch.ops.aten.sub.Tensor(arg0_1, 0.1);  arg0_1 = None\n    neg = torch.ops.aten.neg.default(sub);  sub = None\n    div = torch.ops.aten.div.Tensor(neg, 1.0);  neg = None\n    exp = torch.ops.aten.exp.default(div);  div = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [ge], exp);  ge = exp = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qq3r6iutttyrup346b5hoj3iunplzowinx4le3dezhua3jyjejs] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([290]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2333674778, "cache_state": "hit"}
V0401 21:31:23.537000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "b4fbaa5820829d798366874602e55fc2"}
	{
	"name": "inductor_compile",
	"ts": 1743543083537109.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.538000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "78ebb13a6b29624c84a583b72b0300dd"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083538211.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.539000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "08a971208b3c4e649944937e8f140457"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083539648.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.545000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "aee609640bc566f6016c364e1eff7ccd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083545393.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.546000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "a62d2c937c20fb196b7f13be09d76aea"}
	{
	"name": "backend_compile",
	"ts": 1743543083546242.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.547000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "e23eb717f6fc7512abdf424f76bc5430"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083547193.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.560000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "9710084a3350003f941541a373d7fa11"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['curve'], accessed_by=DictGetItemGuardAccessor(curve)
	| | +- GuardManager: source=L['curve'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['curve'].__code__, 123154978635040)       
	| +- GuardManager: source=L['spread'], accessed_by=DictGetItemGuardAccessor(spread)
	| | +- EQUALS_MATCH: L['spread'] == 1.0                                          
	| +- GuardManager: source=L['min_dist'], accessed_by=DictGetItemGuardAccessor(min_dist)
	| | +- EQUALS_MATCH: L['min_dist'] == 0.1                                        
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- ID_MATCH: ___check_obj_id(L['___stack0'], 123155762880576)            
	| +- GuardManager: source=L['xv'], accessed_by=DictGetItemGuardAccessor(xv)
	| | +- GuardManager: source=___from_numpy(L['xv']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['xv']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['xv']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['xv']), ___from_numpy(L['yv']), ___from_numpy(L['___stack1']))
	| +- GuardManager: source=L['yv'], accessed_by=DictGetItemGuardAccessor(yv)
	| | +- GuardManager: source=___from_numpy(L['yv']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['yv']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['yv']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack1'], accessed_by=DictGetItemGuardAccessor(___stack1)
	| | +- GuardManager: source=___from_numpy(L['___stack1']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack1']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[290], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack1']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['curve_fit'], accessed_by=DictGetItemGuardAccessor(curve_fit)
	| | | +- GuardManager: source=G['curve_fit'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['curve_fit'].__code__, 105251493180592)   
	
V0401 21:31:23.561000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "4c826a16d92870f588a7cc75a5e3932a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083560971.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.561000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "3350526c418d1e598174748971e547e2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083561822.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.562000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "9/0", "frame_key": "23", "co_name": "torch_dynamo_resume_in_find_ab_params_at_1406", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1406, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 6, "graph_node_count": 10, "graph_input_count": 3, "start_time": 1743543083.3269472, "entire_frame_compile_time_s": 0.23392581939697266, "backend_compile_time_s": 0.06996798515319824, "inductor_compile_time_s": 0.016016006469726562, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.11062002182006836, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.566000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", 6]}
V0401 21:31:23.567000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}]}, "frame_id": 10, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.568000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 0, "has_payload": "d58fda262eadbf0f54101f80394f4540"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083568768.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.570000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 0, "has_payload": "099d29aa69ae3e392cd83f38e11d54a2"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083568768.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.641000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"lb": [], "ub": [], "lb_1": [2], "ub_1": [2]}}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "57c6f8d6d473053f1f45eeb955eff7cf"}
	class GraphModule(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:96 in <genexpr>, code: lb, ub = (np.asarray(b, dtype=float) for b in bounds)
	        lb: "f64[][]cpu" = torch__dynamo_utils_wrapped_asarray(-inf, dtype = torch.float64)
	        ub: "f64[][]cpu" = torch__dynamo_utils_wrapped_asarray_1(inf, dtype = torch.float64)
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:98 in prepare_bounds, code: lb = np.resize(lb, n)
	        lb_1: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_resize(lb, 2);  lb = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:101 in prepare_bounds, code: ub = np.resize(ub, n)
	        ub_1: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_resize_1(ub, 2);  ub = None
	        return (lb_1, ub_1)
	        
V0401 21:31:23.642000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "2b168f38cba281e1048c885433a0a2d6"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083642886.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.643000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "4a44fda3c674f29e90312a1d32d255ed"}
	{
	"name": "backend_compile",
	"ts": 1743543083642886.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.646000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "214d7d9f6bae11264d9d5125f934659f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083646828.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.684000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "4514077c742f514dd686e077a8cc0bc2"}
	class <lambda>(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:96 in <genexpr>, code: lb, ub = (np.asarray(b, dtype=float) for b in bounds)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        _tensor_constant1 = self._tensor_constant1
	        lift_fresh_copy_1: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:98 in prepare_bounds, code: lb = np.resize(lb, n)
	        view: "f64[1][1]cpu" = torch.ops.aten.view.default(lift_fresh_copy, [1]);  lift_fresh_copy = None
	        unsqueeze: "f64[1, 1][1, 1]cpu" = torch.ops.aten.unsqueeze.default(view, 0);  view = None
	        expand: "f64[2, 1][0, 1]cpu" = torch.ops.aten.expand.default(unsqueeze, [2, 1]);  unsqueeze = None
	        view_1: "f64[2][0]cpu" = torch.ops.aten.view.default(expand, [2]);  expand = None
	        clone: "f64[2][1]cpu" = torch.ops.aten.clone.default(view_1);  view_1 = None
	        slice_1: "f64[2][1]cpu" = torch.ops.aten.slice.Tensor(clone, 0, 0, 2);  clone = None
	        view_2: "f64[2][1]cpu" = torch.ops.aten.view.default(slice_1, [2]);  slice_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:101 in prepare_bounds, code: ub = np.resize(ub, n)
	        view_3: "f64[1][1]cpu" = torch.ops.aten.view.default(lift_fresh_copy_1, [1]);  lift_fresh_copy_1 = None
	        unsqueeze_1: "f64[1, 1][1, 1]cpu" = torch.ops.aten.unsqueeze.default(view_3, 0);  view_3 = None
	        expand_1: "f64[2, 1][0, 1]cpu" = torch.ops.aten.expand.default(unsqueeze_1, [2, 1]);  unsqueeze_1 = None
	        view_4: "f64[2][0]cpu" = torch.ops.aten.view.default(expand_1, [2]);  expand_1 = None
	        clone_1: "f64[2][1]cpu" = torch.ops.aten.clone.default(view_4);  view_4 = None
	        slice_2: "f64[2][1]cpu" = torch.ops.aten.slice.Tensor(clone_1, 0, 0, 2);  clone_1 = None
	        view_5: "f64[2][1]cpu" = torch.ops.aten.view.default(slice_2, [2]);  slice_2 = None
	        return (view_2, view_5)
	        
V0401 21:31:23.686000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "4bc45883d31f1eaf118251fe0bb3e82b"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083686131.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.698000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "1cfe79404195f86ca853d7ff6fb944c3"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083698226.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.699000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "fee785983f38026d9a5c5662cc3379bd"}
	{
	"name": "inductor_compile",
	"ts": 1743543083698226.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.716000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/w6/cw6dvybjoz7oh5jzk4lyo53ayla553pspwnbqjj4yutick4ynisd.py"}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "e57f6428b7c389fc295cca8e4a49aab5"}
	# AOT ID: ['5_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_view_0 = async_compile.cpp_pybinding(['double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(double* out_ptr0,
	                       double* out_ptr1)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = -std::numeric_limits<double>::infinity();
	            out_ptr0[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = std::numeric_limits<double>::infinity();
	            out_ptr1[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    buf0 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    cpp_fused_view_0(buf0, buf1)
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    fn = lambda: call([])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:23.718000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "2ae8c27b9ac9dcd25d77aa4fc9d19d93"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543083717418.5,
	"args": {
	"key": "fhgsqgiwm5fsnbokv5jaauvp2u4eql3h2ryzytobatsr3zy5hbms",
	"components": [
	"[iulospdvxfqvq5rzqfkbh3qtwwdxweattfoljia6z3k7fcbqcoy] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None\n    _tensor_constant1 = self._tensor_constant1\n    lift_fresh_copy_1 = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None\n    view = torch.ops.aten.view.default(lift_fresh_copy, [1]);  lift_fresh_copy = None\n    unsqueeze = torch.ops.aten.unsqueeze.default(view, 0);  view = None\n    expand = torch.ops.aten.expand.default(unsqueeze, [2, 1]);  unsqueeze = None\n    view_1 = torch.ops.aten.view.default(expand, [2]);  expand = None\n    clone = torch.ops.aten.clone.default(view_1);  view_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(clone, 0, 0, 2);  clone = slice_1 = None\n    full_default = torch.ops.aten.full.default([2], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view_3 = torch.ops.aten.view.default(lift_fresh_copy_1, [1]);  lift_fresh_copy_1 = None\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(view_3, 0);  view_3 = None\n    expand_1 = torch.ops.aten.expand.default(unsqueeze_1, [2, 1]);  unsqueeze_1 = None\n    view_4 = torch.ops.aten.view.default(expand_1, [2]);  expand_1 = None\n    clone_1 = torch.ops.aten.clone.default(view_4);  view_4 = None\n    slice_2 = torch.ops.aten.slice.Tensor(clone_1, 0, 0, 2);  clone_1 = slice_2 = None\n    full_default_1 = torch.ops.aten.full.default([2], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default, full_default_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[dh7igrumoyh7k2z5flvfaxkyxysjutfv6p5suaedvvarlzceiin] fx_kwargs[user_visible_outputs]: {'full_default': None, 'full_default_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2074643546,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:23.719000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "e54a2fc48331b19f377736ca38f47466"}
	{"key": "fhgsqgiwm5fsnbokv5jaauvp2u4eql3h2ryzytobatsr3zy5hbms", "components": ["[iulospdvxfqvq5rzqfkbh3qtwwdxweattfoljia6z3k7fcbqcoy] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None\n    _tensor_constant1 = self._tensor_constant1\n    lift_fresh_copy_1 = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None\n    view = torch.ops.aten.view.default(lift_fresh_copy, [1]);  lift_fresh_copy = None\n    unsqueeze = torch.ops.aten.unsqueeze.default(view, 0);  view = None\n    expand = torch.ops.aten.expand.default(unsqueeze, [2, 1]);  unsqueeze = None\n    view_1 = torch.ops.aten.view.default(expand, [2]);  expand = None\n    clone = torch.ops.aten.clone.default(view_1);  view_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(clone, 0, 0, 2);  clone = slice_1 = None\n    full_default = torch.ops.aten.full.default([2], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view_3 = torch.ops.aten.view.default(lift_fresh_copy_1, [1]);  lift_fresh_copy_1 = None\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(view_3, 0);  view_3 = None\n    expand_1 = torch.ops.aten.expand.default(unsqueeze_1, [2, 1]);  unsqueeze_1 = None\n    view_4 = torch.ops.aten.view.default(expand_1, [2]);  expand_1 = None\n    clone_1 = torch.ops.aten.clone.default(view_4);  view_4 = None\n    slice_2 = torch.ops.aten.slice.Tensor(clone_1, 0, 0, 2);  clone_1 = slice_2 = None\n    full_default_1 = torch.ops.aten.full.default([2], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default, full_default_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[dh7igrumoyh7k2z5flvfaxkyxysjutfv6p5suaedvvarlzceiin] fx_kwargs[user_visible_outputs]: {'full_default': None, 'full_default_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2074643546, "cache_state": "hit"}
V0401 21:31:23.720000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "8b08f00912ddfa6bc9f81b7199d26946"}
	{
	"name": "inductor_compile",
	"ts": 1743543083720334.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.721000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "4954dfc2bee329a111910040e74a84c3"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083721031.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.722000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "e8463121d16c18de1852bf8c697fe155"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083722679.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.727000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "90fbeec7bf3fc815717abd7c6bb19c7e"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083727571.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.729000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "42029512d8c1fa0017368be297ae09c4"}
	{
	"name": "backend_compile",
	"ts": 1743543083729561.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.730000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "a769396c93328471fb81b003d382392a"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083730306.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.768000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "62e0fa7d8cd16e20bc6c286abaa3a270"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 123154978635040)           
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- ID_MATCH: ___check_obj_id(L['p0'], 105251315093216)                   
	| +- GuardManager: source=L['bounds'], accessed_by=DictGetItemGuardAccessor(bounds)
	| | +- TYPE_MATCH: ___check_type_id(L['bounds'], 105251315101760)              
	| | +- LENGTH_CHECK: len(L['bounds']) == 2                                       
	| | +- GuardManager: source=L['bounds'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- EQUALS_MATCH: L['bounds'][0] == -inf                                      
	| | +- GuardManager: source=L['bounds'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- EQUALS_MATCH: L['bounds'][1] == inf                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['Bounds'], accessed_by=DictGetItemGuardAccessor(Bounds)
	| | | +- ID_MATCH: ___check_obj_id(G['Bounds'], 105251492984672)               
	| | +- GuardManager: source=G['prepare_bounds'], accessed_by=DictGetItemGuardAccessor(prepare_bounds)
	| | | +- GuardManager: source=G['prepare_bounds'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['prepare_bounds'].__code__, 123155042893872)
	| | +- GuardManager: source=G['_getfullargspec'], accessed_by=DictGetItemGuardAccessor(_getfullargspec)
	| | | +- GuardManager: source=G['_getfullargspec'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_getfullargspec'].__code__, 105251487708992)
	| | +- GuardManager: source=G['_initialize_feasible'], accessed_by=DictGetItemGuardAccessor(_initialize_feasible)
	| | | +- GuardManager: source=G['_initialize_feasible'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_initialize_feasible'].__code__, 123155057474480)
	| | +- GuardManager: source=G['__builtins_dict___34'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___34)
	| | | +- GuardManager: source=G['__builtins_dict___34']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['len'], 123155769909840)
	| | | +- GuardManager: source=G['__builtins_dict___34']['float'], accessed_by=DictGetItemGuardAccessor(float)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['float'], 105251315063584)
	| | | +- GuardManager: source=G['__builtins_dict___34']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['tuple'], 105251315101760)
	| | | +- GuardManager: source=G['__builtins_dict___34']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['isinstance'], 123155769909520)
	| | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'], accessed_by=DictGetItemGuardAccessor(__import_scipy_dot__lib_dot__util)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'], 123155190568640)
	| | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect, accessed_by=GetAttrGuardAccessor(inspect)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].inspect, 123155768844640)
	| | | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect.Parameter, accessed_by=GetAttrGuardAccessor(Parameter)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].inspect.Parameter, 105251385008560)
	| | | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect.signature, accessed_by=GetAttrGuardAccessor(signature)
	| | | | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect.signature.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].inspect.signature.__code__, 123155766665008)
	| | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].FullArgSpec, accessed_by=GetAttrGuardAccessor(FullArgSpec)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].FullArgSpec, 105251489410176)
	| | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'], accessed_by=DictGetItemGuardAccessor(__import_scipy_dot_optimize_dot__lsq_dot_least_squares)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'], 123155042777936)
	| | | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np, accessed_by=GetAttrGuardAccessor(np)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np, 123155762218864)
	| | | | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.resize, accessed_by=GetAttrGuardAccessor(resize)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.resize, 123155351015344)
	| | | | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.asarray, accessed_by=GetAttrGuardAccessor(asarray)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.asarray, 123155762228064)
	
V0401 21:31:23.769000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "1e84503053afaaecbd6fc5662ba2c615"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083769704.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.770000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "83c41af720a87309cadbe7fb360cb714"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083770738.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.771000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "10/0", "frame_key": "24", "co_name": "curve_fit", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 591, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 27, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 5, "graph_input_count": 0, "start_time": 1743543083.5687547, "entire_frame_compile_time_s": 0.20083379745483398, "backend_compile_time_s": 0.0865170955657959, "inductor_compile_time_s": 0.021932601928710938, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.04169154167175293, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.774000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 574, "name": "_initialize_feasible", "filename": 6}]}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.775000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0, "has_payload": "042e9e545d33357e54a6ed51cac2449e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083775245.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.776000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0, "has_payload": "9e455b5f74fe99ff22f03267a9960de5"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083775245.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.780000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 30, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.781000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f5a9770>", "describer_id": 30}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.782000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 30, "id": 0, "source": "___from_numpy(L['lb'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.788000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 30, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.789000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022fba6080>", "describer_id": 30}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.790000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 30, "id": 1, "source": "___from_numpy(L['ub'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.798000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 31, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.800000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f15d810>", "describer_id": 31}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.801000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 31, "id": 0, "source": "___from_numpy(L['lb'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.806000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 31, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.807000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f5aae40>", "describer_id": 31}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.808000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 31, "id": 1, "source": "___from_numpy(L['ub'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.813000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_lb_": [2], "l_ub_": [2], "p0": [2], "lb_finite": [2], "ub_finite": [2], "mask": [2]}}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "ff71e3effb1665ce0552b39f5aaea5e9"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_lb_: "f64[2][1]cpu", L_ub_: "f64[2][1]cpu"):
	        l_lb_ = L_lb_
	        l_ub_ = L_ub_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:575 in _initialize_feasible, code: p0 = np.ones_like(lb)
	        p0: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_ones_like(l_lb_)
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:576 in _initialize_feasible, code: lb_finite = np.isfinite(lb)
	        lb_finite: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_isfinite(l_lb_);  l_lb_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:577 in _initialize_feasible, code: ub_finite = np.isfinite(ub)
	        ub_finite: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_isfinite_1(l_ub_);  l_ub_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:579 in _initialize_feasible, code: mask = lb_finite & ub_finite
	        mask: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_and_(lb_finite, ub_finite)
	        return (mask, p0, lb_finite, ub_finite)
	        
V0401 21:31:23.814000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "2ddd883ae2bc1beddb67f6e836853ede"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083814793.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.815000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "bfa024cbe394e12171ceded3ad4d90cb"}
	{
	"name": "backend_compile",
	"ts": 1743543083814793.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.818000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "7584c32f520b32ce5e835eed8697a642"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083818903.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.849000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "0c0c854b2cef0dc0459e683dbe297173"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu", arg1_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:575 in _initialize_feasible, code: p0 = np.ones_like(lb)
	        full: "f64[2][1]cpu" = torch.ops.aten.full.default([2], 1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:576 in _initialize_feasible, code: lb_finite = np.isfinite(lb)
	        abs_1: "f64[2][1]cpu" = torch.ops.aten.abs.default(arg0_1)
	        ne: "b8[2][1]cpu" = torch.ops.aten.ne.Scalar(abs_1, inf);  abs_1 = None
	        eq: "b8[2][1]cpu" = torch.ops.aten.eq.Tensor(arg0_1, arg0_1);  arg0_1 = None
	        mul: "b8[2][1]cpu" = torch.ops.aten.mul.Tensor(eq, ne);  eq = ne = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:577 in _initialize_feasible, code: ub_finite = np.isfinite(ub)
	        abs_2: "f64[2][1]cpu" = torch.ops.aten.abs.default(arg1_1)
	        ne_1: "b8[2][1]cpu" = torch.ops.aten.ne.Scalar(abs_2, inf);  abs_2 = None
	        eq_1: "b8[2][1]cpu" = torch.ops.aten.eq.Tensor(arg1_1, arg1_1);  arg1_1 = None
	        mul_1: "b8[2][1]cpu" = torch.ops.aten.mul.Tensor(eq_1, ne_1);  eq_1 = ne_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:579 in _initialize_feasible, code: mask = lb_finite & ub_finite
	        bitwise_and: "b8[2][1]cpu" = torch.ops.aten.bitwise_and.Tensor(mul, mul_1)
	        return (bitwise_and, full, mul, mul_1)
	        
V0401 21:31:23.851000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "96e60709a36166c7af8ded37862a001e"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083850563.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.855000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "8fedaf892256ed28a9d428b246fdbb42"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083855608.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.856000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "151f8c7dd10c249c7466517bfbde6434"}
	{
	"name": "inductor_compile",
	"ts": 1743543083855608.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.868000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/mc/cmcfh3a2emrutfmrbeazds6vn44cuho54q52lufk7oa3tzfnmks4.py"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "393224d84a16a69f195871bb122f4ec4"}
	# AOT ID: ['6_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_abs_bitwise_and_eq_mul_ne_ones_like_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'bool*', 'bool*', 'bool*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       bool* out_ptr0,
	                       bool* out_ptr1,
	                       bool* out_ptr2,
	                       double* out_ptr3)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp6 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = std::abs(tmp0);
	            auto tmp3 = std::numeric_limits<double>::infinity();
	            auto tmp4 = tmp2 != tmp3;
	            auto tmp5 = tmp1 && tmp4;
	            auto tmp7 = tmp6 == tmp6;
	            auto tmp8 = std::abs(tmp6);
	            auto tmp9 = tmp8 != tmp3;
	            auto tmp10 = tmp7 && tmp9;
	            auto tmp11 = decltype(tmp5)(tmp5 & tmp10);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp5;
	            out_ptr1[static_cast<int64_t>(x0)] = tmp10;
	            out_ptr2[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = static_cast<double>(1.0);
	            out_ptr3[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    buf1 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    buf2 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    buf3 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    cpp_fused_abs_bitwise_and_eq_mul_ne_ones_like_0(arg0_1, arg1_1, buf0, buf1, buf2, buf3)
	    del arg0_1
	    del arg1_1
	    return (buf2, buf3, buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:23.869000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "d6d530984f5a1174ad74536f5a1e8194"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543083869402.5,
	"args": {
	"key": "funr2ahlhw56uug5okvs7g4codnhulml4xeci2yvisqb4ws2a2uz",
	"components": [
	"[vyrg4ufxaeuywksed2fgb6wwxbowgaw4v23hlnmy73jh3ooa4ik] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    full_default = torch.ops.aten.full.default([2], 1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    abs_1 = torch.ops.aten.abs.default(arg0_1)\n    ne = torch.ops.aten.ne.Scalar(abs_1, inf);  abs_1 = None\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg0_1);  arg0_1 = None\n    mul = torch.ops.aten.mul.Tensor(eq, ne);  eq = ne = None\n    abs_2 = torch.ops.aten.abs.default(arg1_1)\n    ne_1 = torch.ops.aten.ne.Scalar(abs_2, inf);  abs_2 = None\n    eq_1 = torch.ops.aten.eq.Tensor(arg1_1, arg1_1);  arg1_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(eq_1, ne_1);  eq_1 = ne_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(mul, mul_1)\n    return (bitwise_and, full_default, mul, mul_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[tltqbuwwwdr4yb24wanyx2ncv3wkzebbr424kzuebqega5spijw] fx_kwargs[user_visible_outputs]: {'bitwise_and': None, 'full_default': None, 'mul': None, 'mul_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2189581080,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:23.870000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "503af48cde2cf83fc5673b6b30d57788"}
	{"key": "funr2ahlhw56uug5okvs7g4codnhulml4xeci2yvisqb4ws2a2uz", "components": ["[vyrg4ufxaeuywksed2fgb6wwxbowgaw4v23hlnmy73jh3ooa4ik] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    full_default = torch.ops.aten.full.default([2], 1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    abs_1 = torch.ops.aten.abs.default(arg0_1)\n    ne = torch.ops.aten.ne.Scalar(abs_1, inf);  abs_1 = None\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg0_1);  arg0_1 = None\n    mul = torch.ops.aten.mul.Tensor(eq, ne);  eq = ne = None\n    abs_2 = torch.ops.aten.abs.default(arg1_1)\n    ne_1 = torch.ops.aten.ne.Scalar(abs_2, inf);  abs_2 = None\n    eq_1 = torch.ops.aten.eq.Tensor(arg1_1, arg1_1);  arg1_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(eq_1, ne_1);  eq_1 = ne_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(mul, mul_1)\n    return (bitwise_and, full_default, mul, mul_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[tltqbuwwwdr4yb24wanyx2ncv3wkzebbr424kzuebqega5spijw] fx_kwargs[user_visible_outputs]: {'bitwise_and': None, 'full_default': None, 'mul': None, 'mul_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2189581080, "cache_state": "hit"}
V0401 21:31:23.872000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "9bd9513d667e5c95938cd7509fdc9301"}
	{
	"name": "inductor_compile",
	"ts": 1743543083872166.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.873000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "a6dd8bde787b4117497b2f653b6cb586"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543083872995.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.874000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "27801b68b87fd65cf7d3bda78cccf764"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543083874653.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.880000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "fd403e5a60117a8590e0472f4fee73c8"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543083880071.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.881000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "635381694c8f36601c015eef9b82781c"}
	{
	"name": "backend_compile",
	"ts": 1743543083881711.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.882000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "be95eb372e916eb804a592471fdab4f6"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543083882495.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.890000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "7777a1717ff110c8c87f20984669fe83"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['lb'], accessed_by=DictGetItemGuardAccessor(lb)
	| | +- GuardManager: source=___from_numpy(L['lb']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['lb']), ___from_numpy(L['ub']))
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].isfinite, accessed_by=GetAttrGuardAccessor(isfinite)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].isfinite, 123155762886464)          
	| | | +- GuardManager: source=G['np'].ones_like, accessed_by=GetAttrGuardAccessor(ones_like)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ones_like, 123155351049584)         
	
V0401 21:31:23.891000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "adc76f91e69034252497c388cd55beea"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083891062.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.892000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "b45dec116bc62a69abff4638df07fbb1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083891921.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.892000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "11/0", "frame_key": "25", "co_name": "_initialize_feasible", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 574, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 10, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543083.7752333, "entire_frame_compile_time_s": 0.11573100090026855, "backend_compile_time_s": 0.06683111190795898, "inductor_compile_time_s": 0.016422748565673828, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.01859903335571289, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.894000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}]}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.895000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0, "has_payload": "ff2db568bc4ce6d088afdf5a1c5b61d8"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083895175.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.896000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0, "has_payload": "92b29a65d949fa765ab9d056417cb55c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083895175.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.899000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 33, "size": 16}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.899000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f693980>", "describer_id": 33}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.900000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 33, "id": 0, "source": "___from_numpy(L['ub'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.902000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 33, "size": 2}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.904000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f690eb0>", "describer_id": 33}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.905000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 33, "id": 1, "source": "___from_numpy(L['mask'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.910000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 34, "size": 0}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.911000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f693a20>", "describer_id": 34}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.912000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 34, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.914000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 34, "size": 16}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.915000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6d4280>", "describer_id": 34}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.915000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 34, "id": 1, "source": "___from_numpy(L['ub'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.918000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 34, "size": 2}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.919000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f5ab3e0>", "describer_id": 34}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.919000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 34, "id": 2, "source": "___from_numpy(L['mask'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.930000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1, "has_payload": "82766a801758a57898d4890c6633975d"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- EQUALS_MATCH: L['___stack0'] == 0.5                                       
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['ub']), ___from_numpy(L['mask']), ___from_numpy(L['___stack1']))
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack1'], accessed_by=DictGetItemGuardAccessor(___stack1)
	| | +- GuardManager: source=___from_numpy(L['___stack1']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack1']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack1']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:31:23.931000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1, "has_payload": "8cec1947b91fff7db32db2b4f03a12e2"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083931444.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.932000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1, "has_payload": "2f750576b77b4e39ac405239ad0121e2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083932357.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.933000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "12/0", "frame_key": "26", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_580", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 580, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 6, "graph_input_count": 6, "start_time": 1743543083.8951626, "entire_frame_compile_time_s": 0.03617143630981445, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.01163792610168457, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.935000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "_initialize_feasible", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}]}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.935000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0, "has_payload": "5c4723dd46efdb0d279ebe126f734b3c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543083935775.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.936000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcd147f0f0d67194d5f7e1322ee68eb4"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543083935775.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:23.940000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 35, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.941000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1340a0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.941000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.944000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 35, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.945000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6935c0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.945000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 1, "source": "___from_numpy(L['___stack2'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.951000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 35, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.952000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f5a9270>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.952000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 4, "source": "___from_numpy(L['p0'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.955000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 35, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.955000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f5a9860>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.956000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 5, "source": "___from_numpy(L['mask'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.959000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 35, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.960000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6cd2c0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.961000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 6, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.964000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 35, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.965000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f137b10>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.966000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 8, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.968000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 35, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.969000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 9, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14e940>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.970000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 9, "source": "___from_numpy(L['lb'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:23.975000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 36, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.976000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022fba6670>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.976000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.979000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 36, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.979000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f15f4d0>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.980000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 1, "source": "___from_numpy(L['___stack2'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.983000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 36, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.984000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f5aa580>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.985000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 2, "source": "___from_numpy(L['p0'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.988000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 36, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.989000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f6cc5f0>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.991000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 3, "source": "___from_numpy(L['mask'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.994000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 36, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.995000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f137c50>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.996000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 4, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:23.999000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 36, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.000000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14c410>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.001000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 5, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.004000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 36, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.005000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14c460>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.006000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 6, "source": "___from_numpy(L['lb'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.010000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack1_": [0], "l_stack2_": [0], "l_p0_": [2], "l_mask_": [2], "l_ub_finite_": [2], "l_lb_finite_": [2], "wrapped_add": [0], "wrapped_mul": [0], "wrapped_invert": [2], "mask": [2]}}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "191c1d781df9bb2d9ea3d1026a2fd4d9"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack1_: "f64[0][0]cpu", L_stack2_: "f64[0][0]cpu", L_p0_: "f64[2][1]cpu", L_mask_: "b8[2][1]cpu", L_ub_finite_: "b8[2][1]cpu", L_lb_finite_: "b8[2][1]cpu"):
	        l_stack1_ = L_stack1_
	        l_stack2_ = L_stack2_
	        l_p0_ = L_p0_
	        l_mask_ = L_mask_
	        l_ub_finite_ = L_ub_finite_
	        l_lb_finite_ = L_lb_finite_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:580 in torch_dynamo_resume_in__initialize_feasible_at_580, code: p0[mask] = 0.5 * (lb[mask] + ub[mask])
	        wrapped_add: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_add(l_stack1_, l_stack2_);  l_stack1_ = l_stack2_ = None
	        wrapped_mul: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_mul(0.5, wrapped_add);  wrapped_add = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_p0_, l_mask_, wrapped_mul);  l_p0_ = l_mask_ = wrapped_mul = wrapped___setitem__ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:582 in torch_dynamo_resume_in__initialize_feasible_at_580, code: mask = lb_finite & ~ub_finite
	        wrapped_invert: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_invert(l_ub_finite_);  l_ub_finite_ = None
	        mask: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_and_(l_lb_finite_, wrapped_invert);  l_lb_finite_ = wrapped_invert = None
	        return (mask,)
	        
V0401 21:31:24.011000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "46185193e82a67c48b63a0dd829345fb"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084011871.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.012000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "d16f7dfe5e776e376c24aefa3f961f93"}
	{
	"name": "backend_compile",
	"ts": 1743543084011871.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.018000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "999df6b5768fbc41201f57da910231a2"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084018129.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.048000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "2d3ac8f4ed064f450b9aca3167384e5a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[0][0]cpu", arg1_1: "f64[0][0]cpu", arg2_1: "f64[2][1]cpu", arg3_1: "b8[2][1]cpu", arg4_1: "b8[2][1]cpu", arg5_1: "b8[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:580 in torch_dynamo_resume_in__initialize_feasible_at_580, code: p0[mask] = 0.5 * (lb[mask] + ub[mask])
	        add: "f64[0][1]cpu" = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None
	        mul: "f64[0][1]cpu" = torch.ops.aten.mul.Tensor(0.5, add);  add = None
	        index_put: "f64[2][1]cpu" = torch.ops.aten.index_put.default(arg2_1, [arg3_1], mul);  arg3_1 = mul = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:582 in torch_dynamo_resume_in__initialize_feasible_at_580, code: mask = lb_finite & ~ub_finite
	        bitwise_not: "b8[2][1]cpu" = torch.ops.aten.bitwise_not.default(arg4_1);  arg4_1 = None
	        bitwise_and: "b8[2][1]cpu" = torch.ops.aten.bitwise_and.Tensor(arg5_1, bitwise_not);  arg5_1 = bitwise_not = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:580 in torch_dynamo_resume_in__initialize_feasible_at_580, code: p0[mask] = 0.5 * (lb[mask] + ub[mask])
	        copy_: "f64[2][1]cpu" = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None
	        return (bitwise_and,)
	        
V0401 21:31:24.049000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "d8bd4f0f158ef6d95e8e4327e0614115"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084049435.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.053000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "df8e85d97cc38aa22c526b66cf2c1263"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084053245.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.054000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "7bc263de37bed2c80c282c72fcc52609"}
	{
	"name": "inductor_compile",
	"ts": 1743543084053245.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.066000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/tp/ctpx5pwm3jwdz5wtkibk6srgquv4slonctvvqnrdvxmk4avujakq.py"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "bfd611d92954846361e9bd45dccc21d5"}
	# AOT ID: ['7_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_bitwise_and_bitwise_not_0 = async_compile.cpp_pybinding(['const bool*', 'const bool*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const bool* in_ptr0,
	                       const bool* in_ptr1,
	                       bool* out_ptr0)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = !tmp1;
	            auto tmp3 = decltype(tmp0)(tmp0 & tmp2);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp3;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1 = args
	    args.clear()
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    assert_size_stride(arg3_1, (2, ), (1, ))
	    assert_size_stride(arg4_1, (2, ), (1, ))
	    assert_size_stride(arg5_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((0, ), (1, ), torch.float64)
	    aten.index_put_(arg2_1, [arg3_1], buf0, False)
	    del arg2_1
	    del arg3_1
	    del buf0
	    buf2 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    cpp_fused_bitwise_and_bitwise_not_0(arg5_1, arg4_1, buf2)
	    del arg4_1
	    del arg5_1
	    return (buf2, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg3_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg4_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg5_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:24.067000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "d1dfc053f96ebc954beb5712d731b2a7"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543084066984.2,
	"args": {
	"key": "ftmnajjqc5hkxk5ys55geac643d36qi4rc3odtly2dnj6plbxqrs",
	"components": [
	"[bkls3dgj2tuzcsuhsrorqjeji3ltoqemd5bqtrx2qxfofzwoee2] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    add = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    mul = torch.ops.aten.mul.Tensor(0.5, add);  add = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [arg3_1], mul);  arg3_1 = mul = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg4_1);  arg4_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(arg5_1, bitwise_not);  arg5_1 = bitwise_not = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[5]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2364735383,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:24.068000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "176a1276d22d05b1cbbfe200e1b78a11"}
	{"key": "ftmnajjqc5hkxk5ys55geac643d36qi4rc3odtly2dnj6plbxqrs", "components": ["[bkls3dgj2tuzcsuhsrorqjeji3ltoqemd5bqtrx2qxfofzwoee2] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    add = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    mul = torch.ops.aten.mul.Tensor(0.5, add);  add = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [arg3_1], mul);  arg3_1 = mul = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg4_1);  arg4_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(arg5_1, bitwise_not);  arg5_1 = bitwise_not = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[5]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2364735383, "cache_state": "hit"}
V0401 21:31:24.069000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "a553fb93ccc0416f78d6226269871788"}
	{
	"name": "inductor_compile",
	"ts": 1743543084069439.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.070000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "6e4b5afb71c20c465c08a22f78c6dce5"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084070206.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.071000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "96474ec2f5620e0c33a3a9c26a65e9eb"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084071697.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.075000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "aa70e8ccac9156245d4640bf85257afb"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084075157.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.076000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "2cbc904f277baf63c4cdcf1e3e77f7c9"}
	{
	"name": "backend_compile",
	"ts": 1743543084076036.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.076000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "e69235a3eac7e161052119af1d9e28dc"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084076795.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.089000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "948485724140eac7e94cbc7ba60a0bf2"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- EQUALS_MATCH: L['___stack0'] == 0.5                                       
	| +- GuardManager: source=L['lb'], accessed_by=DictGetItemGuardAccessor(lb)
	| | +- GuardManager: source=___from_numpy(L['lb']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['lb']), ___from_numpy(L['p0']), ___from_numpy(L['mask']), ___from_numpy(L['___stack1']), ___from_numpy(L['___stack2']), ___from_numpy(L['lb_finite']), ___from_numpy(L['ub_finite']))
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack1'], accessed_by=DictGetItemGuardAccessor(___stack1)
	| | +- GuardManager: source=___from_numpy(L['___stack1']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack1']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack1']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack2'], accessed_by=DictGetItemGuardAccessor(___stack2)
	| | +- GuardManager: source=___from_numpy(L['___stack2']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack2']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack2']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['lb_finite'], accessed_by=DictGetItemGuardAccessor(lb_finite)
	| | +- GuardManager: source=___from_numpy(L['lb_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['ub_finite'], accessed_by=DictGetItemGuardAccessor(ub_finite)
	| | +- GuardManager: source=___from_numpy(L['ub_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:31:24.090000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "8f0b425907862a35687bf7206e4b625c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084090737.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.091000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "b1831c1e44332398f2a15e730e23d8c2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084091580.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.092000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "13/0", "frame_key": "27", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_580", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 580, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 12, "graph_input_count": 6, "start_time": 1743543083.9357636, "entire_frame_compile_time_s": 0.15487265586853027, "backend_compile_time_s": 0.06407451629638672, "inductor_compile_time_s": 0.016042470932006836, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.035800933837890625, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.094000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "_initialize_feasible", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}, {"line": 583, "name": "torch_dynamo_resume_in__initialize_feasible_at_583", "filename": 6}]}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.095000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0, "has_payload": "e3bdaaa8f2214e3214f818acda2c5cc9"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084094938.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.095000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0, "has_payload": "0b69e71c3439a664c536c4ed4dea5336"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084094938.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.098000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 38, "size": 0}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.099000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14f5c0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.100000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.104000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 38, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.105000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f8cc9b0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.106000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 3, "source": "___from_numpy(L['p0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.109000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 38, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.109000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f678eb0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.110000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 4, "source": "___from_numpy(L['mask'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.113000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 38, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.113000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f679e50>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.114000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 5, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.117000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 38, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.118000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f678870>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.119000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 6, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.122000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 38, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.122000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 7, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f3bc0a0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.123000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 7, "source": "___from_numpy(L['ub'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.128000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 39, "size": 0}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.129000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1453b0>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.130000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.134000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 39, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.134000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1442d0>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.135000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 3, "source": "___from_numpy(L['p0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.137000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 39, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.138000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f144870>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.139000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 4, "source": "___from_numpy(L['mask'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.141000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 39, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.142000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f147de0>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.143000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 5, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.146000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 39, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.146000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f146b20>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.147000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 6, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.150000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 39, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.151000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 7, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1e9ea0>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.152000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 7, "source": "___from_numpy(L['ub'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.155000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_": [0], "l_p0_": [2], "l_mask_": [2], "l_lb_finite_": [2], "l_ub_finite_": [2], "wrapped_add": [0], "wrapped_invert": [2], "mask": [2]}}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "38e687d42f1f2e6106086df65cc42197"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_: "f64[0][0]cpu", L_p0_: "f64[2][1]cpu", L_mask_: "b8[2][1]cpu", L_lb_finite_: "b8[2][1]cpu", L_ub_finite_: "b8[2][1]cpu"):
	        l_stack0_ = L_stack0_
	        l_p0_ = L_p0_
	        l_mask_ = L_mask_
	        l_lb_finite_ = L_lb_finite_
	        l_ub_finite_ = L_ub_finite_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:583 in torch_dynamo_resume_in__initialize_feasible_at_583, code: p0[mask] = lb[mask] + 1
	        wrapped_add: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_add(l_stack0_, 1);  l_stack0_ = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_p0_, l_mask_, wrapped_add);  l_p0_ = l_mask_ = wrapped_add = wrapped___setitem__ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:585 in torch_dynamo_resume_in__initialize_feasible_at_583, code: mask = ~lb_finite & ub_finite
	        wrapped_invert: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_invert(l_lb_finite_);  l_lb_finite_ = None
	        mask: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_and_(wrapped_invert, l_ub_finite_);  wrapped_invert = l_ub_finite_ = None
	        return (mask,)
	        
V0401 21:31:24.157000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "343a1689e39f968158b27c06e8abaa8e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084157038.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.160000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "21a4889cec1ecacecfa26d81a740332b"}
	{
	"name": "backend_compile",
	"ts": 1743543084157038.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.165000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "b2d4c2947b38ef66959708fdcafc3905"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084165201.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.192000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "e5a95522c98df72911e804ec9d83846a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[0][0]cpu", arg1_1: "f64[2][1]cpu", arg2_1: "b8[2][1]cpu", arg3_1: "b8[2][1]cpu", arg4_1: "b8[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:583 in torch_dynamo_resume_in__initialize_feasible_at_583, code: p0[mask] = lb[mask] + 1
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        add: "f64[0][1]cpu" = torch.ops.aten.add.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        index_put: "f64[2][1]cpu" = torch.ops.aten.index_put.default(arg1_1, [arg2_1], add);  arg2_1 = add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:585 in torch_dynamo_resume_in__initialize_feasible_at_583, code: mask = ~lb_finite & ub_finite
	        bitwise_not: "b8[2][1]cpu" = torch.ops.aten.bitwise_not.default(arg3_1);  arg3_1 = None
	        bitwise_and: "b8[2][1]cpu" = torch.ops.aten.bitwise_and.Tensor(bitwise_not, arg4_1);  bitwise_not = arg4_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:583 in torch_dynamo_resume_in__initialize_feasible_at_583, code: p0[mask] = lb[mask] + 1
	        copy_: "f64[2][1]cpu" = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None
	        return (bitwise_and,)
	        
V0401 21:31:24.193000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "e6cf4ed742ab509c33bf8988872e6df8"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084192820.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.196000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "617dcd1f51600665f04470e0bd825508"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084195932.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.196000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "daae12dbfcd323341290396ecc5bce5e"}
	{
	"name": "inductor_compile",
	"ts": 1743543084195932.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.208000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/6h/c6hqclzdnxhejp2mllp3reuszylzata4w4pfczorn7oypningx6p.py"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "01480e6bbce220c85768b15c477a7635"}
	# AOT ID: ['8_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_bitwise_and_bitwise_not_0 = async_compile.cpp_pybinding(['const bool*', 'const bool*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const bool* in_ptr0,
	                       const bool* in_ptr1,
	                       bool* out_ptr0)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = !tmp0;
	            auto tmp3 = decltype(tmp1)(tmp1 & tmp2);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp3;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1 = args
	    args.clear()
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    assert_size_stride(arg3_1, (2, ), (1, ))
	    assert_size_stride(arg4_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((0, ), (1, ), torch.float64)
	    aten.index_put_(arg1_1, [arg2_1], buf0, False)
	    del arg1_1
	    del arg2_1
	    del buf0
	    buf2 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    cpp_fused_bitwise_and_bitwise_not_0(arg3_1, arg4_1, buf2)
	    del arg3_1
	    del arg4_1
	    return (buf2, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg3_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg4_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:24.209000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "f40e80fedcf00baa27187306fd91daec"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543084209331.5,
	"args": {
	"key": "fdakzmc6rvnpytuk7kzokgs44wuzalnryaq5ymojyaz2ife2qrnd",
	"components": [
	"[i5ethix7lgv7h6rjm2xxzqbxbbxoztf2ozcclb5fhhu2jtity5t] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    add = torch.ops.aten.add.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], add);  arg2_1 = add = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg3_1);  arg3_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(bitwise_not, arg4_1);  bitwise_not = arg4_1 = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2083055314,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:24.210000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "372878276dc9bde9b97a833704299616"}
	{"key": "fdakzmc6rvnpytuk7kzokgs44wuzalnryaq5ymojyaz2ife2qrnd", "components": ["[i5ethix7lgv7h6rjm2xxzqbxbbxoztf2ozcclb5fhhu2jtity5t] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    add = torch.ops.aten.add.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], add);  arg2_1 = add = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg3_1);  arg3_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(bitwise_not, arg4_1);  bitwise_not = arg4_1 = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2083055314, "cache_state": "hit"}
V0401 21:31:24.212000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "c588099bcb702e57398c60e5bfc193dd"}
	{
	"name": "inductor_compile",
	"ts": 1743543084212505.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.213000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "a95427f0cee62b4d4e5d276f9be1d75b"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084213439.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.215000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "569f37d0221fe3bb4ddc9066de029c6e"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084214996.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.220000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "ceda5caf05d2705af246b997e65089f5"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084219806.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.220000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "17e090b4c7822784a9c4f758b3eff7c3"}
	{
	"name": "backend_compile",
	"ts": 1743543084220821.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.222000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "f03593eb51b81ce42c1b3fc4577193c4"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084222106.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.235000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "e536d8457a105e4ea42f4ed2c123944d"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['ub']), ___from_numpy(L['mask']), ___from_numpy(L['___stack0']), ___from_numpy(L['lb_finite']), ___from_numpy(L['ub_finite']))
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['lb_finite'], accessed_by=DictGetItemGuardAccessor(lb_finite)
	| | +- GuardManager: source=___from_numpy(L['lb_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['ub_finite'], accessed_by=DictGetItemGuardAccessor(ub_finite)
	| | +- GuardManager: source=___from_numpy(L['ub_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:31:24.236000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "dfd908c4c1b0b3fb9dd10607ab637463"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084235989.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.236000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "dc1c2d4571bedc5e7ebae7ed2d528eac"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084236836.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.237000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "14/0", "frame_key": "28", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_583", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 583, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 10, "graph_input_count": 5, "start_time": 1743543084.0949275, "entire_frame_compile_time_s": 0.14096522331237793, "backend_compile_time_s": 0.06369638442993164, "inductor_compile_time_s": 0.016474485397338867, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.030301570892333984, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.239000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "_initialize_feasible", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}, {"line": 583, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}, {"line": 586, "name": "torch_dynamo_resume_in__initialize_feasible_at_586", "filename": 6}]}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.240000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "2952731080c7f08f67dc505ac9c6dace"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084240168.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.241000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "0885a6dfa038c03ca5d0d9c1808e9d0d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084240168.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.244000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 41, "size": 0}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.245000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14ccd0>", "describer_id": 41}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.246000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 41, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.251000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 41, "size": 16}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.252000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f3bd4f0>", "describer_id": 41}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.253000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 41, "id": 3, "source": "___from_numpy(L['p0'])"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.255000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 41, "size": 2}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.255000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f15d630>", "describer_id": 41}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.256000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 41, "id": 4, "source": "___from_numpy(L['mask'])"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.260000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_": [0], "l_p0_": [2], "l_mask_": [2], "wrapped_sub": [0]}}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "d38f650955beb6b8cb9a2d923160df4c"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_: "f64[0][0]cpu", L_p0_: "f64[2][1]cpu", L_mask_: "b8[2][1]cpu"):
	        l_stack0_ = L_stack0_
	        l_p0_ = L_p0_
	        l_mask_ = L_mask_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:586 in torch_dynamo_resume_in__initialize_feasible_at_586, code: p0[mask] = ub[mask] - 1
	        wrapped_sub: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_sub(l_stack0_, 1);  l_stack0_ = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_p0_, l_mask_, wrapped_sub);  l_p0_ = l_mask_ = wrapped_sub = wrapped___setitem__ = None
	        return ()
	        
V0401 21:31:24.261000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "dc84ec555fbadb748119570e80def7d3"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084261651.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.264000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "ae28d1c8de78b554cb38fcc35d38ec33"}
	{
	"name": "backend_compile",
	"ts": 1743543084261651.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.269000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "5a1810818edb94b108660d0a0ce91070"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084269078.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.288000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "d9ea633bb9b69eede4840ac85dee0aa4"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[0][0]cpu", arg1_1: "f64[2][1]cpu", arg2_1: "b8[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:586 in torch_dynamo_resume_in__initialize_feasible_at_586, code: p0[mask] = ub[mask] - 1
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        sub: "f64[0][1]cpu" = torch.ops.aten.sub.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        index_put: "f64[2][1]cpu" = torch.ops.aten.index_put.default(arg1_1, [arg2_1], sub);  arg2_1 = sub = None
	        copy_: "f64[2][1]cpu" = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None
	        return ()
	        
V0401 21:31:24.289000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "096380d4676cd28097416d3cd614cd29"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084289129.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.292000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "230abbd8ea7019567b83cb50e333f900"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084292836.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.293000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "8acf5c410d05886d70d5f5ca46557bf4"}
	{
	"name": "inductor_compile",
	"ts": 1743543084292836.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.302000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/dl/cdll33i4idcjni2tmji4jisqc6ixjbjq4dvuwjqsso6rc2nkcjso.py"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "4d267a0bf1958620c9e79ee78abd5af5"}
	# AOT ID: ['9_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((0, ), (1, ), torch.float64)
	    aten.index_put_(arg1_1, [arg2_1], buf0, False)
	    del arg1_1
	    del arg2_1
	    return ()
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:24.303000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "6378b59826653ea8b8b0b2bb31af4507"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543084303068.5,
	"args": {
	"key": "flvnpb3zork5pmpcx6lz2vwjpx7xbbbbsjvrnpgvsq7shmtxwpwv",
	"components": [
	"[o7vddygb3d2vcbxbyxulsvlugfb5xz7pq7kyyepwqevux7tdrrw] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], sub);  arg2_1 = sub = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 10248149,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:24.304000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "691c4d5a08a26b24e2ed30a10bf1d901"}
	{"key": "flvnpb3zork5pmpcx6lz2vwjpx7xbbbbsjvrnpgvsq7shmtxwpwv", "components": ["[o7vddygb3d2vcbxbyxulsvlugfb5xz7pq7kyyepwqevux7tdrrw] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], sub);  arg2_1 = sub = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 10248149, "cache_state": "hit"}
V0401 21:31:24.305000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "f2666a3fbd8f2b41637889edc7cbbb3e"}
	{
	"name": "inductor_compile",
	"ts": 1743543084305309.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.306000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "4a5c19adc69804b7f0b3fc4e30ab39b2"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084306093.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.307000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "7aaa5cd70b796edf0e39a78548deb892"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084307290.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.311000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "a96949cdb58cce2a550c2fec72e159ca"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084311394.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.312000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "ad63eaa0a7d73df974ec190c85423ee3"}
	{
	"name": "backend_compile",
	"ts": 1743543084312307.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.314000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "8d78a59d84f577cc15e34d311fd11ca7"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084314215.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.319000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "197f178dd85ba2f6d0e897a71c0f7119"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['mask']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:31:24.320000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "2d912c8307dcb56f8661228bd1fad30d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084320503.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.321000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "d83f7783b01869a23b0acc399c4d4ac6"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084321522.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.322000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "15/0", "frame_key": "29", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_586", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 586, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 8, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 6, "graph_input_count": 3, "start_time": 1743543084.2401562, "entire_frame_compile_time_s": 0.08025479316711426, "backend_compile_time_s": 0.050577640533447266, "inductor_compile_time_s": 0.012378692626953125, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.325000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}]}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.326000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "eea117183ba7c1d5d126f1e9475ed70c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084326506.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.327000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "654d19fdf55af6df8dac1718d11f6712"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084326506.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.337000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 43, "size": 16}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.338000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f411860>", "describer_id": 43}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.338000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 43, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.341000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 43, "size": 16}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.342000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f411fe0>", "describer_id": 43}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.343000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 43, "id": 1, "source": "___from_numpy(L['lb'])"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.347000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 43, "size": 16}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.349000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f678500>", "describer_id": 43}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.349000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 43, "id": 4, "source": "___from_numpy(L['ub'])"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.358000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_lb_": [2], "l_ub_": [2], "wrapped_gt": [2], "wrapped_lt": [2], "wrapped_or_": [2], "bounded_problem": []}}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "411beb691e04107906795c088671a2fd"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_lb_: "f64[2][1]cpu", L_ub_: "f64[2][1]cpu"):
	        l_lb_ = L_lb_
	        l_ub_ = L_ub_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:916 in torch_dynamo_resume_in_curve_fit_at_914, code: bounded_problem = np.any((lb > -np.inf) | (ub < np.inf))
	        wrapped_gt: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_gt(l_lb_, -inf);  l_lb_ = None
	        wrapped_lt: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_lt(l_ub_, inf);  l_ub_ = None
	        wrapped_or_: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_or_(wrapped_gt, wrapped_lt);  wrapped_gt = wrapped_lt = None
	        bounded_problem: "b8[][]cpu" = torch__dynamo_utils_wrapped_any(wrapped_or_);  wrapped_or_ = None
	        return (bounded_problem,)
	        
V0401 21:31:24.360000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "3f7c7ee3f344a58ff2523b140748cd01"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084360145.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.360000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "d0984cd26bf0c9df6c55e989d3e0b3ed"}
	{
	"name": "backend_compile",
	"ts": 1743543084360145.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.364000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "9ba70bbb9aec9baced1b77553833b88f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084364311.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.387000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "7e31aaf4bda63f2fc5d38c9b85e4ea2b"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu", arg1_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:916 in torch_dynamo_resume_in_curve_fit_at_914, code: bounded_problem = np.any((lb > -np.inf) | (ub < np.inf))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        gt: "b8[2][1]cpu" = torch.ops.aten.gt.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        _tensor_constant1 = self._tensor_constant1
	        lift_fresh_copy_1: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None
	        lt: "b8[2][1]cpu" = torch.ops.aten.lt.Tensor(arg1_1, lift_fresh_copy_1);  arg1_1 = lift_fresh_copy_1 = None
	        bitwise_or: "b8[2][1]cpu" = torch.ops.aten.bitwise_or.Tensor(gt, lt);  gt = lt = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.default(bitwise_or);  bitwise_or = None
	        return (any_1,)
	        
V0401 21:31:24.389000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "c89dc780fd7a8de04ebaa94f4bde7a24"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084388622.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.393000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "8fddac3b804f594513e3b33948f7c857"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084393118.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.394000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "6dc064de7cd5d43eb46edf12de4d0e13"}
	{
	"name": "inductor_compile",
	"ts": 1743543084393118.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.404000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/37/c37hwhbesycsk3sxucpus24q5zu2tfasgk7xqxqmtzvcuvpzuinc.py"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "b5f277ba0efd508927a9db1afd59840d"}
	# AOT ID: ['10_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_any_bitwise_or_gt_lift_fresh_lt_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       bool* out_ptr0)
	{
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                auto tmp3 = in_ptr1[static_cast<int64_t>(x0)];
	                auto tmp1 = -std::numeric_limits<double>::infinity();
	                auto tmp2 = tmp0 > tmp1;
	                auto tmp4 = std::numeric_limits<double>::infinity();
	                auto tmp5 = tmp3 < tmp4;
	                auto tmp6 = decltype(tmp2)(tmp2 | tmp5);
	                tmp_acc0 = tmp_acc0 || tmp6;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    cpp_fused_any_bitwise_or_gt_lift_fresh_lt_0(arg0_1, arg1_1, buf0)
	    del arg0_1
	    del arg1_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:24.405000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "1779ef702c529733eebd3eecab14e9e1"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543084404657.0,
	"args": {
	"key": "fstzt65vvyck4b3j2hkcbkevgez364ihyfhur3iubyrvhyrcue4q",
	"components": [
	"[gkitalcxmcz37pk6n5r7uwhxdfvqwnlmaqgybrlsou6ct7yzmkj] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    gt = torch.ops.aten.gt.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default_1 = torch.ops.aten.full.default([], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Tensor(arg1_1, full_default_1);  arg1_1 = full_default_1 = None\n    bitwise_or = torch.ops.aten.bitwise_or.Tensor(gt, lt);  gt = lt = None\n    any_1 = torch.ops.aten.any.default(bitwise_or);  bitwise_or = None\n    return (any_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[s5yf3qhu2mzuc6huo2hj2x67z5dovjywy454rtpmcch3de7jidr] fx_kwargs[user_visible_outputs]: {'any_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 1980077558,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:24.406000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "5e802dc54dcf44d7268d46517ec0d964"}
	{"key": "fstzt65vvyck4b3j2hkcbkevgez364ihyfhur3iubyrvhyrcue4q", "components": ["[gkitalcxmcz37pk6n5r7uwhxdfvqwnlmaqgybrlsou6ct7yzmkj] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    gt = torch.ops.aten.gt.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default_1 = torch.ops.aten.full.default([], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Tensor(arg1_1, full_default_1);  arg1_1 = full_default_1 = None\n    bitwise_or = torch.ops.aten.bitwise_or.Tensor(gt, lt);  gt = lt = None\n    any_1 = torch.ops.aten.any.default(bitwise_or);  bitwise_or = None\n    return (any_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[s5yf3qhu2mzuc6huo2hj2x67z5dovjywy454rtpmcch3de7jidr] fx_kwargs[user_visible_outputs]: {'any_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 1980077558, "cache_state": "hit"}
V0401 21:31:24.407000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "30a5741bf21862972397e53f72df4c67"}
	{
	"name": "inductor_compile",
	"ts": 1743543084406981.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.407000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "5c800eefa6df0afbfdb56eeb96f9cdb0"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543084407728.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.409000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "e37438c5572b3038be0473b5f1fc4569"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543084409124.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.412000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "1b0e99d54beba8a52f98dbd885c851e5"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543084412913.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.413000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "b7e93c29376baa4080c7e36f2bb2d237"}
	{
	"name": "backend_compile",
	"ts": 1743543084413732.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.414000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "58d52d9ed0ff53b7ba5894c64a24db82"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543084414655.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.588000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "9aae1bdd5df9cc91f52a8b8ba91ac271"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['method'], accessed_by=DictGetItemGuardAccessor(method)
	| | +- ID_MATCH: ___check_obj_id(L['method'], 105251315093216)               
	| +- GuardManager: source=L['lb'], accessed_by=DictGetItemGuardAccessor(lb)
	| | +- GuardManager: source=___from_numpy(L['lb']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['lb']), ___from_numpy(L['ub']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].any, accessed_by=GetAttrGuardAccessor(any)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].any, 123155351020784)               
	| | | +- GuardManager: source=G['np'].inf, accessed_by=GetAttrGuardAccessor(inf)
	| | | | +- EQUALS_MATCH: G['np'].inf == inf                                          
	
V0401 21:31:24.589000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "adadbca1b928bef6104e6c7269f0fe46"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084589442.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.590000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "c0ec488532f0f2473584332e17ff97ce"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084590489.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.592000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "16/0", "frame_key": "30", "co_name": "torch_dynamo_resume_in_curve_fit_at_914", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 914, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543084.3264947, "entire_frame_compile_time_s": 0.2628154754638672, "backend_compile_time_s": 0.05351519584655762, "inductor_compile_time_s": 0.013754606246948242, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.596000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}]}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.599000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "018ee500396fd49c5c4e31a74430c27d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084599593.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.600000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "a3b0284db5387128d4fb0eaf8f0fd89e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084599593.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.612000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 45, "size": 1}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.613000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 0, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f3bdc20>", "describer_id": 45}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.614000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 45, "id": 0, "source": "___from_numpy(L['bounded_problem'])"}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.749000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "d10a2e666d6a11f0cbf86fd87901a5b3"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['bounded_problem'], accessed_by=DictGetItemGuardAccessor(bounded_problem)
	| | +- GuardManager: source=___from_numpy(L['bounded_problem']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['bounded_problem']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[], stride=[])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['bounded_problem']), '_dynamo_dynamic_indices') == False
	
V0401 21:31:24.750000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "b7689b8ba37dafe88741ffeb56457f8a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084750762.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.751000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "e5a4b5b8be68bf97d079f9617fda7c82"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084751685.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.753000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "17/0", "frame_key": "31", "co_name": "torch_dynamo_resume_in_curve_fit_at_918", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 918, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 6, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543084.5995777, "entire_frame_compile_time_s": 0.1510450839996338, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.755000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}]}, "frame_id": 18, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:24.756000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 0, "has_payload": "252660b15a2fa9c4377636a767193990"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543084755994.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.756000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 0, "has_payload": "0f64b757208f9b1dcdbca931488069ca"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543084755994.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:24.774000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 47, "size": 2400}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.774000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f14e6c0>", "describer_id": 47}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:24.775000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 47, "id": 0, "source": "___from_numpy(L['ydata'])"}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.100000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1, "has_payload": "88f6fd6529de7b19e6efccb879708d52"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['nan_policy'], accessed_by=DictGetItemGuardAccessor(nan_policy)
	| | +- ID_MATCH: ___check_obj_id(L['nan_policy'], 105251315093216)           
	| +- GuardManager: source=L['check_finite'], accessed_by=DictGetItemGuardAccessor(check_finite)
	| | +- ID_MATCH: ___check_obj_id(L['check_finite'], 105251315093216)         
	| +- GuardManager: source=L['ydata'], accessed_by=DictGetItemGuardAccessor(ydata)
	| | +- GuardManager: source=___from_numpy(L['ydata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ydata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ydata']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].asarray_chkfinite, accessed_by=GetAttrGuardAccessor(asarray_chkfinite)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].asarray_chkfinite, 123155305644256) 
	| | +- GuardManager: source=G['__builtins_dict___62'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___62)
	| | | +- GuardManager: source=G['__builtins_dict___62']['float'], accessed_by=DictGetItemGuardAccessor(float)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___62']['float'], 105251315063584)
	
V0401 21:31:25.101000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1, "has_payload": "a9ffad40443a6d86f1583237b5ef243b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085101448.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.102000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1, "has_payload": "51779bfad52a342407382f858d91366f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085102407.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.103000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "18/0", "frame_key": "32", "co_name": "torch_dynamo_resume_in_curve_fit_at_923", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 923, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543084.755982, "entire_frame_compile_time_s": 0.34534502029418945, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Can't find numpy function <function asarray_chkfinite at 0x7002543ec0e0> in torch._numpy.  Please file an issue to request support for this function."], "dynamo_time_before_restart_s": 0.007741451263427734, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.106000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}]}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.107000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0, "has_payload": "add781299a1b3242897649ddd0275f6b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085107166.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.108000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0, "has_payload": "21ff4e7e65d81b8adb1e0ef84ca1d5b3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085107166.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.116000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 48, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.117000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f83a530>", "describer_id": 48}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.118000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 48, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.121000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 48, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.122000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f72ec60>", "describer_id": 48}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.122000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 48, "id": 1, "source": "___from_numpy(L['xdata'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.132000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 49, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.133000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f8b4c80>", "describer_id": 49}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.134000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 49, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.137000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 49, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.137000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f8b5fe0>", "describer_id": 49}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.138000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 49, "id": 1, "source": "___from_numpy(L['xdata'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.297000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1, "has_payload": "c2a2b187f324de68a0f322d8a5229c84"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['check_finite'], accessed_by=DictGetItemGuardAccessor(check_finite)
	| | +- ID_MATCH: ___check_obj_id(L['check_finite'], 105251315000224)         
	| +- GuardManager: source=L['xdata'], accessed_by=DictGetItemGuardAccessor(xdata)
	| | +- GuardManager: source=___from_numpy(L['xdata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['xdata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['xdata']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['xdata']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].ndarray, accessed_by=GetAttrGuardAccessor(ndarray)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ndarray, 123155389901056)           
	| | | +- GuardManager: source=G['np'].asarray_chkfinite, accessed_by=GetAttrGuardAccessor(asarray_chkfinite)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].asarray_chkfinite, 123155305644256) 
	| | +- GuardManager: source=G['__builtins_dict___65'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___65)
	| | | +- GuardManager: source=G['__builtins_dict___65']['list'], accessed_by=DictGetItemGuardAccessor(list)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['list'], 105251315071904)
	| | | +- GuardManager: source=G['__builtins_dict___65']['float'], accessed_by=DictGetItemGuardAccessor(float)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['float'], 105251315063584)
	| | | +- GuardManager: source=G['__builtins_dict___65']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['tuple'], 105251315101760)
	| | | +- GuardManager: source=G['__builtins_dict___65']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['isinstance'], 123155769909520)
	
V0401 21:31:25.298000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1, "has_payload": "09f1f05ab973eb79e5a89183b05a751a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085298191.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.299000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1, "has_payload": "3edb5e06b0884ff0ca45e01886a375f5"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085299218.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.300000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "19/0", "frame_key": "33", "co_name": "torch_dynamo_resume_in_curve_fit_at_932", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 932, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 15, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543085.1071534, "entire_frame_compile_time_s": 0.19091010093688965, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Can't find numpy function <function asarray_chkfinite at 0x7002543ec0e0> in torch._numpy.  Please file an issue to request support for this function."], "dynamo_time_before_restart_s": 0.01646709442138672, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.303000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}]}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.303000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0, "has_payload": "cedeb1b140ef8fb0807a69058f642275"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085303682.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.306000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0, "has_payload": "a931f6c3b0d6a43463ba165472d6d28f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085303682.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.315000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 50, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.316000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f71c280>", "describer_id": 50}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.317000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 50, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.319000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 50, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.320000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f72eb20>", "describer_id": 50}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.320000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 50, "id": 1, "source": "___from_numpy(L['ydata'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.334000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 51, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.335000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1eb250>", "describer_id": 51}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.336000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 51, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.338000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 51, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.339000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1e9900>", "describer_id": 51}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.340000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 51, "id": 1, "source": "___from_numpy(L['ydata'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.409000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1, "has_payload": "bdb1b0440e5fb1e98a1f3fef7e7268c6"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 123154978635040)           
	| +- GuardManager: source=L['sigma'], accessed_by=DictGetItemGuardAccessor(sigma)
	| | +- ID_MATCH: ___check_obj_id(L['sigma'], 105251315093216)                
	| +- GuardManager: source=L['check_finite'], accessed_by=DictGetItemGuardAccessor(check_finite)
	| | +- ID_MATCH: ___check_obj_id(L['check_finite'], 105251315000224)         
	| +- GuardManager: source=L['ydata'], accessed_by=DictGetItemGuardAccessor(ydata)
	| | +- GuardManager: source=___from_numpy(L['ydata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ydata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ydata']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['ydata']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['_wrap_func'], accessed_by=DictGetItemGuardAccessor(_wrap_func)
	| | | +- GuardManager: source=G['_wrap_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_wrap_func'].__code__, 123155047931488)  
	| | +- GuardManager: source=G['_lightweight_memoizer'], accessed_by=DictGetItemGuardAccessor(_lightweight_memoizer)
	| | | +- GuardManager: source=G['_lightweight_memoizer'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_lightweight_memoizer'].__code__, 123155042366768)
	
V0401 21:31:25.411000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1, "has_payload": "d1c3343432c1c3d76d54f97c893cb7c8"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085411450.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.413000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1, "has_payload": "c73e0c2fcb41ed095498d16a3a417a5d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085413580.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.416000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "20/0", "frame_key": "34", "co_name": "torch_dynamo_resume_in_curve_fit_at_940", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 940, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543085.3036702, "entire_frame_compile_time_s": 0.10765600204467773, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: setattr [<class 'torch._dynamo.variables.functions.NestedUserFunctionVariable'>, <class 'torch._dynamo.variables.constant.ConstantVariable'>, <class 'torch._dynamo.variables.constant.ConstantVariable'>] False"], "dynamo_time_before_restart_s": 0.01979231834411621, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.419000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 989, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}]}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.421000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0, "has_payload": "c20329ad4c346a6d5de23cd38379d05c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085421643.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.422000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0, "has_payload": "5297c77170754664b2c0124999778fce"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085421643.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.432000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 52, "size": 2400}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.433000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f4256d0>", "describer_id": 52}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.434000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 52, "id": 0, "source": "___from_numpy(L['ydata'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.441000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 52, "size": 16}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.442000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f29cb90>", "describer_id": 52}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.443000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 52, "id": 1, "source": "___from_numpy(L['p0'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.462000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 53, "size": 2400}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.463000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f7403c0>", "describer_id": 53}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.464000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 53, "id": 0, "source": "___from_numpy(L['ydata'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.469000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 53, "size": 16}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.470000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f741180>", "describer_id": 53}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.470000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 53, "id": 1, "source": "___from_numpy(L['p0'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.543000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1, "has_payload": "abd7068ec46df8c0142aac7b4b0a0437"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['n'], accessed_by=DictGetItemGuardAccessor(n)
	| | +- EQUALS_MATCH: L['n'] == 2                                                 
	| +- GuardManager: source=L['jac'], accessed_by=DictGetItemGuardAccessor(jac)
	| | +- ID_MATCH: ___check_obj_id(L['jac'], 105251315093216)                  
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=L['method'], accessed_by=DictGetItemGuardAccessor(method)
	| | +- EQUALS_MATCH: L['method'] == 'lm'                                         
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=L['___stack0'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['___stack0'].__code__, 123155042439440)   
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['ydata']))
	| +- GuardManager: source=L['ydata'], accessed_by=DictGetItemGuardAccessor(ydata)
	| | +- GuardManager: source=___from_numpy(L['ydata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ydata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ydata']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['leastsq'], accessed_by=DictGetItemGuardAccessor(leastsq)
	| | | +- GuardManager: source=G['leastsq'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['leastsq'].__code__, 105251493172224)     
	| | +- GuardManager: source=G['__builtins_dict___71'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___71)
	| | | +- GuardManager: source=G['__builtins_dict___71']['callable'], accessed_by=DictGetItemGuardAccessor(callable)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___71']['callable'], 123155769908240)
	
V0401 21:31:25.544000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1, "has_payload": "1020ef0da9dc31a1685dbe18fcd04f21"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085544745.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.545000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1, "has_payload": "ab5f37b8e8ffb118a0479d1055e42645"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085545768.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.547000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "21/0", "frame_key": "36", "co_name": "torch_dynamo_resume_in_curve_fit_at_989", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 989, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 15, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543085.4216306, "entire_frame_compile_time_s": 0.12299561500549316, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands"], "dynamo_time_before_restart_s": 0.030530929565429688, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.550000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}]}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.551000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0, "has_payload": "6faa0a534c88b01e38d05bdba2392620"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085551247.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.552000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0, "has_payload": "fd8c91011bdd93a340a2414c358c32f6"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085551247.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.558000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 54, "size": 16}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.559000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f4fe3a0>", "describer_id": 54}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.560000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 54, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.573000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 55, "size": 16}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.573000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0177f0>", "describer_id": 55}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.574000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 55, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.579000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_x0_": [2], "wrapped_asarray": [2], "x0": [2]}}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "741c37af5591f03c34ee26b5e0d9e3bd"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_x0_: "f64[2][1]cpu"):
	        l_x0_ = L_x0_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:422 in leastsq, code: x0 = asarray(x0).flatten()
	        wrapped_asarray: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_asarray(l_x0_);  l_x0_ = None
	        x0: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_flatten(wrapped_asarray);  wrapped_asarray = None
	        return (x0,)
	        
V0401 21:31:25.580000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "7f835a97d9b641cb777a5a8305258945"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085580564.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.581000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "bdc63d900e4f17f1bf54170bd52a4ef6"}
	{
	"name": "backend_compile",
	"ts": 1743543085580564.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.583000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "cef2bef7c84e5905fbbd393cb93279da"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085583731.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.591000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "7131d01c24ed02c36e4dd3a1bc5908c9"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	        return (arg0_1,)
	        
V0401 21:31:25.592000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "ad1b7ca5bcc5fc4e585cf11db6997467"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085592449.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.594000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "a3059bf308fb5035290182a3c1a6b118"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085594163.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.594000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "afea4025df4381c37b7034a65d242ad4"}
	{
	"name": "inductor_compile",
	"ts": 1743543085594163.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.596000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "a3c6a68d2257b52ba409b4e309908b86"}
	{
	"name": "inductor_compile",
	"ts": 1743543085596397.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.597000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "54065cb240d31df89f7adc1c61fbb483"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085597012.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.598000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "e96dd4085d5ca612c8ab6679cc833934"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085598325.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.602000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "54059e5004d03de1626b67b98d67b87c"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085602346.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.603000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "bcd1b226782b5d4c1fa40a38188f3c20"}
	{
	"name": "backend_compile",
	"ts": 1743543085603165.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.604000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "80ebcddf8a91876afb0bc2d905a947b0"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085604009.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.626000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "848d66d6c0f40cad0335b57188e019db"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['args'], accessed_by=DictGetItemGuardAccessor(args)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 105251315101760)                
	| | +- LENGTH_CHECK: not L['args']                                               
	| +- GuardManager: source=L['func'], accessed_by=DictGetItemGuardAccessor(func)
	| | +- GuardManager: source=L['func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['func'].__code__, 123155042439440)        
	| +- GuardManager: source=L['x0'], accessed_by=DictGetItemGuardAccessor(x0)
	| | +- GuardManager: source=___from_numpy(L['x0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['x0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['x0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['asarray'], accessed_by=DictGetItemGuardAccessor(asarray)
	| | | +- ID_MATCH: ___check_obj_id(G['asarray'], 123155762228064)              
	| | +- GuardManager: source=G['_check_func'], accessed_by=DictGetItemGuardAccessor(_check_func)
	| | | +- GuardManager: source=G['_check_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_check_func'].__code__, 105251493150640) 
	| | +- GuardManager: source=G['__builtins_dict___74'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___74)
	| | | +- GuardManager: source=G['__builtins_dict___74']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___74']['len'], 123155769909840)
	| | | +- GuardManager: source=G['__builtins_dict___74']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___74']['tuple'], 105251315101760)
	| | | +- GuardManager: source=G['__builtins_dict___74']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___74']['isinstance'], 123155769909520)
	
V0401 21:31:25.627000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "72c9e540427ccf537de90596c0a1187b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085627240.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.628000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "0e554503f1fd1d8e95e2a95072cbbd78"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085628211.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.629000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "22/0", "frame_key": "37", "co_name": "leastsq", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 292, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543085.551235, "entire_frame_compile_time_s": 0.07590866088867188, "backend_compile_time_s": 0.02253103256225586, "inductor_compile_time_s": 0.0021619796752929688, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands"], "dynamo_time_before_restart_s": 0.01505422592163086, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.631000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 21, "name": "_check_func", "filename": 6}]}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.632000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0, "has_payload": "f9619c29cffa22c2a2bc299de639728c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085632269.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.633000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0, "has_payload": "7e3382f2587f9e7ed38386d163210ff0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085632269.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.638000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 57, "size": 16}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.639000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f72e120>", "describer_id": 57}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.640000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 57, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.651000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 58, "size": 16}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.653000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f72dea0>", "describer_id": 58}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.654000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 58, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.659000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_x0_": [2], "wrapped_getitem": [2]}}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "3d9625ce453d85332b40846605cfc418"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_x0_: "f64[2][1]cpu"):
	        l_x0_ = L_x0_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:23 in _check_func, code: res = atleast_1d(thefunc(*((x0[:numinputs],) + args)))
	        wrapped_getitem: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_getitem(l_x0_, slice(None, 2, None));  l_x0_ = None
	        return (wrapped_getitem,)
	        
V0401 21:31:25.660000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "0c5c004da027cee297208c9285e562ce"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085660028.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.660000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "54cb781ef7e0bcc44ccfdb9acee7c205"}
	{
	"name": "backend_compile",
	"ts": 1743543085660028.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.662000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "37323c8f8ea2042a24bb66075affc7de"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085662887.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.672000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "662fa58c3d349b3d2bc1776ae6494e47"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:23 in _check_func, code: res = atleast_1d(thefunc(*((x0[:numinputs],) + args)))
	        slice_1: "f64[2][1]cpu" = torch.ops.aten.slice.Tensor(arg0_1, 0, 0, 2);  arg0_1 = None
	        return (slice_1,)
	        
V0401 21:31:25.673000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "a10603653ae43dc7aa87b2fc7a9af67a"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085673271.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.675000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "9e0826635937cb3a017daf00e336636a"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085675128.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.675000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "6f467e51a8447cc3c82dc03cda7ed74a"}
	{
	"name": "inductor_compile",
	"ts": 1743543085675128.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.682000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/fp/cfp2ilt7vffar6bq4ic47nuai6tnrhuul3apzay3uqo3c4pkmd7t.py"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "ff0acf423232e489ae3de0b92d360976"}
	# AOT ID: ['12_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    return (arg0_1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:25.683000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "6cd448e07752fda5e1b835e83c370daf"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543085682904.2,
	"args": {
	"key": "fwkysxunwbmfh7xpdqnoc25mqewdv4fg4fgxhl63th4atggugobz",
	"components": [
	"[eotweswpn6tdut4xjsrwsmwo33n4g63uq2ujhpdsvi3xe4jmsf5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    slice_1 = torch.ops.aten.slice.Tensor(arg0_1, 0, 0, 2);  arg0_1 = None\n    return (slice_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[scxqngv652g7lmdzehboht3ccivqzlxyzcibzxvt52nw4kxiwuj] fx_kwargs[user_visible_outputs]: {'slice_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 5296711,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:25.684000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "a796028ed53933f94b4ed61bc15cb83f"}
	{"key": "fwkysxunwbmfh7xpdqnoc25mqewdv4fg4fgxhl63th4atggugobz", "components": ["[eotweswpn6tdut4xjsrwsmwo33n4g63uq2ujhpdsvi3xe4jmsf5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    slice_1 = torch.ops.aten.slice.Tensor(arg0_1, 0, 0, 2);  arg0_1 = None\n    return (slice_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[scxqngv652g7lmdzehboht3ccivqzlxyzcibzxvt52nw4kxiwuj] fx_kwargs[user_visible_outputs]: {'slice_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 5296711, "cache_state": "hit"}
V0401 21:31:25.685000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "c7196a8a6289ea0a0b4bd29cd70921e6"}
	{
	"name": "inductor_compile",
	"ts": 1743543085685289.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.686000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "0f954c6733d8147831b446b9458b9e13"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085686086.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.687000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "c3825949b020fba86441344dc42cf132"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085687270.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.690000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "54f25c1d2eca3b529528d31a979602fc"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085690378.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.691000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "36995767a1d02bb9fab3a29268b89cc3"}
	{
	"name": "backend_compile",
	"ts": 1743543085691145.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.692000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "86225fe790e35ed1043620320422c7a8"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085692012.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.702000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "e53427b996d46d5df0e654c4e6e9d378"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['args'], accessed_by=DictGetItemGuardAccessor(args)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 105251315101760)                
	| | +- LENGTH_CHECK: not L['args']                                               
	| +- GuardManager: source=L['thefunc'], accessed_by=DictGetItemGuardAccessor(thefunc)
	| | +- GuardManager: source=L['thefunc'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['thefunc'].__code__, 123155042439440)     
	| +- GuardManager: source=L['numinputs'], accessed_by=DictGetItemGuardAccessor(numinputs)
	| | +- EQUALS_MATCH: L['numinputs'] == 2                                         
	| +- GuardManager: source=L['x0'], accessed_by=DictGetItemGuardAccessor(x0)
	| | +- GuardManager: source=___from_numpy(L['x0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['x0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['x0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['atleast_1d'], accessed_by=DictGetItemGuardAccessor(atleast_1d)
	| | | +- ID_MATCH: ___check_obj_id(G['atleast_1d'], 123155350677808)           
	
V0401 21:31:25.703000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "fe1b48238ed866a7d50be6a42f03a781"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085703612.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.704000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "ac4cb67b05f4de9724f83bbaff176449"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085704626.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.706000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "23/0", "frame_key": "38", "co_name": "_check_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 21, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 10, "shape_env_guard_count": 0, "graph_op_count": 1, "graph_node_count": 3, "graph_input_count": 1, "start_time": 1743543085.6322575, "entire_frame_compile_time_s": 0.07106351852416992, "backend_compile_time_s": 0.031050682067871094, "inductor_compile_time_s": 0.010082721710205078, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands"], "dynamo_time_before_restart_s": 0.01276254653930664, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.708000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}]}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.709000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "4f5e881c0aa8cb33c006c4fdf1d684bc"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085709152.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.710000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "8e9f0e1a88f5193843202378c57b060a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085709152.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.713000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 60, "size": 16}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.714000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f691590>", "describer_id": 60}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.714000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 60, "id": 0, "source": "___from_numpy(L['params'])"}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.719000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_params_": [2], "wrapped_eq": [2], "wrapped_all": []}}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "4f5440b3b1824eaaf02610b2c1eb2ae3"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_params_: "f64[2][1]cpu"):
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        wrapped_eq: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_eq(None, l_params_);  l_params_ = None
	        wrapped_all: "b8[][]cpu" = torch__dynamo_utils_wrapped_all(wrapped_eq);  wrapped_eq = None
	        return (wrapped_all,)
	        
V0401 21:31:25.720000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "09bf5e0babff82a2b7f4b26906dbe19e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085720022.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.720000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "9f75dba28f9178d945ea0472fcad0902"}
	{
	"name": "backend_compile",
	"ts": 1743543085720022.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.723000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "469e0a52c8793fa40585e45bea450555"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085722937.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.736000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "3ff372be4afe2733f214453ae3569ae7"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        full: "b8[2][1]cpu" = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
	        logical_not: "b8[2][1]cpu" = torch.ops.aten.logical_not.default(full);  full = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.dims(logical_not);  logical_not = None
	        logical_not_1: "b8[][]cpu" = torch.ops.aten.logical_not.default(any_1);  any_1 = None
	        return (logical_not_1,)
	        
V0401 21:31:25.737000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "dabfd7d7adee7d4740ceaf84f076c3fd"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085737402.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.740000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "428e2c89f83183cc472e71f03af5b679"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085740381.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.741000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "454bda7cd6cc527f3716730e979987f7"}
	{
	"name": "inductor_compile",
	"ts": 1743543085740381.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.751000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/q5/cq5wfl2yqwi4le4rmfqq2y4pyn42e4qf7spssmca6py4ottabw2n.py"}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "2090f44d633c618d126ad013c3bd287a"}
	# AOT ID: ['13_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_all_0 = async_compile.cpp_pybinding(['bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(bool* in_out_ptr0)
	{
	    auto out_ptr0 = in_out_ptr0;
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = static_cast<bool>(true);
	                tmp_acc0 = tmp_acc0 || tmp0;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	    {
	        auto tmp0 = out_ptr0[static_cast<int64_t>(0L)];
	        auto tmp1 = !tmp0;
	        in_out_ptr0[static_cast<int64_t>(0L)] = tmp1;
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    buf1 = buf0; del buf0  # reuse
	    cpp_fused_all_0(buf1)
	    return (buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:25.752000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "95029020313fa27807eec1763886abc2"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543085751794.0,
	"args": {
	"key": "ff4kynrazp4b7vy6kbhgasuju7t34d7crvkb6eeokypc2is6exml",
	"components": [
	"[pf766mtcrjcjiazes3g7xrt2s7i6e7amn6isktw3bzfloau65xn] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False);  full = None\n    full_default = torch.ops.aten.full.default([2], True, dtype = torch.bool, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    any_1 = torch.ops.aten.any.dims(full_default);  full_default = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2241340438,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:25.753000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "b648851298b6a9bc59c02c7c954dc131"}
	{"key": "ff4kynrazp4b7vy6kbhgasuju7t34d7crvkb6eeokypc2is6exml", "components": ["[pf766mtcrjcjiazes3g7xrt2s7i6e7amn6isktw3bzfloau65xn] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False);  full = None\n    full_default = torch.ops.aten.full.default([2], True, dtype = torch.bool, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    any_1 = torch.ops.aten.any.dims(full_default);  full_default = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2241340438, "cache_state": "hit"}
V0401 21:31:25.754000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "4b2fcc6e70727df0c9f3bb80438677b8"}
	{
	"name": "inductor_compile",
	"ts": 1743543085754693.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.756000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "9f9623c30abfbae2e8c02c065d6af199"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085755902.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.757000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "6af5d375357c4553ad3265fff2dc972d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085757124.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.760000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "d8792ea53e2eea88f3675163cd65babd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085760604.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.761000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "5645d3ca59b4f772d2a0279e9f42ff42"}
	{
	"name": "backend_compile",
	"ts": 1743543085761567.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.762000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "7327e79073d1ac23a90ac5c0615b4947"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085762204.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.771000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "4addb631dd9f28d84fd31a4d046ecf53"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].last_params, 105251315093216)
	| | +- GuardManager: source=L['_memoized_func'].skip_lookup, accessed_by=GetAttrGuardAccessor(skip_lookup)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].skip_lookup, 105251315000256)
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].all, accessed_by=GetAttrGuardAccessor(all)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].all, 123155351021488)               
	
V0401 21:31:25.772000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "8f45e4f903d66d3968536598a9a3172b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085772837.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.773000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "5639e78514b47ac03f4910d64c7be555"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085773554.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.774000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "24/0", "frame_key": "39", "co_name": "_memoized_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 515, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543085.709125, "entire_frame_compile_time_s": 0.06351161003112793, "backend_compile_time_s": 0.041455984115600586, "inductor_compile_time_s": 0.014222145080566406, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.776000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "_check_func", "filename": 6}, {"line": 519, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}]}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.777000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0, "has_payload": "86fa63e3ca3cd2f5843ade5137231b9b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085777043.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.778000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0, "has_payload": "598d29fd75df504fc6b38f71befb464f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085777043.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.781000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 62, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.782000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f424910>", "describer_id": 62}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.783000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 62, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.785000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 62, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.786000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f67ba20>", "describer_id": 62}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.786000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 62, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.788000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 62, "size": 16}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.789000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f8b72f0>", "describer_id": 62}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.790000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 62, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.803000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 63, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.804000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f4ffe80>", "describer_id": 63}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.805000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 63, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.808000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 63, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.809000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f4244b0>", "describer_id": 63}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.810000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 63, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.814000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 63, "size": 16}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.815000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f4feb70>", "describer_id": 63}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.815000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 63, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.825000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_f_closure_1_cell_contents": [300], "l_f_closure_2_cell_contents": [300], "l_params_": [2], "getitem": [], "getitem_1": [], "wrapped_mul": [], "wrapped_pow": [300], "wrapped_mul_1": [300], "wrapped_add": [300], "wrapped_truediv": [300], "val": [300], "wrapped_copy": [2]}}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "209f55592c558cee921ee7d582103b9b"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_f_closure_1_cell_contents: "f64[300][1]cpu", L_f_closure_2_cell_contents: "f64[300][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_f_closure_1_cell_contents = L_f_closure_1_cell_contents
	        l_f_closure_2_cell_contents = L_f_closure_2_cell_contents
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        getitem: "f64[][]cpu" = l_params_[0]
	        getitem_1: "f64[][]cpu" = l_params_[1]
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        wrapped_mul: "f64[][]cpu" = torch__dynamo_utils_wrapped_mul(2, getitem_1);  getitem_1 = None
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_f_closure_1_cell_contents, wrapped_mul);  l_f_closure_1_cell_contents = wrapped_mul = None
	        wrapped_mul_1: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_mul_1(getitem, wrapped_pow);  getitem = wrapped_pow = None
	        wrapped_add: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_add(1.0, wrapped_mul_1);  wrapped_mul_1 = None
	        wrapped_truediv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_truediv(1.0, wrapped_add);  wrapped_add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        val: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_sub(wrapped_truediv, l_f_closure_2_cell_contents);  wrapped_truediv = l_f_closure_2_cell_contents = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:527 in torch_dynamo_resume_in__memoized_func_at_519, code: _memoized_func.last_params = np.copy(params)
	        wrapped_copy: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_copy(l_params_);  l_params_ = None
	        return (wrapped_copy, val)
	        
V0401 21:31:25.827000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "d4855383cdf551071a926419117880f0"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085827067.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.827000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "f6d6dddad0c2b5aab7e52a55e987e2a2"}
	{
	"name": "backend_compile",
	"ts": 1743543085827067.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.831000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "35446e01a40a60856d1852fcc3ecc535"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085831767.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.858000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "6d87fd1e965b7dfb9d3b08028667c404"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[300][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 1)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        mul: "f64[][]cpu" = torch.ops.aten.mul.Tensor(lift_fresh_copy, select_1);  lift_fresh_copy = select_1 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None
	        div: "f64[300][1]cpu" = torch.ops.aten.div.Tensor(1.0, add);  add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        sub: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:527 in torch_dynamo_resume_in__memoized_func_at_519, code: _memoized_func.last_params = np.copy(params)
	        clone: "f64[2][1]cpu" = torch.ops.aten.clone.default(arg2_1);  arg2_1 = None
	        return (clone, sub)
	        
V0401 21:31:25.859000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "81e9e0a84ef568bb1291bda5eca15438"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085858966.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.861000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "9da86da9d3a184a1c8fd525a10ec1313"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085861920.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.862000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "91fd63cdf8912430e15d186357dc47a8"}
	{
	"name": "inductor_compile",
	"ts": 1743543085861920.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.873000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/7r/c7roapbkgtvgf2d2szvit2awwmzo2or7qrswygzfvmio4bhhcs3b.py"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "bd645d3dd92d61184aba96a36e695974"}
	# AOT ID: ['14_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_clone_div_lift_fresh_mul_pow_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'const double*', 'double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       const double* in_ptr2,
	                       double* out_ptr0,
	                       double* out_ptr1)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            out_ptr0[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp13 = at::vec::VectorizedN<double,2>::loadu(in_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = at::vec::VectorizedN<double,2>(tmp4);
	            auto tmp6 = tmp1.pow(tmp5);
	            auto tmp7 = at::vec::VectorizedN<double,2>(tmp0);
	            auto tmp8 = tmp7 * tmp6;
	            auto tmp9 = static_cast<double>(1.0);
	            auto tmp10 = at::vec::VectorizedN<double,2>(tmp9);
	            auto tmp11 = tmp10 + tmp8;
	            auto tmp12 = tmp10 / tmp11;
	            auto tmp14 = tmp12 - tmp13;
	            tmp14.store(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = std::pow(tmp1, tmp4);
	            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
	            auto tmp7 = static_cast<double>(1.0);
	            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
	            auto tmp9 = tmp7 / tmp8;
	            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
	            out_ptr1[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (300, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_add_clone_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    del arg2_1
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:25.874000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "63ad616f707519c5121a4d9629e8d48c"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543085874296.0,
	"args": {
	"key": "fwfwm3gcqnr4cvyzyoh2avpgdjkbl2zk7ymh4eijjhtpkoavhcvx",
	"components": [
	"[qflafsz2p4czhhersyocmxtxngfqw2jhm2baxmkqbkxhzskr6mz] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1)\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    clone = torch.ops.aten.clone.default(arg2_1);  arg2_1 = None\n    return (clone, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[36g36hx2xkznopwzdieqcx5gxtoradcuz4vsqu53gvtlrapu5aw] fx_kwargs[user_visible_outputs]: {'clone': None, 'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2031973205,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:25.875000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "399036bbb0b94f797a52c5daecbcb130"}
	{"key": "fwfwm3gcqnr4cvyzyoh2avpgdjkbl2zk7ymh4eijjhtpkoavhcvx", "components": ["[qflafsz2p4czhhersyocmxtxngfqw2jhm2baxmkqbkxhzskr6mz] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1)\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    clone = torch.ops.aten.clone.default(arg2_1);  arg2_1 = None\n    return (clone, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[36g36hx2xkznopwzdieqcx5gxtoradcuz4vsqu53gvtlrapu5aw] fx_kwargs[user_visible_outputs]: {'clone': None, 'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2031973205, "cache_state": "hit"}
V0401 21:31:25.877000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "240df6cf4a80ba33cdb58916f872fcde"}
	{
	"name": "inductor_compile",
	"ts": 1743543085877061.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.877000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "82862f050e5621c93ea85db5cc9e4a8d"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543085877822.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.879000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "b8981c3682edbab775ef86b9e51cd6a8"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543085878982.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.883000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "2aab6dff8bb9cea21739573896c86c18"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543085883231.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.884000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "0dad53601cd57da0670652c18a5c587d"}
	{
	"name": "backend_compile",
	"ts": 1743543085884364.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.885000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "3dea9a2550e24d7421eaefcea8e7cd7b"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543085885356.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.905000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "a3728104d2bde180042aeec1e9ca2180"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 123155042877488)           
	| | +- GuardManager: source=L['f'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | +- GuardManager: source=L['f'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['f'].__closure__[0].cell_contents.__code__, 123154978635040)
	| | | +- GuardManager: source=L['f'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- GuardManager: source=L['f'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[1].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[1].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[1].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['f'].__closure__[1].cell_contents), ___from_numpy(L['f'].__closure__[2].cell_contents))
	| | | +- GuardManager: source=L['f'].__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- GuardManager: source=L['f'].__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[2].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[2].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[2].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].last_params, 105251315093216)
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].copy, accessed_by=GetAttrGuardAccessor(copy)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].copy, 123155305661296)              
	
V0401 21:31:25.906000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "ce7160e427bf5c5d7f6e685f59f630ae"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085906683.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.907000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "613096024dc1e59aae60098301e163b2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085907686.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.908000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "25/0", "frame_key": "40", "co_name": "torch_dynamo_resume_in__memoized_func_at_519", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 519, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 14, "shape_env_guard_count": 0, "graph_op_count": 9, "graph_node_count": 13, "graph_input_count": 3, "start_time": 1743543085.7769997, "entire_frame_compile_time_s": 0.1294703483581543, "backend_compile_time_s": 0.057233572006225586, "inductor_compile_time_s": 0.015059947967529297, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.022643089294433594, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.911000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "_check_func", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}, {"line": 527, "name": "torch_dynamo_resume_in__memoized_func_at_527", "filename": 6}]}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.912000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0, "has_payload": "4851e984634f92ec0fe82f0a16b317ce"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085912458.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.913000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0, "has_payload": "bc22d9c4e6f074b8fb68b1b7a1c56a10"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085912458.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.917000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 65, "size": 2400}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.918000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f028460>", "describer_id": 65}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.919000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 65, "id": 0, "source": "___from_numpy(L['val'])"}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.924000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 66, "size": 2400}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.925000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0a7ac0>", "describer_id": 66}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.926000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 66, "id": 0, "source": "___from_numpy(L['val'])"}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.943000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1, "has_payload": "5ebf1701575d445709fcad517251ab1c"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| +- GuardManager: source=L['val'], accessed_by=DictGetItemGuardAccessor(val)
	| | +- GuardManager: source=___from_numpy(L['val']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['val']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['val']), '_dynamo_dynamic_indices') == False
	
V0401 21:31:25.945000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1, "has_payload": "9bb0777f0e78309f0ec8c71fe89b79df"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085945014.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.946000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1, "has_payload": "0f37bf1dbe40f1a2f38b23edc4a9bb59"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085946031.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.947000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "26/0", "frame_key": "41", "co_name": "torch_dynamo_resume_in__memoized_func_at_527", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 527, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543085.9124248, "entire_frame_compile_time_s": 0.032482147216796875, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.0070362091064453125, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:25.949000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "_check_func", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}, {"line": 527, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}, {"line": 528, "name": "torch_dynamo_resume_in__memoized_func_at_528", "filename": 6}]}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.950000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "06cb4cefbe2e01d91d98b9c0d07f3a02"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085950569.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.951000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "166284f6a3282c3533a39fc7652150d6"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085950569.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.955000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 67, "size": 2400}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.956000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f05be30>", "describer_id": 67}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.957000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 67, "id": 0, "source": "___from_numpy(L['val'])"}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.959000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "9be78d939ac3b82b09526cf13b8a237a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085959427.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.960000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "e4073bf250febf7d823cdfd4aaf1bf70"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085960484.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.961000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "27/0", "frame_key": "42", "co_name": "torch_dynamo_resume_in__memoized_func_at_528", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 528, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543085.9505575, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.010903596878051758, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.964000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "torch_dynamo_resume_in__check_func_at_23", "filename": 6}]}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.965000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "349e8ffe8e8c632cf1300425b145f3a1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085965094.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.966000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "3d1dadf69169b5d69a3524d7c62fb532"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085965094.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.971000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 68, "size": 2400}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.972000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f679950>", "describer_id": 68}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.973000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 68, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.977000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "a410ded913429b719944b63bd80eabc7"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085977400.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.978000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "73c41bf675e325823186a61d8abf1ec9"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085978850.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.980000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "28/0", "frame_key": "43", "co_name": "torch_dynamo_resume_in__check_func_at_23", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 23, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543085.9650676, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "TODO: add support for ndarray.dtype", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "fail_user_frame_lineno": 38, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.01509714126586914, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.988000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}]}, "frame_id": 29, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:25.989000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 0, "has_payload": "5e2f468c8fb81b8fda9dc5825fb6abc4"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543085989390.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:25.990000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 0, "has_payload": "c28915d17506beb955a7f9ec40952c47"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543085989390.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.013000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 70, "size": 16}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.015000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0e7fc0>", "describer_id": 70}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.016000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 70, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.058000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1, "has_payload": "80fba7107822e2a4465166fc0cf9af4a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['n'], accessed_by=DictGetItemGuardAccessor(n)
	| | +- EQUALS_MATCH: L['n'] == 2                                                 
	| +- GuardManager: source=L['Dfun'], accessed_by=DictGetItemGuardAccessor(Dfun)
	| | +- ID_MATCH: ___check_obj_id(L['Dfun'], 105251315093216)                 
	| +- GuardManager: source=L['args'], accessed_by=DictGetItemGuardAccessor(args)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 105251315101760)                
	| | +- LENGTH_CHECK: not L['args']                                               
	| +- GuardManager: source=L['diag'], accessed_by=DictGetItemGuardAccessor(diag)
	| | +- ID_MATCH: ___check_obj_id(L['diag'], 105251315093216)                 
	| +- GuardManager: source=L['ftol'], accessed_by=DictGetItemGuardAccessor(ftol)
	| | +- EQUALS_MATCH: L['ftol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['func'], accessed_by=DictGetItemGuardAccessor(func)
	| | +- GuardManager: source=L['func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['func'].__code__, 123155042439440)        
	| +- GuardManager: source=L['gtol'], accessed_by=DictGetItemGuardAccessor(gtol)
	| | +- EQUALS_MATCH: L['gtol'] == 0.0                                            
	| +- GuardManager: source=L['xtol'], accessed_by=DictGetItemGuardAccessor(xtol)
	| | +- EQUALS_MATCH: L['xtol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['epsfcn'], accessed_by=DictGetItemGuardAccessor(epsfcn)
	| | +- ID_MATCH: ___check_obj_id(L['epsfcn'], 105251315093216)               
	| +- GuardManager: source=L['factor'], accessed_by=DictGetItemGuardAccessor(factor)
	| | +- EQUALS_MATCH: L['factor'] == 100                                          
	| +- GuardManager: source=L['maxfev'], accessed_by=DictGetItemGuardAccessor(maxfev)
	| | +- EQUALS_MATCH: L['maxfev'] == 0                                            
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 105251315101760)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 2                                    
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- TYPE_MATCH: ___check_type_id(L['___stack0'][0], 105251315101760)        
	| | | +- LENGTH_CHECK: len(L['___stack0'][0]) == 1                                 
	| | | +- GuardManager: source=L['___stack0'][0][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- EQUALS_MATCH: L['___stack0'][0][0] == 300                                 
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- ID_MATCH: ___check_obj_id(L['___stack0'][1], 123155389857824)         
	| +- GuardManager: source=L['full_output'], accessed_by=DictGetItemGuardAccessor(full_output)
	| | +- EQUALS_MATCH: L['full_output'] == 1                                       
	| +- GuardManager: source=L['x0'], accessed_by=DictGetItemGuardAccessor(x0)
	| | +- GuardManager: source=___from_numpy(L['x0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['x0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['x0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['finfo'], accessed_by=DictGetItemGuardAccessor(finfo)
	| | | +- ID_MATCH: ___check_obj_id(G['finfo'], 105251434564784)                
	| | +- GuardManager: source=G['_minpack'], accessed_by=DictGetItemGuardAccessor(_minpack)
	| | | +- ID_MATCH: ___check_obj_id(G['_minpack'], 123155042776656)             
	| | | +- GuardManager: source=G['_minpack']._lmdif, accessed_by=GetAttrGuardAccessor(_lmdif)
	| | | | +- ID_MATCH: ___check_obj_id(G['_minpack']._lmdif, 123155042776976)      
	
V0401 21:31:26.059000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1, "has_payload": "cfb518c82dab60119407dbd272ded3cd"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086059651.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.060000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1, "has_payload": "4f6e45700d5ae3dc3afa5a6922ecb479"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086060568.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.061000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "29/0", "frame_key": "44", "co_name": "torch_dynamo_resume_in_leastsq_at_426", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 426, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 25, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543085.9893794, "entire_frame_compile_time_s": 0.07015061378479004, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Graph break due to unsupported builtin scipy.optimize._minpack._lmdif. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph."], "dynamo_time_before_restart_s": 0.011667728424072266, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.063000 13296 torch/_dynamo/guards.py:2817] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "00aff8c07458c37745130c20bc1b5c54"}
	[
	"24/0: ___check_obj_id(L['_memoized_func'].last_params, 105251315093216)"
	]
V0401 21:31:26.064000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}]}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.065000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "a4448423bef98a0bb12ee4b036dde127"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086065808.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.066000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "93f8efb36919f954e35888cfe5dfd15c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086065808.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.070000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 71, "size": 16}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.071000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ef05fe0>", "describer_id": 71}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.072000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 71, "id": 0, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.074000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 71, "size": 16}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.075000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ef05a40>", "describer_id": 71}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.076000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 71, "id": 1, "source": "___from_numpy(L['params'])"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.086000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_memoized_func_last_params": [2], "l_params_": [2], "wrapped_eq": [2], "wrapped_all": []}}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "73b6a6bc86473a0cac176805ec557312"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_memoized_func_last_params: "f64[2][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_memoized_func_last_params = L_memoized_func_last_params
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        wrapped_eq: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_eq(l_memoized_func_last_params, l_params_);  l_memoized_func_last_params = l_params_ = None
	        wrapped_all: "b8[][]cpu" = torch__dynamo_utils_wrapped_all(wrapped_eq);  wrapped_eq = None
	        return (wrapped_all,)
	        
V0401 21:31:26.088000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "1641dda970d3e8ea632b3bc911a96a87"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086088034.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.089000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "a515f6c99437ca258a649d59a4430ae1"}
	{
	"name": "backend_compile",
	"ts": 1743543086088034.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.094000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "f470518fd52fad4330697acde2d68871"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086094680.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.119000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "2f46f8cc4583d303690a2c0c213887cb"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu", arg1_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        eq: "b8[2][1]cpu" = torch.ops.aten.eq.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None
	        logical_not: "b8[2][1]cpu" = torch.ops.aten.logical_not.default(eq);  eq = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.dims(logical_not);  logical_not = None
	        logical_not_1: "b8[][]cpu" = torch.ops.aten.logical_not.default(any_1);  any_1 = None
	        return (logical_not_1,)
	        
V0401 21:31:26.121000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "cc360183877f75e6ec1d5e0f6ed0105e"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086120988.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.123000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "e9008c2f8bee666b82c59974e65cd085"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086123770.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.125000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "49c2da8aab08d19ff00cf4ce81d0101d"}
	{
	"name": "inductor_compile",
	"ts": 1743543086123770.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.140000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/7f/c7fumvbspyk4ft7v32ry3fkyy36pnlvdhpdaxqvwoyftvdbs2yv2.py"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "c34934ec506ade5679fe49b736ffadd6"}
	# AOT ID: ['15_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_all_eq_0 = async_compile.cpp_pybinding(['bool*', 'const double*', 'const double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(bool* in_out_ptr0,
	                       const double* in_ptr0,
	                       const double* in_ptr1)
	{
	    auto out_ptr0 = in_out_ptr0;
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	                auto tmp2 = tmp0 == tmp1;
	                auto tmp3 = !tmp2;
	                tmp_acc0 = tmp_acc0 || tmp3;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	    {
	        auto tmp0 = out_ptr0[static_cast<int64_t>(0L)];
	        auto tmp1 = !tmp0;
	        in_out_ptr0[static_cast<int64_t>(0L)] = tmp1;
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    buf1 = buf0; del buf0  # reuse
	    cpp_fused_all_eq_0(buf1, arg0_1, arg1_1)
	    del arg0_1
	    del arg1_1
	    return (buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:26.142000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "d59e1692556a063455297b3499a2fc11"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543086142059.2,
	"args": {
	"key": "fz3tibsiysm6l7g7br74ma7iwd5qmdmol555vebgvnafgtakoxu7",
	"components": [
	"[cig7omdtbkjqq5aareag4of6n6f7qadmqzvdyodfxbrarlu5g7n] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    logical_not = torch.ops.aten.logical_not.default(eq);  eq = None\n    any_1 = torch.ops.aten.any.dims(logical_not);  logical_not = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2111348231,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:26.144000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "601a13ff23a9bec850b8cf421d221134"}
	{"key": "fz3tibsiysm6l7g7br74ma7iwd5qmdmol555vebgvnafgtakoxu7", "components": ["[cig7omdtbkjqq5aareag4of6n6f7qadmqzvdyodfxbrarlu5g7n] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    logical_not = torch.ops.aten.logical_not.default(eq);  eq = None\n    any_1 = torch.ops.aten.any.dims(logical_not);  logical_not = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2111348231, "cache_state": "hit"}
V0401 21:31:26.146000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "79431cd0a7af83b3e926f1c8a6b73212"}
	{
	"name": "inductor_compile",
	"ts": 1743543086146162.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.147000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "64790bed20d287f995c0743d8d8c683a"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086147633.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.150000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "857090dcc582b6ab3ea0e7c5acf0ccc1"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086150771.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.156000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "5f048dfb60b752636686f9573d5a6973"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086156416.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.157000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "1a8dc4dc2acabace02f0a770fe5a00fd"}
	{
	"name": "backend_compile",
	"ts": 1743543086157729.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.158000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "d532707fb9344fa48b0f62bb260a934e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086158731.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.169000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "09b57a4034ee0e52e8c13ae4cd19de3a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| | +- GuardManager: source=L['_memoized_func'].skip_lookup, accessed_by=GetAttrGuardAccessor(skip_lookup)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].skip_lookup, 105251315000256)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- GuardManager: source=___from_numpy(L['_memoized_func'].last_params), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['_memoized_func'].last_params), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['_memoized_func'].last_params), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['_memoized_func'].last_params))
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].all, accessed_by=GetAttrGuardAccessor(all)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].all, 123155351021488)               
	
V0401 21:31:26.170000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "557b730930e5b56217592efe3bebb7ca"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086170768.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.171000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "9c106383d2185835925a87d4d143a8cc"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086171838.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.174000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "24/1", "frame_key": "45", "co_name": "_memoized_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 515, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 5, "graph_input_count": 2, "start_time": 1743543086.065774, "entire_frame_compile_time_s": 0.10486984252929688, "backend_compile_time_s": 0.06961941719055176, "inductor_compile_time_s": 0.02194070816040039, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.177000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 519, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}]}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.180000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "f8dca81d3f3ca6ee01c98b4ecae9412e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086179909.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.181000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "ebc4df8269720038ae98ec26c74299b7"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086179909.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.186000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "9cf9cfb27f77421ae52934fb0431c0c8"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086186523.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.187000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "2fad053ccf13685c72f2f14f3de27f4b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086187726.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.190000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "30/0", "frame_key": "46", "co_name": "torch_dynamo_resume_in__memoized_func_at_519", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 519, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543086.1798966, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.01011204719543457, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.195000 13296 torch/_dynamo/guards.py:2817] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0, "has_payload": "875eb01b5ce201d684a99f5d1e0e113c"}
	[
	"25/0: ___check_obj_id(L['_memoized_func'].last_params, 105251315093216)"
	]
V0401 21:31:26.198000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 519, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}]}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.199000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0, "has_payload": "5fdab590617101ef3df8ed78fed17818"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086199432.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.201000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0, "has_payload": "236ddf6af96ff8bcc108abdc35354d71"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086199432.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.206000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 74, "size": 16}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.208000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0ef1b0>", "describer_id": 74}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.209000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 74, "id": 0, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:31:26.215000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 75, "size": 16}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:31:26.216000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f7429e0>", "describer_id": 75}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:31:26.218000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 75, "id": 0, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:31:26.231000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1, "has_payload": "ef31d63acdf9f8cbd091ff235c5df1fc"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- GuardManager: source=___from_numpy(L['_memoized_func'].last_params), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['_memoized_func'].last_params), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['_memoized_func'].last_params), '_dynamo_dynamic_indices') == False
	
V0401 21:31:26.233000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1, "has_payload": "f0b84a87209e4dd67793edc72e5cadf0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086233217.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.234000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1, "has_payload": "5fb8845f0e60a7daeb46ebe65a5049ff"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086234620.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.236000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "25/1", "frame_key": "47", "co_name": "torch_dynamo_resume_in__memoized_func_at_519", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 519, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543086.1994202, "entire_frame_compile_time_s": 0.03368854522705078, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.010122299194335938, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:31:26.240000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}, {"line": 522, "name": "torch_dynamo_resume_in__memoized_func_at_522", "filename": 6}]}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.242000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "ac8a989926b4017149cf7cae318ced07"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086242118.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.244000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "202b450ede1d3880ee7a41c433b7a7eb"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086242118.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.249000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 76, "size": 2400}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.250000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0ed9f0>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.255000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.259000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 76, "size": 2400}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.261000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0ec5a0>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.262000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.265000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 76, "size": 16}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.266000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0ed810>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.267000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.279000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 76, "size": 16}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.280000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0eecb0>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.281000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 5, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.287000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_f_closure_1_cell_contents": [300], "l_f_closure_2_cell_contents": [300], "l_params_": [2], "getitem": [], "getitem_1": [], "wrapped_mul": [], "wrapped_pow": [300], "wrapped_mul_1": [300], "wrapped_add": [300], "wrapped_truediv": [300], "val": [300]}}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "97d252891cb86f7dc40ba7016106a293"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_f_closure_1_cell_contents: "f64[300][1]cpu", L_f_closure_2_cell_contents: "f64[300][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_f_closure_1_cell_contents = L_f_closure_1_cell_contents
	        l_f_closure_2_cell_contents = L_f_closure_2_cell_contents
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        getitem: "f64[][]cpu" = l_params_[0]
	        getitem_1: "f64[][]cpu" = l_params_[1];  l_params_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        wrapped_mul: "f64[][]cpu" = torch__dynamo_utils_wrapped_mul(2, getitem_1);  getitem_1 = None
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_f_closure_1_cell_contents, wrapped_mul);  l_f_closure_1_cell_contents = wrapped_mul = None
	        wrapped_mul_1: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_mul_1(getitem, wrapped_pow);  getitem = wrapped_pow = None
	        wrapped_add: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_add(1.0, wrapped_mul_1);  wrapped_mul_1 = None
	        wrapped_truediv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_truediv(1.0, wrapped_add);  wrapped_add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        val: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_sub(wrapped_truediv, l_f_closure_2_cell_contents);  wrapped_truediv = l_f_closure_2_cell_contents = None
	        return (val,)
	        
V0401 21:31:26.289000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "653070018716514a7e69ec2c1df318f3"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086289341.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.290000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "043493fb5be2936f4fbc4e7ea503394d"}
	{
	"name": "backend_compile",
	"ts": 1743543086289341.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.296000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "db2c287d31c6652d0526bc3617264069"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086296843.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.337000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "41cd24a03980b1c9303fa3bb07bbaf3a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[300][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        mul: "f64[][]cpu" = torch.ops.aten.mul.Tensor(lift_fresh_copy, select_1);  lift_fresh_copy = select_1 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None
	        div: "f64[300][1]cpu" = torch.ops.aten.div.Tensor(1.0, add);  add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        sub: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None
	        return (sub,)
	        
V0401 21:31:26.341000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "ac784b7351395aaf881574b81059b7d1"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086340654.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.346000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "9c71c6d21ac3331a6a4ab1c95ac57dd3"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086346861.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.348000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "7e466141d2ebb9ab4e00550ff7ae5abe"}
	{
	"name": "inductor_compile",
	"ts": 1743543086346861.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.363000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/ar/carqk2ql6j3s35ha36vpi7bhf3u4fub6jcd75oip6pratc6wk5po.py"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "bbc4b287ccbb00bb12b7165fa99cb0c6"}
	# AOT ID: ['16_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_div_lift_fresh_mul_pow_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'const double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       const double* in_ptr2,
	                       double* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp13 = at::vec::VectorizedN<double,2>::loadu(in_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = at::vec::VectorizedN<double,2>(tmp4);
	            auto tmp6 = tmp1.pow(tmp5);
	            auto tmp7 = at::vec::VectorizedN<double,2>(tmp0);
	            auto tmp8 = tmp7 * tmp6;
	            auto tmp9 = static_cast<double>(1.0);
	            auto tmp10 = at::vec::VectorizedN<double,2>(tmp9);
	            auto tmp11 = tmp10 + tmp8;
	            auto tmp12 = tmp10 / tmp11;
	            auto tmp14 = tmp12 - tmp13;
	            tmp14.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = std::pow(tmp1, tmp4);
	            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
	            auto tmp7 = static_cast<double>(1.0);
	            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
	            auto tmp9 = tmp7 / tmp8;
	            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (300, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_add_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0)
	    del arg0_1
	    del arg1_1
	    del arg2_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:26.364000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "d1e1979fd73bde71f20cf891255ed8f0"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543086364202.8,
	"args": {
	"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5",
	"components": [
	"[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2072073507,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:26.365000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "b2e1720821fdb1b98ae07236016837cf"}
	{"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5", "components": ["[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2072073507, "cache_state": "hit"}
V0401 21:31:26.366000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "036f195c104f523a59af108ceb38ef63"}
	{
	"name": "inductor_compile",
	"ts": 1743543086366861.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.367000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "365740cf1d575d78fda7a7241dde5d84"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086367775.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.368000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "8136c4f87d41cd5dfdd9ec3267a3f7b8"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086368822.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.372000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "d98bef1ae9f2eff9b821cdcecae4d4bd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086372039.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.372000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "cbc232ee7d67e2bfd5928affe7c5672d"}
	{
	"name": "backend_compile",
	"ts": 1743543086372849.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.373000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "920533a19ed04e1c57990aad7f71f633"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086373612.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.381000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "3fd2483191496af3404d1e8815d5d5dd"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 123155042877488)           
	| | +- GuardManager: source=L['f'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | +- GuardManager: source=L['f'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['f'].__closure__[0].cell_contents.__code__, 123154978635040)
	| | | +- GuardManager: source=L['f'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- GuardManager: source=L['f'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[1].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[1].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[1].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['_memoized_func'].last_params), ___from_numpy(L['f'].__closure__[1].cell_contents), ___from_numpy(L['f'].__closure__[2].cell_contents))
	| | | +- GuardManager: source=L['f'].__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- GuardManager: source=L['f'].__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[2].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[2].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[2].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- GuardManager: source=___from_numpy(L['_memoized_func'].last_params), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['_memoized_func'].last_params), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['_memoized_func'].last_params), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:31:26.381000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "9164e1d8f1b1d540e7aa5ed1b8f063b9"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086381853.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.382000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "e3876f69a1a48729f56e5aba55ac456b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086382677.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.383000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "31/0", "frame_key": "48", "co_name": "torch_dynamo_resume_in__memoized_func_at_522", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 522, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 8, "graph_node_count": 12, "graph_input_count": 3, "start_time": 1743543086.242106, "entire_frame_compile_time_s": 0.13954424858093262, "backend_compile_time_s": 0.08343505859375, "inductor_compile_time_s": 0.019887685775756836, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.385000 13296 torch/_dynamo/guards.py:2817] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "6287d7cd87ef389105d4d5e1fb7c8e4f"}
	[
	"24/1: ___check_obj_id(L['_memoized_func'].skip_lookup, 105251315000256)",
	"24/0: ___check_obj_id(L['_memoized_func'].last_params, 105251315093216)"
	]
V0401 21:31:26.386000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}]}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.387000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "9fa47461b6b7238087f3f94f0b110e17"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086387446.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.388000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "ee802b55f3122a07de101511a96af87d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086387446.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.391000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 78, "size": 2400}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.392000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f05a260>", "describer_id": 78}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.393000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 78, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.395000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 78, "size": 2400}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.396000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f05a0d0>", "describer_id": 78}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.397000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 78, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.398000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 78, "size": 16}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.399000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0eecb0>", "describer_id": 78}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.400000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 78, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.409000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_f_closure_1_cell_contents": [300], "l_f_closure_2_cell_contents": [300], "l_params_": [2], "getitem": [], "getitem_1": [], "wrapped_mul": [], "wrapped_pow": [300], "wrapped_mul_1": [300], "wrapped_add": [300], "wrapped_truediv": [300], "wrapped_sub": [300]}}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "b86e84ae184ef9563a10f3b1220b4abc"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_f_closure_1_cell_contents: "f64[300][1]cpu", L_f_closure_2_cell_contents: "f64[300][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_f_closure_1_cell_contents = L_f_closure_1_cell_contents
	        l_f_closure_2_cell_contents = L_f_closure_2_cell_contents
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        getitem: "f64[][]cpu" = l_params_[0]
	        getitem_1: "f64[][]cpu" = l_params_[1];  l_params_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        wrapped_mul: "f64[][]cpu" = torch__dynamo_utils_wrapped_mul(2, getitem_1);  getitem_1 = None
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_f_closure_1_cell_contents, wrapped_mul);  l_f_closure_1_cell_contents = wrapped_mul = None
	        wrapped_mul_1: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_mul_1(getitem, wrapped_pow);  getitem = wrapped_pow = None
	        wrapped_add: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_add(1.0, wrapped_mul_1);  wrapped_mul_1 = None
	        wrapped_truediv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_truediv(1.0, wrapped_add);  wrapped_add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        wrapped_sub: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_sub(wrapped_truediv, l_f_closure_2_cell_contents);  wrapped_truediv = l_f_closure_2_cell_contents = None
	        return (wrapped_sub,)
	        
V0401 21:31:26.410000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "f07ba48c2a75955e0f2d960f9e6cc603"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086410641.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.411000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "38ea3082fdae4729c32c3ddc01be67d1"}
	{
	"name": "backend_compile",
	"ts": 1743543086410641.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.417000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "f88030cb9d4d34d414d67dcfe1960d1d"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086417398.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.445000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "41cd24a03980b1c9303fa3bb07bbaf3a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[300][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        mul: "f64[][]cpu" = torch.ops.aten.mul.Tensor(lift_fresh_copy, select_1);  lift_fresh_copy = select_1 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None
	        div: "f64[300][1]cpu" = torch.ops.aten.div.Tensor(1.0, add);  add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        sub: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None
	        return (sub,)
	        
V0401 21:31:26.446000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "1f339fe1af4f0cefe2e4989a74ef569b"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086445898.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.449000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "7e1cd6f1f62840d0eb6216b062ea5924"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086448943.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.449000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "31af90cf5c279515fb7327a3939bbef3"}
	{
	"name": "inductor_compile",
	"ts": 1743543086448943.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.457000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/ar/carqk2ql6j3s35ha36vpi7bhf3u4fub6jcd75oip6pratc6wk5po.py"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "bbc4b287ccbb00bb12b7165fa99cb0c6"}
	# AOT ID: ['16_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_div_lift_fresh_mul_pow_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'const double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       const double* in_ptr2,
	                       double* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp13 = at::vec::VectorizedN<double,2>::loadu(in_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = at::vec::VectorizedN<double,2>(tmp4);
	            auto tmp6 = tmp1.pow(tmp5);
	            auto tmp7 = at::vec::VectorizedN<double,2>(tmp0);
	            auto tmp8 = tmp7 * tmp6;
	            auto tmp9 = static_cast<double>(1.0);
	            auto tmp10 = at::vec::VectorizedN<double,2>(tmp9);
	            auto tmp11 = tmp10 + tmp8;
	            auto tmp12 = tmp10 / tmp11;
	            auto tmp14 = tmp12 - tmp13;
	            tmp14.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = std::pow(tmp1, tmp4);
	            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
	            auto tmp7 = static_cast<double>(1.0);
	            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
	            auto tmp9 = tmp7 / tmp8;
	            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (300, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_add_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0)
	    del arg0_1
	    del arg1_1
	    del arg2_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:26.458000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "e4308647608a23df28c5543c6bf5f26b"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543086458114.8,
	"args": {
	"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5",
	"components": [
	"[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2072073507,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:26.459000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "b2e1720821fdb1b98ae07236016837cf"}
	{"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5", "components": ["[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2072073507, "cache_state": "hit"}
V0401 21:31:26.460000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "c675eeef4c315fb7736bd63eed6bb863"}
	{
	"name": "inductor_compile",
	"ts": 1743543086460686.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.461000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "7c46cf467b642080fb9ba0f9e5de69b0"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086461430.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.462000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "edac2e48eb560512a9a3c5cfbfb409ee"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086462599.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.465000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "7f4c71c086aeb3437b1bc79b01a7c134"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086465616.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.466000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "fc5306353bde2da1403793e5fc8e08b2"}
	{
	"name": "backend_compile",
	"ts": 1743543086466454.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.467000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "e29428fa59d39208ba2306a2d1dba06a"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086467247.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.474000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "7e51715926266581996b3d50a412280e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 123155042877488)           
	| | +- GuardManager: source=L['f'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | +- GuardManager: source=L['f'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['f'].__closure__[0].cell_contents.__code__, 123154978635040)
	| | | +- GuardManager: source=L['f'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- GuardManager: source=L['f'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[1].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[1].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[1].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['f'].__closure__[1].cell_contents), ___from_numpy(L['f'].__closure__[2].cell_contents))
	| | | +- GuardManager: source=L['f'].__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- GuardManager: source=L['f'].__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[2].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[2].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[2].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 123155042439440)
	| | +- GuardManager: source=L['_memoized_func'].skip_lookup, accessed_by=GetAttrGuardAccessor(skip_lookup)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].skip_lookup, 105251315000224)
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:31:26.474000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "31a6e09e2f0798f4a740c2a8ac20d8d3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086474881.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.475000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "d90bc898861afb7af1d3598e2e2f83be"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086475690.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.476000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "24/2", "frame_key": "49", "co_name": "_memoized_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 515, "cache_size": 2, "accumulated_cache_size": 2, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 8, "graph_node_count": 12, "graph_input_count": 3, "start_time": 1743543086.3874164, "entire_frame_compile_time_s": 0.08736348152160645, "backend_compile_time_s": 0.05574631690979004, "inductor_compile_time_s": 0.011667728424072266, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:31:26.479000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}]}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.480000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0, "has_payload": "236c70acf4463a2a2091162362ed3bc1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086480244.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.481000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0, "has_payload": "e292aa7728a07fc583db1a570ac7d449"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086480244.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.491000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 80, "size": 8}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.492000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.int32", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ef37cf0>", "describer_id": 80}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.493000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 80, "id": 0, "source": "___from_numpy(L['___stack0'][1]['ipvt'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.498000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 80, "size": 4800}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.499000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 300], "is_leaf": true, "stride": [300, 1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ef0c190>", "describer_id": 80}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.500000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 80, "id": 3, "source": "___from_numpy(L['___stack0'][1]['fjac'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.516000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 81, "size": 8}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.516000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.int32", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022efb3d40>", "describer_id": 81}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.517000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 81, "id": 0, "source": "___from_numpy(L['___stack0'][1]['ipvt'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.521000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 81, "size": 4800}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.522000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 300], "is_leaf": true, "stride": [300, 1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022efb32f0>", "describer_id": 81}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.523000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 81, "id": 3, "source": "___from_numpy(L['___stack0'][1]['fjac'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.530000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_1_ipvt_": [2], "l_stack0_1_fjac_": [2, 300], "perm": [2], "wrapped_transpose": [300, 2], "wrapped_getitem": [2, 2], "r": [2, 2]}}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "3910dae55555ff32cfabebdc5a84883a"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_1_ipvt_: "i32[2][1]cpu", L_stack0_1_fjac_: "f64[2, 300][300, 1]cpu"):
	        l_stack0_1_ipvt_ = L_stack0_1_ipvt_
	        l_stack0_1_fjac_ = L_stack0_1_fjac_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:489 in torch_dynamo_resume_in_leastsq_at_439, code: perm = retval[1]['ipvt'] - 1
	        perm: "i32[2][1]cpu" = torch__dynamo_utils_wrapped_sub(l_stack0_1_ipvt_, 1);  l_stack0_1_ipvt_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:491 in torch_dynamo_resume_in_leastsq_at_439, code: r = triu(transpose(retval[1]['fjac'])[:n, :])
	        wrapped_transpose: "f64[300, 2][1, 300]cpu" = torch__dynamo_utils_wrapped_transpose(l_stack0_1_fjac_);  l_stack0_1_fjac_ = None
	        wrapped_getitem: "f64[2, 2][1, 300]cpu" = torch__dynamo_utils_wrapped_getitem(wrapped_transpose, (slice(None, 2, None), slice(None, None, None)));  wrapped_transpose = None
	        r: "f64[2, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_triu(wrapped_getitem);  wrapped_getitem = None
	        return (r, perm)
	        
V0401 21:31:26.531000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "949dc639da25d63722fbb54a6d8c2cef"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086531048.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.531000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "a2e20d023794b7f0a88f0dba8b1b43b9"}
	{
	"name": "backend_compile",
	"ts": 1743543086531048.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.534000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "daa7c32be79c27c1b2d54d638890dd34"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086534560.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.573000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "5262070eaaa061788d0744a9ef045ba4"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i32[2][1]cpu", arg1_1: "f64[2, 300][300, 1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:489 in torch_dynamo_resume_in_leastsq_at_439, code: perm = retval[1]['ipvt'] - 1
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "i32[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        sub: "i32[2][1]cpu" = torch.ops.aten.sub.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:491 in torch_dynamo_resume_in_leastsq_at_439, code: r = triu(transpose(retval[1]['fjac'])[:n, :])
	        permute: "f64[300, 2][1, 300]cpu" = torch.ops.aten.permute.default(arg1_1, [1, 0]);  arg1_1 = None
	        slice_1: "f64[2, 2][1, 300]cpu" = torch.ops.aten.slice.Tensor(permute, 0, 0, 2);  permute = None
	        slice_2: "f64[2, 2][1, 300]cpu" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 9223372036854775807);  slice_1 = None
	        iota: "i64[2][1]cpu" = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)
	        unsqueeze: "i64[1, 2][2, 1]cpu" = torch.ops.aten.unsqueeze.default(iota, -2);  iota = None
	        iota_1: "i64[2][1]cpu" = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)
	        unsqueeze_1: "i64[2, 1][1, 1]cpu" = torch.ops.aten.unsqueeze.default(iota_1, -1);  iota_1 = None
	        sub_1: "i64[2, 2][2, 1]cpu" = torch.ops.aten.sub.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None
	        ge: "b8[2, 2][2, 1]cpu" = torch.ops.aten.ge.Scalar(sub_1, 0);  sub_1 = None
	        scalar_tensor: "f64[][]cpu" = torch.ops.aten.scalar_tensor.default(0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'))
	        where: "f64[2, 2][2, 1]cpu" = torch.ops.aten.where.self(ge, slice_2, scalar_tensor);  ge = slice_2 = scalar_tensor = None
	        return (where, sub)
	        
V0401 21:31:26.575000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "24812c4271608d87749b420e9a23b595"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086574995.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.581000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "04ae68ef9c1e280ac541509e858a33ff"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086580936.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.582000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "509601426da3427c7cfccd084366c37e"}
	{
	"name": "inductor_compile",
	"ts": 1743543086580936.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.600000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/yo/cyogko7nrwqotb23uabtpsudbm7n7svnlebxyaukni5ogmmgf3d6.py"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "763e92f5bb4ae5b626560b77f822ac49"}
	# AOT ID: ['18_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_lift_fresh_sub_triu_0 = async_compile.cpp_pybinding(['const double*', 'const int32_t*', 'double*', 'int32_t*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const int32_t* in_ptr1,
	                       double* out_ptr0,
	                       int32_t* out_ptr1)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            #pragma GCC ivdep
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(2L); x1+=static_cast<int64_t>(1L))
	            {
	                auto tmp4 = in_ptr0[static_cast<int64_t>(x0 + (300L*x1))];
	                auto tmp0 = x1 + ((-1L)*x0);
	                auto tmp1 = c10::convert<int64_t>(tmp0);
	                auto tmp2 = static_cast<int64_t>(0);
	                auto tmp3 = tmp1 >= tmp2;
	                auto tmp5 = static_cast<double>(0.0);
	                auto tmp6 = tmp3 ? tmp4 : tmp5;
	                out_ptr0[static_cast<int64_t>(x1 + (2L*x0))] = tmp6;
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = static_cast<int32_t>(1);
	            auto tmp2 = decltype(tmp0)(tmp0 - tmp1);
	            out_ptr1[static_cast<int64_t>(x0)] = tmp2;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, 300), (300, 1))
	    buf0 = empty_strided_cpu((2, 2), (2, 1), torch.float64)
	    buf1 = empty_strided_cpu((2, ), (1, ), torch.int32)
	    cpp_fused_lift_fresh_sub_triu_0(arg1_1, arg0_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.int32)
	    arg1_1 = rand_strided((2, 300), (300, 1), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:26.602000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "afcd33f5a602f052cd77b41c7236f58c"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543086601907.0,
	"args": {
	"key": "fkco7lv3m6ac6i5piarqgfxdmo6kdvocbjygzntmae4t5phjwwqd",
	"components": [
	"[zsxjvs4u2tzwgkiiod7qsglqnprvvu2zsf7dohtszkhod632hu4] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1, dtype = torch.int32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    permute = torch.ops.aten.permute.default(arg1_1, [1, 0]);  arg1_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(permute, 0, 0, 2);  permute = None\n    iota = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze = torch.ops.aten.unsqueeze.default(iota, -2);  iota = None\n    iota_1 = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(iota_1, -1);  iota_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None\n    ge = torch.ops.aten.ge.Scalar(sub_1, 0);  sub_1 = None\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    where = torch.ops.aten.where.self(ge, slice_1, full_default_1);  ge = slice_1 = full_default_1 = None\n    return (where, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[flokpmchmdzcwbxjrazdrm3ghpakwvxsz5d4vcsewg37j3zkzsb] example_inputs[0]: TensorMetadata(dtype=torch.int32, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[kprzcuvn6cyvzyepuwrnxonr6roucdchb5qz32l4ndpdlhe3fxi] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 300]), stride=(300, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[pqcdrbhudjrcl7i4c7ig4brfd4jva36vaoveljqxkf65opic7kb] fx_kwargs[user_visible_outputs]: {'where': None, 'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 3458077117,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:26.603000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "970859a4ceed7b9bf90a338b83ab02a2"}
	{"key": "fkco7lv3m6ac6i5piarqgfxdmo6kdvocbjygzntmae4t5phjwwqd", "components": ["[zsxjvs4u2tzwgkiiod7qsglqnprvvu2zsf7dohtszkhod632hu4] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1, dtype = torch.int32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    permute = torch.ops.aten.permute.default(arg1_1, [1, 0]);  arg1_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(permute, 0, 0, 2);  permute = None\n    iota = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze = torch.ops.aten.unsqueeze.default(iota, -2);  iota = None\n    iota_1 = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(iota_1, -1);  iota_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None\n    ge = torch.ops.aten.ge.Scalar(sub_1, 0);  sub_1 = None\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    where = torch.ops.aten.where.self(ge, slice_1, full_default_1);  ge = slice_1 = full_default_1 = None\n    return (where, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[flokpmchmdzcwbxjrazdrm3ghpakwvxsz5d4vcsewg37j3zkzsb] example_inputs[0]: TensorMetadata(dtype=torch.int32, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[kprzcuvn6cyvzyepuwrnxonr6roucdchb5qz32l4ndpdlhe3fxi] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 300]), stride=(300, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[pqcdrbhudjrcl7i4c7ig4brfd4jva36vaoveljqxkf65opic7kb] fx_kwargs[user_visible_outputs]: {'where': None, 'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 3458077117, "cache_state": "hit"}
V0401 21:31:26.605000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "868709db9de2ca44fe8df88348c95a95"}
	{
	"name": "inductor_compile",
	"ts": 1743543086604952.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.605000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "e95ffa0adb34a48a959b38544653ef54"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086605805.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.606000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "2b61a7ba2896b5667b56ed285ca1285f"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086606925.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.610000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "ec3ba5ef01464ba28587032bd12cb8c8"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086610743.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.611000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "2bb5a4f0da5b3b5ee4e4c193a3482953"}
	{
	"name": "backend_compile",
	"ts": 1743543086611779.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.612000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "f1bc9b132a9aa09a25cb9da4be417eb6"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086612615.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.671000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "2c1fb21fa7c0e196bca8332723d2e31e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['ftol'], accessed_by=DictGetItemGuardAccessor(ftol)
	| | +- EQUALS_MATCH: L['ftol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['gtol'], accessed_by=DictGetItemGuardAccessor(gtol)
	| | +- EQUALS_MATCH: L['gtol'] == 0.0                                            
	| +- GuardManager: source=L['xtol'], accessed_by=DictGetItemGuardAccessor(xtol)
	| | +- EQUALS_MATCH: L['xtol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['maxfev'], accessed_by=DictGetItemGuardAccessor(maxfev)
	| | +- EQUALS_MATCH: L['maxfev'] == 600                                          
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 105251315101760)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 3                                    
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- DICT_LENGTH: len(L['___stack0'][1]) == 5                                 
	| | | +- GuardManager: source=L['___stack0'][1]['fvec'], accessed_by=DictGetItemGuardAccessor(fvec)
	| | | +- GuardManager: source=L['___stack0'][1]['nfev'], accessed_by=DictGetItemGuardAccessor(nfev)
	| | | +- GuardManager: source=L['___stack0'][1]['fjac'], accessed_by=DictGetItemGuardAccessor(fjac)
	| | | | +- GuardManager: source=___from_numpy(L['___stack0'][1]['fjac']), accessed_by=PythonLambdaGuardAccessor
	| | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]['fjac']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 300], stride=[300, 1])
	| | | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]['fjac']), '_dynamo_dynamic_indices') == False
	| | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][1]['fjac']), ___from_numpy(L['___stack0'][1]['ipvt']))
	| | | +- GuardManager: source=L['___stack0'][1]['ipvt'], accessed_by=DictGetItemGuardAccessor(ipvt)
	| | | | +- GuardManager: source=___from_numpy(L['___stack0'][1]['ipvt']), accessed_by=PythonLambdaGuardAccessor
	| | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]['ipvt']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int32, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]['ipvt']), '_dynamo_dynamic_indices') == False
	| | | | | +- NO_TENSOR_ALIASING
	| | | +- GuardManager: source=L['___stack0'][1]['qtf'], accessed_by=DictGetItemGuardAccessor(qtf)
	| | +- GuardManager: source=L['___stack0'][2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | +- EQUALS_MATCH: L['___stack0'][2] == 1                                      
	| +- GuardManager: source=L['full_output'], accessed_by=DictGetItemGuardAccessor(full_output)
	| | +- EQUALS_MATCH: L['full_output'] == 1                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['triu'], accessed_by=DictGetItemGuardAccessor(triu)
	| | | +- ID_MATCH: ___check_obj_id(G['triu'], 123155307666992)                 
	| | +- GuardManager: source=G['linalg'], accessed_by=DictGetItemGuardAccessor(linalg)
	| | | +- ID_MATCH: ___check_obj_id(G['linalg'], 123155189212208)               
	| | | +- GuardManager: source=G['linalg'].get_lapack_funcs, accessed_by=GetAttrGuardAccessor(get_lapack_funcs)
	| | | | +- GuardManager: source=G['linalg'].get_lapack_funcs.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['linalg'].get_lapack_funcs.__code__, 123155189637040)
	| | +- GuardManager: source=G['transpose'], accessed_by=DictGetItemGuardAccessor(transpose)
	| | | +- ID_MATCH: ___check_obj_id(G['transpose'], 123155350945008)            
	| | +- GuardManager: source=G['LEASTSQ_SUCCESS'], accessed_by=DictGetItemGuardAccessor(LEASTSQ_SUCCESS)
	| | | +- TYPE_MATCH: ___check_type_id(G['LEASTSQ_SUCCESS'], 105251315071904)     
	| | | +- LENGTH_CHECK: len(G['LEASTSQ_SUCCESS']) == 4                              
	| | | +- GuardManager: source=G['LEASTSQ_SUCCESS'][0], accessed_by=ListGetItemGuardAccessor(0)
	| | | | +- EQUALS_MATCH: G['LEASTSQ_SUCCESS'][0] == 1                                
	| | +- GuardManager: source=G['__builtins_dict___110'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___110)
	| | | +- GuardManager: source=G['__builtins_dict___110']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___110']['len'], 123155769909840)
	| | | +- GuardManager: source=G['__builtins_dict___110']['TypeError'], accessed_by=DictGetItemGuardAccessor(TypeError)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___110']['TypeError'], 105251315054048)
	| | | +- GuardManager: source=G['__builtins_dict___110']['ValueError'], accessed_by=DictGetItemGuardAccessor(ValueError)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___110']['ValueError'], 105251315035584)
	
V0401 21:31:26.672000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "bff43a144ebde1a0be673747b649e03d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086672081.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.673000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "b51920d6ae05729b97ac94a659c54db4"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086673011.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.674000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "32/0", "frame_key": "50", "co_name": "torch_dynamo_resume_in_leastsq_at_439", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 439, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 25, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543086.480206, "entire_frame_compile_time_s": 0.19175434112548828, "backend_compile_time_s": 0.08066821098327637, "inductor_compile_time_s": 0.023933887481689453, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["TODO: add support for ndarray.dtype"], "dynamo_time_before_restart_s": 0.02830028533935547, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.676000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", 7]}
V0401 21:31:26.676000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 384, "name": "getter", "filename": 7}]}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.677000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "a412eed091faa3d0298f8eb9a3f94052"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086677748.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.678000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "dd93f5339766d36077cb01a068d96e8c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086677748.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.681000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 83, "size": 32}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.682000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1eb160>", "describer_id": 83}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.683000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 83, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.685000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "120c9b403cb432555e6ef43f18d1ad49"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086685723.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.687000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "5220c07fcdc3a57cea9d2f1c0e300eac"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086687833.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.689000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "33/0", "frame_key": "51", "co_name": "getter", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "co_firstlineno": 384, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543086.6777365, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "TODO: add support for ndarray.dtype", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "fail_user_frame_lineno": 389, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.011189937591552734, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.692000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/lapack.py", 8]}
V0401 21:31:26.692000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}, {"line": 884, "name": "get_lapack_funcs", "filename": 8}]}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.693000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0, "has_payload": "f229644a78bf2c9dc88c2e895fbec611"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086693462.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.694000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0, "has_payload": "2a6c524578e9d6dea22520f5dab0b5e1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086693462.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.707000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 84, "size": 32}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.707000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0e7110>", "describer_id": 84}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.708000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 84, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.717000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1, "has_payload": "5e06f655bfa515c23f229832e62b4729"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['dtype'], accessed_by=DictGetItemGuardAccessor(dtype)
	| | +- ID_MATCH: ___check_obj_id(L['dtype'], 105251315093216)                
	| +- GuardManager: source=L['ilp64'], accessed_by=DictGetItemGuardAccessor(ilp64)
	| | +- ID_MATCH: ___check_obj_id(L['ilp64'], 105251315000256)                
	| +- GuardManager: source=L['names'], accessed_by=DictGetItemGuardAccessor(names)
	| | +- EQUALS_MATCH: L['names'] == 'trtri'                                       
	| +- GuardManager: source=L['arrays'], accessed_by=DictGetItemGuardAccessor(arrays)
	| | +- TYPE_MATCH: ___check_type_id(L['arrays'], 105251315101760)              
	| | +- LENGTH_CHECK: len(L['arrays']) == 1                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['_clapack'], accessed_by=DictGetItemGuardAccessor(_clapack)
	| | | +- ID_MATCH: ___check_obj_id(G['_clapack'], 105251315093216)             
	| | +- GuardManager: source=G['_flapack'], accessed_by=DictGetItemGuardAccessor(_flapack)
	| | | +- ID_MATCH: ___check_obj_id(G['_flapack'], 123155189214448)             
	| | +- GuardManager: source=G['_get_funcs'], accessed_by=DictGetItemGuardAccessor(_get_funcs)
	| | | +- GuardManager: source=G['_get_funcs'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_get_funcs'].__code__, 105251489907456)  
	| | +- GuardManager: source=G['_lapack_alias'], accessed_by=DictGetItemGuardAccessor(_lapack_alias)
	| | | +- DICT_LENGTH: len(G['_lapack_alias']) == 10                               
	| | | +- GuardManager: source=G['_lapack_alias']['corghr'], accessed_by=DictGetItemGuardAccessor(corghr)
	| | | +- GuardManager: source=G['_lapack_alias']['zorghr'], accessed_by=DictGetItemGuardAccessor(zorghr)
	| | | +- GuardManager: source=G['_lapack_alias']['corghr_lwork'], accessed_by=DictGetItemGuardAccessor(corghr_lwork)
	| | | +- GuardManager: source=G['_lapack_alias']['zorghr_lwork'], accessed_by=DictGetItemGuardAccessor(zorghr_lwork)
	| | | +- GuardManager: source=G['_lapack_alias']['corgqr'], accessed_by=DictGetItemGuardAccessor(corgqr)
	| | | +- GuardManager: source=G['_lapack_alias']['zorgqr'], accessed_by=DictGetItemGuardAccessor(zorgqr)
	| | | +- GuardManager: source=G['_lapack_alias']['cormqr'], accessed_by=DictGetItemGuardAccessor(cormqr)
	| | | +- GuardManager: source=G['_lapack_alias']['zormqr'], accessed_by=DictGetItemGuardAccessor(zormqr)
	| | | +- GuardManager: source=G['_lapack_alias']['corgrq'], accessed_by=DictGetItemGuardAccessor(corgrq)
	| | | +- GuardManager: source=G['_lapack_alias']['zorgrq'], accessed_by=DictGetItemGuardAccessor(zorgrq)
	| | +- GuardManager: source=G['__builtins_dict___115'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___115)
	| | | +- GuardManager: source=G['__builtins_dict___115']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___115']['str'], 105251315119040)
	| | | +- GuardManager: source=G['__builtins_dict___115']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___115']['isinstance'], 123155769909520)
	
V0401 21:31:26.718000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1, "has_payload": "baa8742da0f46dc7dda2782ac36977d0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086718197.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.719000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1, "has_payload": "5e85e4c24f3a00a6ca22cbb36e5c2e84"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086719054.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.720000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "34/0", "frame_key": "52", "co_name": "get_lapack_funcs", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/lapack.py", "co_firstlineno": 884, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 16, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543086.6934507, "entire_frame_compile_time_s": 0.02465987205505371, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["TODO: add support for ndarray.dtype"], "dynamo_time_before_restart_s": 0.015621662139892578, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.721000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}, {"line": 401, "name": "getter", "filename": 7}, {"line": 326, "name": "_get_funcs", "filename": 7}]}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.722000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0, "has_payload": "8034362392d991b1be6e86ca8cb6d354"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086722378.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.723000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0, "has_payload": "0818d7e94f69398a43a6c1069ab89b4a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086722378.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.730000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 86, "size": 32}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.731000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022efb0640>", "describer_id": 86}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.731000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 86, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.737000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 1, "has_payload": "bc24fc9e806a8a470789d86473058e02"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086737187.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.737000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 1, "has_payload": "afda93c431abd145ede781b981f32457"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086737806.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.738000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "35/0", "frame_key": "53", "co_name": "_get_funcs", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "co_firstlineno": 326, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543086.7223678, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "reconstruct: NumpyDTypeVariable()", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "fail_user_frame_lineno": 346, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.016362905502319336, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 35, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:26.742000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}, {"line": 401, "name": "getter", "filename": 7}, {"line": 884, "name": "get_lapack_funcs", "filename": 8}, {"line": 259, "name": "find_best_blas_type", "filename": 7}]}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.743000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "8a31127cf844176ee4675eb8a7b748e0"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086743400.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.744000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "891c3e7328282dd228cae1a7c153f077"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086743400.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.748000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 88, "size": 32}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.749000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0e6710>", "describer_id": 88}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.750000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 88, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.752000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "6dc833f4b1afb8426a7dfdec0267d90f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086752113.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.752000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "897c6b340534988d250483d658dea38b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086752746.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.753000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "36/0", "frame_key": "54", "co_name": "find_best_blas_type", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "co_firstlineno": 259, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543086.7433896, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "TODO: add support for ndarray.dtype", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "fail_user_frame_lineno": 304, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.010250329971313477, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.757000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 492, "name": "torch_dynamo_resume_in_leastsq_at_492", "filename": 6}]}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.757000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "e2c16cbc0359e592052f1d82383d0fec"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086757599.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.758000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "916ed1cc0e1333ce6c4b99eb9facfd76"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086757599.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.764000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "345a0e9c3c2b59bd5e139195d9717cc0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086764058.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.764000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "b1c61911a755a8424bb5d08ad522323a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086764676.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.765000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "37/0", "frame_key": "55", "co_name": "torch_dynamo_resume_in_leastsq_at_492", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 492, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543086.7575886, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "call_method UserDefinedObjectVariable(fortran) __call__ [LazyVariableTracker()] {}", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "fail_user_frame_lineno": 495, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.007993221282958984, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.769000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_1007", "filename": 6}]}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.770000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "20b800de1ad7c113905a5cce5b15fd0d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086770317.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.771000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "137eb639e6bce54afe08ca3b6b140b86"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086770317.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.780000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 90, "size": 16}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.780000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022efa2440>", "describer_id": 90}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.781000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 90, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.784000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 90, "size": 32}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.784000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0a66c0>", "describer_id": 90}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.785000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 90, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.788000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 90, "size": 2400}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.789000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f1341e0>", "describer_id": 90}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.790000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 90, "id": 2, "source": "___from_numpy(L['___stack0'][2]['fvec'])"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.800000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_1_": [2, 2], "l_stack0_2_fvec_": [300], "wrapped_pow": [300], "cost": [], "wrapped_isnan": [2, 2], "wrapped_any": []}}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "ec1498e7abfbc0f1a7b0f6d45b769f35"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_1_: "f64[2, 2][2, 1]cpu", L_stack0_2_fvec_: "f64[300][1]cpu"):
	        l_stack0_1_ = L_stack0_1_
	        l_stack0_2_fvec_ = L_stack0_2_fvec_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1010 in torch_dynamo_resume_in_curve_fit_at_1007, code: cost = np.sum(infodict['fvec'] ** 2)
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_stack0_2_fvec_, 2);  l_stack0_2_fvec_ = None
	        cost: "f64[][]cpu" = torch__dynamo_utils_wrapped_sum(wrapped_pow);  wrapped_pow = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1040 in torch_dynamo_resume_in_curve_fit_at_1007, code: if pcov is None or np.isnan(pcov).any():
	        wrapped_isnan: "b8[2, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_isnan(l_stack0_1_);  l_stack0_1_ = None
	        wrapped_any: "b8[][]cpu" = torch__dynamo_utils_wrapped_any(wrapped_isnan);  wrapped_isnan = None
	        return (wrapped_any, cost)
	        
V0401 21:31:26.801000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0f38dc634e4d873cf700bca1ca704b59"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086801130.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.802000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0c8b5f40416d9549e92ebcdbed880416"}
	{
	"name": "backend_compile",
	"ts": 1743543086801130.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.805000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "ba54774785476e31b653110f1c2134f3"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086805651.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.823000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "13f1d1972f80612f026a454817609c30"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2, 2][2, 1]cpu", arg1_1: "f64[300][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1010 in torch_dynamo_resume_in_curve_fit_at_1007, code: cost = np.sum(infodict['fvec'] ** 2)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg1_1, lift_fresh_copy);  arg1_1 = lift_fresh_copy = None
	        sum_1: "f64[][]cpu" = torch.ops.aten.sum.default(pow_1);  pow_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1040 in torch_dynamo_resume_in_curve_fit_at_1007, code: if pcov is None or np.isnan(pcov).any():
	        isnan: "b8[2, 2][2, 1]cpu" = torch.ops.aten.isnan.default(arg0_1);  arg0_1 = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.default(isnan);  isnan = None
	        return (any_1, sum_1)
	        
V0401 21:31:26.824000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "a8ee4b44d455abeb93595be9af9abbae"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086824568.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.827000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "96e041abc2528b0bf77f3938974b2817"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086826968.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.827000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "74ead88e2474f1fd23d3ff707d301168"}
	{
	"name": "inductor_compile",
	"ts": 1743543086826968.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.837000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/br/cbrjwdf4b2s2oqv2gmwz6shtxlxqge65yufuoqox6zgfajmp4beb.py"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "af0d72c4394264d5a3e62f59fa58be39"}
	# AOT ID: ['19_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_any_isnan_lift_fresh_pow_sum_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'bool*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       bool* out_ptr0,
	                       double* out_ptr1)
	{
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(4L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                auto tmp1 = std::isnan(tmp0);
	                tmp_acc0 = tmp_acc0 || tmp1;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	    {
	        {
	            double tmp_acc0 = 0;
	            at::vec::VectorizedN<double,2> tmp_acc0_vec = at::vec::VectorizedN<double,2>(0);
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	                auto tmp1 = static_cast<double>(2.0);
	                auto tmp2 = at::vec::VectorizedN<double,2>(tmp1);
	                auto tmp3 = tmp0.pow(tmp2);
	                tmp_acc0_vec = tmp_acc0_vec + tmp3;
	            }
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr1[static_cast<int64_t>(x0)];
	                auto tmp1 = static_cast<double>(2.0);
	                auto tmp2 = std::pow(tmp0, tmp1);
	                tmp_acc0 = tmp_acc0 + tmp2;
	            }
	            tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<double, 2>([](at::vec::Vectorized<double>& x, at::vec::Vectorized<double>& y) { return x + y; }, tmp_acc0_vec);
	            out_ptr1[static_cast<int64_t>(0L)] = static_cast<double>(tmp_acc0);
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, 2), (2, 1))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    buf1 = empty_strided_cpu((), (), torch.float64)
	    cpp_fused_any_isnan_lift_fresh_pow_sum_0(arg0_1, arg1_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, 2), (2, 1), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:26.838000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "b1e5fd60e74e2448c9ad542bc0ea1f3e"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543086838018.8,
	"args": {
	"key": "f7ibtjcuzkgnds5amxrn2zxytyljrywl7fsf2rj4ylhljku3i57r",
	"components": [
	"[z5xh4zriyhmmkzvbr6iu67ibftwitzm5a2nyu3b7i2tdayqbxk5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    sum_1 = torch.ops.aten.sum.default(pow_1);  pow_1 = None\n    isnan = torch.ops.aten.isnan.default(arg0_1);  arg0_1 = None\n    any_1 = torch.ops.aten.any.default(isnan);  isnan = None\n    return (any_1, sum_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[mw75reeo2vrojk7xzpdms2gvbmgb57pqrm6atjvidfizxwrnaab] fx_kwargs[user_visible_outputs]: {'any_1': None, 'sum_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2011997958,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:26.839000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "35c3ef5fa715b72e3e87076c33f90762"}
	{"key": "f7ibtjcuzkgnds5amxrn2zxytyljrywl7fsf2rj4ylhljku3i57r", "components": ["[z5xh4zriyhmmkzvbr6iu67ibftwitzm5a2nyu3b7i2tdayqbxk5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    sum_1 = torch.ops.aten.sum.default(pow_1);  pow_1 = None\n    isnan = torch.ops.aten.isnan.default(arg0_1);  arg0_1 = None\n    any_1 = torch.ops.aten.any.default(isnan);  isnan = None\n    return (any_1, sum_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[mw75reeo2vrojk7xzpdms2gvbmgb57pqrm6atjvidfizxwrnaab] fx_kwargs[user_visible_outputs]: {'any_1': None, 'sum_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2011997958, "cache_state": "hit"}
V0401 21:31:26.840000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "d7370a18ccbabbfa85339f8501e010ff"}
	{
	"name": "inductor_compile",
	"ts": 1743543086840528.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.841000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "6adba2bfa38b58931722cad09d4d8482"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543086841287.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.842000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "00aa78f07381f0018a24321d8524f0b6"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543086842434.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.846000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0b95a4062aee16960049e0fda726baa8"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543086846475.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.847000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "3dda36c57b6959474393d9adf1a4d1e4"}
	{
	"name": "backend_compile",
	"ts": 1743543086847575.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.848000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "783f3b92533635ce15efccf1fa3f1c0d"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543086848554.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.973000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "fccbddd0a5e9af49a6bae329da59b511"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 105251315101760)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 5                                    
	| | +- GuardManager: source=L['___stack0'][2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | +- DICT_LENGTH: len(L['___stack0'][2]) == 5                                 
	| | | +- GuardManager: source=L['___stack0'][2]['fvec'], accessed_by=DictGetItemGuardAccessor(fvec)
	| | | | +- GuardManager: source=___from_numpy(L['___stack0'][2]['fvec']), accessed_by=PythonLambdaGuardAccessor
	| | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][2]['fvec']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][2]['fvec']), '_dynamo_dynamic_indices') == False
	| | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][0]), ___from_numpy(L['___stack0'][1]), ___from_numpy(L['___stack0'][2]['fvec']))
	| | | +- GuardManager: source=L['___stack0'][2]['nfev'], accessed_by=DictGetItemGuardAccessor(nfev)
	| | | +- GuardManager: source=L['___stack0'][2]['fjac'], accessed_by=DictGetItemGuardAccessor(fjac)
	| | | +- GuardManager: source=L['___stack0'][2]['ipvt'], accessed_by=DictGetItemGuardAccessor(ipvt)
	| | | +- GuardManager: source=L['___stack0'][2]['qtf'], accessed_by=DictGetItemGuardAccessor(qtf)
	| | +- GuardManager: source=L['___stack0'][3], accessed_by=TupleGetItemGuardAccessor(3)
	| | | +- EQUALS_MATCH: L['___stack0'][3] == 'Both actual and predicted relative reductions in the sum of squares\n  are at most 0.000000'
	| | +- GuardManager: source=L['___stack0'][4], accessed_by=TupleGetItemGuardAccessor(4)
	| | | +- EQUALS_MATCH: L['___stack0'][4] == 1                                      
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][0]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][0]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][0]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][1]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].sum, accessed_by=GetAttrGuardAccessor(sum)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].sum, 123155351020272)               
	| | | +- GuardManager: source=G['np'].isnan, accessed_by=GetAttrGuardAccessor(isnan)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].isnan, 123155762887232)             
	| | +- GuardManager: source=G['__builtins_dict___120'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___120)
	| | | +- GuardManager: source=G['__builtins_dict___120']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___120']['len'], 123155769909840)
	
V0401 21:31:26.974000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "3924f7d8de62b5b78338031cf170d033"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086973797.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.974000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "c1a32dfebe7f82c6ab1bbb78477d57a5"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086974752.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.976000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "38/0", "frame_key": "56", "co_name": "torch_dynamo_resume_in_curve_fit_at_1007", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 1007, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 17, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543086.770306, "entire_frame_compile_time_s": 0.2033991813659668, "backend_compile_time_s": 0.04635214805603027, "inductor_compile_time_s": 0.013478994369506836, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.980000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 1040, "name": "torch_dynamo_resume_in_curve_fit_at_1040", "filename": 6}]}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.981000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "9863a0eb7efc691bd126106b0e102d30"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543086980954.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.982000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "3ab2d1ead5a8b5f61920d24c173ba0ea"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543086980954.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:26.991000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 92, "size": 16}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.992000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ee81770>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.993000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 0, "source": "___from_numpy(L['p0'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.995000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 92, "size": 8}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.996000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ee81e00>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:26.996000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 1, "source": "___from_numpy(L['cost'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.000000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 92, "size": 32}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.001000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ee5fd90>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.002000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 4, "source": "___from_numpy(L['pcov'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.005000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 92, "size": 16}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.006000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ee81900>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.007000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 6, "source": "___from_numpy(L['popt'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.010000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_cost_": [], "l_pcov_": [2, 2], "s_sq": [], "pcov": [2, 2]}}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "903a53807a5c78c4443f8bf908de0d35"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_cost_: "f64[][]cpu", L_pcov_: "f64[2, 2][2, 1]cpu"):
	        l_cost_ = L_cost_
	        l_pcov_ = L_pcov_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1047 in torch_dynamo_resume_in_curve_fit_at_1040, code: s_sq = cost / (ysize - p0.size)
	        s_sq: "f64[][]cpu" = torch__dynamo_utils_wrapped_truediv(l_cost_, 298);  l_cost_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1048 in torch_dynamo_resume_in_curve_fit_at_1040, code: pcov = pcov * s_sq
	        pcov: "f64[2, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_mul(l_pcov_, s_sq);  l_pcov_ = s_sq = None
	        return (pcov,)
	        
V0401 21:31:27.011000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "48c016160adb8f9536a1f8b95db759c5"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543087011675.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.012000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "7f0e14ec3d812e5467c226b60114aab8"}
	{
	"name": "backend_compile",
	"ts": 1743543087011675.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.015000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "1f8ee0c6decabafffab2d83464c67128"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543087015172.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.033000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "b081c5092cf61e9b056b5b26d88f5563"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[][]cpu", arg1_1: "f64[2, 2][2, 1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1047 in torch_dynamo_resume_in_curve_fit_at_1040, code: s_sq = cost / (ysize - p0.size)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        div: "f64[][]cpu" = torch.ops.aten.div.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1048 in torch_dynamo_resume_in_curve_fit_at_1040, code: pcov = pcov * s_sq
	        mul: "f64[2, 2][2, 1]cpu" = torch.ops.aten.mul.Tensor(arg1_1, div);  arg1_1 = div = None
	        return (mul,)
	        
V0401 21:31:27.034000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "07ed67487f8eaca9701a48b031939a34"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543087034217.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.036000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "17cdfb6cd9a6de4295ed2fd839f8adbd"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543087036797.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.037000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "3cd25dec409e8b02c377ddeea9506c36"}
	{
	"name": "inductor_compile",
	"ts": 1743543087036797.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.046000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/ef/cefvveq36ljn5bkveegoxa3v65k3axdmf26w6c26pdgmhe4azohh.py"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "45a117617a23bdf409eb2c90a429944d"}
	# AOT ID: ['20_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_div_lift_fresh_mul_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       double* out_ptr0)
	{
	    {
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(4L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(0L)];
	            auto tmp2 = static_cast<double>(0.003355704697986577);
	            auto tmp3 = decltype(tmp1)(tmp1 * tmp2);
	            auto tmp4 = decltype(tmp0)(tmp0 * tmp3);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp4;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (), ())
	    assert_size_stride(arg1_1, (2, 2), (2, 1))
	    buf0 = empty_strided_cpu((2, 2), (2, 1), torch.float64)
	    cpp_fused_div_lift_fresh_mul_0(arg1_1, arg0_1, buf0)
	    del arg0_1
	    del arg1_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((), (), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, 2), (2, 1), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:27.047000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "b312c364b33e9431b7b54d7bf27c91f5"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543087047129.8,
	"args": {
	"key": "f3nrqjnlgotrkyjm7svtaxbecxqxi4ec6m2sabnfba4pztv6b2vx",
	"components": [
	"[jtmnjcpeee5hki7vjv7qi2sjjuqib4ym5xuyileqkmr3wq6gc2k] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 298.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    div = torch.ops.aten.div.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    mul = torch.ops.aten.mul.Tensor(arg1_1, div);  arg1_1 = div = None\n    return (mul,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[t75wnpkhdzho245k77fsy6jvriwrirovfy4byuuieeof5qil45t] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([]), stride=(), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xrrldqonl36w4z2az7sr3dnmawa4xjmy4qw7tjj6vilhmcl424y] fx_kwargs[user_visible_outputs]: {'mul': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2038363573,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:27.048000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "c7140f0f970345d14787e8431a100d69"}
	{"key": "f3nrqjnlgotrkyjm7svtaxbecxqxi4ec6m2sabnfba4pztv6b2vx", "components": ["[jtmnjcpeee5hki7vjv7qi2sjjuqib4ym5xuyileqkmr3wq6gc2k] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 298.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    div = torch.ops.aten.div.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    mul = torch.ops.aten.mul.Tensor(arg1_1, div);  arg1_1 = div = None\n    return (mul,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[t75wnpkhdzho245k77fsy6jvriwrirovfy4byuuieeof5qil45t] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([]), stride=(), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xrrldqonl36w4z2az7sr3dnmawa4xjmy4qw7tjj6vilhmcl424y] fx_kwargs[user_visible_outputs]: {'mul': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2038363573, "cache_state": "hit"}
V0401 21:31:27.049000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "107260ce61200eba608c18e672062d88"}
	{
	"name": "inductor_compile",
	"ts": 1743543087049635.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.050000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "b781088487a4bfcfd149bbe5f6826875"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543087050264.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.051000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "7dde63960ae29a4ce990defa23d4b98c"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543087051500.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.054000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "a10525bc52de3ef2f6babcd4c2b027ab"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543087054500.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.055000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "8d682fa2157dedc43f2288448d7238ca"}
	{
	"name": "backend_compile",
	"ts": 1743543087055265.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.056000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "b1fb342901cdb3d6126b38eca71ecaea"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543087056054.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.062000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "a30697707cf5c63343519cee688cada0"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['ysize'], accessed_by=DictGetItemGuardAccessor(ysize)
	| | +- EQUALS_MATCH: L['ysize'] == 300                                           
	| +- GuardManager: source=L['warn_cov'], accessed_by=DictGetItemGuardAccessor(warn_cov)
	| | +- ID_MATCH: ___check_obj_id(L['warn_cov'], 105251315000256)             
	| +- GuardManager: source=L['full_output'], accessed_by=DictGetItemGuardAccessor(full_output)
	| | +- ID_MATCH: ___check_obj_id(L['full_output'], 105251315000256)          
	| +- GuardManager: source=L['absolute_sigma'], accessed_by=DictGetItemGuardAccessor(absolute_sigma)
	| | +- ID_MATCH: ___check_obj_id(L['absolute_sigma'], 105251315000256)       
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['cost']), ___from_numpy(L['pcov']), ___from_numpy(L['popt']))
	| +- GuardManager: source=L['cost'], accessed_by=DictGetItemGuardAccessor(cost)
	| | +- GuardManager: source=___from_numpy(L['cost']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['cost']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[], stride=[])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['cost']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['pcov'], accessed_by=DictGetItemGuardAccessor(pcov)
	| | +- GuardManager: source=___from_numpy(L['pcov']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['pcov']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['pcov']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['popt'], accessed_by=DictGetItemGuardAccessor(popt)
	| | +- GuardManager: source=___from_numpy(L['popt']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['popt']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['popt']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	+- LAMBDA_GUARD: not __math_isnan(___from_numpy(L['cost']).item())             # _dynamo/output_graph.py:463 in init_ambient_guards
	
V0401 21:31:27.063000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "29b8a9a0d70b610525a6a51cb1ca5f8c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087063210.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.064000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "10d120916340b8c2116d4fefbdd96c00"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087064050.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.065000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "39/0", "frame_key": "57", "co_name": "torch_dynamo_resume_in_curve_fit_at_1040", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 1040, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 5, "graph_input_count": 2, "start_time": 1743543086.9809237, "entire_frame_compile_time_s": 0.08215570449829102, "backend_compile_time_s": 0.04352903366088867, "inductor_compile_time_s": 0.01275634765625, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.066000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1407, "name": "torch_dynamo_resume_in_find_ab_params_at_1407", "filename": 4}]}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.067000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "7d83a1e3ccc16a6e89fae88c69046f4b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087067381.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.068000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "f13f2f2e6eb3a55c9371fbda05abe3d6"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087067381.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.071000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 94, "size": 16}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.071000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022efb12c0>", "describer_id": 94}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.073000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 94, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.077000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 94, "size": 32}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.078000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022efb0190>", "describer_id": 94}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.080000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 94, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.087000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_0_": [2], "wrapped_getitem": [], "wrapped_getitem_1": []}}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "fa6a428f86ec82876592483fcaebf0b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_0_: "f64[2][1]cpu"):
	        l_stack0_0_ = L_stack0_0_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1408 in torch_dynamo_resume_in_find_ab_params_at_1407, code: return params[0], params[1]
	        wrapped_getitem: "f64[][]cpu" = torch__dynamo_utils_wrapped_getitem(l_stack0_0_, 0)
	        wrapped_getitem_1: "f64[][]cpu" = torch__dynamo_utils_wrapped_getitem_1(l_stack0_0_, 1);  l_stack0_0_ = None
	        return (wrapped_getitem, wrapped_getitem_1)
	        
V0401 21:31:27.088000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "ab3e0ce03f33fc2b3a33ca266ba985d5"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543087088360.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.089000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "83b34adfc207254adead7e50a5b6e75a"}
	{
	"name": "backend_compile",
	"ts": 1743543087088360.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.091000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "98d36fe00852e4fb6b8b2056e76c2bbc"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543087091603.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.104000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "e1858c754268403596c82303239f4c07"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1408 in torch_dynamo_resume_in_find_ab_params_at_1407, code: return params[0], params[1]
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None
	        return (select, select_1)
	        
V0401 21:31:27.106000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "e7f919cc8945ed2ad7d0d40c02cfe7c1"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543087106158.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.110000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "2a93c6ba5ef4e0b37bcf19dcb6899e18"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543087110399.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.111000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "ead43b8abfa1eae0a332be1ff97d510e"}
	{
	"name": "inductor_compile",
	"ts": 1743543087110399.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.118000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/hd/chd37lcz4x3qev2qg5wjzrfa2lpkkpoajfmf7xru37hr2v44pi4e.py"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "9758e0955c95c26b1925bfad1b208517"}
	# AOT ID: ['21_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    return (reinterpret_tensor(arg0_1, (), (), 0), reinterpret_tensor(arg0_1, (), (), 1), )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:27.119000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "1d2b4c132260160422b9187873d70284"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543087118903.0,
	"args": {
	"key": "fxcvgvelixobhs5zr4mamq64nra6i4kgjlscfkoo2xu5evnibuhl",
	"components": [
	"[ippwpplt7o64l5zxxthx2ri2fxf6csf4dji7wiyj7rrmp2wqwkm] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None\n    return (select, select_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[zeb3repuwtz6sp4lhxsz2xnup5arzdbhbj4srmaa56mj2f7tat3] fx_kwargs[user_visible_outputs]: {'select': None, 'select_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 10609572,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:27.120000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "c60d09b01dae82d90865738efc24223e"}
	{"key": "fxcvgvelixobhs5zr4mamq64nra6i4kgjlscfkoo2xu5evnibuhl", "components": ["[ippwpplt7o64l5zxxthx2ri2fxf6csf4dji7wiyj7rrmp2wqwkm] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None\n    return (select, select_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[zeb3repuwtz6sp4lhxsz2xnup5arzdbhbj4srmaa56mj2f7tat3] fx_kwargs[user_visible_outputs]: {'select': None, 'select_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 10609572, "cache_state": "hit"}
V0401 21:31:27.121000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "db2086cf59481153f47848525ffafab9"}
	{
	"name": "inductor_compile",
	"ts": 1743543087121412.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.122000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "cf1686dcf074f227adacc09c5e7174b3"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543087122178.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.123000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "8770d68b2bdf03ee0bfa9426f9c0200a"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543087123453.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.128000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "d3fa75f8883e2674f068c371a1c78d14"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543087128338.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.129000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "c731e742349e163d8e1add14b3d25741"}
	{
	"name": "backend_compile",
	"ts": 1743543087129133.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.129000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "f239dc92f5503133a943a3ab3320c8cd"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543087129866.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.136000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "5ced603b12985d943a32325a76483251"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 105251315101760)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 2                                    
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][0]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][0]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][0]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][0]), ___from_numpy(L['___stack0'][1]))
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][1]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	
V0401 21:31:27.136000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "59688da0190185736fa142e8f58e1779"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087136766.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.137000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "b091280dd148bf01f308e9be897af0da"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087137694.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.138000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "40/0", "frame_key": "58", "co_name": "torch_dynamo_resume_in_find_ab_params_at_1407", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1407, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 8, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543087.067371, "entire_frame_compile_time_s": 0.06931734085083008, "backend_compile_time_s": 0.040688276290893555, "inductor_compile_time_s": 0.01093602180480957, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.141000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}]}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.142000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0, "has_payload": "81151989717c7b42665621235b2d06d5"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087142150.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.143000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0, "has_payload": "c917dd9c919b731194e35bb84f5f5152"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087142150.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.159000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 96, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.161000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022adbb520>", "describer_id": 96}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.164000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 96, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.167000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 96, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.170000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022f0fbb10>", "describer_id": 96}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.173000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 96, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.192000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 96, "size": 40}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.192000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ac21090>", "describer_id": 96}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.193000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 96, "id": 2, "source": "___from_numpy(L['self']._raw_data)"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.215000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 97, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.217000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022adabde0>", "describer_id": 97}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.219000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 97, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.222000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 97, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.224000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022adab7f0>", "describer_id": 97}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.227000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 97, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.370000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1, "has_payload": "4f5aedcf37abb748dc013341c32ba46f"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].init, accessed_by=GetAttrGuardAccessor(init)
	| | | +- EQUALS_MATCH: L['self'].init == 'spectral'                                
	| | +- GuardManager: source=L['self'].learning_rate, accessed_by=GetAttrGuardAccessor(learning_rate)
	| | | +- EQUALS_MATCH: L['self'].learning_rate == 1.0                              
	| | +- GuardManager: source=L['self'].precomputed_knn, accessed_by=GetAttrGuardAccessor(precomputed_knn)
	| | | +- TYPE_MATCH: ___check_type_id(L['self'].precomputed_knn, 105251315101760)
	| | | +- LENGTH_CHECK: len(L['self'].precomputed_knn) == 3                         
	| | | +- GuardManager: source=L['self'].precomputed_knn[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- ID_MATCH: ___check_obj_id(L['self'].precomputed_knn[0], 105251315093216)
	| | | +- GuardManager: source=L['self'].precomputed_knn[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- ID_MATCH: ___check_obj_id(L['self'].precomputed_knn[1], 105251315093216)
	| | | +- GuardManager: source=L['self'].precomputed_knn[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- ID_MATCH: ___check_obj_id(L['self'].precomputed_knn[2], 105251315093216)
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 105251315101760)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 2                                    
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][0]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][0]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[], stride=[])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][0]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][0]), ___from_numpy(L['___stack0'][1]))
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][1]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[], stride=[])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].ndarray, accessed_by=GetAttrGuardAccessor(ndarray)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ndarray, 123155389901056)           
	| | +- GuardManager: source=G['__builtins_dict___129'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___129)
	| | | +- GuardManager: source=G['__builtins_dict___129']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___129']['len'], 123155769909840)
	| | | +- GuardManager: source=G['__builtins_dict___129']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___129']['isinstance'], 123155769909520)
	+- LAMBDA_GUARD: not __math_isnan(___from_numpy(L['___stack0'][0]).item())     # _dynamo/output_graph.py:463 in init_ambient_guards
	+- LAMBDA_GUARD: not __math_isnan(___from_numpy(L['___stack0'][1]).item())     # _dynamo/output_graph.py:463 in init_ambient_guards
	
V0401 21:31:27.371000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1, "has_payload": "80b31fac36791cd67af662c14b341e63"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087371044.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.372000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1, "has_payload": "b4a4759c30ac6175e08e72ce737e8991"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087372084.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.373000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "41/0", "frame_key": "59", "co_name": "torch_dynamo_resume_in_fit_at_2383", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2383, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 19, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543087.1421404, "entire_frame_compile_time_s": 0.22881650924682617, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Graph break due to unsupported Python builtin _warnings.warn. Please file an issue on GitHub so the PyTorch team can add support for it. "], "dynamo_time_before_restart_s": 0.056461334228515625, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.375000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1752, "name": "_validate_parameters", "filename": 4}]}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.376000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0, "has_payload": "d2da12c98a6ccff5b2f6e0e30f4fe276"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087376245.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.377000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0, "has_payload": "f5c44d395a04c42c11d1d75663aa5277"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087376245.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.393000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 98, "size": 40}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.394000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ada9c70>", "describer_id": 98}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.395000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 98, "id": 0, "source": "___from_numpy(L['self']._raw_data)"}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.416000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 99, "size": 40}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.417000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ac03020>", "describer_id": 99}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.418000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 99, "id": 0, "source": "___from_numpy(L['self']._raw_data)"}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.490000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1, "has_payload": "c22af40502eddd8e98c58fe10e39b91d"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].init, accessed_by=GetAttrGuardAccessor(init)
	| | | +- EQUALS_MATCH: L['self'].init == 'spectral'                                
	| | +- GuardManager: source=L['self'].metric, accessed_by=GetAttrGuardAccessor(metric)
	| | | +- EQUALS_MATCH: L['self'].metric == 'euclidean'                             
	| | +- GuardManager: source=L['self'].n_jobs, accessed_by=GetAttrGuardAccessor(n_jobs)
	| | | +- EQUALS_MATCH: L['self'].n_jobs == -1                                      
	| | +- GuardManager: source=L['self'].spread, accessed_by=GetAttrGuardAccessor(spread)
	| | | +- EQUALS_MATCH: L['self'].spread == 1.0                                     
	| | +- GuardManager: source=L['self'].min_dist, accessed_by=GetAttrGuardAccessor(min_dist)
	| | | +- EQUALS_MATCH: L['self'].min_dist == 0.1                                   
	| | +- GuardManager: source=L['self'].n_epochs, accessed_by=GetAttrGuardAccessor(n_epochs)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].n_epochs, 105251315093216)        
	| | +- GuardManager: source=L['self'].metric_kwds, accessed_by=GetAttrGuardAccessor(metric_kwds)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].metric_kwds, 105251315093216)     
	| | +- GuardManager: source=L['self'].n_neighbors, accessed_by=GetAttrGuardAccessor(n_neighbors)
	| | | +- EQUALS_MATCH: L['self'].n_neighbors == 2                                  
	| | +- GuardManager: source=L['self'].n_components, accessed_by=GetAttrGuardAccessor(n_components)
	| | | +- EQUALS_MATCH: L['self'].n_components == 2                                 
	| | +- GuardManager: source=L['self'].random_state, accessed_by=GetAttrGuardAccessor(random_state)
	| | | +- EQUALS_MATCH: L['self'].random_state == 42                                
	| | +- GuardManager: source=L['self'].output_metric, accessed_by=GetAttrGuardAccessor(output_metric)
	| | | +- EQUALS_MATCH: L['self'].output_metric == 'euclidean'                      
	| | +- GuardManager: source=L['self']._initial_alpha, accessed_by=GetAttrGuardAccessor(_initial_alpha)
	| | | +- EQUALS_MATCH: L['self']._initial_alpha == 1.0                             
	| | +- GuardManager: source=L['self'].set_op_mix_ratio, accessed_by=GetAttrGuardAccessor(set_op_mix_ratio)
	| | | +- EQUALS_MATCH: L['self'].set_op_mix_ratio == 1.0                           
	| | +- GuardManager: source=L['self'].output_metric_kwds, accessed_by=GetAttrGuardAccessor(output_metric_kwds)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].output_metric_kwds, 105251315093216)
	| | +- GuardManager: source=L['self'].repulsion_strength, accessed_by=GetAttrGuardAccessor(repulsion_strength)
	| | | +- EQUALS_MATCH: L['self'].repulsion_strength == 1.0                         
	| | +- GuardManager: source=L['self'].target_metric_kwds, accessed_by=GetAttrGuardAccessor(target_metric_kwds)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].target_metric_kwds, 105251315093216)
	| | +- GuardManager: source=L['self'].target_n_neighbors, accessed_by=GetAttrGuardAccessor(target_n_neighbors)
	| | | +- EQUALS_MATCH: L['self'].target_n_neighbors == -1                          
	| | +- GuardManager: source=L['self'].negative_sample_rate, accessed_by=GetAttrGuardAccessor(negative_sample_rate)
	| | | +- EQUALS_MATCH: L['self'].negative_sample_rate == 5                         
	| | +- GuardManager: source=L['self']._raw_data, accessed_by=GetAttrGuardAccessor(_raw_data)
	| | | +- GuardManager: source=___from_numpy(L['self']._raw_data), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['self']._raw_data), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['self']._raw_data), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].ndarray, accessed_by=GetAttrGuardAccessor(ndarray)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ndarray, 123155389901056)           
	| | +- GuardManager: source=G['dist'], accessed_by=DictGetItemGuardAccessor(dist)
	| | | +- ID_MATCH: ___check_obj_id(G['dist'], 123154957258240)                 
	| | | +- GuardManager: source=G['dist'].named_distances, accessed_by=GetAttrGuardAccessor(named_distances)
	| | | | +- DICT_LENGTH: len(G['dist'].named_distances) == 39                        
	| | | | +- GuardManager: source=G['dist'].named_distances['euclidean'], accessed_by=DictGetItemGuardAccessor(euclidean)
	| | | | | +- TYPE_MATCH: ___check_type_id(G['dist'].named_distances['euclidean'], 105251516625776)
	| | | | +- GuardManager: source=G['dist'].named_distances['l2'], accessed_by=DictGetItemGuardAccessor(l2)
	| | | | +- GuardManager: source=G['dist'].named_distances['manhattan'], accessed_by=DictGetItemGuardAccessor(manhattan)
	| | | | +- GuardManager: source=G['dist'].named_distances['taxicab'], accessed_by=DictGetItemGuardAccessor(taxicab)
	| | | | +- GuardManager: source=G['dist'].named_distances['l1'], accessed_by=DictGetItemGuardAccessor(l1)
	| | | | +- GuardManager: source=G['dist'].named_distances['chebyshev'], accessed_by=DictGetItemGuardAccessor(chebyshev)
	| | | | +- GuardManager: source=G['dist'].named_distances['linfinity'], accessed_by=DictGetItemGuardAccessor(linfinity)
	| | | | +- GuardManager: source=G['dist'].named_distances['linfty'], accessed_by=DictGetItemGuardAccessor(linfty)
	| | | | +- GuardManager: source=G['dist'].named_distances['linf'], accessed_by=DictGetItemGuardAccessor(linf)
	| | | | +- GuardManager: source=G['dist'].named_distances['minkowski'], accessed_by=DictGetItemGuardAccessor(minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances['poincare'], accessed_by=DictGetItemGuardAccessor(poincare)
	| | | | +- GuardManager: source=G['dist'].named_distances['seuclidean'], accessed_by=DictGetItemGuardAccessor(seuclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances['standardised_euclidean'], accessed_by=DictGetItemGuardAccessor(standardised_euclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances['wminkowski'], accessed_by=DictGetItemGuardAccessor(wminkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances['weighted_minkowski'], accessed_by=DictGetItemGuardAccessor(weighted_minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances['mahalanobis'], accessed_by=DictGetItemGuardAccessor(mahalanobis)
	| | | | +- GuardManager: source=G['dist'].named_distances['canberra'], accessed_by=DictGetItemGuardAccessor(canberra)
	| | | | +- GuardManager: source=G['dist'].named_distances['cosine'], accessed_by=DictGetItemGuardAccessor(cosine)
	| | | | +- GuardManager: source=G['dist'].named_distances['correlation'], accessed_by=DictGetItemGuardAccessor(correlation)
	| | | | +- GuardManager: source=G['dist'].named_distances['hellinger'], accessed_by=DictGetItemGuardAccessor(hellinger)
	| | | | +- GuardManager: source=G['dist'].named_distances['haversine'], accessed_by=DictGetItemGuardAccessor(haversine)
	| | | | +- GuardManager: source=G['dist'].named_distances['braycurtis'], accessed_by=DictGetItemGuardAccessor(braycurtis)
	| | | | +- GuardManager: source=G['dist'].named_distances['ll_dirichlet'], accessed_by=DictGetItemGuardAccessor(ll_dirichlet)
	| | | | +- GuardManager: source=G['dist'].named_distances['symmetric_kl'], accessed_by=DictGetItemGuardAccessor(symmetric_kl)
	| | | | +- GuardManager: source=G['dist'].named_distances['hamming'], accessed_by=DictGetItemGuardAccessor(hamming)
	| | | | +- GuardManager: source=G['dist'].named_distances['jaccard'], accessed_by=DictGetItemGuardAccessor(jaccard)
	| | | | +- GuardManager: source=G['dist'].named_distances['dice'], accessed_by=DictGetItemGuardAccessor(dice)
	| | | | +- GuardManager: source=G['dist'].named_distances['matching'], accessed_by=DictGetItemGuardAccessor(matching)
	| | | | +- GuardManager: source=G['dist'].named_distances['kulsinski'], accessed_by=DictGetItemGuardAccessor(kulsinski)
	| | | | +- GuardManager: source=G['dist'].named_distances['rogerstanimoto'], accessed_by=DictGetItemGuardAccessor(rogerstanimoto)
	| | | | +- GuardManager: source=G['dist'].named_distances['russellrao'], accessed_by=DictGetItemGuardAccessor(russellrao)
	| | | | +- GuardManager: source=G['dist'].named_distances['sokalsneath'], accessed_by=DictGetItemGuardAccessor(sokalsneath)
	| | | | +- GuardManager: source=G['dist'].named_distances['sokalmichener'], accessed_by=DictGetItemGuardAccessor(sokalmichener)
	| | | | +- GuardManager: source=G['dist'].named_distances['yule'], accessed_by=DictGetItemGuardAccessor(yule)
	| | | | +- GuardManager: source=G['dist'].named_distances['categorical'], accessed_by=DictGetItemGuardAccessor(categorical)
	| | | | +- GuardManager: source=G['dist'].named_distances['ordinal'], accessed_by=DictGetItemGuardAccessor(ordinal)
	| | | | +- GuardManager: source=G['dist'].named_distances['hierarchical_categorical'], accessed_by=DictGetItemGuardAccessor(hierarchical_categorical)
	| | | | +- GuardManager: source=G['dist'].named_distances['count'], accessed_by=DictGetItemGuardAccessor(count)
	| | | | +- GuardManager: source=G['dist'].named_distances['string'], accessed_by=DictGetItemGuardAccessor(string)
	| | | +- GuardManager: source=G['dist'].named_distances_with_gradients, accessed_by=GetAttrGuardAccessor(named_distances_with_gradients)
	| | | | +- DICT_LENGTH: len(G['dist'].named_distances_with_gradients) == 26         
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['euclidean'], accessed_by=DictGetItemGuardAccessor(euclidean)
	| | | | | +- TYPE_MATCH: ___check_type_id(G['dist'].named_distances_with_gradients['euclidean'], 105251516625776)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['l2'], accessed_by=DictGetItemGuardAccessor(l2)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['manhattan'], accessed_by=DictGetItemGuardAccessor(manhattan)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['taxicab'], accessed_by=DictGetItemGuardAccessor(taxicab)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['l1'], accessed_by=DictGetItemGuardAccessor(l1)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['chebyshev'], accessed_by=DictGetItemGuardAccessor(chebyshev)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['linfinity'], accessed_by=DictGetItemGuardAccessor(linfinity)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['linfty'], accessed_by=DictGetItemGuardAccessor(linfty)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['linf'], accessed_by=DictGetItemGuardAccessor(linf)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['minkowski'], accessed_by=DictGetItemGuardAccessor(minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['seuclidean'], accessed_by=DictGetItemGuardAccessor(seuclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['standardised_euclidean'], accessed_by=DictGetItemGuardAccessor(standardised_euclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['wminkowski'], accessed_by=DictGetItemGuardAccessor(wminkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['weighted_minkowski'], accessed_by=DictGetItemGuardAccessor(weighted_minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['mahalanobis'], accessed_by=DictGetItemGuardAccessor(mahalanobis)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['canberra'], accessed_by=DictGetItemGuardAccessor(canberra)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['cosine'], accessed_by=DictGetItemGuardAccessor(cosine)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['correlation'], accessed_by=DictGetItemGuardAccessor(correlation)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['hellinger'], accessed_by=DictGetItemGuardAccessor(hellinger)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['haversine'], accessed_by=DictGetItemGuardAccessor(haversine)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['braycurtis'], accessed_by=DictGetItemGuardAccessor(braycurtis)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['symmetric_kl'], accessed_by=DictGetItemGuardAccessor(symmetric_kl)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['spherical_gaussian_energy'], accessed_by=DictGetItemGuardAccessor(spherical_gaussian_energy)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['diagonal_gaussian_energy'], accessed_by=DictGetItemGuardAccessor(diagonal_gaussian_energy)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['gaussian_energy'], accessed_by=DictGetItemGuardAccessor(gaussian_energy)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['hyperboloid'], accessed_by=DictGetItemGuardAccessor(hyperboloid)
	| | +- GuardManager: source=G['warn'], accessed_by=DictGetItemGuardAccessor(warn)
	| | | +- ID_MATCH: ___check_obj_id(G['warn'], 123155769984160)                 
	| | +- GuardManager: source=G['scipy'], accessed_by=DictGetItemGuardAccessor(scipy)
	| | | +- ID_MATCH: ___check_obj_id(G['scipy'], 123155192265792)                
	| | | +- GuardManager: source=G['scipy'].sparse, accessed_by=GetAttrGuardAccessor(sparse)
	| | | | +- ID_MATCH: ___check_obj_id(G['scipy'].sparse, 123155192262352)         
	| | | | +- GuardManager: source=G['scipy'].sparse.isspmatrix_csr, accessed_by=GetAttrGuardAccessor(isspmatrix_csr)
	| | | | | +- GuardManager: source=G['scipy'].sparse.isspmatrix_csr.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['scipy'].sparse.isspmatrix_csr.__code__, 123155188340160)
	| | +- GuardManager: source=G['__builtins_dict___132'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___132)
	| | | +- GuardManager: source=G['__builtins_dict___132']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['int'], 105251315073760)
	| | | +- GuardManager: source=G['__builtins_dict___132']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['str'], 105251315119040)
	| | | +- GuardManager: source=G['__builtins_dict___132']['list'], accessed_by=DictGetItemGuardAccessor(list)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['list'], 105251315071904)
	| | | +- GuardManager: source=G['__builtins_dict___132']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['tuple'], 105251315101760)
	| | | +- GuardManager: source=G['__builtins_dict___132']['callable'], accessed_by=DictGetItemGuardAccessor(callable)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['callable'], 123155769908240)
	| | | +- GuardManager: source=G['__builtins_dict___132']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['isinstance'], 123155769909520)
	| | +- GuardManager: source=G['__import_scipy_dot_sparse_dot__csr'], accessed_by=DictGetItemGuardAccessor(__import_scipy_dot_sparse_dot__csr)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_sparse_dot__csr'], 123155188566912)
	| | | +- GuardManager: source=G['__import_scipy_dot_sparse_dot__csr'].csr_matrix, accessed_by=GetAttrGuardAccessor(csr_matrix)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_sparse_dot__csr'].csr_matrix, 105251489504720)
	
V0401 21:31:27.491000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1, "has_payload": "2470feff60f32db4a448fdb268a8c95d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087491414.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.492000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1, "has_payload": "6c802d8c3871ab58ef2dd59453dfedcc"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087492289.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.493000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "42/0", "frame_key": "60", "co_name": "_validate_parameters", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1752, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 46, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543087.3762343, "entire_frame_compile_time_s": 0.11508941650390625, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Graph break due to unsupported Python builtin _warnings.warn. Please file an issue on GitHub so the PyTorch team can add support for it. "], "dynamo_time_before_restart_s": 0.023156404495239258, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.496000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 1952, "name": "torch_dynamo_resume_in__validate_parameters_at_1952", "filename": 4}]}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.496000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "76c40c8277110da9bf68543c2c5f70f7"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087496812.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.497000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "a61b3b99e51f96b0ab5c067e16adebdb"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087496812.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.518000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "4642d3341c5b30076d8745464234d392"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087518005.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.518000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "b5399f04bcef30664db80438d953f16e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087518637.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.519000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "43/0", "frame_key": "61", "co_name": "torch_dynamo_resume_in__validate_parameters_at_1952", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1952, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543087.496802, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.022690773010253906, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.522000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}]}, "frame_id": 44, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.523000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 0, "has_payload": "0f68aab473191d21f7076c9079445ed3"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087523121.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.524000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 0, "has_payload": "56279b23b56ab09760bfced656a89faa"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087523121.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.715000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1, "has_payload": "b3f9928d6e4945c97e3b90f3b1dda599"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].verbose, accessed_by=GetAttrGuardAccessor(verbose)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].verbose, 105251315000256)         
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['numba'], accessed_by=DictGetItemGuardAccessor(numba)
	| | | +- ID_MATCH: ___check_obj_id(G['numba'], 123154956963248)                
	| | | +- GuardManager: source=G['numba'].get_num_threads, accessed_by=GetAttrGuardAccessor(get_num_threads)
	| | | | +- GuardManager: source=G['numba'].get_num_threads.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['numba'].get_num_threads.__code__, 123154849380960)
	
V0401 21:31:27.716000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1, "has_payload": "c3c0ab98c71303e23f5f3dfdb641c310"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087716466.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.717000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1, "has_payload": "081832e88dca74756b46d1033df96b5f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087717392.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.718000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "44/0", "frame_key": "62", "co_name": "torch_dynamo_resume_in_fit_at_2408", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2408, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543087.523111, "entire_frame_compile_time_s": 0.19324588775634766, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["BEFORE_WITH UserDefinedObjectVariable(RLock)"], "dynamo_time_before_restart_s": 0.03182220458984375, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.735000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2413, "name": "torch_dynamo_resume_in_fit_at_2413", "filename": 4}]}, "frame_id": 45, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.736000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 0, "has_payload": "95cb948b1cfd2a32e5da16519e74fd18"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087736223.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.737000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 0, "has_payload": "f405fd766fada8d7cdf59c0e8b5bc50f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087736223.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.928000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1, "has_payload": "cf50b6ba2f24e30d141baf0c188e41f7"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].n_jobs, accessed_by=GetAttrGuardAccessor(n_jobs)
	| | | +- EQUALS_MATCH: L['self'].n_jobs == 1                                       
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- EQUALS_MATCH: L['___stack0'] == 2                                         
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['numba'], accessed_by=DictGetItemGuardAccessor(numba)
	| | | +- ID_MATCH: ___check_obj_id(G['numba'], 123154956963248)                
	| | | +- GuardManager: source=G['numba'].set_num_threads, accessed_by=GetAttrGuardAccessor(set_num_threads)
	| | | | +- GuardManager: source=G['numba'].set_num_threads.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['numba'].set_num_threads.__code__, 123154844947664)
	
V0401 21:31:27.928000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1, "has_payload": "76ef973a26c9ae8ef14cf3448be95ceb"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087928809.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.929000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1, "has_payload": "da7ae140293e92f34a75ab56f6ee4a90"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087929878.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.930000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "45/0", "frame_key": "89", "co_name": "torch_dynamo_resume_in_fit_at_2413", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2413, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 10, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543087.7362096, "entire_frame_compile_time_s": 0.19247913360595703, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["BEFORE_WITH UserDefinedObjectVariable(RLock)"], "dynamo_time_before_restart_s": 0.03398609161376953, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.932000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", 9]}
V0401 21:31:27.933000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 584, "name": "set_num_threads", "filename": 9}]}, "frame_id": 46, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.934000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 0, "has_payload": "b386e9a04c4f032aff9224c6c665acf0"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087934465.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.935000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 0, "has_payload": "d33bc7fa2ec38b4e3a9af22d59cd4897"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087934465.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.946000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1, "has_payload": "9b4a6bfc21f809312544f4956d2b4161"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['_launch_threads'], accessed_by=DictGetItemGuardAccessor(_launch_threads)
	| | | +- GuardManager: source=G['_launch_threads'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_launch_threads'].__code__, 105251516684736)
	
V0401 21:31:27.946000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1, "has_payload": "89920c68ae1598e0e962e721a9228c98"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087946865.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.947000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1, "has_payload": "3310de6d493cf4de2c96472279896b7d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087947789.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.948000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "46/0", "frame_key": "90", "co_name": "set_num_threads", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", "co_firstlineno": 584, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 6, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543087.9344518, "entire_frame_compile_time_s": 0.012326955795288086, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["BEFORE_WITH UserDefinedObjectVariable(RLock)"], "dynamo_time_before_restart_s": 0.005898475646972656, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.950000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 2413, "name": "torch_dynamo_resume_in_fit_at_2413", "filename": 4}, {"line": 607, "name": "torch_dynamo_resume_in_set_num_threads_at_607", "filename": 9}]}, "frame_id": 47, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.950000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 0, "has_payload": "a5f6e45e9bde89b1d53468228948bcea"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087950797.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.951000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 0, "has_payload": "1754d66cdd7ca6536689de82132ae3dd"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087950797.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.964000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1, "has_payload": "48bfb3bc37f6823eef971562f8578c41"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['n'], accessed_by=DictGetItemGuardAccessor(n)
	| | +- EQUALS_MATCH: L['n'] == 1                                                 
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].integer, accessed_by=GetAttrGuardAccessor(integer)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].integer, 123155389887616)           
	| | +- GuardManager: source=G['snt_check'], accessed_by=DictGetItemGuardAccessor(snt_check)
	| | | +- GuardManager: source=G['snt_check'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['snt_check'].__code__, 123154843012192)   
	| | | +- GuardManager: source=G['snt_check'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | | +- GuardManager: source=G['snt_check'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | | +- GuardManager: source=G['snt_check'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | | +- EQUALS_MATCH: G['snt_check'].__closure__[0].cell_contents == 2            
	| | | | +- GuardManager: source=G['snt_check'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | | +- GuardManager: source=G['snt_check'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | | +- EQUALS_MATCH: G['snt_check'].__closure__[1].cell_contents == 'The number of threads must be between 1 and 2'
	| | +- GuardManager: source=G['_set_num_threads'], accessed_by=DictGetItemGuardAccessor(_set_num_threads)
	| | | +- TYPE_MATCH: ___check_type_id(G['_set_num_threads'], 105251484422800)    
	| | +- GuardManager: source=G['__builtins_dict___145'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___145)
	| | | +- GuardManager: source=G['__builtins_dict___145']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___145']['int'], 105251315073760)
	| | | +- GuardManager: source=G['__builtins_dict___145']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___145']['isinstance'], 123155769909520)
	
V0401 21:31:27.965000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1, "has_payload": "3919e3808932ec8a3bbb2d48bc5dd7dd"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087965364.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.966000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1, "has_payload": "045321f3a6b4b673ae4d49fa5e514b10"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087966211.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.967000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "47/0", "frame_key": "91", "co_name": "torch_dynamo_resume_in_set_num_threads_at_607", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", "co_firstlineno": 607, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 14, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543087.9507868, "entire_frame_compile_time_s": 0.014506816864013672, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["call_method UserDefinedObjectVariable(CFunctionType) __call__ [ConstantVariable()] {}"], "dynamo_time_before_restart_s": 0.0031266212463378906, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1}
V0401 21:31:27.968000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 2413, "name": "torch_dynamo_resume_in_fit_at_2413", "filename": 4}, {"line": 584, "name": "set_num_threads", "filename": 9}, {"line": 611, "name": "torch_dynamo_resume_in_set_num_threads_at_611", "filename": 9}]}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.969000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "cb851741fe76976395f39cf66b98fc6f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087969150.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.970000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "858b0be4015d61f11180bf407bbe3924"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087969150.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.972000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "6193f1007dbd294446ca7ccc17ce0c27"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087972135.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.972000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "602a0122c56b1157c9615695bb388950"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087972812.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.973000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "48/0", "frame_key": "92", "co_name": "torch_dynamo_resume_in_set_num_threads_at_611", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", "co_firstlineno": 611, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543087.9691405, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.004545450210571289, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.976000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 2415, "name": "torch_dynamo_resume_in_fit_at_2415", "filename": 4}]}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.977000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "0fd4876555493d2227b07d8ea4d72c8c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543087977138.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.978000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "4b9399237140c1966530195503610019"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543087977138.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:27.993000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 110, "size": 40}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.994000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022ac35c70>", "describer_id": 110}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:27.995000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 110, "id": 0, "source": "___from_numpy(L['X'])"}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.006000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_x_": [1, 10], "wrapped_getitem": [1, 10], "wrapped_getitem_1": [1, 10], "wrapped_zeros": [1, 2]}}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "d9ad318e1de4396c6099639ca08a9152"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_X_: "f32[1, 10][10, 1]cpu"):
	        l_x_ = L_X_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2455 in torch_dynamo_resume_in_fit_at_2415, code: if X[index].shape[0] <= self.n_neighbors:
	        wrapped_getitem: "f32[1, 10][10, 1]cpu" = torch__dynamo_utils_wrapped_getitem(l_x_, [0]);  wrapped_getitem = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2456 in torch_dynamo_resume_in_fit_at_2415, code: if X[index].shape[0] == 1:
	        wrapped_getitem_1: "f32[1, 10][10, 1]cpu" = torch__dynamo_utils_wrapped_getitem_1(l_x_, [0]);  l_x_ = wrapped_getitem_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2457 in torch_dynamo_resume_in_fit_at_2415, code: self.embedding_ = np.zeros(
	        wrapped_zeros: "f64[1, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_zeros((1, 2))
	        return (wrapped_zeros,)
	        
V0401 21:31:28.007000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "baeb9e7098affd006b397bc9a38d9883"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543088007250.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.008000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "40fb74ecde6f124d6c5c7212c692950c"}
	{
	"name": "backend_compile",
	"ts": 1743543088007250.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.011000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "dd294c99b3247789ee369e3de276611d"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543088011298.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.031000 13296 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "6387f5fe86d19ec1d312bda6f0a2f8fe"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f32[1, 10][10, 1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2457 in torch_dynamo_resume_in_fit_at_2415, code: self.embedding_ = np.zeros(
	        full: "f64[1, 2][2, 1]cpu" = torch.ops.aten.full.default([1, 2], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        return (full,)
	        
V0401 21:31:28.032000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "b9da02a787b99e036b4e2dbf669932ce"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543088031929.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.034000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "ba0aea9ea6d1bb12f8ae95e074a9f75f"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543088034368.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.035000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "aa9e818aee5bb0b20702303b7660fbc1"}
	{
	"name": "inductor_compile",
	"ts": 1743543088034368.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.044000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/k7/ck7jjpr25wynl4kevfr2zwjcxeiwq6gyvpjx34m6cruxgqovwf3b.py"}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "ff408293b4d8f9c3910e6fad6e48557c"}
	# AOT ID: ['22_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_zeros_0 = async_compile.cpp_pybinding(['double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(double* out_ptr0)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = static_cast<double>(0.0);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    buf0 = empty_strided_cpu((1, 2), (2, 1), torch.float64)
	    cpp_fused_zeros_0(buf0)
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.float32)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:28.045000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "38785568ac61f5a8a9b927b9ad0bf8a4"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543088045147.2,
	"args": {
	"key": "fo2f6zvjs5lqkplvxo2e6xjnr4db3ilelj2si7dmgjrmk6ld3lvo",
	"components": [
	"[lvbow72o5gnv3mlsi4hjz24xm6wc4i75vwr4i7tkq5hcauuxywp] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full_default = torch.ops.aten.full.default([1, 2], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[2e74ctehigkd3ueulg6yyzt5nu3mdccgs6232onhxly2y7ldib7] example_inputs[0]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[rdcqaibaq4cmzf5ixiuy6tar4tfbmoziy7qrb5emggotlsoruhj] fx_kwargs[user_visible_outputs]: {'full_default': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 1970801553,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:28.046000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "68bac69f0561b20b5eb954f0397e5843"}
	{"key": "fo2f6zvjs5lqkplvxo2e6xjnr4db3ilelj2si7dmgjrmk6ld3lvo", "components": ["[lvbow72o5gnv3mlsi4hjz24xm6wc4i75vwr4i7tkq5hcauuxywp] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full_default = torch.ops.aten.full.default([1, 2], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[2e74ctehigkd3ueulg6yyzt5nu3mdccgs6232onhxly2y7ldib7] example_inputs[0]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[rdcqaibaq4cmzf5ixiuy6tar4tfbmoziy7qrb5emggotlsoruhj] fx_kwargs[user_visible_outputs]: {'full_default': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 1970801553, "cache_state": "hit"}
V0401 21:31:28.047000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "8a16d8a3cc36cbe3e8553fdb73f7e8ad"}
	{
	"name": "inductor_compile",
	"ts": 1743543088047678.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.048000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "38f69856cf28f7013209fd7ecb52d2dc"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543088048407.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.049000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "da82373e9cac4a8c62beb2b7ab54c98c"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543088049630.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.053000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "4360b49e989d27c0cc84aec062c9ca9c"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543088052980.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.053000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "58901829ef871bf2703cfd950dc9b2bf"}
	{
	"name": "backend_compile",
	"ts": 1743543088053919.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.055000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "7c9183a92bfcb0d39886030532688075"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543088055165.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.060000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "9e4f2e77748f1e3031251de5504cdb51"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251536270224)                
	| | +- GuardManager: source=L['self'].unique, accessed_by=GetAttrGuardAccessor(unique)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].unique, 105251315000256)          
	| | +- GuardManager: source=L['self'].n_neighbors, accessed_by=GetAttrGuardAccessor(n_neighbors)
	| | | +- EQUALS_MATCH: L['self'].n_neighbors == 2                                  
	| | +- GuardManager: source=L['self'].n_components, accessed_by=GetAttrGuardAccessor(n_components)
	| | | +- EQUALS_MATCH: L['self'].n_components == 2                                 
	| +- GuardManager: source=L['X'], accessed_by=DictGetItemGuardAccessor(X)
	| | +- GuardManager: source=___from_numpy(L['X']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['X']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['X']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 123155762218864)                   
	| | | +- GuardManager: source=G['np'].zeros, accessed_by=GetAttrGuardAccessor(zeros)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].zeros, 123155762228624)             
	| | +- GuardManager: source=G['__builtins_dict___148'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___148)
	| | | +- GuardManager: source=G['__builtins_dict___148']['list'], accessed_by=DictGetItemGuardAccessor(list)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___148']['list'], 105251315071904)
	| | | +- GuardManager: source=G['__builtins_dict___148']['range'], accessed_by=DictGetItemGuardAccessor(range)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___148']['range'], 105251315094912)
	
V0401 21:31:28.061000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "c20df6e51446f3f2fbcaf9566f6a16e8"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543088061560.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.062000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "c3c871d961555cecd62e504dcb1ea8c9"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543088062357.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.063000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "49/0", "frame_key": "93", "co_name": "torch_dynamo_resume_in_fit_at_2415", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2415, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 14, "shape_env_guard_count": 0, "graph_op_count": 3, "graph_node_count": 5, "graph_input_count": 1, "start_time": 1743543087.9771283, "entire_frame_compile_time_s": 0.08434009552001953, "backend_compile_time_s": 0.046602487564086914, "inductor_compile_time_s": 0.013228893280029297, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.069000 13296 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", 10]}
V0401 21:31:28.070000 13296 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 1001, "name": "forward", "filename": 10}]}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.071000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "658a61e049276fd0ca55497f8d1d2275"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543088071011.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.071000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "3d297c0cf0bcf150d8d336157c863b45"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543088071011.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.080000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 112, "size": 80}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.080000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x70022fe97980>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.081000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 0, "source": "L['input_ids']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.400000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 112, "size": 4096}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.401000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "stride": [512, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x700236c2d7c0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.402000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 1, "source": "L['self']._modules['embeddings']._buffers['token_type_ids']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.410000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 112, "size": 4096}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.411000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x700236c1cd70>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.412000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "is_view": true, "stride": [512, 1], "storage": 2, "base": 6, "creation_meta": "CreationMeta.DEFAULT", "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x700236c2d720>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.413000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 5, "source": "L['self']._modules['embeddings']._buffers['position_ids']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.420000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 112, "size": 15627264}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.421000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [30522, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c6aa30>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.422000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 8, "source": "L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.431000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 112, "size": 1024}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.432000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 9, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [2, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c68960>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.433000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 9, "source": "L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.439000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.440000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 11, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c68730>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.441000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 11, "source": "L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.448000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.448000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 12, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c6abc0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.449000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 12, "source": "L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.451000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 7, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.452000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 13, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 7, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c1ce60>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.453000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 13, "source": "L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.518000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 8, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.519000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 25, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 8, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c6a990>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.520000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 25, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.523000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 9, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.525000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 26, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 9, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c6b340>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.526000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 26, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.541000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 10, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.542000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 36, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 10, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2d810>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.543000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 36, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.545000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 11, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.546000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 37, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 11, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c6b160>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.547000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 37, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.554000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 12, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.555000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 38, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 12, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2d860>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.556000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 38, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.558000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 13, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.558000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 39, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 13, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2d8b0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.559000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 39, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.585000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 14, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.587000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 45, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 14, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c69270>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.588000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 45, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.591000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 15, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.593000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 46, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 15, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c68230>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.593000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 46, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.600000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 16, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.601000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 47, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 16, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2d9f0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.602000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 47, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.604000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 17, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.605000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 48, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 17, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2d900>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.605000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 48, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.622000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 18, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.623000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 52, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 18, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2da90>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.624000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 52, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.626000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 19, "describer_id": 112, "size": 2048}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.627000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 53, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 19, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dae0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.628000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 53, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.648000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 20, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.649000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 61, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 20, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2da40>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.650000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 61, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.652000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 21, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.653000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 62, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 21, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c6a850>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.654000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 62, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.669000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 22, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.671000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 66, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 22, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dbd0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.672000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 66, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.674000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 23, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.675000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 67, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 23, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2db80>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.677000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 67, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.719000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 24, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.722000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 71, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 24, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2d9a0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.725000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 71, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.728000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 25, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.729000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 72, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 25, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2db30>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.730000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 72, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.737000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 26, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.738000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 73, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 26, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dc70>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.739000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 73, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.740000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 27, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.741000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 74, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 27, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dd10>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.742000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 74, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.749000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 28, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.749000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 75, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 28, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dd60>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.750000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 75, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.752000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 29, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.753000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 76, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 29, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2ddb0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.754000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 76, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.768000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 30, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.769000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 79, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 30, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2de00>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.770000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 79, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.772000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 31, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.773000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 80, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 31, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2de50>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.773000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 80, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.783000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 32, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.784000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 81, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 32, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2def0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.785000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 81, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.787000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 33, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.787000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 82, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 33, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dea0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.788000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 82, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.799000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 34, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.800000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 86, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 34, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dfe0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.801000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 86, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.803000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 35, "describer_id": 112, "size": 2048}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.803000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 87, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 35, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2dc20>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.804000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 87, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.812000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 36, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.813000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 88, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 36, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2df90>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.813000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 88, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.815000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 37, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.816000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 89, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 37, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2df40>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.817000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 89, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.824000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 38, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.825000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 90, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 38, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2e0d0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.826000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 90, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.828000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 39, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.829000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 91, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 39, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c2e080>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.829000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 91, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.852000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 40, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.853000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 97, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 40, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c1cdc0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.854000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 97, "source": "L['self']._modules['pooler']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.856000 13296 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 41, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.857000 13296 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 98, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 41, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x700236c1ce10>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.858000 13296 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 98, "source": "L['self']._modules['pooler']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:31:28.888000 13296 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_input_ids_": [1, 10], "l_self_modules_embeddings_buffers_token_type_ids_": [1, 512], "l_self_modules_embeddings_buffers_position_ids_": [1, 512], "l_self_modules_embeddings_modules_word_embeddings_parameters_weight_": [30522, 128], "l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_": [2, 128], "l_self_modules_embeddings_modules_position_embeddings_parameters_weight_": [512, 128], "l_self_modules_embeddings_modules_layer_norm_parameters_weight_": [128], "l_self_modules_embeddings_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_": [512], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_": [128, 512], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_": [512], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_": [128, 512], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_pooler_modules_dense_parameters_weight_": [128, 128], "l_self_modules_pooler_modules_dense_parameters_bias_": [128], "buffered_token_type_ids": [1, 10], "buffered_token_type_ids_expanded": [1, 10], "position_ids": [1, 10], "inputs_embeds": [1, 10, 128], "token_type_embeddings": [1, 10, 128], "embeddings": [1, 10, 128], "position_embeddings": [1, 10, 128], "embeddings_1": [1, 10, 128], "embeddings_2": [1, 10, 128], "embeddings_3": [1, 10, 128], "attention_mask": [1, 10], "getitem_2": [1, 1, 1, 10], "expand_1": [1, 1, 10, 10], "expanded_mask": [1, 1, 10, 10], "inverted_mask": [1, 1, 10, 10], "to_1": [1, 1, 10, 10], "extended_attention_mask": [1, 1, 10, 10], "linear": [1, 10, 128], "x": [1, 10, 2, 64], "query_layer": [1, 2, 10, 64], "linear_1": [1, 10, 128], "x_1": [1, 10, 2, 64], "key_layer": [1, 2, 10, 64], "linear_2": [1, 10, 128], "x_2": [1, 10, 2, 64], "value_layer": [1, 2, 10, 64], "attn_output": [1, 2, 10, 64], "attn_output_1": [1, 10, 2, 64], "attn_output_2": [1, 10, 128], "hidden_states": [1, 10, 128], "hidden_states_1": [1, 10, 128], "add_1": [1, 10, 128], "hidden_states_2": [1, 10, 128], "hidden_states_3": [1, 10, 512], "hidden_states_4": [1, 10, 512], "hidden_states_5": [1, 10, 128], "hidden_states_6": [1, 10, 128], "add_2": [1, 10, 128], "hidden_states_7": [1, 10, 128], "linear_6": [1, 10, 128], "x_3": [1, 10, 2, 64], "query_layer_1": [1, 2, 10, 64], "linear_7": [1, 10, 128], "x_4": [1, 10, 2, 64], "key_layer_1": [1, 2, 10, 64], "linear_8": [1, 10, 128], "x_5": [1, 10, 2, 64], "value_layer_1": [1, 2, 10, 64], "attn_output_3": [1, 2, 10, 64], "attn_output_4": [1, 10, 2, 64], "attn_output_5": [1, 10, 128], "hidden_states_8": [1, 10, 128], "hidden_states_9": [1, 10, 128], "add_3": [1, 10, 128], "hidden_states_10": [1, 10, 128], "hidden_states_11": [1, 10, 512], "hidden_states_12": [1, 10, 512], "hidden_states_13": [1, 10, 128], "hidden_states_14": [1, 10, 128], "add_4": [1, 10, 128], "hidden_states_15": [1, 10, 128], "first_token_tensor": [1, 128], "pooled_output": [1, 128], "pooled_output_1": [1, 128]}}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "ab467e954c31af9f03b0e717a844571c"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_input_ids_: "i64[1, 10][10, 1]cpu", L_self_modules_embeddings_buffers_token_type_ids_: "i64[1, 512][512, 1]cpu", L_self_modules_embeddings_buffers_position_ids_: "i64[1, 512][512, 1]cpu", L_self_modules_embeddings_modules_word_embeddings_parameters_weight_: "f32[30522, 128][128, 1]cpu", L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_: "f32[2, 128][128, 1]cpu", L_self_modules_embeddings_modules_position_embeddings_parameters_weight_: "f32[512, 128][128, 1]cpu", L_self_modules_embeddings_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_embeddings_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_pooler_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_pooler_modules_dense_parameters_bias_: "f32[128][1]cpu"):
	        l_input_ids_ = L_input_ids_
	        l_self_modules_embeddings_buffers_token_type_ids_ = L_self_modules_embeddings_buffers_token_type_ids_
	        l_self_modules_embeddings_buffers_position_ids_ = L_self_modules_embeddings_buffers_position_ids_
	        l_self_modules_embeddings_modules_word_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_word_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_position_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_position_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_layer_norm_parameters_weight_ = L_self_modules_embeddings_modules_LayerNorm_parameters_weight_
	        l_self_modules_embeddings_modules_layer_norm_parameters_bias_ = L_self_modules_embeddings_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_pooler_modules_dense_parameters_weight_ = L_self_modules_pooler_modules_dense_parameters_weight_
	        l_self_modules_pooler_modules_dense_parameters_bias_ = L_self_modules_pooler_modules_dense_parameters_bias_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        buffered_token_type_ids: "i64[1, 10][512, 1]cpu" = l_self_modules_embeddings_buffers_token_type_ids_[(slice(None, None, None), slice(None, 10, None))];  l_self_modules_embeddings_buffers_token_type_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        buffered_token_type_ids_expanded: "i64[1, 10][512, 1]cpu" = buffered_token_type_ids.expand(1, 10);  buffered_token_type_ids = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        position_ids: "i64[1, 10][512, 1]cpu" = l_self_modules_embeddings_buffers_position_ids_[(slice(None, None, None), slice(0, 10, None))];  l_self_modules_embeddings_buffers_position_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        inputs_embeds: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(l_input_ids_, l_self_modules_embeddings_modules_word_embeddings_parameters_weight_, 0, None, 2.0, False, False);  l_input_ids_ = l_self_modules_embeddings_modules_word_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        token_type_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(buffered_token_type_ids_expanded, l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_, None, None, 2.0, False, False);  buffered_token_type_ids_expanded = l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = inputs_embeds + token_type_embeddings;  inputs_embeds = token_type_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        position_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(position_ids, l_self_modules_embeddings_modules_position_embeddings_parameters_weight_, None, None, 2.0, False, False);  position_ids = l_self_modules_embeddings_modules_position_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        embeddings += position_embeddings;  embeddings_1: "f32[1, 10, 128][1280, 128, 1]cpu" = embeddings;  embeddings = position_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        embeddings_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(embeddings_1, (128,), l_self_modules_embeddings_modules_layer_norm_parameters_weight_, l_self_modules_embeddings_modules_layer_norm_parameters_bias_, 1e-12);  embeddings_1 = l_self_modules_embeddings_modules_layer_norm_parameters_weight_ = l_self_modules_embeddings_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        embeddings_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(embeddings_2, 0.1, False, False);  embeddings_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        attention_mask: "f32[1, 10][10, 1]cpu" = torch.ones((1, 10), device = device(type='cpu'))
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        getitem_2: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = attention_mask[(slice(None, None, None), None, None, slice(None, None, None))];  attention_mask = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = getitem_2.expand(1, 1, 10, 10);  getitem_2 = None
	        expanded_mask: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = expand_1.to(torch.float32);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        inverted_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = 1.0 - expanded_mask;  expanded_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        to_1: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.to(torch.bool)
	        extended_attention_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.masked_fill(to_1, -3.4028234663852886e+38);  inverted_mask = to_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear.view((1, 10, 2, 64));  linear = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x.permute(0, 2, 1, 3);  x = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_1.view((1, 10, 2, 64));  linear_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_1.permute(0, 2, 1, 3);  x_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_2.view((1, 10, 2, 64));  linear_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_2.permute(0, 2, 1, 3);  x_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer, key_layer, value_layer, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer = key_layer = value_layer = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output.transpose(1, 2);  attn_output = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_2: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_1.reshape(1, 10, 128);  attn_output_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_2, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_2 = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states, 0.1, False, False);  hidden_states = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_1 + embeddings_3;  hidden_states_1 = embeddings_3 = None
	        hidden_states_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_1, (128,), l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_1 = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_2, l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_3);  hidden_states_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_4, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_);  hidden_states_4 = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_5, 0.1, False, False);  hidden_states_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_2: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_6 + hidden_states_2;  hidden_states_6 = hidden_states_2 = None
	        hidden_states_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_2, (128,), l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_2 = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_3: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_6.view((1, 10, 2, 64));  linear_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_3.permute(0, 2, 1, 3);  x_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_7.view((1, 10, 2, 64));  linear_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_4.permute(0, 2, 1, 3);  x_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_8.view((1, 10, 2, 64));  linear_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_5.permute(0, 2, 1, 3);  x_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer_1, key_layer_1, value_layer_1, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer_1 = key_layer_1 = value_layer_1 = extended_attention_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output_3.transpose(1, 2);  attn_output_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_5: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_4.reshape(1, 10, 128);  attn_output_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_5, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_5 = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_8, 0.1, False, False);  hidden_states_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_9 + hidden_states_7;  hidden_states_9 = hidden_states_7 = None
	        hidden_states_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_3, (128,), l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_3 = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_10, l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_11);  hidden_states_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_12, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_);  hidden_states_12 = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_13, 0.1, False, False);  hidden_states_13 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_14 + hidden_states_10;  hidden_states_14 = hidden_states_10 = None
	        hidden_states_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_4, (128,), l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_4 = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        first_token_tensor: "f32[1, 128][1280, 1]cpu" = hidden_states_15[(slice(None, None, None), 0)]
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        pooled_output: "f32[1, 128][128, 1]cpu" = torch._C._nn.linear(first_token_tensor, l_self_modules_pooler_modules_dense_parameters_weight_, l_self_modules_pooler_modules_dense_parameters_bias_);  first_token_tensor = l_self_modules_pooler_modules_dense_parameters_weight_ = l_self_modules_pooler_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        pooled_output_1: "f32[1, 128][128, 1]cpu" = torch.tanh(pooled_output);  pooled_output = None
	        return (hidden_states_15, pooled_output_1)
	        
V0401 21:31:28.890000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "30b6e760a85c3c28c4925ad3d92686fb"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543088890335.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.891000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "55985b0455be95cdad38ff4310c205e9"}
	{
	"name": "backend_compile",
	"ts": 1743543088890335.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:28.927000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "54c1a46497438b371aa49c33fad992c9"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543088927517.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:29.605000 13296 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:352] {"aot_joint_graph": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcb09d2e1a88d319c9f911a929a3e77d"}
	class joint_helper(torch.nn.Module):
	    def forward(self, primals, tangents):
	        primals_1: "i64[1, 10][10, 1]cpu"; primals_2: "i64[1, 512][512, 1]cpu"; primals_3: "i64[1, 512][512, 1]cpu"; primals_4: "f32[30522, 128][128, 1]cpu"; primals_5: "f32[2, 128][128, 1]cpu"; primals_6: "f32[512, 128][128, 1]cpu"; primals_7: "f32[128][1]cpu"; primals_8: "f32[128][1]cpu"; primals_9: "f32[128, 128][1, 128]cpu"; primals_10: "f32[128][1]cpu"; primals_11: "f32[128, 128][1, 128]cpu"; primals_12: "f32[128][1]cpu"; primals_13: "f32[128, 128][1, 128]cpu"; primals_14: "f32[128][1]cpu"; primals_15: "f32[128, 128][1, 128]cpu"; primals_16: "f32[128][1]cpu"; primals_17: "f32[128][1]cpu"; primals_18: "f32[128][1]cpu"; primals_19: "f32[512, 128][1, 512]cpu"; primals_20: "f32[512][1]cpu"; primals_21: "f32[128, 512][1, 128]cpu"; primals_22: "f32[128][1]cpu"; primals_23: "f32[128][1]cpu"; primals_24: "f32[128][1]cpu"; primals_25: "f32[128, 128][1, 128]cpu"; primals_26: "f32[128][1]cpu"; primals_27: "f32[128, 128][1, 128]cpu"; primals_28: "f32[128][1]cpu"; primals_29: "f32[128, 128][1, 128]cpu"; primals_30: "f32[128][1]cpu"; primals_31: "f32[128, 128][1, 128]cpu"; primals_32: "f32[128][1]cpu"; primals_33: "f32[128][1]cpu"; primals_34: "f32[128][1]cpu"; primals_35: "f32[512, 128][1, 512]cpu"; primals_36: "f32[512][1]cpu"; primals_37: "f32[128, 512][1, 128]cpu"; primals_38: "f32[128][1]cpu"; primals_39: "f32[128][1]cpu"; primals_40: "f32[128][1]cpu"; primals_41: "f32[128, 128][1, 128]cpu"; primals_42: "f32[128][1]cpu"; tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu"; tangents_2: "f32[1, 128][128, 1]cpu"; 
	    
	        primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, tangents_1, tangents_2, = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_1: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 0, 0, 9223372036854775807);  primals_2 = None
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 10);  slice_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_3: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 0, 0, 9223372036854775807);  primals_3 = None
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_3, 1, 0, 10);  slice_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1)
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7);  mul = None
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        clone: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(add_3);  add_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        full: "f32[1, 10][10, 1]cpu" = torch.ops.aten.full.default([1, 10], 1, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        slice_5: "f32[1, 10][10, 1]cpu" = torch.ops.aten.slice.Tensor(full, 0, 0, 9223372036854775807);  full = None
	        unsqueeze: "f32[1, 1, 10][10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(slice_5, 1);  slice_5 = None
	        unsqueeze_1: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
	        slice_6: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.slice.Tensor(unsqueeze_1, 3, 0, 9223372036854775807);  unsqueeze_1 = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = torch.ops.aten.expand.default(slice_6, [1, 1, 10, 10]);  slice_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        sub_1: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.sub.Tensor(1.0, expand_1);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        convert_element_type: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.prims.convert_element_type.default(sub_1, torch.bool)
	        scalar_tensor: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(-3.4028234663852886e+38, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.where.self(convert_element_type, scalar_tensor, sub_1);  convert_element_type = scalar_tensor = sub_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view_3, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view_6, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = where)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        alias: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_2)
	        alias_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias);  alias = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3]);  getitem_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_11);  view_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_1, clone);  clone_1 = clone = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5)
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17);  mul_2 = None
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_15);  view_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_2, add_6);  clone_2 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7)
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23);  mul_7 = None
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_19: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_19, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_22, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = where)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        alias_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_8)
	        alias_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_2);  alias_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3]);  getitem_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_27);  view_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_3, add_10);  clone_3 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11)
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33);  mul_9 = None
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_31);  view_31 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_4, add_13);  clone_4 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13)
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39);  mul_14 = None
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        slice_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice.Tensor(add_17, 0, 0, 9223372036854775807)
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(slice_7, 1, 0);  slice_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        alias_4: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(tanh)
	        alias_5: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_4);  alias_4 = None
	        alias_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_5);  alias_5 = None
	        alias_7: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_6);  alias_6 = None
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(alias_7, alias_7);  alias_7 = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_1, mm, 1, 0);  full_1 = mm = None
	        full_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        slice_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice_scatter.default(full_2, select_scatter, 0, 0, 9223372036854775807);  full_2 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, slice_scatter);  tangents_1 = slice_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_7, rsqrt_4);  sub_7 = None
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_18);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_18, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_18);  mul_18 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_2: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_25);  mul_25 = None
	        add_19: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_2, 1);  erf_2 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_19, 0.5);  add_19 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_32: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_10, rsqrt_3);  sub_10 = None
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_32);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_32, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_32);  mul_32 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_3);  alias_3 = None
	        alias_9: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_8);  alias_8 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, alias_9, getitem_9, 0.0, False, attn_mask = where);  permute_33 = permute_11 = permute_13 = permute_15 = alias_9 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_22, [1, 0]);  view_22 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44);  permute_36 = None
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        permute_40: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_19, [1, 0]);  view_19 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_40, view_48);  permute_40 = None
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        permute_44: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_44, view_52);  permute_44 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_39: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_13, rsqrt_2);  sub_13 = None
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_39);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_39, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_39);  mul_39 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_46: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_46);  mul_46 = None
	        add_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_3, 1);  erf_3 = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_25, 0.5);  add_25 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_16: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_53: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_16, rsqrt_1);  sub_16 = None
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_53);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_53, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_53);  mul_53 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_10: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_1);  alias_1 = None
	        alias_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_10);  alias_10 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, alias_11, getitem_3, 0.0, False, attn_mask = where);  permute_55 = permute_1 = permute_3 = permute_5 = alias_11 = getitem_3 = where = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_6, [1, 0]);  view_6 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66);  permute_58 = None
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        permute_62: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_3, [1, 0]);  view_3 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_62, view_70);  permute_62 = None
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        permute_66: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_66, view_74);  permute_66 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        sub_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_19, rsqrt);  sub_19 = None
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul_60);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_60, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul_60);  mul_60 = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        scalar_tensor_1: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, scalar_tensor_1, mul_65);  unsqueeze_2 = scalar_tensor_1 = None
	        full_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_3, [slice_4], where_1, True);  full_3 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        scalar_tensor_2: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, scalar_tensor_2, mul_65);  unsqueeze_3 = scalar_tensor_2 = None
	        full_4: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_4, [expand], where_2, True);  full_4 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        scalar_tensor_3: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, scalar_tensor_3, mul_65);  unsqueeze_4 = scalar_tensor_3 = mul_65 = None
	        full_5: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_5, [primals_1], where_3, True);  full_5 = primals_1 = where_3 = None
	        return pytree.tree_unflatten([add_17, tanh, None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32], self._out_spec)
	        
V0401 21:31:30.096000 13296 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:545] {"aot_forward_graph": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "79ae68c5ee14a8aca5626a97bbc2e0b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_2: "i64[1, 512][512, 1]cpu", primals_3: "i64[1, 512][512, 1]cpu", primals_4: "f32[30522, 128][128, 1]cpu", primals_5: "f32[2, 128][128, 1]cpu", primals_6: "f32[512, 128][128, 1]cpu", primals_7: "f32[128][1]cpu", primals_8: "f32[128][1]cpu", primals_9: "f32[128, 128][1, 128]cpu", primals_10: "f32[128][1]cpu", primals_11: "f32[128, 128][1, 128]cpu", primals_12: "f32[128][1]cpu", primals_13: "f32[128, 128][1, 128]cpu", primals_14: "f32[128][1]cpu", primals_15: "f32[128, 128][1, 128]cpu", primals_16: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_18: "f32[128][1]cpu", primals_19: "f32[512, 128][1, 512]cpu", primals_20: "f32[512][1]cpu", primals_21: "f32[128, 512][1, 128]cpu", primals_22: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_24: "f32[128][1]cpu", primals_25: "f32[128, 128][1, 128]cpu", primals_26: "f32[128][1]cpu", primals_27: "f32[128, 128][1, 128]cpu", primals_28: "f32[128][1]cpu", primals_29: "f32[128, 128][1, 128]cpu", primals_30: "f32[128][1]cpu", primals_31: "f32[128, 128][1, 128]cpu", primals_32: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_34: "f32[128][1]cpu", primals_35: "f32[512, 128][1, 512]cpu", primals_36: "f32[512][1]cpu", primals_37: "f32[128, 512][1, 128]cpu", primals_38: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", primals_40: "f32[128][1]cpu", primals_41: "f32[128, 128][1, 128]cpu", primals_42: "f32[128][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_3, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17)
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23)
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33)
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39)
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(add_17, 1, 0)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)
	        
V0401 21:31:30.108000 13296 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] {"aot_backward_graph": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "8ef2f550890c1bc6143556bd01aa3cc0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_7: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", expand: "i64[1, 10][512, 1]cpu", slice_4: "i64[1, 10][512, 1]cpu", mul: "f32[1, 10, 128][1280, 128, 1]cpu", full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu", permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_3: "f32[1, 2, 10][20, 1, 2]cpu", mul_2: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_4: "f32[10, 512][512, 1]cpu", mul_7: "f32[1, 10, 128][1280, 128, 1]cpu", permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_9: "f32[1, 2, 10][20, 1, 2]cpu", mul_9: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_10: "f32[10, 512][512, 1]cpu", mul_14: "f32[1, 10, 128][1280, 128, 1]cpu", tanh: "f32[1, 128][128, 1]cpu", permute_21: "f32[128, 128][1, 128]cpu", permute_22: "f32[128, 1][1, 1280]cpu", div: "f32[1, 10, 1][10, 1, 1]cpu", permute_24: "f32[128, 512][1, 128]cpu", permute_25: "f32[512, 10][1, 512]cpu", permute_27: "f32[512, 128][1, 512]cpu", permute_28: "f32[128, 10][1, 128]cpu", div_1: "f32[1, 10, 1][10, 1, 1]cpu", permute_30: "f32[128, 128][1, 128]cpu", permute_35: "f32[128, 128][1, 128]cpu", permute_36: "f32[128, 10][1, 128]cpu", permute_39: "f32[128, 128][1, 128]cpu", permute_43: "f32[128, 128][1, 128]cpu", div_2: "f32[1, 10, 1][10, 1, 1]cpu", permute_46: "f32[128, 512][1, 128]cpu", permute_47: "f32[512, 10][1, 512]cpu", permute_49: "f32[512, 128][1, 512]cpu", permute_50: "f32[128, 10][1, 128]cpu", div_3: "f32[1, 10, 1][10, 1, 1]cpu", permute_52: "f32[128, 128][1, 128]cpu", permute_57: "f32[128, 128][1, 128]cpu", permute_58: "f32[128, 10][1, 128]cpu", permute_61: "f32[128, 128][1, 128]cpu", permute_65: "f32[128, 128][1, 128]cpu", div_4: "f32[1, 10, 1][10, 1, 1]cpu", tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu", tangents_2: "f32[1, 128][128, 1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tanh, tanh);  tanh = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_default_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_default_1, mm, 1, 0);  full_default_1 = mm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, select_scatter);  tangents_1 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_14);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_14);  mul_14 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_14, 0.5);  add_14 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_9);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_9);  mul_9 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, getitem_8, getitem_9, 0.0, False, attn_mask = full_default);  permute_33 = permute_11 = permute_13 = permute_15 = getitem_8 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44)
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_48)
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_52);  permute_36 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_7);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_7);  mul_7 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_7, 0.5);  add_7 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_2);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_2);  mul_2 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, getitem_2, getitem_3, 0.0, False, attn_mask = full_default);  permute_55 = permute_1 = permute_3 = permute_5 = getitem_2 = getitem_3 = full_default = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66)
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_70)
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_74);  permute_58 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul);  mul = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        full_default_3: "f32[][]cpu" = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, full_default_3, mul_65);  unsqueeze_2 = None
	        full_default_4: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_4, [slice_4], where_1, True);  full_default_4 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, full_default_3, mul_65);  unsqueeze_3 = None
	        full_default_6: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_6, [expand], where_2, True);  full_default_6 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, full_default_3, mul_65);  unsqueeze_4 = full_default_3 = mul_65 = None
	        full_default_8: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_8, [primals_1], where_3, True);  full_default_8 = primals_1 = where_3 = None
	        return (None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32)
	        
V0401 21:31:30.109000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "8a6eaf723bc1aed95d5b43f6c276fa12"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543090109173.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.110000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "9f3aa33490fa8c37a63f99fc1dec0ad1"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543090110629.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.111000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "70216584ef3eb0ce47919d8f11e27fe2"}
	{
	"name": "inductor_compile",
	"ts": 1743543090110629.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.159000 13296 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/wj/cwj2yvfe4p4qqpw45iwdct6oixfgysw425lsdrk75mhovzer24kt.py"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "27c0d546112e14e158896e97040f6d61"}
	# AOT ID: ['23_forward']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0 = async_compile.cpp_pybinding(['const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       const float* in_ptr1,
	                       const int64_t* in_ptr2,
	                       const float* in_ptr3,
	                       const int64_t* in_ptr4,
	                       const float* in_ptr5,
	                       const float* in_ptr6,
	                       const float* in_ptr7,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4,
	                       float* out_ptr5,
	                       float* out_ptr6)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                    auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	                    auto tmp21 = in_ptr4[static_cast<int64_t>(x0)];
	                    auto tmp1 = 30522L;
	                    auto tmp2 = c10::convert<int64_t>(tmp1);
	                    auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
	                    auto tmp4 = tmp0 < 0;
	                    auto tmp5 = tmp4 ? tmp3 : tmp0;
	                    auto tmp6 = tmp5;
	                    auto tmp7 = c10::convert<int64_t>(tmp6);
	                    TORCH_CHECK((0 <= tmp7) & (tmp7 < 30522L), "index out of bounds: 0 <= tmp7 < 30522L");
	                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*tmp5)), static_cast<int64_t>(8));
	                    auto tmp11 = 2L;
	                    auto tmp12 = c10::convert<int64_t>(tmp11);
	                    auto tmp13 = decltype(tmp10)(tmp10 + tmp12);
	                    auto tmp14 = tmp10 < 0;
	                    auto tmp15 = tmp14 ? tmp13 : tmp10;
	                    auto tmp16 = tmp15;
	                    auto tmp17 = c10::convert<int64_t>(tmp16);
	                    TORCH_CHECK((0 <= tmp17) & (tmp17 < 2L), "index out of bounds: 0 <= tmp17 < 2L");
	                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1 + (128L*tmp15)), static_cast<int64_t>(8));
	                    auto tmp20 = tmp9 + tmp19;
	                    auto tmp22 = 512L;
	                    auto tmp23 = c10::convert<int64_t>(tmp22);
	                    auto tmp24 = decltype(tmp21)(tmp21 + tmp23);
	                    auto tmp25 = tmp21 < 0;
	                    auto tmp26 = tmp25 ? tmp24 : tmp21;
	                    auto tmp27 = tmp26;
	                    auto tmp28 = c10::convert<int64_t>(tmp27);
	                    TORCH_CHECK((0 <= tmp28) & (tmp28 < 512L), "index out of bounds: 0 <= tmp28 < 512L");
	                    auto tmp30 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x1 + (128L*tmp26)), static_cast<int64_t>(8));
	                    auto tmp31 = tmp20 + tmp30;
	                    tmp31.store(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)));
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp31, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr2[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp4 = out_ptr2[static_cast<int64_t>(x0)];
	                auto tmp12 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = at::vec::Vectorized<float>(tmp1);
	                auto tmp3 = tmp0 - tmp2;
	                auto tmp5 = static_cast<float>(128.0);
	                auto tmp6 = tmp4 / tmp5;
	                auto tmp7 = static_cast<float>(1e-12);
	                auto tmp8 = decltype(tmp6)(tmp6 + tmp7);
	                auto tmp9 = 1 / std::sqrt(tmp8);
	                auto tmp10 = at::vec::Vectorized<float>(tmp9);
	                auto tmp11 = tmp3 * tmp10;
	                auto tmp13 = tmp11 * tmp12;
	                auto tmp15 = tmp13 + tmp14;
	                tmp11.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp15.store(out_ptr4 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(96L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(96L); x0<static_cast<int64_t>(100L); x0+=static_cast<int64_t>(4L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0), static_cast<int64_t>(4L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_1 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_2 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_3 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_4 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_5 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_6 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_tanh_7 = async_compile.cpp_pybinding(['float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(float* in_out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(128L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = decltype(tmp0)(2) / (decltype(tmp0)(1) + (decltype(tmp0)(-2) * tmp0).exp()) - decltype(tmp0)(1);
	            tmp1.store(in_out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42 = args
	    args.clear()
	    assert_size_stride(primals_1, (1, 10), (10, 1))
	    assert_size_stride(primals_2, (1, 512), (512, 1))
	    assert_size_stride(primals_3, (1, 512), (512, 1))
	    assert_size_stride(primals_4, (30522, 128), (128, 1))
	    assert_size_stride(primals_5, (2, 128), (128, 1))
	    assert_size_stride(primals_6, (512, 128), (128, 1))
	    assert_size_stride(primals_7, (128, ), (1, ))
	    assert_size_stride(primals_8, (128, ), (1, ))
	    assert_size_stride(primals_9, (128, 128), (1, 128))
	    assert_size_stride(primals_10, (128, ), (1, ))
	    assert_size_stride(primals_11, (128, 128), (1, 128))
	    assert_size_stride(primals_12, (128, ), (1, ))
	    assert_size_stride(primals_13, (128, 128), (1, 128))
	    assert_size_stride(primals_14, (128, ), (1, ))
	    assert_size_stride(primals_15, (128, 128), (1, 128))
	    assert_size_stride(primals_16, (128, ), (1, ))
	    assert_size_stride(primals_17, (128, ), (1, ))
	    assert_size_stride(primals_18, (128, ), (1, ))
	    assert_size_stride(primals_19, (512, 128), (1, 512))
	    assert_size_stride(primals_20, (512, ), (1, ))
	    assert_size_stride(primals_21, (128, 512), (1, 128))
	    assert_size_stride(primals_22, (128, ), (1, ))
	    assert_size_stride(primals_23, (128, ), (1, ))
	    assert_size_stride(primals_24, (128, ), (1, ))
	    assert_size_stride(primals_25, (128, 128), (1, 128))
	    assert_size_stride(primals_26, (128, ), (1, ))
	    assert_size_stride(primals_27, (128, 128), (1, 128))
	    assert_size_stride(primals_28, (128, ), (1, ))
	    assert_size_stride(primals_29, (128, 128), (1, 128))
	    assert_size_stride(primals_30, (128, ), (1, ))
	    assert_size_stride(primals_31, (128, 128), (1, 128))
	    assert_size_stride(primals_32, (128, ), (1, ))
	    assert_size_stride(primals_33, (128, ), (1, ))
	    assert_size_stride(primals_34, (128, ), (1, ))
	    assert_size_stride(primals_35, (512, 128), (1, 512))
	    assert_size_stride(primals_36, (512, ), (1, ))
	    assert_size_stride(primals_37, (128, 512), (1, 128))
	    assert_size_stride(primals_38, (128, ), (1, ))
	    assert_size_stride(primals_39, (128, ), (1, ))
	    assert_size_stride(primals_40, (128, ), (1, ))
	    assert_size_stride(primals_41, (128, 128), (1, 128))
	    assert_size_stride(primals_42, (128, ), (1, ))
	    buf0 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf1 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf2 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf4 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf6 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf53 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    buf5 = empty_strided_cpu((1, 1, 10, 10), (100, 100, 10, 1), torch.float32)
	    cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0(primals_1, primals_4, primals_2, primals_5, primals_3, primals_6, primals_7, primals_8, buf0, buf1, buf2, buf4, buf6, buf53, buf5)
	    del primals_4
	    del primals_5
	    del primals_6
	    del primals_8
	    buf7 = reinterpret_tensor(buf0, (10, 128), (128, 1), 0); del buf0  # reuse
	    # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_10, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_9, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf7)
	    del primals_10
	    buf8 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_1], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_12, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_11, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf8)
	    del primals_12
	    buf9 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_14, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_13, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf9)
	    del primals_14
	    # Topologically Sorted Source Nodes: [attn_output], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf10 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf11 = buf10[0]
	    buf12 = buf10[1]
	    del buf10
	    buf13 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_16, reinterpret_tensor(buf11, (10, 128), (128, 1), 0), reinterpret_tensor(primals_15, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf13)
	    del primals_16
	    buf14 = buf2; del buf2  # reuse
	    buf15 = buf1; del buf1  # reuse
	    buf17 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf18 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf52 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_1(buf13, buf6, primals_17, primals_18, buf14, buf15, buf17, buf18, buf52)
	    del primals_18
	    buf19 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_3], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_20, reinterpret_tensor(buf18, (10, 128), (128, 1), 0), reinterpret_tensor(primals_19, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf19)
	    del primals_20
	    buf20 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_2(buf19, buf20)
	    buf21 = buf13; del buf13  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_5], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_22, reinterpret_tensor(buf20, (10, 512), (512, 1), 0), reinterpret_tensor(primals_21, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf21)
	    del primals_22
	    buf22 = buf15; del buf15  # reuse
	    buf23 = buf14; del buf14  # reuse
	    buf25 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf26 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf51 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_3(buf21, buf18, primals_23, primals_24, buf22, buf23, buf25, buf26, buf51)
	    del primals_24
	    buf27 = buf21; del buf21  # reuse
	    # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_26, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_25, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf27)
	    del primals_26
	    buf28 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_7], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_28, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_27, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf28)
	    del primals_28
	    buf29 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_30, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_29, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf29)
	    del primals_30
	    # Topologically Sorted Source Nodes: [attn_output_3], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf30 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf31 = buf30[0]
	    buf32 = buf30[1]
	    del buf30
	    buf33 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_32, reinterpret_tensor(buf31, (10, 128), (128, 1), 0), reinterpret_tensor(primals_31, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf33)
	    del primals_32
	    buf34 = buf23; del buf23  # reuse
	    buf35 = buf22; del buf22  # reuse
	    buf37 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf38 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf50 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_4(buf33, buf26, primals_33, primals_34, buf34, buf35, buf37, buf38, buf50)
	    del primals_34
	    buf39 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_11], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_36, reinterpret_tensor(buf38, (10, 128), (128, 1), 0), reinterpret_tensor(primals_35, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf39)
	    del primals_36
	    buf40 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_5(buf39, buf40)
	    buf41 = buf33; del buf33  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_13], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_38, reinterpret_tensor(buf40, (10, 512), (512, 1), 0), reinterpret_tensor(primals_37, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf41)
	    del primals_38
	    buf42 = buf35; del buf35  # reuse
	    buf43 = buf34; del buf34  # reuse
	    buf45 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf46 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf49 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_6(buf41, buf38, primals_39, primals_40, buf42, buf43, buf45, buf46, buf49)
	    del buf41
	    del buf42
	    del buf43
	    del primals_40
	    buf47 = empty_strided_cpu((1, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [pooled_output], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_42, reinterpret_tensor(buf46, (1, 128), (128, 1), 0), reinterpret_tensor(primals_41, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf47)
	    del primals_42
	    buf48 = buf47; del buf47  # reuse
	    cpp_fused_tanh_7(buf48)
	    return (buf46, buf48, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, reinterpret_tensor(primals_2, (1, 10), (512, 1), 0), reinterpret_tensor(primals_3, (1, 10), (512, 1), 0), buf4, buf5, reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf11, buf12, buf17, buf19, buf25, reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf31, buf32, buf37, buf39, buf45, buf48, primals_41, reinterpret_tensor(buf46, (128, 1), (1, 1280), 0), buf49, primals_37, reinterpret_tensor(buf40, (512, 10), (1, 512), 0), primals_35, reinterpret_tensor(buf38, (128, 10), (1, 128), 0), buf50, primals_31, primals_29, reinterpret_tensor(buf26, (128, 10), (1, 128), 0), primals_27, primals_25, buf51, primals_21, reinterpret_tensor(buf20, (512, 10), (1, 512), 0), primals_19, reinterpret_tensor(buf18, (128, 10), (1, 128), 0), buf52, primals_15, primals_13, reinterpret_tensor(buf6, (128, 10), (1, 128), 0), primals_11, primals_9, buf53, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    primals_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    primals_2 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_3 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_4 = rand_strided((30522, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_5 = rand_strided((2, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_6 = rand_strided((512, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_7 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_8 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_9 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_10 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_11 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_12 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_13 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_14 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_15 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_16 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_17 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_18 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_19 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_20 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_21 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_22 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_23 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_24 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_25 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_26 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_27 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_28 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_29 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_30 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_31 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_32 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_33 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_34 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_35 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_36 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_37 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_38 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_39 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_40 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_41 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_42 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:31:30.160000 13296 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "1eef48bdc39d76ac41bf312a0d1dea10"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543090159994.5,
	"args": {
	"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a",
	"components": [
	"[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]",
	"[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 9358179354,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:31:30.162000 13296 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "e79f0f8d777e763e920651daa30b6af1"}
	{"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a", "components": ["[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]", "[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 9358179354, "cache_state": "hit"}
V0401 21:31:30.164000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "5dba2bfe62ea2fd8fd1d71d1d9969dda"}
	{
	"name": "inductor_compile",
	"ts": 1743543090164184.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.164000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "a35354d4c2dd644ddc862870c1e0389b"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543090164824.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.166000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "5ee62f5034d10bd75e99127293b213ea"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543090166084.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.169000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "cd71d4fd9eb38dc73a9b86a8c1aae0fd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543090169718.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.170000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "0c53332a61fb7616c9736a49fc1c566e"}
	{
	"name": "backend_compile",
	"ts": 1743543090170663.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.171000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "2dda420248a9bae386e02113a8d4734f"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543090171354.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.402000 13296 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "a566a8860d85a2cb8ba3dfe87ecf5193"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 105251544206032)                
	| | +- GuardManager: source=L['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | +- GuardManager: source=L['self'].config, accessed_by=DictGetItemGuardAccessor(config)
	| | | | +- TYPE_MATCH: ___check_type_id(L['self'].config, 105251538872368)         
	| | | | +- GuardManager: source=L['self'].config.is_decoder, accessed_by=GetAttrGuardAccessor(is_decoder)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.is_decoder, 105251315000256)
	| | | | +- GuardManager: source=L['self'].config.use_return_dict, accessed_by=GetAttrGuardAccessor(use_return_dict)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.use_return_dict, 105251315000224)
	| | | | +- GuardManager: source=L['self'].config.num_hidden_layers, accessed_by=GetAttrGuardAccessor(num_hidden_layers)
	| | | | | +- EQUALS_MATCH: L['self'].config.num_hidden_layers == 2                     
	| | | | +- GuardManager: source=L['self'].config.output_attentions, accessed_by=GetAttrGuardAccessor(output_attentions)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.output_attentions, 105251315000256)
	| | | | +- GuardManager: source=L['self'].config.output_hidden_states, accessed_by=GetAttrGuardAccessor(output_hidden_states)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.output_hidden_states, 105251315000256)
	| | | +- GuardManager: source=L['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | +- DICT_LENGTH: len(L['self']._modules) == 3                                
	| | | | +- GuardManager: source=L['self']._modules['embeddings'], accessed_by=DictGetItemGuardAccessor(embeddings)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings'], 105251543424176)
	| | | | | +- GuardManager: source=L['self']._modules['embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers, accessed_by=DictGetItemGuardAccessor(_buffers)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._buffers) == 2         
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._buffers['position_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['input_ids'], L['self']._modules['embeddings']._buffers['position_ids'], L['self']._modules['embeddings']._buffers['token_type_ids'], L['self']._modules['pooler']._modules['dense']._parameters['bias'], L['self']._modules['pooler']._modules['dense']._parameters['weight'], L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'])
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._buffers['token_type_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules) == 5         
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'], accessed_by=DictGetItemGuardAccessor(word_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['word_embeddings'], 105251444541440)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['word_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].sparse, 105251315000256)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].max_norm, 105251315093216)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['word_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['word_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[30522, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['word_embeddings'].padding_idx == 0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, 105251315000256)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'], accessed_by=DictGetItemGuardAccessor(position_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['position_embeddings'], 105251444541440)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['position_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].sparse, 105251315000256)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].max_norm, 105251315093216)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['position_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['position_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].padding_idx, 105251315093216)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, 105251315000256)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'], accessed_by=DictGetItemGuardAccessor(token_type_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['token_type_embeddings'], 105251444541440)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['token_type_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].sparse, 105251315000256)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].max_norm, 105251315093216)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['token_type_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[2, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].padding_idx, 105251315093216)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, 105251315000256)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['LayerNorm'], 105251443980464)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['LayerNorm'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape, 105251315101760)
	| | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['dropout'], 105251442659536)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['dropout'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['dropout'].p == 0.1
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['dropout'].inplace, 105251315000256)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['dropout'].training, 105251315000256)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._parameters            
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['embeddings']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._backward_hooks        
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['embeddings']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._backward_pre_hooks    
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings'].position_embedding_type == 'absolute'
	| | | | +- GuardManager: source=L['self']._modules['encoder'], accessed_by=DictGetItemGuardAccessor(encoder)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder'], 105251481660288)
	| | | | | +- GuardManager: source=L['self']._modules['encoder'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules) == 1            
	| | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer'], accessed_by=DictGetItemGuardAccessor(layer)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer'], 105251442632288)
	| | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']) == 2   
	| | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DictGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | +- KeyValueManager pair at index=0
	| | | | | | | | | | | +- KeyManager: GuardManager: source=list(L['self']._modules['encoder']._modules['layer']._modules.keys())[0]
	| | | | | | | | | | | | +- EQUALS_MATCH: list(L['self']._modules['encoder']._modules['layer']._modules.keys())[0] == '0'
	| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0'], 105251543928608)
	| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0'].__dict__)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules) == 3
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'], 105251543897760)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], 105251543844848)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], 105251543846624)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], 105251443980464)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 105251315101760)
	| | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], 105251442659536)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, 105251315000256)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], 105251315093216)
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], 105251543899536)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], 105251443168208)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], 105251543362032)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, 123155304625824)
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'], 105251543926832)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], 105251443168208)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], 105251443980464)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, 105251315101760)
	| | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], 105251442659536)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, 105251315000256)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0'].is_decoder, 105251315000256)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._parameters
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._backward_hooks
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward == 0
	| | | | | | | | | | +- KeyValueManager pair at index=1
	| | | | | | | | | | | +- KeyManager: GuardManager: source=list(L['self']._modules['encoder']._modules['layer']._modules.keys())[1]
	| | | | | | | | | | | | +- EQUALS_MATCH: list(L['self']._modules['encoder']._modules['layer']._modules.keys())[1] == '1'
	| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1'], 105251543928608)
	| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1'].__dict__)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules) == 3
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'], 105251543897760)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], 105251543844848)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], 105251543846624)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], 105251443168208)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], 105251443980464)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 105251315101760)
	| | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], 105251442659536)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, 105251315000256)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], 105251315093216)
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], 105251543899536)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], 105251443168208)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], 105251543362032)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, 123155304625824)
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'], 105251543926832)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], 105251443168208)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], 105251443980464)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, 105251315101760)
	| | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], 105251442659536)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, 105251315000256)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, 105251315000256)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1'].is_decoder, 105251315000256)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._parameters
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._backward_hooks
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward == 0
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._parameters               
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._backward_hooks           
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._backward_pre_hooks       
	| | | | | | +- GuardManager: source=L['self']._modules['encoder'].gradient_checkpointing, accessed_by=DictGetItemGuardAccessor(gradient_checkpointing)
	| | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder'].gradient_checkpointing, 105251315000256)
	| | | | +- GuardManager: source=L['self']._modules['pooler'], accessed_by=DictGetItemGuardAccessor(pooler)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler'], 105251481662064)
	| | | | | +- GuardManager: source=L['self']._modules['pooler'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['pooler']._modules) == 2             
	| | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler']._modules['dense'], 105251443168208)
	| | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler']._modules['dense'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['pooler']._modules['dense']._parameters) == 2
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['pooler']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['pooler']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['activation'], accessed_by=DictGetItemGuardAccessor(activation)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler']._modules['activation'], 105251442799840)
	| | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['activation'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler']._modules['activation'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._parameters                
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['pooler']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._backward_hooks            
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['pooler']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._backward_pre_hooks        
	| | | +- GuardManager: source=L['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | +- DICT_LENGTH: not L['self']._parameters                                   
	| | | +- GuardManager: source=L['self'].attn_implementation, accessed_by=DictGetItemGuardAccessor(attn_implementation)
	| | | | +- EQUALS_MATCH: L['self'].attn_implementation == 'sdpa'                     
	| | | +- GuardManager: source=L['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | +- EQUALS_MATCH: L['self'].position_embedding_type == 'absolute'             
	| +- GuardManager: source=L['head_mask'], accessed_by=DictGetItemGuardAccessor(head_mask)
	| | +- ID_MATCH: ___check_obj_id(L['head_mask'], 105251315093216)            
	| +- GuardManager: source=L['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False 
	| | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['return_dict'], accessed_by=DictGetItemGuardAccessor(return_dict)
	| | +- ID_MATCH: ___check_obj_id(L['return_dict'], 105251315093216)          
	| +- GuardManager: source=L['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | +- ID_MATCH: ___check_obj_id(L['position_ids'], 105251315093216)         
	| +- GuardManager: source=L['inputs_embeds'], accessed_by=DictGetItemGuardAccessor(inputs_embeds)
	| | +- ID_MATCH: ___check_obj_id(L['inputs_embeds'], 105251315093216)        
	| +- GuardManager: source=L['attention_mask'], accessed_by=DictGetItemGuardAccessor(attention_mask)
	| | +- ID_MATCH: ___check_obj_id(L['attention_mask'], 105251315093216)       
	| +- GuardManager: source=L['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | +- ID_MATCH: ___check_obj_id(L['token_type_ids'], 105251315093216)       
	| +- GuardManager: source=L['past_key_values'], accessed_by=DictGetItemGuardAccessor(past_key_values)
	| | +- ID_MATCH: ___check_obj_id(L['past_key_values'], 105251315093216)      
	| +- GuardManager: source=L['output_attentions'], accessed_by=DictGetItemGuardAccessor(output_attentions)
	| | +- ID_MATCH: ___check_obj_id(L['output_attentions'], 105251315093216)    
	| +- GuardManager: source=L['output_hidden_states'], accessed_by=DictGetItemGuardAccessor(output_hidden_states)
	| | +- ID_MATCH: ___check_obj_id(L['output_hidden_states'], 105251315093216) 
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__import_torch'], accessed_by=DictGetItemGuardAccessor(__import_torch)
	| | | +- GuardManager: source=G['__import_torch'].fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx, 123155281062832)    
	| | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | | +- GuardManager: source=G['__import_torch'].fx.Proxy, accessed_by=GetAttrGuardAccessor(Proxy)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx.Proxy, 105251449564240)
	| | | +- GuardManager: source=G['__import_torch'].compiler, accessed_by=GetAttrGuardAccessor(compiler)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler, 123155264082608)
	| | | | +- GuardManager: source=G['__import_torch'].compiler.is_compiling, accessed_by=GetAttrGuardAccessor(is_compiling)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler.is_compiling, 123155264473184)
	| | +- GuardManager: source=G['apply_chunking_to_forward'], accessed_by=DictGetItemGuardAccessor(apply_chunking_to_forward)
	| | | +- GuardManager: source=G['apply_chunking_to_forward'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['apply_chunking_to_forward'].__code__, 105251486364624)
	| | +- GuardManager: source=G['__builtins_dict___150'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___150)
	| | | +- GuardManager: source=G['__builtins_dict___150']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['int'], 105251315073760)
	| | | +- GuardManager: source=G['__builtins_dict___150']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['len'], 123155769909840)
	| | | +- GuardManager: source=G['__builtins_dict___150']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['str'], 105251315119040)
	| | | +- GuardManager: source=G['__builtins_dict___150']['dict'], accessed_by=DictGetItemGuardAccessor(dict)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['dict'], 105251315079392)
	| | | +- GuardManager: source=G['__builtins_dict___150']['iter'], accessed_by=DictGetItemGuardAccessor(iter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['iter'], 123155769909680)
	| | | +- GuardManager: source=G['__builtins_dict___150']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['tuple'], 105251315101760)
	| | | +- GuardManager: source=G['__builtins_dict___150']['hasattr'], accessed_by=DictGetItemGuardAccessor(hasattr)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['hasattr'], 123155769909120)
	| | | +- GuardManager: source=G['__builtins_dict___150']['enumerate'], accessed_by=DictGetItemGuardAccessor(enumerate)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['enumerate'], 105251315022240)
	| | | +- GuardManager: source=G['__builtins_dict___150']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['isinstance'], 123155769909520)
	| | +- GuardManager: source=G['_prepare_4d_attention_mask_for_sdpa'], accessed_by=DictGetItemGuardAccessor(_prepare_4d_attention_mask_for_sdpa)
	| | | +- GuardManager: source=G['_prepare_4d_attention_mask_for_sdpa'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_prepare_4d_attention_mask_for_sdpa'].__code__, 123154813415984)
	| | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_pytorch_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'], 123155198756240)
	| | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect, accessed_by=GetAttrGuardAccessor(inspect)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect, 123155768844640)
	| | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature, accessed_by=GetAttrGuardAccessor(signature)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, 123155766665008)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'], 123154813660480)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch, 123155767988992)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['torch']
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn, accessed_by=GetAttrGuardAccessor(nn)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.nn, 123155301894560)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn.functional, accessed_by=GetAttrGuardAccessor(functional)
	| | | | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit, accessed_by=GetAttrGuardAccessor(jit)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit, 123155288274192)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, accessed_by=GetAttrGuardAccessor(is_tracing)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, 123155287030688)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.bool, accessed_by=GetAttrGuardAccessor(bool)
	| | | | | +- EQUALS_MATCH: G['__import_transformers_dot_modeling_utils'].torch.bool == torch.bool
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.ones, accessed_by=GetAttrGuardAccessor(ones)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.ones, 123155762060784)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.tanh, accessed_by=GetAttrGuardAccessor(tanh)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.tanh, 123155762123200)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.finfo, accessed_by=GetAttrGuardAccessor(finfo)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.finfo, 123155759173920)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy, accessed_by=GetAttrGuardAccessor(is_torch_fx_proxy)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, 123155218996880)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, 123155219375936)
	| | +- GuardManager: source=G['BaseModelOutputWithPastAndCrossAttentions'], accessed_by=DictGetItemGuardAccessor(BaseModelOutputWithPastAndCrossAttentions)
	| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPastAndCrossAttentions'], 105251486255376)
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_generic'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_generic)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_generic'], 123155215669728)
	| | +- GuardManager: source=G['BaseModelOutputWithPoolingAndCrossAttentions'], accessed_by=DictGetItemGuardAccessor(BaseModelOutputWithPoolingAndCrossAttentions)
	| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPoolingAndCrossAttentions'], 105251486245696)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_linear)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 123155293039776)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_module)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 123155301900160)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_sparse)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'], 123155290565952)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, 123155293039936)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, accessed_by=GetAttrGuardAccessor(linear)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, 123155304626944)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, accessed_by=GetAttrGuardAccessor(dropout)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, 123155291027264)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, accessed_by=GetAttrGuardAccessor(embedding)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, 123155291097664)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, 123155291098624)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, accessed_by=GetAttrGuardAccessor(scaled_dot_product_attention)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, 123155304678640)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_dropout)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_dropout'], 123155289886128)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_container)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'], 123155289628304)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_activation)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_activation'], 123155291598784)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_import_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'], 123155217474448)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_available, accessed_by=GetAttrGuardAccessor(_torch_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_available, 105251315000224)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available, accessed_by=GetAttrGuardAccessor(is_torch_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, 123155219458880)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, accessed_by=GetAttrGuardAccessor(_torch_fx_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, 105251315000224)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available, accessed_by=GetAttrGuardAccessor(is_torch_fx_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, 123155219461792)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_attn_mask_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'], 123154813655600)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, accessed_by=GetAttrGuardAccessor(AttentionMaskConverter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, 105251543396416)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask, accessed_by=GetAttrGuardAccessor(_expand_mask)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, 123154813414960)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, 123155219375936)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_normalization)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 123155290002976)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | +- GuardManager: source=G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot__dynamo_dot_polyfills_dot_builtins)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], 123155227012256)
	| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor(torch)
	| | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['torch']
	
V0401 21:31:30.403000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "b897beb2adc01e66dd84fbfb69da1560"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543090403818.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.404000 13296 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "a23426aee0fd8823b573672fd1916f01"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543090404851.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:31:30.406000 13296 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "50/0", "frame_key": "95", "co_name": "forward", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", "co_firstlineno": 1001, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 642, "shape_env_guard_count": 0, "graph_op_count": 64, "graph_node_count": 107, "graph_input_count": 42, "start_time": 1743543088.0710006, "entire_frame_compile_time_s": 2.332707643508911, "backend_compile_time_s": 1.2802565097808838, "inductor_compile_time_s": 0.05345940589904785, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
