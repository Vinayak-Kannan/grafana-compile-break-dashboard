V0401 21:32:40.379000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", 0]}
V0401 21:32:40.380000 13985 torch/_logging/structured.py:22] {"str": ["/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", 1]}
V0401 21:32:40.381000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", 2]}
V0401 21:32:40.382000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", 3]}
V0401 21:32:40.383000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}]}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:40.384000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "d590b520c80388738886510256aeba4e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543160384314.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.385000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "dfbd53bae0e76ed7241402904e6cce50"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543160384314.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.410000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 0, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:40.411000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d840c1cd2c0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:40.411000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 0, "source": "L['kwargs']['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:40.422000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 1, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:40.423000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d840c1cd2c0>", "describer_id": 1}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:40.424000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 1, "id": 0, "source": "L['kwargs']['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:40.433000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_kwargs_input_ids_": [1, 10], "modified_input_ids": [1, 10], "getitem": [], "iadd": [], "getitem_1": []}}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "6c0020aaeb7d7d3760b62c08f9f2bfed"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_kwargs_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_kwargs_input_ids_ = L_kwargs_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:27 in forward_refined, code: modified_input_ids = input_ids.clone()
	        modified_input_ids: "i64[1, 10][10, 1]cpu" = l_kwargs_input_ids_.clone()
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:31 in forward_refined, code: modified_input_ids[0, 0] += seq_length
	        getitem: "i64[][]cpu" = modified_input_ids[(0, 0)]
	        getitem += 10;  iadd: "i64[][]cpu" = getitem;  getitem = None
	        modified_input_ids[(0, 0)] = iadd;  setitem = modified_input_ids;  iadd = setitem = None
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:34 in forward_refined, code: print(f"Original first element: {input_ids[0, 0]}")
	        getitem_1: "i64[][]cpu" = l_kwargs_input_ids_[(0, 0)];  l_kwargs_input_ids_ = None
	        return (getitem_1, modified_input_ids)
	        
V0401 21:32:40.434000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "a20381bfff4774f6995508b75b13f429"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543160434680.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.435000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "c91e176601f905b3a560df7b1d6b0ad7"}
	{
	"name": "backend_compile",
	"ts": 1743543160434680.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.440000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "9781f86e300dba147e96ab4eef9f3fcb"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543160440868.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.477000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "9f707f30b1279384c519811dad0b9552"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:27 in forward_refined, code: modified_input_ids = input_ids.clone()
	        clone: "i64[1, 10][10, 1]cpu" = torch.ops.aten.clone.default(arg0_1)
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:31 in forward_refined, code: modified_input_ids[0, 0] += seq_length
	        select: "i64[10][1]cpu" = torch.ops.aten.select.int(clone, 0, 0)
	        select_1: "i64[][]cpu" = torch.ops.aten.select.int(select, 0, 0);  select = None
	        add: "i64[][]cpu" = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None
	        select_2: "i64[10][1]cpu" = torch.ops.aten.select.int(clone, 0, 0)
	        select_scatter: "i64[10][1]cpu" = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None
	        select_scatter_1: "i64[1, 10][10, 1]cpu" = torch.ops.aten.select_scatter.default(clone, select_scatter, 0, 0);  clone = select_scatter = None
	        select_3: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_4: "i64[][]cpu" = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None
	        select_7: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_8: "i64[][]cpu" = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = None
	        copy: "i64[][]cpu" = torch.ops.aten.copy.default(select_8, select_4);  select_8 = select_4 = None
	        select_9: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_scatter_2: "i64[10][1]cpu" = torch.ops.aten.select_scatter.default(select_9, copy, 0, 0);  select_9 = copy = None
	        select_scatter_3: "i64[1, 10][10, 1]cpu" = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:34 in forward_refined, code: print(f"Original first element: {input_ids[0, 0]}")
	        select_12: "i64[10][1]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None
	        select_13: "i64[][]cpu" = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None
	        return (select_13, select_scatter_3)
	        
V0401 21:32:40.478000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "7de9ec66a0cb68b8bf7c7c526ac3e622"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543160477735.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.612000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "9349457a59152d31db3a2349006fc512"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543160612200.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:40.613000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "148d4e1ceaf44f191788e6d23a37658d"}
	{
	"name": "inductor_compile",
	"ts": 1743543160612200.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.482000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/za/cza42ezs6wdnqo3b4nlw4kwua42vqcv5gso47esdzicghfon3frt.py"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "b03204725a32a1e8cfe9a86df64c4b5d"}
	# AOT ID: ['0_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_0 = async_compile.cpp_pybinding(['const int64_t*', 'int64_t*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       int64_t* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp7 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp12 = at::vec::VectorizedN<int64_t,2>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp0 = static_cast<int32_t>(0);
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = x0;
	            auto tmp3 = c10::convert<int32_t>(tmp2);
	            auto tmp4 = at::vec::Vectorized<int32_t>::arange(tmp3, 1);
	            auto tmp5 = at::vec::Vectorized<int32_t>(tmp0);
	            auto tmp6 = at::vec::VecMask<int32_t,1>(tmp4 == tmp5);
	            auto tmp8 = static_cast<int64_t>(10);
	            auto tmp9 = decltype(tmp7)(tmp7 + tmp8);
	            auto tmp10 = tmp1 ? tmp9 : tmp7;
	            auto tmp11 = tmp1 ? tmp10 : tmp7;
	            auto tmp13 = at::vec::VectorizedN<int64_t,2>(tmp9);
	            auto tmp14 = decltype(tmp13)::blendv(tmp12, tmp13, tmp6.template cast<int64_t,2>());
	            auto tmp15 = at::vec::VecMask<float,1>::from(tmp1);
	            auto tmp16 = decltype(tmp14)::blendv(tmp12, tmp14, tmp15.template cast<int64_t,2>());
	            auto tmp17 = at::vec::VectorizedN<int64_t,2>(tmp11);
	            auto tmp18 = decltype(tmp17)::blendv(tmp16, tmp17, tmp6.template cast<int64_t,2>());
	            auto tmp19 = decltype(tmp18)::blendv(tmp16, tmp18, tmp15.template cast<int64_t,2>());
	            tmp19.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp5 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp10 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp0 = static_cast<int32_t>(0);
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = x0;
	            auto tmp3 = c10::convert<int32_t>(tmp2);
	            auto tmp4 = tmp3 == tmp0;
	            auto tmp6 = static_cast<int64_t>(10);
	            auto tmp7 = decltype(tmp5)(tmp5 + tmp6);
	            auto tmp8 = tmp1 ? tmp7 : tmp5;
	            auto tmp9 = tmp1 ? tmp8 : tmp5;
	            auto tmp11 = tmp4 ? tmp7 : tmp10;
	            auto tmp12 = tmp1 ? tmp11 : tmp10;
	            auto tmp13 = tmp4 ? tmp9 : tmp12;
	            auto tmp14 = tmp1 ? tmp13 : tmp12;
	            out_ptr0[static_cast<int64_t>(x0)] = tmp14;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    buf0 = empty_strided_cpu((1, 10), (10, 1), torch.int64)
	    cpp_fused_add_0(arg0_1, buf0)
	    return (reinterpret_tensor(arg0_1, (), (), 0), buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:42.483000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "4baa637433c5c48cd6c0aac590f9facb"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543162483006.8,
	"args": {
	"key": "f45yeswqixng4eyeijdmgdg6qxts7wnacm33wctqnuimy5akgqsg",
	"components": [
	"[lhff6jmwhay6uafbrkejb2az4bylpedd2xot6tiu6smleylsdao] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    add = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None\n    select_2 = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_scatter = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None\n    select_scatter_1 = torch.ops.aten.select_scatter.default(arg0_1, select_scatter, 0, 0);  select_scatter = None\n    select_3 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_4 = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None\n    select_7 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_8 = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = select_8 = None\n    select_9 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_scatter_2 = torch.ops.aten.select_scatter.default(select_9, select_4, 0, 0);  select_9 = select_4 = None\n    select_scatter_3 = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None\n    select_12 = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_13 = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None\n    return (select_13, select_scatter_3)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xakmu6hsswqogysgn56movvhqlw4wodj3bhszmkotgxxv3ro4uw] fx_kwargs[user_visible_outputs]: {'select_13': None, 'select_scatter_3': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 6573314886,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:42.484000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "8142b1e4e0519319e771637003402f44"}
	{"key": "f45yeswqixng4eyeijdmgdg6qxts7wnacm33wctqnuimy5akgqsg", "components": ["[lhff6jmwhay6uafbrkejb2az4bylpedd2xot6tiu6smleylsdao] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    add = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None\n    select_2 = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_scatter = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None\n    select_scatter_1 = torch.ops.aten.select_scatter.default(arg0_1, select_scatter, 0, 0);  select_scatter = None\n    select_3 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_4 = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None\n    select_7 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_8 = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = select_8 = None\n    select_9 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_scatter_2 = torch.ops.aten.select_scatter.default(select_9, select_4, 0, 0);  select_9 = select_4 = None\n    select_scatter_3 = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None\n    select_12 = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_13 = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None\n    return (select_13, select_scatter_3)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xakmu6hsswqogysgn56movvhqlw4wodj3bhszmkotgxxv3ro4uw] fx_kwargs[user_visible_outputs]: {'select_13': None, 'select_scatter_3': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 6573314886, "cache_state": "hit"}
V0401 21:32:42.486000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "7984c699ae645c92481af8d0464b705c"}
	{
	"name": "inductor_compile",
	"ts": 1743543162486447.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.487000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "b9626c2987cec796e1e3a6fd1d11a769"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543162487087.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.488000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "8d9ac34902c9ba092ff9a2b73be70c9c"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543162488554.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.492000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "712fcfcfcfd76e071a36afbd37d148cc"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543162492624.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.493000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "004e419a65c6fbb1d3f2e39a67309401"}
	{
	"name": "backend_compile",
	"ts": 1743543162493612.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.494000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "e04c520950c83ab6ff96e25ba3ebabf3"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543162494360.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.504000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "d08f6f15d11d7720374f67777e49cf46"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: len(L['kwargs']) == 1                                       
	| | +- GuardManager: source=L['kwargs']['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | | +- TENSOR_MATCH: check_tensor(L['kwargs']['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(L['kwargs']['input_ids'], '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___1'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___1)
	| | | +- GuardManager: source=G['__builtins_dict___1']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___1']['print'], 138006094275872)
	
V0401 21:32:42.505000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "79863a95b2f00a4213e7a32cab3502f1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162505135.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.506000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "c3131dc83b832c10d143810f6e325d1d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162505990.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.507000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "0/0", "frame_key": "1", "co_name": "forward_refined", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 19, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 7, "graph_input_count": 1, "start_time": 1743543160.3842947, "entire_frame_compile_time_s": 2.1206207275390625, "backend_compile_time_s": 2.058858633041382, "inductor_compile_time_s": 1.8738906383514404, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.misc.StringFormatVariable'>] False"], "dynamo_time_before_restart_s": 0.03391456604003906, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.509000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}]}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.509000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0, "has_payload": "b5cffd2627f7ad232404581ce151532f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162509760.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.510000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0, "has_payload": "12ffa4ad334d4127cf33a1a9c5badd4e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162509760.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.513000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 5, "size": 80}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.514000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d03938e0>", "describer_id": 5}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.515000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 5, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.520000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 6, "size": 80}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.521000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d03938e0>", "describer_id": 6}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.522000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 6, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.525000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_modified_input_ids_": [1, 10], "getitem": []}}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "37c5f5824b4dd3725b99b1c5447f0161"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_modified_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_modified_input_ids_ = L_modified_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:35 in torch_dynamo_resume_in_forward_refined_at_34, code: print(f"Modified first element: {modified_input_ids[0, 0]}")
	        getitem: "i64[][]cpu" = l_modified_input_ids_[(0, 0)];  l_modified_input_ids_ = None
	        return (getitem,)
	        
V0401 21:32:42.526000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "faa813d22b206ab861bd3af410802afa"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543162526488.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.527000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "d70c111314442cdcd6a8f0535ae2b0d9"}
	{
	"name": "backend_compile",
	"ts": 1743543162526488.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.529000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "21921409f845c16ad63ae9cbc4f050eb"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543162529648.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.540000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "1cd4c8f6fa09852cb5f89469b8223930"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:35 in torch_dynamo_resume_in_forward_refined_at_34, code: print(f"Modified first element: {modified_input_ids[0, 0]}")
	        select: "i64[10][1]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None
	        select_1: "i64[][]cpu" = torch.ops.aten.select.int(select, 0, 0);  select = None
	        return (select_1,)
	        
V0401 21:32:42.541000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "23fcccf3045abc3d1e6ab979b3247f24"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543162540983.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.543000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "77a3a58957def004a049d3f772521e6f"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543162543106.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.543000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "bc5bb8ac441180ba923d27607acd4156"}
	{
	"name": "inductor_compile",
	"ts": 1743543162543106.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.550000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/mf/cmfwsynimsavisgwplg33qd33nmpeiz6yigdbqzhgwumgq5l7im3.py"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "02aa93543631a1582a9db906672174f8"}
	# AOT ID: ['1_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    return (reinterpret_tensor(arg0_1, (), (), 0), )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:42.551000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "80669418de90ddc741f7722859574e86"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543162550801.5,
	"args": {
	"key": "fjjuflzqe3xa3bki3hrdezh2yb7fcvpr5a7vabgq2eqgcfqqmqpa",
	"components": [
	"[fl2wa3duqskceg3a4tsvilaaejxeh5hx5joo6yg7wnyjgjtwpfr] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    return (select_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[vnytv4vvduj2micgs6fvhtgyftmyf4tv24dcsrt3c2rpsdyaevy] fx_kwargs[user_visible_outputs]: {'select_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 17118202,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:42.552000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "6ff4022008a9b440da7b9a59ac7c88f4"}
	{"key": "fjjuflzqe3xa3bki3hrdezh2yb7fcvpr5a7vabgq2eqgcfqqmqpa", "components": ["[fl2wa3duqskceg3a4tsvilaaejxeh5hx5joo6yg7wnyjgjtwpfr] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    return (select_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[vnytv4vvduj2micgs6fvhtgyftmyf4tv24dcsrt3c2rpsdyaevy] fx_kwargs[user_visible_outputs]: {'select_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 17118202, "cache_state": "hit"}
V0401 21:32:42.553000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "7cb9832d2b27e76089a5d7a7fc2cdbef"}
	{
	"name": "inductor_compile",
	"ts": 1743543162553099.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.553000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "92c342bac0fb293c0561b105353d6690"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543162553886.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.555000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "9e853df4b9582e23d1900d0c48be9180"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543162555064.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.558000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "348be007cc9bb88301894e8c16f88198"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543162558598.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.559000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "1289b8b4bfb8a55cf021e22f5e9fce83"}
	{
	"name": "backend_compile",
	"ts": 1743543162559551.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.560000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "85c22892cd1089bb896a500ac343517e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543162560387.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.573000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "8edc1c0b338fc535a9ea62ed4e820af9"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['modified_input_ids'], accessed_by=DictGetItemGuardAccessor(modified_input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['modified_input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['modified_input_ids'], '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___5'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___5)
	| | | +- GuardManager: source=G['__builtins_dict___5']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___5']['print'], 138006094275872)
	
V0401 21:32:42.574000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "e5a7ee105670f1b8cc981b2fa094f6e8"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162574058.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.575000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "6dc53bffa21faee3e16cb2060b739346"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162574926.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.575000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "1/0", "frame_key": "2", "co_name": "torch_dynamo_resume_in_forward_refined_at_34", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 34, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 1, "graph_node_count": 3, "graph_input_count": 1, "start_time": 1743543162.5097492, "entire_frame_compile_time_s": 0.06422615051269531, "backend_compile_time_s": 0.03297758102416992, "inductor_compile_time_s": 0.009917974472045898, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.misc.StringFormatVariable'>] False"], "dynamo_time_before_restart_s": 0.006981849670410156, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.577000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}]}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.578000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0, "has_payload": "675995a8566c891d7d891755ab01d267"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162578291.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.579000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0, "has_payload": "3567a706787556b62c46a5e4ec2f32ee"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162578291.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.596000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "d6afa7fbf9f895260a5f28ba9845950a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['seq_length'], accessed_by=DictGetItemGuardAccessor(seq_length)
	| | +- EQUALS_MATCH: L['seq_length'] == 10                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___9'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___9)
	| | | +- GuardManager: source=G['__builtins_dict___9']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___9']['print'], 138006094275872)
	
V0401 21:32:42.597000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "6810dfb0f55079c4c67496a090bb855f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162597220.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.598000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "f66634b31e2bd331bb465bae945392b7"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162598109.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.599000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "2/0", "frame_key": "3", "co_name": "torch_dynamo_resume_in_forward_refined_at_35", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 35, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543162.5782816, "entire_frame_compile_time_s": 0.018863677978515625, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.constant.ConstantVariable'>] False"], "dynamo_time_before_restart_s": 0.0028808116912841797, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.600000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 36, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}]}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.601000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "8f368c01222f9773318ab6784807f513"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162601414.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.602000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "177a7b65422cff8e703a67da443970cf"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162601414.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.605000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 10, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.606000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d840c1cd2c0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.607000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 0, "source": "L['input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.663000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 11, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.663000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d840c1cd2c0>", "describer_id": 11}, "frame_id": 3, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.664000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 11, "id": 0, "source": "L['input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.673000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 12, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:32:42.674000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d840c1cd2c0>", "describer_id": 12}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:32:42.675000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 12, "id": 0, "source": "L['input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:32:42.683000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_input_ids_": [1, 10], "cpu": [1, 10], "input_ids_np": [1, 10]}}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "c74eb8f1fcfac94e6d35f9dd4236f6ca"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_input_ids_ = L_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:40 in torch_dynamo_resume_in_forward_refined_at_36, code: input_ids_np = input_ids.cpu().numpy()
	        cpu: "i64[1, 10][10, 1]cpu" = l_input_ids_.cpu();  l_input_ids_ = None
	        input_ids_np: "i64[1, 10][10, 1]cpu" = cpu.view_as(cpu);  cpu = None
	        return (input_ids_np,)
	        
V0401 21:32:42.684000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "fac1a00984307af5c14c733dbc6548e2"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543162684077.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.684000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "fd49e100988512cfc849dae8ef8d142f"}
	{
	"name": "backend_compile",
	"ts": 1743543162684077.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.687000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "5f96f1ca247583e6d7dda750f2c985ab"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543162687195.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.696000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "e6e59f19e0b541b9e36bef4b4d515d57"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:40 in torch_dynamo_resume_in_forward_refined_at_36, code: input_ids_np = input_ids.cpu().numpy()
	        view: "i64[1, 10][10, 1]cpu" = torch.ops.aten.view.default(arg0_1, [1, 10]);  arg0_1 = None
	        return (view,)
	        
V0401 21:32:42.697000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "94797556baf017f18a31cf82c0ce248a"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543162697326.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.699000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "3d4b167cb213237c1082af9291bc4edc"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543162699403.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.700000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "e1ea9375820b606dea1876082a6584c3"}
	{
	"name": "inductor_compile",
	"ts": 1743543162699403.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.701000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "0a0a155c8821a8a61d89aee17a9d27dc"}
	{
	"name": "inductor_compile",
	"ts": 1743543162701777.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.702000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "f251d563b473b1a67d1fd7b2cdcd72a6"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543162702493.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.703000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "77f8091cb3b399369eba174a4d5a46fb"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543162703923.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.707000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "e5e9cfc8f3bd240323e6b4da7f4b76fd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543162707094.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.707000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "7be456ce09e44ad35816bb1571f0b3a3"}
	{
	"name": "backend_compile",
	"ts": 1743543162707845.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.708000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "e73d3f2d509ac3d1e29d9a5ffca55468"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543162708639.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.714000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "d6c3e5e76e7fb141b784f4d05640a3c2"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False 
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['umap'], accessed_by=DictGetItemGuardAccessor(umap)
	| | | +- ID_MATCH: ___check_obj_id(G['umap'], 138005549456960)                 
	| | | +- GuardManager: source=G['umap'].UMAP, accessed_by=GetAttrGuardAccessor(UMAP)
	| | | | +- ID_MATCH: ___check_obj_id(G['umap'].UMAP, 111057029776464)            
	
V0401 21:32:42.714000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "122b0c6cef4642a5373859b5b7767b21"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162714665.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.715000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2, "has_payload": "c67c918b25b8993aa613fce08e868f24"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162715542.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.716000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "3/0", "frame_key": "4", "co_name": "torch_dynamo_resume_in_forward_refined_at_36", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 36, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 8, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543162.601405, "entire_frame_compile_time_s": 0.1131899356842041, "backend_compile_time_s": 0.023693561553955078, "inductor_compile_time_s": 0.0022974014282226562, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["'skip function check_array in file /home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py'", "Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.06812143325805664, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 3, "frame_compile_id": 0, "attempt": 2}
V0401 21:32:42.718000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", 4]}
V0401 21:32:42.719000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 2890, "name": "fit_transform", "filename": 4}]}, "frame_id": 4, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.720000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 0, "has_payload": "8fecd6311e482cd8d73e8f0536e4fb2d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162720124.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.721000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 0, "has_payload": "3dba39cf677bde44d045d9a99ea2b2dc"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162720124.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.741000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 15, "size": 80}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.742000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d0393c50>", "describer_id": 15}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.742000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 15, "id": 0, "source": "___from_numpy(L['X'])"}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.749000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1, "has_payload": "5044a903ec5846a71f643dfccb7c15fe"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=L['X'], accessed_by=DictGetItemGuardAccessor(X)
	| | +- GuardManager: source=___from_numpy(L['X']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['X']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['X']), '_dynamo_dynamic_indices') == False
	
V0401 21:32:42.750000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1, "has_payload": "717eee66bb535b9ab39d5ce2e01e86d2"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162750211.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.751000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1, "has_payload": "281123aaf35567e09add7faef24e7127"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162750952.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.751000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "4/0", "frame_key": "5", "co_name": "fit_transform", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2890, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543162.720114, "entire_frame_compile_time_s": 0.02987217903137207, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["'skip function check_array in file /home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py'"], "dynamo_time_before_restart_s": 0.01722240447998047, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 4, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.754000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2339, "name": "fit", "filename": 4}]}, "frame_id": 5, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.755000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 0, "has_payload": "19bc03b5d3bb71e371042ddc6f060918"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162755250.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.756000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 0, "has_payload": "6a65f7ddbc5a2c8308905c1b2e8b0b2d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162755250.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.789000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 17, "size": 80}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.790000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb64bb60>", "describer_id": 17}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.791000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 17, "id": 0, "source": "___from_numpy(L['X'])"}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.857000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1, "has_payload": "5cab2f54fecda06706a3002a96b765ba"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].metric, accessed_by=GetAttrGuardAccessor(metric)
	| | | +- EQUALS_MATCH: L['self'].metric == 'euclidean'                             
	| +- GuardManager: source=L['force_all_finite'], accessed_by=DictGetItemGuardAccessor(force_all_finite)
	| | +- ID_MATCH: ___check_obj_id(L['force_all_finite'], 111055818658720)     
	| +- GuardManager: source=L['X'], accessed_by=DictGetItemGuardAccessor(X)
	| | +- GuardManager: source=___from_numpy(L['X']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['X']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['X']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].float32, accessed_by=GetAttrGuardAccessor(float32)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].float32, 138005714233120)           
	| | +- GuardManager: source=G['check_array'], accessed_by=DictGetItemGuardAccessor(check_array)
	| | | +- ID_MATCH: ___check_obj_id(G['check_array'], 138005304660096)          
	
V0401 21:32:42.858000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1, "has_payload": "b249833ddd5d1d5c5edb009eab77d438"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162858075.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.859000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1, "has_payload": "aed9c278e9177c05b3bb914d5e39b014"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162859120.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.860000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "5/0", "frame_key": "6", "co_name": "fit", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2339, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543162.75524, "entire_frame_compile_time_s": 0.10275650024414062, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["'skip function check_array in file /home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py'"], "dynamo_time_before_restart_s": 0.015159368515014648, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 5, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.865000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/sparse/_base.py", 5]}
V0401 21:32:42.866000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 1335, "name": "issparse", "filename": 5}]}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.867000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "93caf278663ec29cdca8733502df8ac4"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162867366.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.868000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "ad535823034456408b45c39617a37492"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162867366.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.871000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 18, "size": 80}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.874000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb683570>", "describer_id": 18}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.876000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 18, "id": 0, "source": "___from_numpy(L['x'])"}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.879000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "1613bc4629f4d5dc7a82f1fb75a5dad3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162878996.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.879000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0, "has_payload": "9229195f5e71334ea7b848119a323396"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162879635.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.880000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "6/0", "frame_key": "15", "co_name": "issparse", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/sparse/_base.py", "co_firstlineno": 1335, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543162.867355, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.013129472732543945, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 6, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.886000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}]}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.887000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0, "has_payload": "fc9ab92685f01d378caf4b088f5627b1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543162887273.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.888000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0, "has_payload": "37a9bcc65dc7de48de7eaeb232154591"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543162887273.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:42.903000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 19, "size": 40}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.904000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6410e0>", "describer_id": 19}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.905000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 19, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 7, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:42.935000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 20, "size": 40}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.935000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb4fe30>", "describer_id": 20}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:42.936000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 20, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.070000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1, "has_payload": "445e553acf6fa63ae321689b24533c97"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].a, accessed_by=GetAttrGuardAccessor(a)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].a, 111055818751712)               
	| | +- GuardManager: source=L['self'].spread, accessed_by=GetAttrGuardAccessor(spread)
	| | | +- EQUALS_MATCH: L['self'].spread == 1.0                                     
	| | +- GuardManager: source=L['self'].min_dist, accessed_by=GetAttrGuardAccessor(min_dist)
	| | | +- EQUALS_MATCH: L['self'].min_dist == 0.1                                   
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['find_ab_params'], accessed_by=DictGetItemGuardAccessor(find_ab_params)
	| | | +- GuardManager: source=G['find_ab_params'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['find_ab_params'].__code__, 138005297130880)
	
V0401 21:32:43.071000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1, "has_payload": "e263c0d3a15b6c430e22cee904c4b2c3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163071646.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.072000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1, "has_payload": "974fea7ed2e8524f418b071279449db9"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163072517.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.073000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "7/0", "frame_key": "21", "co_name": "torch_dynamo_resume_in_fit_at_2372", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2372, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543162.887264, "entire_frame_compile_time_s": 0.18430280685424805, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.030104637145996094, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 7, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.075000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 1393, "name": "find_ab_params", "filename": 4}]}, "frame_id": 8, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.076000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 0, "has_payload": "d49df68a82180167d47aee231c8c1a3c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163075953.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.076000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 0, "has_payload": "5044169432d9b1c2d8694631819d5e3b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163075953.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.096000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"xv": [300], "yv": [300], "wrapped_lt": [300], "wrapped_ge": [300]}}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "55f47d9e0bf1af31c29501dfe1fba563"}
	class GraphModule(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1403 in find_ab_params, code: xv = np.linspace(0, spread * 3, 300)
	        xv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_linspace(0, 3.0, 300)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1404 in find_ab_params, code: yv = np.zeros(xv.shape)
	        yv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_zeros((300,))
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1405 in find_ab_params, code: yv[xv < min_dist] = 1.0
	        wrapped_lt: "b8[300][1]cpu" = torch__dynamo_utils_wrapped_lt(xv, 0.1)
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(yv, wrapped_lt, 1.0);  wrapped_lt = wrapped___setitem__ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in find_ab_params, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        wrapped_ge: "b8[300][1]cpu" = torch__dynamo_utils_wrapped_ge(xv, 0.1)
	        return (xv, wrapped_ge, yv)
	        
V0401 21:32:43.097000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "a89ec35a558b2a3e80db05c5cb419331"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163097587.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.098000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "51fef51e35db2e6a7b29142ac706437d"}
	{
	"name": "backend_compile",
	"ts": 1743543163097587.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.100000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "6ff29d86a20ef31990ee87268743c4e9"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163100404.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.143000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "884d6c6132cd21993a3f7096f47aa4c0"}
	class <lambda>(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1403 in find_ab_params, code: xv = np.linspace(0, spread * 3, 300)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "i64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        _tensor_constant1 = self._tensor_constant1
	        lift_fresh_copy_1: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None
	        convert_element_type: "f64[][]cpu" = torch.ops.prims.convert_element_type.default(lift_fresh_copy, torch.float64);  lift_fresh_copy = None
	        iota: "i64[300][1]cpu" = torch.ops.prims.iota.default(300, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)
	        sub: "f64[][]cpu" = torch.ops.aten.sub.Tensor(lift_fresh_copy_1, convert_element_type)
	        div: "f64[][]cpu" = torch.ops.aten.div.Tensor(sub, 299);  sub = None
	        lt: "b8[300][1]cpu" = torch.ops.aten.lt.Scalar(iota, 150.0)
	        convert_element_type_1: "f64[300][1]cpu" = torch.ops.prims.convert_element_type.default(iota, torch.float64)
	        mul: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(div, convert_element_type_1);  convert_element_type_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(convert_element_type, mul);  convert_element_type = mul = None
	        sub_1: "i64[300][1]cpu" = torch.ops.aten.sub.Tensor(299, iota);  iota = None
	        convert_element_type_2: "f64[300][1]cpu" = torch.ops.prims.convert_element_type.default(sub_1, torch.float64);  sub_1 = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(div, convert_element_type_2);  div = convert_element_type_2 = None
	        sub_2: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(lift_fresh_copy_1, mul_1);  lift_fresh_copy_1 = mul_1 = None
	        where: "f64[300][1]cpu" = torch.ops.aten.where.self(lt, add, sub_2);  lt = add = sub_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1404 in find_ab_params, code: yv = np.zeros(xv.shape)
	        full: "f64[300][1]cpu" = torch.ops.aten.full.default([300], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1405 in find_ab_params, code: yv[xv < min_dist] = 1.0
	        _tensor_constant2 = self._tensor_constant2
	        lift_fresh_copy_2: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant2);  _tensor_constant2 = None
	        lt_1: "b8[300][1]cpu" = torch.ops.aten.lt.Tensor(where, lift_fresh_copy_2);  lift_fresh_copy_2 = None
	        _tensor_constant3 = self._tensor_constant3
	        lift_fresh_copy_3: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant3);  _tensor_constant3 = None
	        index_put: "f64[300][1]cpu" = torch.ops.aten.index_put.default(full, [lt_1], lift_fresh_copy_3);  full = lt_1 = lift_fresh_copy_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in find_ab_params, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        _tensor_constant4 = self._tensor_constant4
	        lift_fresh_copy_4: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant4);  _tensor_constant4 = None
	        ge: "b8[300][1]cpu" = torch.ops.aten.ge.Tensor(where, lift_fresh_copy_4);  lift_fresh_copy_4 = None
	        return (where, ge, index_put)
	        
V0401 21:32:43.145000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "03ffbc7f732486a65cd97f1613d449d0"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163144737.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.153000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "94ec891ac362b4cef0215a8c2b808b19"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163152972.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.155000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "3ccd603dc4db847efd63850acf7cd6d1"}
	{
	"name": "inductor_compile",
	"ts": 1743543163152972.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.172000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/nt/cntbgzb2vnymycik6kg4ylecrpu5yugftj55begun2ly3v6e4hki.py"}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "7d18f30503b2495a7d180c4f4a95ff5c"}
	# AOT ID: ['3_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_ge_index_put_lift_fresh_linspace_zeros_0 = async_compile.cpp_pybinding(['double*', 'bool*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(double* out_ptr0,
	                       bool* out_ptr1,
	                       double* out_ptr2)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = at::vec::Vectorized<float>::arange(tmp1, 1);
	            auto tmp3 = static_cast<float>(150.0);
	            auto tmp4 = at::vec::Vectorized<float>(tmp3);
	            auto tmp5 = at::vec::VecMask<float,1>(tmp2 < tmp4);
	            auto tmp6 = static_cast<double>(0.010033444816053512);
	            auto tmp7 = c10::convert<double>(tmp0);
	            auto tmp8 = at::vec::VectorizedN<double,2>::arange(tmp7, 1);
	            auto tmp9 = at::vec::VectorizedN<double,2>(tmp6);
	            auto tmp10 = tmp9 * tmp8;
	            auto tmp11 = 299L + ((-1L)*x0);
	            auto tmp12 = c10::convert<double>(tmp11);
	            auto tmp13 = at::vec::VectorizedN<double,2>::arange(tmp12, -1);
	            auto tmp14 = tmp9 * tmp13;
	            auto tmp15 = static_cast<double>(3.0);
	            auto tmp16 = at::vec::VectorizedN<double,2>(tmp15);
	            auto tmp17 = tmp16 - tmp14;
	            auto tmp18 = decltype(tmp10)::blendv(tmp17, tmp10, tmp5.template cast<double,2>());
	            tmp18.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = static_cast<float>(150.0);
	            auto tmp3 = tmp1 < tmp2;
	            auto tmp4 = static_cast<double>(0.010033444816053512);
	            auto tmp5 = c10::convert<double>(tmp0);
	            auto tmp6 = decltype(tmp4)(tmp4 * tmp5);
	            auto tmp7 = 299L + ((-1L)*x0);
	            auto tmp8 = c10::convert<double>(tmp7);
	            auto tmp9 = decltype(tmp4)(tmp4 * tmp8);
	            auto tmp10 = static_cast<double>(3.0);
	            auto tmp11 = decltype(tmp10)(tmp10 - tmp9);
	            auto tmp12 = tmp3 ? tmp6 : tmp11;
	            out_ptr0[static_cast<int64_t>(x0)] = tmp12;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = at::vec::Vectorized<float>::arange(tmp1, 1);
	            auto tmp3 = static_cast<float>(150.0);
	            auto tmp4 = at::vec::Vectorized<float>(tmp3);
	            auto tmp5 = at::vec::VecMask<float,1>(tmp2 < tmp4);
	            auto tmp6 = static_cast<double>(0.010033444816053512);
	            auto tmp7 = c10::convert<double>(tmp0);
	            auto tmp8 = at::vec::VectorizedN<double,2>::arange(tmp7, 1);
	            auto tmp9 = at::vec::VectorizedN<double,2>(tmp6);
	            auto tmp10 = tmp9 * tmp8;
	            auto tmp11 = 299L + ((-1L)*x0);
	            auto tmp12 = c10::convert<double>(tmp11);
	            auto tmp13 = at::vec::VectorizedN<double,2>::arange(tmp12, -1);
	            auto tmp14 = tmp9 * tmp13;
	            auto tmp15 = static_cast<double>(3.0);
	            auto tmp16 = at::vec::VectorizedN<double,2>(tmp15);
	            auto tmp17 = tmp16 - tmp14;
	            auto tmp18 = decltype(tmp10)::blendv(tmp17, tmp10, tmp5.template cast<double,2>());
	            auto tmp19 = static_cast<double>(0.1);
	            auto tmp20 = at::vec::VectorizedN<double,2>(tmp19);
	            auto tmp21 = at::vec::VecMask<double,2>(tmp18 >= tmp20);
	            tmp21.store(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = static_cast<float>(150.0);
	            auto tmp3 = tmp1 < tmp2;
	            auto tmp4 = static_cast<double>(0.010033444816053512);
	            auto tmp5 = c10::convert<double>(tmp0);
	            auto tmp6 = decltype(tmp4)(tmp4 * tmp5);
	            auto tmp7 = 299L + ((-1L)*x0);
	            auto tmp8 = c10::convert<double>(tmp7);
	            auto tmp9 = decltype(tmp4)(tmp4 * tmp8);
	            auto tmp10 = static_cast<double>(3.0);
	            auto tmp11 = decltype(tmp10)(tmp10 - tmp9);
	            auto tmp12 = tmp3 ? tmp6 : tmp11;
	            auto tmp13 = static_cast<double>(0.1);
	            auto tmp14 = tmp12 >= tmp13;
	            out_ptr1[static_cast<int64_t>(x0)] = tmp14;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = at::vec::Vectorized<float>::arange(tmp1, 1);
	            auto tmp3 = static_cast<float>(150.0);
	            auto tmp4 = at::vec::Vectorized<float>(tmp3);
	            auto tmp5 = at::vec::VecMask<float,1>(tmp2 < tmp4);
	            auto tmp6 = static_cast<double>(0.010033444816053512);
	            auto tmp7 = c10::convert<double>(tmp0);
	            auto tmp8 = at::vec::VectorizedN<double,2>::arange(tmp7, 1);
	            auto tmp9 = at::vec::VectorizedN<double,2>(tmp6);
	            auto tmp10 = tmp9 * tmp8;
	            auto tmp11 = 299L + ((-1L)*x0);
	            auto tmp12 = c10::convert<double>(tmp11);
	            auto tmp13 = at::vec::VectorizedN<double,2>::arange(tmp12, -1);
	            auto tmp14 = tmp9 * tmp13;
	            auto tmp15 = static_cast<double>(3.0);
	            auto tmp16 = at::vec::VectorizedN<double,2>(tmp15);
	            auto tmp17 = tmp16 - tmp14;
	            auto tmp18 = decltype(tmp10)::blendv(tmp17, tmp10, tmp5.template cast<double,2>());
	            auto tmp19 = static_cast<double>(0.1);
	            auto tmp20 = at::vec::VectorizedN<double,2>(tmp19);
	            auto tmp21 = at::vec::VecMask<double,2>(tmp18 < tmp20);
	            auto tmp22 = static_cast<double>(1.0);
	            auto tmp23 = static_cast<double>(0.0);
	            auto tmp24 = at::vec::VectorizedN<double,2>(tmp22);
	            auto tmp25 = at::vec::VectorizedN<double,2>(tmp23);
	            auto tmp26 = decltype(tmp24)::blendv(tmp25, tmp24, tmp21.template cast<double,2>());
	            tmp26.store(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = x0;
	            auto tmp1 = c10::convert<float>(tmp0);
	            auto tmp2 = static_cast<float>(150.0);
	            auto tmp3 = tmp1 < tmp2;
	            auto tmp4 = static_cast<double>(0.010033444816053512);
	            auto tmp5 = c10::convert<double>(tmp0);
	            auto tmp6 = decltype(tmp4)(tmp4 * tmp5);
	            auto tmp7 = 299L + ((-1L)*x0);
	            auto tmp8 = c10::convert<double>(tmp7);
	            auto tmp9 = decltype(tmp4)(tmp4 * tmp8);
	            auto tmp10 = static_cast<double>(3.0);
	            auto tmp11 = decltype(tmp10)(tmp10 - tmp9);
	            auto tmp12 = tmp3 ? tmp6 : tmp11;
	            auto tmp13 = static_cast<double>(0.1);
	            auto tmp14 = tmp12 < tmp13;
	            auto tmp15 = static_cast<double>(1.0);
	            auto tmp16 = static_cast<double>(0.0);
	            auto tmp17 = tmp14 ? tmp15 : tmp16;
	            out_ptr2[static_cast<int64_t>(x0)] = tmp17;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    buf0 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((300, ), (1, ), torch.bool)
	    buf2 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_ge_index_put_lift_fresh_linspace_zeros_0(buf0, buf1, buf2)
	    return (buf0, buf1, buf2, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    fn = lambda: call([])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:43.174000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "133cc00da4ed1998b990542e0647573c"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543163173595.0,
	"args": {
	"key": "fzl5qjtrd5cithub2slqbdncrkoutl6amq6o3cvtjbteozwxhueh",
	"components": [
	"[tonr2mrgdlu2nen3ozhu3ijdxmfcg2rjrzqzmvblwymuszvx3sd] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = lift_fresh_copy = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default = torch.ops.aten.full.default([], 3.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False);  full_default_1 = None\n    iota = torch.ops.prims.iota.default(300, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    full_default_2 = torch.ops.aten.full.default([], 0.010033444816053512, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Scalar(iota, 150.0)\n    convert_element_type_1 = torch.ops.prims.convert_element_type.default(iota, torch.float64)\n    mul = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_1);  convert_element_type_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(299, iota);  iota = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(sub_1, torch.float64);  sub_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_2);  full_default_2 = convert_element_type_2 = None\n    sub_2 = torch.ops.aten.sub.Tensor(full_default, mul_1);  full_default = mul_1 = None\n    where = torch.ops.aten.where.self(lt, mul, sub_2);  lt = mul = sub_2 = None\n    full_default_3 = torch.ops.aten.full.default([300], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    _tensor_constant2 = self._tensor_constant2;  _tensor_constant2 = None\n    full_default_4 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt_1 = torch.ops.aten.lt.Tensor(where, full_default_4);  full_default_4 = None\n    _tensor_constant3 = self._tensor_constant3;  _tensor_constant3 = None\n    full_default_5 = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    index_put = torch.ops.aten.index_put.default(full_default_3, [lt_1], full_default_5);  full_default_3 = lt_1 = full_default_5 = None\n    _tensor_constant4 = self._tensor_constant4;  _tensor_constant4 = None\n    full_default_6 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(where, full_default_6);  full_default_6 = None\n    return (where, ge, index_put)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[4pgrl5wuvi6oqmjehmimwaduhxq6rrasw6f65kiwgepz2acoxp2] fx_kwargs[user_visible_outputs]: {'where': None, 'ge': None, 'index_put': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 3291860166,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:43.175000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "ec3523ba2c99e5b67ac979a96345da4f"}
	{"key": "fzl5qjtrd5cithub2slqbdncrkoutl6amq6o3cvtjbteozwxhueh", "components": ["[tonr2mrgdlu2nen3ozhu3ijdxmfcg2rjrzqzmvblwymuszvx3sd] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = lift_fresh_copy = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default = torch.ops.aten.full.default([], 3.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False);  full_default_1 = None\n    iota = torch.ops.prims.iota.default(300, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    full_default_2 = torch.ops.aten.full.default([], 0.010033444816053512, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Scalar(iota, 150.0)\n    convert_element_type_1 = torch.ops.prims.convert_element_type.default(iota, torch.float64)\n    mul = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_1);  convert_element_type_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(299, iota);  iota = None\n    convert_element_type_2 = torch.ops.prims.convert_element_type.default(sub_1, torch.float64);  sub_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(full_default_2, convert_element_type_2);  full_default_2 = convert_element_type_2 = None\n    sub_2 = torch.ops.aten.sub.Tensor(full_default, mul_1);  full_default = mul_1 = None\n    where = torch.ops.aten.where.self(lt, mul, sub_2);  lt = mul = sub_2 = None\n    full_default_3 = torch.ops.aten.full.default([300], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    _tensor_constant2 = self._tensor_constant2;  _tensor_constant2 = None\n    full_default_4 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt_1 = torch.ops.aten.lt.Tensor(where, full_default_4);  full_default_4 = None\n    _tensor_constant3 = self._tensor_constant3;  _tensor_constant3 = None\n    full_default_5 = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    index_put = torch.ops.aten.index_put.default(full_default_3, [lt_1], full_default_5);  full_default_3 = lt_1 = full_default_5 = None\n    _tensor_constant4 = self._tensor_constant4;  _tensor_constant4 = None\n    full_default_6 = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(where, full_default_6);  full_default_6 = None\n    return (where, ge, index_put)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[4pgrl5wuvi6oqmjehmimwaduhxq6rrasw6f65kiwgepz2acoxp2] fx_kwargs[user_visible_outputs]: {'where': None, 'ge': None, 'index_put': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 3291860166, "cache_state": "hit"}
V0401 21:32:43.176000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "3e55ff5ac646cf04386609f3e302bcf7"}
	{
	"name": "inductor_compile",
	"ts": 1743543163176760.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.179000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "af4d99742c3e015e4cd3a0686d40d3ae"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163179178.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.182000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "fd46dd7299f3e1f2cdac1251a4a2e888"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163182632.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.187000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "908038e957198141fc7e4e94cac33688"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163187262.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.188000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "8ac927ae375c08e0880df214a5b9ee59"}
	{
	"name": "backend_compile",
	"ts": 1743543163188424.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.189000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "07480b6582920354cc82139d85c2740b"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163189321.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.199000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "f3c154e9cb794dd820e7d2c7f336ae7d"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['spread'], accessed_by=DictGetItemGuardAccessor(spread)
	| | +- EQUALS_MATCH: L['spread'] == 1.0                                          
	| +- GuardManager: source=L['min_dist'], accessed_by=DictGetItemGuardAccessor(min_dist)
	| | +- EQUALS_MATCH: L['min_dist'] == 0.1                                        
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].exp, accessed_by=GetAttrGuardAccessor(exp)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].exp, 138006087262272)               
	| | | +- GuardManager: source=G['np'].zeros, accessed_by=GetAttrGuardAccessor(zeros)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].zeros, 138006086610480)             
	| | | +- GuardManager: source=G['np'].linspace, accessed_by=GetAttrGuardAccessor(linspace)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].linspace, 138005631360304)          
	
V0401 21:32:43.200000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "db635d4147316951fb4c88cb9c35c6bf"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163200514.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.201000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1, "has_payload": "8c73e043b68454050aef181e420d7525"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163201363.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.202000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "8/0", "frame_key": "22", "co_name": "find_ab_params", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1393, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 6, "graph_input_count": 0, "start_time": 1743543163.075943, "entire_frame_compile_time_s": 0.12449383735656738, "backend_compile_time_s": 0.0907752513885498, "inductor_compile_time_s": 0.02370905876159668, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.009740352630615234, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 8, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.206000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}]}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.212000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0, "has_payload": "cef2959adf4f9f17901dbf1c74bd16cc"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163212720.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.214000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0, "has_payload": "9b76f8552c21523f0aacb04cb0e1fba3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163212720.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.219000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 24, "size": 2320}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.221000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [290], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbaafd0>", "describer_id": 24}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.224000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 24, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.239000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 24, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.241000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbc87d0>", "describer_id": 24}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.245000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 24, "id": 5, "source": "___from_numpy(L['xv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.252000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 24, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.256000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbc8e10>", "describer_id": 24}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.261000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 24, "id": 8, "source": "___from_numpy(L['yv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.348000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 25, "size": 2320}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.349000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [290], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb1770>", "describer_id": 25}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.351000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 25, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.356000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 25, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.358000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbc8d70>", "describer_id": 25}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.360000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 25, "id": 1, "source": "___from_numpy(L['xv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.365000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 25, "size": 2400}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.366000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb0dc0>", "describer_id": 25}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.369000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 25, "id": 4, "source": "___from_numpy(L['yv'])"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.377000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack1_": [290], "l_xv_": [300], "l_yv_": [300], "wrapped_sub": [290], "wrapped_neg": [290], "wrapped_truediv": [290], "wrapped_exp": [290], "wrapped_ge": [300]}}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "c480bb8f9ce479ebbca554f41be8f641"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack1_: "f64[290][1]cpu", L_xv_: "f64[300][1]cpu", L_yv_: "f64[300][1]cpu"):
	        l_stack1_ = L_stack1_
	        l_xv_ = L_xv_
	        l_yv_ = L_yv_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in torch_dynamo_resume_in_find_ab_params_at_1406, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        wrapped_sub: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_sub(l_stack1_, 0.1);  l_stack1_ = None
	        wrapped_neg: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_neg(wrapped_sub);  wrapped_sub = None
	        wrapped_truediv: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_truediv(wrapped_neg, 1.0);  wrapped_neg = None
	        wrapped_exp: "f64[290][1]cpu" = torch__dynamo_utils_wrapped_exp(wrapped_truediv);  wrapped_truediv = None
	        wrapped_ge: "b8[300][1]cpu" = torch__dynamo_utils_wrapped_ge(l_xv_, 0.1);  l_xv_ = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_yv_, wrapped_ge, wrapped_exp);  l_yv_ = wrapped_ge = wrapped_exp = wrapped___setitem__ = None
	        return ()
	        
V0401 21:32:43.378000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "61edb8813ebd56d6e793ff46b6736f9d"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163378222.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.378000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "0684a2da352ba4311e715eb107709191"}
	{
	"name": "backend_compile",
	"ts": 1743543163378222.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.382000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "bac3cc483a649e62faa645e62ebbf223"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163382238.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.414000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "9fb4be2f26b589c77f4084b871f6897a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[290][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[300][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1406 in torch_dynamo_resume_in_find_ab_params_at_1406, code: yv[xv >= min_dist] = np.exp(-(xv[xv >= min_dist] - min_dist) / spread)
	        sub: "f64[290][1]cpu" = torch.ops.aten.sub.Tensor(arg0_1, 0.1);  arg0_1 = None
	        neg: "f64[290][1]cpu" = torch.ops.aten.neg.default(sub);  sub = None
	        div: "f64[290][1]cpu" = torch.ops.aten.div.Tensor(neg, 1.0);  neg = None
	        exp: "f64[290][1]cpu" = torch.ops.aten.exp.default(div);  div = None
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        ge: "b8[300][1]cpu" = torch.ops.aten.ge.Tensor(arg1_1, lift_fresh_copy);  arg1_1 = lift_fresh_copy = None
	        index_put: "f64[300][1]cpu" = torch.ops.aten.index_put.default(arg2_1, [ge], exp);  ge = exp = None
	        copy_: "f64[300][1]cpu" = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None
	        return ()
	        
V0401 21:32:43.415000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "ddd62c2aaceeb91a1db6b7f74649f50b"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163415488.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.420000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "b9d2706b72d446f7392c294f07f231af"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163420132.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.421000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "bd60852805f1be3ff5870576a2052bad"}
	{
	"name": "inductor_compile",
	"ts": 1743543163420132.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.432000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/dk/cdk6qhze7a7o4zdrvtlr5ny5lhfq4ej3ylypq7rudzh2emcmthg2.py"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "4aa7b9ddca4abb04bcd64a9ecd07eed1"}
	# AOT ID: ['4_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_div_exp_ge_lift_fresh_neg_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'double*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       double* out_ptr0,
	                       bool* out_ptr1)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(288L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::VectorizedN<double,2>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = at::vec::VectorizedN<double,2>(tmp1);
	            auto tmp3 = tmp0 - tmp2;
	            auto tmp4 = tmp3.neg();
	            auto tmp5 = static_cast<double>(1.0);
	            auto tmp6 = at::vec::VectorizedN<double,2>(tmp5);
	            auto tmp7 = tmp4 * tmp6;
	            auto tmp8 = tmp7.exp();
	            tmp8.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(288L); x0<static_cast<int64_t>(290L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = decltype(tmp0)(tmp0 - tmp1);
	            auto tmp3 = decltype(tmp2)(-tmp2);
	            auto tmp4 = static_cast<double>(1.0);
	            auto tmp5 = decltype(tmp3)(tmp3 * tmp4);
	            auto tmp6 = std::exp(tmp5);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp6;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = at::vec::VectorizedN<double,2>(tmp1);
	            auto tmp3 = at::vec::VecMask<double,2>(tmp0 >= tmp2);
	            tmp3.store(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = static_cast<double>(0.1);
	            auto tmp2 = tmp0 >= tmp1;
	            out_ptr1[static_cast<int64_t>(x0)] = tmp2;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (290, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (300, ), (1, ))
	    buf0 = empty_strided_cpu((290, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((300, ), (1, ), torch.bool)
	    cpp_fused_div_exp_ge_lift_fresh_neg_sub_0(arg0_1, arg1_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    aten.index_put_(arg2_1, [buf1], buf0, False)
	    del arg2_1
	    return ()
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((290, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:43.433000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "3443d95c2563e9f46a8a8688c81a0590"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543163432810.2,
	"args": {
	"key": "fcxeq3o3h62scxy65dfbtk4okqddemndlldvrlhugjurxh2kuiqa",
	"components": [
	"[jfat3osakyvxfe2j5x7i25ax7olumljfj3r2xjzwijgqcmz3fql] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    sub = torch.ops.aten.sub.Tensor(arg0_1, 0.1);  arg0_1 = None\n    neg = torch.ops.aten.neg.default(sub);  sub = None\n    div = torch.ops.aten.div.Tensor(neg, 1.0);  neg = None\n    exp = torch.ops.aten.exp.default(div);  div = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [ge], exp);  ge = exp = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qq3r6iutttyrup346b5hoj3iunplzowinx4le3dezhua3jyjejs] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([290]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2333674778,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:43.434000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "2e09640378612dd3288af906c8c47102"}
	{"key": "fcxeq3o3h62scxy65dfbtk4okqddemndlldvrlhugjurxh2kuiqa", "components": ["[jfat3osakyvxfe2j5x7i25ax7olumljfj3r2xjzwijgqcmz3fql] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    sub = torch.ops.aten.sub.Tensor(arg0_1, 0.1);  arg0_1 = None\n    neg = torch.ops.aten.neg.default(sub);  sub = None\n    div = torch.ops.aten.div.Tensor(neg, 1.0);  neg = None\n    exp = torch.ops.aten.exp.default(div);  div = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 0.1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    ge = torch.ops.aten.ge.Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [ge], exp);  ge = exp = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qq3r6iutttyrup346b5hoj3iunplzowinx4le3dezhua3jyjejs] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([290]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2333674778, "cache_state": "hit"}
V0401 21:32:43.435000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "980a0861bfd72b8939a5a7109d592924"}
	{
	"name": "inductor_compile",
	"ts": 1743543163435164.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.436000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "325eb4cdbed73f94b631c547514f8d2e"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163436114.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.437000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "40d8fbe8aa62c96d7e792b14ebfd1fc3"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163437593.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.442000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "6b2578b41786bc8df50651b69150c5da"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163442382.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.443000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "e3f9226356df5818bfbf8bfbdda0a0a8"}
	{
	"name": "backend_compile",
	"ts": 1743543163443247.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.444000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "b6ff5d9f7536e77f01817753d856e11b"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163444000.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.455000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "1cebec1e30aeeeb719725a36ca63fd58"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['curve'], accessed_by=DictGetItemGuardAccessor(curve)
	| | +- GuardManager: source=L['curve'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['curve'].__code__, 138005303065888)       
	| +- GuardManager: source=L['spread'], accessed_by=DictGetItemGuardAccessor(spread)
	| | +- EQUALS_MATCH: L['spread'] == 1.0                                          
	| +- GuardManager: source=L['min_dist'], accessed_by=DictGetItemGuardAccessor(min_dist)
	| | +- EQUALS_MATCH: L['min_dist'] == 0.1                                        
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- ID_MATCH: ___check_obj_id(L['___stack0'], 138006087262272)            
	| +- GuardManager: source=L['xv'], accessed_by=DictGetItemGuardAccessor(xv)
	| | +- GuardManager: source=___from_numpy(L['xv']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['xv']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['xv']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['xv']), ___from_numpy(L['yv']), ___from_numpy(L['___stack1']))
	| +- GuardManager: source=L['yv'], accessed_by=DictGetItemGuardAccessor(yv)
	| | +- GuardManager: source=___from_numpy(L['yv']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['yv']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['yv']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack1'], accessed_by=DictGetItemGuardAccessor(___stack1)
	| | +- GuardManager: source=___from_numpy(L['___stack1']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack1']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[290], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack1']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['curve_fit'], accessed_by=DictGetItemGuardAccessor(curve_fit)
	| | | +- GuardManager: source=G['curve_fit'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['curve_fit'].__code__, 111056999998384)   
	
V0401 21:32:43.456000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "fc279c39f5f1db303625d109450298e6"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163456570.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.457000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1, "has_payload": "a47c71ef8c734fb6919320711f4cf7a2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163457401.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 4,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.458000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "9/0", "frame_key": "23", "co_name": "torch_dynamo_resume_in_find_ab_params_at_1406", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1406, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 6, "graph_node_count": 10, "graph_input_count": 3, "start_time": 1743543163.2127094, "entire_frame_compile_time_s": 0.243757963180542, "backend_compile_time_s": 0.06494402885437012, "inductor_compile_time_s": 0.01494908332824707, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.1304936408996582, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 9, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.462000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", 6]}
V0401 21:32:43.464000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}]}, "frame_id": 10, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.466000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 0, "has_payload": "fb34eb99a2504614e7346ef0b8dc8500"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163465996.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.467000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 0, "has_payload": "5527b3e14b9d999b9339abb954e50004"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163465996.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.546000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"lb": [], "ub": [], "lb_1": [2], "ub_1": [2]}}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "57c6f8d6d473053f1f45eeb955eff7cf"}
	class GraphModule(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:96 in <genexpr>, code: lb, ub = (np.asarray(b, dtype=float) for b in bounds)
	        lb: "f64[][]cpu" = torch__dynamo_utils_wrapped_asarray(-inf, dtype = torch.float64)
	        ub: "f64[][]cpu" = torch__dynamo_utils_wrapped_asarray_1(inf, dtype = torch.float64)
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:98 in prepare_bounds, code: lb = np.resize(lb, n)
	        lb_1: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_resize(lb, 2);  lb = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:101 in prepare_bounds, code: ub = np.resize(ub, n)
	        ub_1: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_resize_1(ub, 2);  ub = None
	        return (lb_1, ub_1)
	        
V0401 21:32:43.547000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "aa654140a8f03ca4eb9610e52d980d21"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163547755.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.548000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "cceb4d178959af51c6f9400b2b69d3bd"}
	{
	"name": "backend_compile",
	"ts": 1743543163547755.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.551000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "c29b3189f69b2a4549875e3ff183af4f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163551009.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.589000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "4514077c742f514dd686e077a8cc0bc2"}
	class <lambda>(torch.nn.Module):
	    def forward(self):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:96 in <genexpr>, code: lb, ub = (np.asarray(b, dtype=float) for b in bounds)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        _tensor_constant1 = self._tensor_constant1
	        lift_fresh_copy_1: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:98 in prepare_bounds, code: lb = np.resize(lb, n)
	        view: "f64[1][1]cpu" = torch.ops.aten.view.default(lift_fresh_copy, [1]);  lift_fresh_copy = None
	        unsqueeze: "f64[1, 1][1, 1]cpu" = torch.ops.aten.unsqueeze.default(view, 0);  view = None
	        expand: "f64[2, 1][0, 1]cpu" = torch.ops.aten.expand.default(unsqueeze, [2, 1]);  unsqueeze = None
	        view_1: "f64[2][0]cpu" = torch.ops.aten.view.default(expand, [2]);  expand = None
	        clone: "f64[2][1]cpu" = torch.ops.aten.clone.default(view_1);  view_1 = None
	        slice_1: "f64[2][1]cpu" = torch.ops.aten.slice.Tensor(clone, 0, 0, 2);  clone = None
	        view_2: "f64[2][1]cpu" = torch.ops.aten.view.default(slice_1, [2]);  slice_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:101 in prepare_bounds, code: ub = np.resize(ub, n)
	        view_3: "f64[1][1]cpu" = torch.ops.aten.view.default(lift_fresh_copy_1, [1]);  lift_fresh_copy_1 = None
	        unsqueeze_1: "f64[1, 1][1, 1]cpu" = torch.ops.aten.unsqueeze.default(view_3, 0);  view_3 = None
	        expand_1: "f64[2, 1][0, 1]cpu" = torch.ops.aten.expand.default(unsqueeze_1, [2, 1]);  unsqueeze_1 = None
	        view_4: "f64[2][0]cpu" = torch.ops.aten.view.default(expand_1, [2]);  expand_1 = None
	        clone_1: "f64[2][1]cpu" = torch.ops.aten.clone.default(view_4);  view_4 = None
	        slice_2: "f64[2][1]cpu" = torch.ops.aten.slice.Tensor(clone_1, 0, 0, 2);  clone_1 = None
	        view_5: "f64[2][1]cpu" = torch.ops.aten.view.default(slice_2, [2]);  slice_2 = None
	        return (view_2, view_5)
	        
V0401 21:32:43.592000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "41feb6e95f8b00624fdb005aeddb42f0"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163591602.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.603000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "03534e767e366c5b11fa8477045346b5"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163603769.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.604000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "9c9f0fa9b56d88706ac94af9533c2320"}
	{
	"name": "inductor_compile",
	"ts": 1743543163603769.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.620000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/w6/cw6dvybjoz7oh5jzk4lyo53ayla553pspwnbqjj4yutick4ynisd.py"}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "e57f6428b7c389fc295cca8e4a49aab5"}
	# AOT ID: ['5_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_view_0 = async_compile.cpp_pybinding(['double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(double* out_ptr0,
	                       double* out_ptr1)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = -std::numeric_limits<double>::infinity();
	            out_ptr0[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = std::numeric_limits<double>::infinity();
	            out_ptr1[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    buf0 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    cpp_fused_view_0(buf0, buf1)
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    fn = lambda: call([])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:43.622000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "dbbc3bda3439c9e7153923569f23a6f0"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543163621581.2,
	"args": {
	"key": "fhgsqgiwm5fsnbokv5jaauvp2u4eql3h2ryzytobatsr3zy5hbms",
	"components": [
	"[iulospdvxfqvq5rzqfkbh3qtwwdxweattfoljia6z3k7fcbqcoy] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None\n    _tensor_constant1 = self._tensor_constant1\n    lift_fresh_copy_1 = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None\n    view = torch.ops.aten.view.default(lift_fresh_copy, [1]);  lift_fresh_copy = None\n    unsqueeze = torch.ops.aten.unsqueeze.default(view, 0);  view = None\n    expand = torch.ops.aten.expand.default(unsqueeze, [2, 1]);  unsqueeze = None\n    view_1 = torch.ops.aten.view.default(expand, [2]);  expand = None\n    clone = torch.ops.aten.clone.default(view_1);  view_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(clone, 0, 0, 2);  clone = slice_1 = None\n    full_default = torch.ops.aten.full.default([2], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view_3 = torch.ops.aten.view.default(lift_fresh_copy_1, [1]);  lift_fresh_copy_1 = None\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(view_3, 0);  view_3 = None\n    expand_1 = torch.ops.aten.expand.default(unsqueeze_1, [2, 1]);  unsqueeze_1 = None\n    view_4 = torch.ops.aten.view.default(expand_1, [2]);  expand_1 = None\n    clone_1 = torch.ops.aten.clone.default(view_4);  view_4 = None\n    slice_2 = torch.ops.aten.slice.Tensor(clone_1, 0, 0, 2);  clone_1 = slice_2 = None\n    full_default_1 = torch.ops.aten.full.default([2], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default, full_default_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[dh7igrumoyh7k2z5flvfaxkyxysjutfv6p5suaedvvarlzceiin] fx_kwargs[user_visible_outputs]: {'full_default': None, 'full_default_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2074643546,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:43.623000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "e54a2fc48331b19f377736ca38f47466"}
	{"key": "fhgsqgiwm5fsnbokv5jaauvp2u4eql3h2ryzytobatsr3zy5hbms", "components": ["[iulospdvxfqvq5rzqfkbh3qtwwdxweattfoljia6z3k7fcbqcoy] gm: <lambda>()\n\n\n\ndef forward(self):\n    _tensor_constant0 = self._tensor_constant0\n    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None\n    _tensor_constant1 = self._tensor_constant1\n    lift_fresh_copy_1 = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None\n    view = torch.ops.aten.view.default(lift_fresh_copy, [1]);  lift_fresh_copy = None\n    unsqueeze = torch.ops.aten.unsqueeze.default(view, 0);  view = None\n    expand = torch.ops.aten.expand.default(unsqueeze, [2, 1]);  unsqueeze = None\n    view_1 = torch.ops.aten.view.default(expand, [2]);  expand = None\n    clone = torch.ops.aten.clone.default(view_1);  view_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(clone, 0, 0, 2);  clone = slice_1 = None\n    full_default = torch.ops.aten.full.default([2], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view_3 = torch.ops.aten.view.default(lift_fresh_copy_1, [1]);  lift_fresh_copy_1 = None\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(view_3, 0);  view_3 = None\n    expand_1 = torch.ops.aten.expand.default(unsqueeze_1, [2, 1]);  unsqueeze_1 = None\n    view_4 = torch.ops.aten.view.default(expand_1, [2]);  expand_1 = None\n    clone_1 = torch.ops.aten.clone.default(view_4);  view_4 = None\n    slice_2 = torch.ops.aten.slice.Tensor(clone_1, 0, 0, 2);  clone_1 = slice_2 = None\n    full_default_1 = torch.ops.aten.full.default([2], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default, full_default_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[dh7igrumoyh7k2z5flvfaxkyxysjutfv6p5suaedvvarlzceiin] fx_kwargs[user_visible_outputs]: {'full_default': None, 'full_default_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2074643546, "cache_state": "hit"}
V0401 21:32:43.624000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "42a95ecd7c91e8f2bda6edecdbf518b6"}
	{
	"name": "inductor_compile",
	"ts": 1743543163624242.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.625000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "6bd6cb9764cbf9585e10c17c797b307c"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163625084.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.626000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "e6448bf4b72478f014426111ff6ecbff"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163626636.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.631000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "ee0707f506940c467a8d4e711ea45fa8"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163631264.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.633000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "41d79fef74a7fdb7c51cc5eaa5971d14"}
	{
	"name": "backend_compile",
	"ts": 1743543163633146.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.634000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "7ac3d78d748f4e578b63e3741a24623a"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163633987.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.673000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "25e500a77e52f9805abc86401dc70544"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 138005303065888)           
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- ID_MATCH: ___check_obj_id(L['p0'], 111055818751712)                   
	| +- GuardManager: source=L['bounds'], accessed_by=DictGetItemGuardAccessor(bounds)
	| | +- TYPE_MATCH: ___check_type_id(L['bounds'], 111055818760256)              
	| | +- LENGTH_CHECK: len(L['bounds']) == 2                                       
	| | +- GuardManager: source=L['bounds'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- EQUALS_MATCH: L['bounds'][0] == -inf                                      
	| | +- GuardManager: source=L['bounds'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- EQUALS_MATCH: L['bounds'][1] == inf                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['Bounds'], accessed_by=DictGetItemGuardAccessor(Bounds)
	| | | +- ID_MATCH: ___check_obj_id(G['Bounds'], 111056999806864)               
	| | +- GuardManager: source=G['prepare_bounds'], accessed_by=DictGetItemGuardAccessor(prepare_bounds)
	| | | +- GuardManager: source=G['prepare_bounds'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['prepare_bounds'].__code__, 138005367259184)
	| | +- GuardManager: source=G['_getfullargspec'], accessed_by=DictGetItemGuardAccessor(_getfullargspec)
	| | | +- GuardManager: source=G['_getfullargspec'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_getfullargspec'].__code__, 111056994540560)
	| | +- GuardManager: source=G['_initialize_feasible'], accessed_by=DictGetItemGuardAccessor(_initialize_feasible)
	| | | +- GuardManager: source=G['_initialize_feasible'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_initialize_feasible'].__code__, 138005371861936)
	| | +- GuardManager: source=G['__builtins_dict___34'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___34)
	| | | +- GuardManager: source=G['__builtins_dict___34']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['len'], 138006094275152)
	| | | +- GuardManager: source=G['__builtins_dict___34']['float'], accessed_by=DictGetItemGuardAccessor(float)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['float'], 111055818722080)
	| | | +- GuardManager: source=G['__builtins_dict___34']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['tuple'], 111055818760256)
	| | | +- GuardManager: source=G['__builtins_dict___34']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___34']['isinstance'], 138006094274832)
	| | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'], accessed_by=DictGetItemGuardAccessor(__import_scipy_dot__lib_dot__util)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'], 138005515064544)
	| | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect, accessed_by=GetAttrGuardAccessor(inspect)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].inspect, 138006093226336)
	| | | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect.Parameter, accessed_by=GetAttrGuardAccessor(Parameter)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].inspect.Parameter, 111056891703728)
	| | | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect.signature, accessed_by=GetAttrGuardAccessor(signature)
	| | | | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].inspect.signature.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].inspect.signature.__code__, 138006091046704)
	| | | +- GuardManager: source=G['__import_scipy_dot__lib_dot__util'].FullArgSpec, accessed_by=GetAttrGuardAccessor(FullArgSpec)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot__lib_dot__util'].FullArgSpec, 111056996187264)
	| | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'], accessed_by=DictGetItemGuardAccessor(__import_scipy_dot_optimize_dot__lsq_dot_least_squares)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'], 138005367159712)
	| | | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np, accessed_by=GetAttrGuardAccessor(np)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np, 138006086600640)
	| | | | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.resize, accessed_by=GetAttrGuardAccessor(resize)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.resize, 138005633272048)
	| | | | +- GuardManager: source=G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.asarray, accessed_by=GetAttrGuardAccessor(asarray)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_optimize_dot__lsq_dot_least_squares'].np.asarray, 138006086609920)
	
V0401 21:32:43.674000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "55e8459cb8084547de049eeeeb23c555"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163674337.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.675000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1, "has_payload": "8bef8ab5f818bc112cbe3be7094d68cb"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163675246.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 5,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.676000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "10/0", "frame_key": "24", "co_name": "curve_fit", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 591, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 27, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 5, "graph_input_count": 0, "start_time": 1743543163.4659832, "entire_frame_compile_time_s": 0.20827698707580566, "backend_compile_time_s": 0.08532118797302246, "inductor_compile_time_s": 0.020388364791870117, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.03748011589050293, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 10, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.678000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 574, "name": "_initialize_feasible", "filename": 6}]}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.678000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0, "has_payload": "0033ecc4eb1961bc8e095eca72911413"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163678751.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.679000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0, "has_payload": "158e5bfac2db089c30ce33e94d1d5fa3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163678751.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.682000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 30, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.683000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb631ef0>", "describer_id": 30}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.684000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 30, "id": 0, "source": "___from_numpy(L['lb'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.688000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 30, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.689000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb633610>", "describer_id": 30}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.690000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 30, "id": 1, "source": "___from_numpy(L['ub'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.696000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 31, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.697000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb630050>", "describer_id": 31}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.698000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 31, "id": 0, "source": "___from_numpy(L['lb'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.702000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 31, "size": 16}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.703000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbdcaee0>", "describer_id": 31}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.703000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 31, "id": 1, "source": "___from_numpy(L['ub'])"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.708000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_lb_": [2], "l_ub_": [2], "p0": [2], "lb_finite": [2], "ub_finite": [2], "mask": [2]}}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "ff71e3effb1665ce0552b39f5aaea5e9"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_lb_: "f64[2][1]cpu", L_ub_: "f64[2][1]cpu"):
	        l_lb_ = L_lb_
	        l_ub_ = L_ub_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:575 in _initialize_feasible, code: p0 = np.ones_like(lb)
	        p0: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_ones_like(l_lb_)
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:576 in _initialize_feasible, code: lb_finite = np.isfinite(lb)
	        lb_finite: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_isfinite(l_lb_);  l_lb_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:577 in _initialize_feasible, code: ub_finite = np.isfinite(ub)
	        ub_finite: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_isfinite_1(l_ub_);  l_ub_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:579 in _initialize_feasible, code: mask = lb_finite & ub_finite
	        mask: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_and_(lb_finite, ub_finite)
	        return (mask, p0, lb_finite, ub_finite)
	        
V0401 21:32:43.710000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "420104213fc7aecbdeab73fa353ea09e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163710042.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.710000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "3593b8ec10df8e75b6db0f01a7047fc5"}
	{
	"name": "backend_compile",
	"ts": 1743543163710042.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.714000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "1173b8b5efd9d42330c1d7f092dedafc"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163713971.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.743000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "0c0c854b2cef0dc0459e683dbe297173"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu", arg1_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:575 in _initialize_feasible, code: p0 = np.ones_like(lb)
	        full: "f64[2][1]cpu" = torch.ops.aten.full.default([2], 1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:576 in _initialize_feasible, code: lb_finite = np.isfinite(lb)
	        abs_1: "f64[2][1]cpu" = torch.ops.aten.abs.default(arg0_1)
	        ne: "b8[2][1]cpu" = torch.ops.aten.ne.Scalar(abs_1, inf);  abs_1 = None
	        eq: "b8[2][1]cpu" = torch.ops.aten.eq.Tensor(arg0_1, arg0_1);  arg0_1 = None
	        mul: "b8[2][1]cpu" = torch.ops.aten.mul.Tensor(eq, ne);  eq = ne = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:577 in _initialize_feasible, code: ub_finite = np.isfinite(ub)
	        abs_2: "f64[2][1]cpu" = torch.ops.aten.abs.default(arg1_1)
	        ne_1: "b8[2][1]cpu" = torch.ops.aten.ne.Scalar(abs_2, inf);  abs_2 = None
	        eq_1: "b8[2][1]cpu" = torch.ops.aten.eq.Tensor(arg1_1, arg1_1);  arg1_1 = None
	        mul_1: "b8[2][1]cpu" = torch.ops.aten.mul.Tensor(eq_1, ne_1);  eq_1 = ne_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:579 in _initialize_feasible, code: mask = lb_finite & ub_finite
	        bitwise_and: "b8[2][1]cpu" = torch.ops.aten.bitwise_and.Tensor(mul, mul_1)
	        return (bitwise_and, full, mul, mul_1)
	        
V0401 21:32:43.745000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "43bbef6a6f24ed24f9a2facbafbed30e"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163744507.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.749000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "b715734636daff9b5cb1d67b1194a2b7"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163749639.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.750000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "b78b6e34552810d4baaa39d01c648936"}
	{
	"name": "inductor_compile",
	"ts": 1743543163749639.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.761000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/mc/cmcfh3a2emrutfmrbeazds6vn44cuho54q52lufk7oa3tzfnmks4.py"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "393224d84a16a69f195871bb122f4ec4"}
	# AOT ID: ['6_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_abs_bitwise_and_eq_mul_ne_ones_like_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'bool*', 'bool*', 'bool*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       bool* out_ptr0,
	                       bool* out_ptr1,
	                       bool* out_ptr2,
	                       double* out_ptr3)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp6 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = std::abs(tmp0);
	            auto tmp3 = std::numeric_limits<double>::infinity();
	            auto tmp4 = tmp2 != tmp3;
	            auto tmp5 = tmp1 && tmp4;
	            auto tmp7 = tmp6 == tmp6;
	            auto tmp8 = std::abs(tmp6);
	            auto tmp9 = tmp8 != tmp3;
	            auto tmp10 = tmp7 && tmp9;
	            auto tmp11 = decltype(tmp5)(tmp5 & tmp10);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp5;
	            out_ptr1[static_cast<int64_t>(x0)] = tmp10;
	            out_ptr2[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = static_cast<double>(1.0);
	            out_ptr3[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    buf1 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    buf2 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    buf3 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    cpp_fused_abs_bitwise_and_eq_mul_ne_ones_like_0(arg0_1, arg1_1, buf0, buf1, buf2, buf3)
	    del arg0_1
	    del arg1_1
	    return (buf2, buf3, buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:43.762000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "b9ee2fadcf73282cfcfdc41804b43545"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543163762232.5,
	"args": {
	"key": "funr2ahlhw56uug5okvs7g4codnhulml4xeci2yvisqb4ws2a2uz",
	"components": [
	"[vyrg4ufxaeuywksed2fgb6wwxbowgaw4v23hlnmy73jh3ooa4ik] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    full_default = torch.ops.aten.full.default([2], 1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    abs_1 = torch.ops.aten.abs.default(arg0_1)\n    ne = torch.ops.aten.ne.Scalar(abs_1, inf);  abs_1 = None\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg0_1);  arg0_1 = None\n    mul = torch.ops.aten.mul.Tensor(eq, ne);  eq = ne = None\n    abs_2 = torch.ops.aten.abs.default(arg1_1)\n    ne_1 = torch.ops.aten.ne.Scalar(abs_2, inf);  abs_2 = None\n    eq_1 = torch.ops.aten.eq.Tensor(arg1_1, arg1_1);  arg1_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(eq_1, ne_1);  eq_1 = ne_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(mul, mul_1)\n    return (bitwise_and, full_default, mul, mul_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[tltqbuwwwdr4yb24wanyx2ncv3wkzebbr424kzuebqega5spijw] fx_kwargs[user_visible_outputs]: {'bitwise_and': None, 'full_default': None, 'mul': None, 'mul_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2189581080,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:43.763000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "503af48cde2cf83fc5673b6b30d57788"}
	{"key": "funr2ahlhw56uug5okvs7g4codnhulml4xeci2yvisqb4ws2a2uz", "components": ["[vyrg4ufxaeuywksed2fgb6wwxbowgaw4v23hlnmy73jh3ooa4ik] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    full_default = torch.ops.aten.full.default([2], 1, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    abs_1 = torch.ops.aten.abs.default(arg0_1)\n    ne = torch.ops.aten.ne.Scalar(abs_1, inf);  abs_1 = None\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg0_1);  arg0_1 = None\n    mul = torch.ops.aten.mul.Tensor(eq, ne);  eq = ne = None\n    abs_2 = torch.ops.aten.abs.default(arg1_1)\n    ne_1 = torch.ops.aten.ne.Scalar(abs_2, inf);  abs_2 = None\n    eq_1 = torch.ops.aten.eq.Tensor(arg1_1, arg1_1);  arg1_1 = None\n    mul_1 = torch.ops.aten.mul.Tensor(eq_1, ne_1);  eq_1 = ne_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(mul, mul_1)\n    return (bitwise_and, full_default, mul, mul_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[tltqbuwwwdr4yb24wanyx2ncv3wkzebbr424kzuebqega5spijw] fx_kwargs[user_visible_outputs]: {'bitwise_and': None, 'full_default': None, 'mul': None, 'mul_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2189581080, "cache_state": "hit"}
V0401 21:32:43.765000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "620e99f2e9e0ecf839fee9f2566697eb"}
	{
	"name": "inductor_compile",
	"ts": 1743543163765002.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.766000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "c0fb313dad7dae2b1ed5e498f16fc658"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163765911.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.767000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "f4934335eea69b9c370baa4ea8319bdc"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163767296.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.771000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "b92e319d06f76e9fd745b7ea214d7967"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163771844.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.773000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "f82c572106137cd6d9dab635604a0a79"}
	{
	"name": "backend_compile",
	"ts": 1743543163773362.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.774000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "d1251e6b90914a3a3558afcc931ac347"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163774169.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.781000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "3f359f0ac7879875ec51f684738783bd"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['lb'], accessed_by=DictGetItemGuardAccessor(lb)
	| | +- GuardManager: source=___from_numpy(L['lb']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['lb']), ___from_numpy(L['ub']))
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].isfinite, accessed_by=GetAttrGuardAccessor(isfinite)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].isfinite, 138006087268160)          
	| | | +- GuardManager: source=G['np'].ones_like, accessed_by=GetAttrGuardAccessor(ones_like)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ones_like, 138005631209008)         
	
V0401 21:32:43.782000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "8fb1eae23c7965584099bafbb397b4c1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163782353.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.783000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1, "has_payload": "6a9922b3eb851a1a7b0ce42aec66349f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163783195.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.784000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "11/0", "frame_key": "25", "co_name": "_initialize_feasible", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 574, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 10, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543163.6787407, "entire_frame_compile_time_s": 0.10353660583496094, "backend_compile_time_s": 0.06325268745422363, "inductor_compile_time_s": 0.015225887298583984, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.013939380645751953, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 11, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.785000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}]}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.786000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0, "has_payload": "e36dd947f601fa2eed5e58059df7c080"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163786339.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.787000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0, "has_payload": "3fc4bcc3e8bf231077238c5bf9d5568d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163786339.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.789000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 33, "size": 16}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.790000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6436b0>", "describer_id": 33}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.791000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 33, "id": 0, "source": "___from_numpy(L['ub'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.793000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 33, "size": 2}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.795000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb642260>", "describer_id": 33}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.796000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 33, "id": 1, "source": "___from_numpy(L['mask'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.801000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 34, "size": 0}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.802000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb631310>", "describer_id": 34}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.803000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 34, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.805000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 34, "size": 16}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.806000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb633ed0>", "describer_id": 34}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.807000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 34, "id": 1, "source": "___from_numpy(L['ub'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.809000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 34, "size": 2}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.810000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb76b70>", "describer_id": 34}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.810000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 34, "id": 2, "source": "___from_numpy(L['mask'])"}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.821000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1, "has_payload": "82766a801758a57898d4890c6633975d"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- EQUALS_MATCH: L['___stack0'] == 0.5                                       
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['ub']), ___from_numpy(L['mask']), ___from_numpy(L['___stack1']))
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack1'], accessed_by=DictGetItemGuardAccessor(___stack1)
	| | +- GuardManager: source=___from_numpy(L['___stack1']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack1']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack1']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:32:43.822000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1, "has_payload": "8de6655d5562b2609d7cbb343c95c5be"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163822661.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.823000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1, "has_payload": "e89e4e082eddbd7c344ac38c07a25e50"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163823473.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 6,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.824000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "12/0", "frame_key": "26", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_580", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 580, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 6, "graph_input_count": 6, "start_time": 1743543163.7863297, "entire_frame_compile_time_s": 0.03625798225402832, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.011519193649291992, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 12, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.825000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "_initialize_feasible", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}]}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.826000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0, "has_payload": "c222ace8e8fde68c852685fd5b175c06"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163826483.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.827000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcc7c70d0506247c1bad6071fe776a95"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163826483.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.830000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 35, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.831000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbdc86e0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.831000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.833000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 35, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.834000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6322b0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.835000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 1, "source": "___from_numpy(L['___stack2'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.840000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 35, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.841000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb631360>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.841000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 4, "source": "___from_numpy(L['p0'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.844000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 35, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.844000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6338e0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.845000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 5, "source": "___from_numpy(L['mask'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.848000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 35, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.849000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb64b8e0>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.849000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 6, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.853000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 35, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.854000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbdc8140>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.854000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 8, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.857000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 35, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.858000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 9, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb649f40>", "describer_id": 35}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.859000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 35, "id": 9, "source": "___from_numpy(L['lb'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.864000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 36, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.864000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb641fe0>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.865000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.867000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 36, "size": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.868000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6420d0>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.869000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 1, "source": "___from_numpy(L['___stack2'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.872000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 36, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.873000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbdc8c30>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.874000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 2, "source": "___from_numpy(L['p0'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.876000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 36, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.877000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb633a70>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.878000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 3, "source": "___from_numpy(L['mask'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.880000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 36, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.881000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6330c0>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.882000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 4, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.884000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 36, "size": 2}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.885000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6480a0>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.886000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 5, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.889000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 36, "size": 16}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.890000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb3c50>", "describer_id": 36}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.891000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 36, "id": 6, "source": "___from_numpy(L['lb'])"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.895000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack1_": [0], "l_stack2_": [0], "l_p0_": [2], "l_mask_": [2], "l_ub_finite_": [2], "l_lb_finite_": [2], "wrapped_add": [0], "wrapped_mul": [0], "wrapped_invert": [2], "mask": [2]}}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "191c1d781df9bb2d9ea3d1026a2fd4d9"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack1_: "f64[0][0]cpu", L_stack2_: "f64[0][0]cpu", L_p0_: "f64[2][1]cpu", L_mask_: "b8[2][1]cpu", L_ub_finite_: "b8[2][1]cpu", L_lb_finite_: "b8[2][1]cpu"):
	        l_stack1_ = L_stack1_
	        l_stack2_ = L_stack2_
	        l_p0_ = L_p0_
	        l_mask_ = L_mask_
	        l_ub_finite_ = L_ub_finite_
	        l_lb_finite_ = L_lb_finite_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:580 in torch_dynamo_resume_in__initialize_feasible_at_580, code: p0[mask] = 0.5 * (lb[mask] + ub[mask])
	        wrapped_add: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_add(l_stack1_, l_stack2_);  l_stack1_ = l_stack2_ = None
	        wrapped_mul: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_mul(0.5, wrapped_add);  wrapped_add = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_p0_, l_mask_, wrapped_mul);  l_p0_ = l_mask_ = wrapped_mul = wrapped___setitem__ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:582 in torch_dynamo_resume_in__initialize_feasible_at_580, code: mask = lb_finite & ~ub_finite
	        wrapped_invert: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_invert(l_ub_finite_);  l_ub_finite_ = None
	        mask: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_and_(l_lb_finite_, wrapped_invert);  l_lb_finite_ = wrapped_invert = None
	        return (mask,)
	        
V0401 21:32:43.896000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "eb1648eb82b80139e233bc77aa2c6591"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163896587.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.897000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "dd780c5addc61947db16bd0f669b74ca"}
	{
	"name": "backend_compile",
	"ts": 1743543163896587.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.902000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "d6d0fce8347b4395e229f06e968bb7ff"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163902931.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.931000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "2d3ac8f4ed064f450b9aca3167384e5a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[0][0]cpu", arg1_1: "f64[0][0]cpu", arg2_1: "f64[2][1]cpu", arg3_1: "b8[2][1]cpu", arg4_1: "b8[2][1]cpu", arg5_1: "b8[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:580 in torch_dynamo_resume_in__initialize_feasible_at_580, code: p0[mask] = 0.5 * (lb[mask] + ub[mask])
	        add: "f64[0][1]cpu" = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None
	        mul: "f64[0][1]cpu" = torch.ops.aten.mul.Tensor(0.5, add);  add = None
	        index_put: "f64[2][1]cpu" = torch.ops.aten.index_put.default(arg2_1, [arg3_1], mul);  arg3_1 = mul = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:582 in torch_dynamo_resume_in__initialize_feasible_at_580, code: mask = lb_finite & ~ub_finite
	        bitwise_not: "b8[2][1]cpu" = torch.ops.aten.bitwise_not.default(arg4_1);  arg4_1 = None
	        bitwise_and: "b8[2][1]cpu" = torch.ops.aten.bitwise_and.Tensor(arg5_1, bitwise_not);  arg5_1 = bitwise_not = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:580 in torch_dynamo_resume_in__initialize_feasible_at_580, code: p0[mask] = 0.5 * (lb[mask] + ub[mask])
	        copy_: "f64[2][1]cpu" = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None
	        return (bitwise_and,)
	        
V0401 21:32:43.932000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "bf69f7a08998f63be05bc4d927f0d8ad"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163932607.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.936000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "780acfb202104690c8ba3913dc65f429"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163936289.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.937000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "db10de771a69eaaa70cc02a58c844717"}
	{
	"name": "inductor_compile",
	"ts": 1743543163936289.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.947000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/tp/ctpx5pwm3jwdz5wtkibk6srgquv4slonctvvqnrdvxmk4avujakq.py"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "bfd611d92954846361e9bd45dccc21d5"}
	# AOT ID: ['7_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_bitwise_and_bitwise_not_0 = async_compile.cpp_pybinding(['const bool*', 'const bool*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const bool* in_ptr0,
	                       const bool* in_ptr1,
	                       bool* out_ptr0)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = !tmp1;
	            auto tmp3 = decltype(tmp0)(tmp0 & tmp2);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp3;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1 = args
	    args.clear()
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    assert_size_stride(arg3_1, (2, ), (1, ))
	    assert_size_stride(arg4_1, (2, ), (1, ))
	    assert_size_stride(arg5_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((0, ), (1, ), torch.float64)
	    aten.index_put_(arg2_1, [arg3_1], buf0, False)
	    del arg2_1
	    del arg3_1
	    del buf0
	    buf2 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    cpp_fused_bitwise_and_bitwise_not_0(arg5_1, arg4_1, buf2)
	    del arg4_1
	    del arg5_1
	    return (buf2, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg3_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg4_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg5_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:43.948000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "5d25129be3ada6ffcc0495170c4911ab"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543163947841.8,
	"args": {
	"key": "ftmnajjqc5hkxk5ys55geac643d36qi4rc3odtly2dnj6plbxqrs",
	"components": [
	"[bkls3dgj2tuzcsuhsrorqjeji3ltoqemd5bqtrx2qxfofzwoee2] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    add = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    mul = torch.ops.aten.mul.Tensor(0.5, add);  add = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [arg3_1], mul);  arg3_1 = mul = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg4_1);  arg4_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(arg5_1, bitwise_not);  arg5_1 = bitwise_not = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[5]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2364735383,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:43.949000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "176a1276d22d05b1cbbfe200e1b78a11"}
	{"key": "ftmnajjqc5hkxk5ys55geac643d36qi4rc3odtly2dnj6plbxqrs", "components": ["[bkls3dgj2tuzcsuhsrorqjeji3ltoqemd5bqtrx2qxfofzwoee2] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1):\n    add = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    mul = torch.ops.aten.mul.Tensor(0.5, add);  add = None\n    index_put = torch.ops.aten.index_put.default(arg2_1, [arg3_1], mul);  arg3_1 = mul = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg4_1);  arg4_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(arg5_1, bitwise_not);  arg5_1 = bitwise_not = None\n    copy_ = torch.ops.aten.copy_.default(arg2_1, index_put);  arg2_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[5]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2364735383, "cache_state": "hit"}
V0401 21:32:43.950000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "dd77e05c63ac31b6202032dd302617cd"}
	{
	"name": "inductor_compile",
	"ts": 1743543163950211.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.951000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "a84538c53c01027d84e02ef9e3278c53"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543163951030.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.952000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "4bfa9cdda69f61c845e813bf496e2c09"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543163952442.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.955000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "b8c4b692f627aebe63fe3da51a2f95bd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543163955783.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.956000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "b13159453f41046fc7c1c8eac773c238"}
	{
	"name": "backend_compile",
	"ts": 1743543163956600.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.957000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "11b4ac9390bd6abb2d688fb9545ed32d"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543163957439.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.970000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "948485724140eac7e94cbc7ba60a0bf2"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- EQUALS_MATCH: L['___stack0'] == 0.5                                       
	| +- GuardManager: source=L['lb'], accessed_by=DictGetItemGuardAccessor(lb)
	| | +- GuardManager: source=___from_numpy(L['lb']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['lb']), ___from_numpy(L['p0']), ___from_numpy(L['mask']), ___from_numpy(L['___stack1']), ___from_numpy(L['___stack2']), ___from_numpy(L['lb_finite']), ___from_numpy(L['ub_finite']))
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack1'], accessed_by=DictGetItemGuardAccessor(___stack1)
	| | +- GuardManager: source=___from_numpy(L['___stack1']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack1']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack1']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack2'], accessed_by=DictGetItemGuardAccessor(___stack2)
	| | +- GuardManager: source=___from_numpy(L['___stack2']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack2']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack2']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['lb_finite'], accessed_by=DictGetItemGuardAccessor(lb_finite)
	| | +- GuardManager: source=___from_numpy(L['lb_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['ub_finite'], accessed_by=DictGetItemGuardAccessor(ub_finite)
	| | +- GuardManager: source=___from_numpy(L['ub_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:32:43.971000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "42c234e28e186fe471327a7e754097f0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163971126.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.972000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1, "has_payload": "f248fcbe11e0fa2d313f92e58de9aa0a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163971971.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 7,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.972000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "13/0", "frame_key": "27", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_580", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 580, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 12, "graph_input_count": 6, "start_time": 1743543163.8264732, "entire_frame_compile_time_s": 0.1445777416229248, "backend_compile_time_s": 0.05994272232055664, "inductor_compile_time_s": 0.013795137405395508, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.03409886360168457, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 13, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:43.974000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "_initialize_feasible", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}, {"line": 583, "name": "torch_dynamo_resume_in__initialize_feasible_at_583", "filename": 6}]}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.975000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0, "has_payload": "a64a22e14017cd89068ef7fd5eff5e62"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543163975592.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.976000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0, "has_payload": "1c967e60710febde6d4dc01830bb037b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543163975592.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:43.979000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 38, "size": 0}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.980000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb3b10>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.980000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.984000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 38, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.985000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb14a0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.986000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 3, "source": "___from_numpy(L['p0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.988000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 38, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.989000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6ec6e0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.989000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 4, "source": "___from_numpy(L['mask'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.992000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 38, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.993000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6e46e0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.994000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 5, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.996000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 38, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.997000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6e66c0>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:43.998000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 6, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.001000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 38, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.001000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 7, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6e5d60>", "describer_id": 38}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.002000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 38, "id": 7, "source": "___from_numpy(L['ub'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.007000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 39, "size": 0}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.008000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb892c0>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.009000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.013000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 39, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.014000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb88a00>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.014000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 3, "source": "___from_numpy(L['p0'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.017000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 39, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.017000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb88320>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.018000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 4, "source": "___from_numpy(L['mask'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.021000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 39, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.021000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb899a0>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.022000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 5, "source": "___from_numpy(L['lb_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.025000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 39, "size": 2}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.026000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb8b890>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.027000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 6, "source": "___from_numpy(L['ub_finite'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.030000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 39, "size": 16}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.030000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 7, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb633570>", "describer_id": 39}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.031000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 39, "id": 7, "source": "___from_numpy(L['ub'])"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.035000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_": [0], "l_p0_": [2], "l_mask_": [2], "l_lb_finite_": [2], "l_ub_finite_": [2], "wrapped_add": [0], "wrapped_invert": [2], "mask": [2]}}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "38e687d42f1f2e6106086df65cc42197"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_: "f64[0][0]cpu", L_p0_: "f64[2][1]cpu", L_mask_: "b8[2][1]cpu", L_lb_finite_: "b8[2][1]cpu", L_ub_finite_: "b8[2][1]cpu"):
	        l_stack0_ = L_stack0_
	        l_p0_ = L_p0_
	        l_mask_ = L_mask_
	        l_lb_finite_ = L_lb_finite_
	        l_ub_finite_ = L_ub_finite_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:583 in torch_dynamo_resume_in__initialize_feasible_at_583, code: p0[mask] = lb[mask] + 1
	        wrapped_add: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_add(l_stack0_, 1);  l_stack0_ = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_p0_, l_mask_, wrapped_add);  l_p0_ = l_mask_ = wrapped_add = wrapped___setitem__ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:585 in torch_dynamo_resume_in__initialize_feasible_at_583, code: mask = ~lb_finite & ub_finite
	        wrapped_invert: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_invert(l_lb_finite_);  l_lb_finite_ = None
	        mask: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_and_(wrapped_invert, l_ub_finite_);  wrapped_invert = l_ub_finite_ = None
	        return (mask,)
	        
V0401 21:32:44.036000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "1f57a1d6cbe4ca8ab7ca98c4a7913c0d"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543164036815.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.039000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "5a94dfabb7be9f815703a46fdf46ba5d"}
	{
	"name": "backend_compile",
	"ts": 1743543164036815.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.044000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "df2c7f1fa0e7a9b49c610b68eaa7ae26"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543164044330.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.069000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "e5a95522c98df72911e804ec9d83846a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[0][0]cpu", arg1_1: "f64[2][1]cpu", arg2_1: "b8[2][1]cpu", arg3_1: "b8[2][1]cpu", arg4_1: "b8[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:583 in torch_dynamo_resume_in__initialize_feasible_at_583, code: p0[mask] = lb[mask] + 1
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        add: "f64[0][1]cpu" = torch.ops.aten.add.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        index_put: "f64[2][1]cpu" = torch.ops.aten.index_put.default(arg1_1, [arg2_1], add);  arg2_1 = add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:585 in torch_dynamo_resume_in__initialize_feasible_at_583, code: mask = ~lb_finite & ub_finite
	        bitwise_not: "b8[2][1]cpu" = torch.ops.aten.bitwise_not.default(arg3_1);  arg3_1 = None
	        bitwise_and: "b8[2][1]cpu" = torch.ops.aten.bitwise_and.Tensor(bitwise_not, arg4_1);  bitwise_not = arg4_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:583 in torch_dynamo_resume_in__initialize_feasible_at_583, code: p0[mask] = lb[mask] + 1
	        copy_: "f64[2][1]cpu" = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None
	        return (bitwise_and,)
	        
V0401 21:32:44.070000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "fcb4980f7743f43f8d6430aacaa3ec24"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543164070236.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.073000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "a963a6d5a9b52d63a41a19ab805d617a"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543164073456.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.074000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "1d564b18ab9e8c5d84ab55244e99233f"}
	{
	"name": "inductor_compile",
	"ts": 1743543164073456.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.084000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/6h/c6hqclzdnxhejp2mllp3reuszylzata4w4pfczorn7oypningx6p.py"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "01480e6bbce220c85768b15c477a7635"}
	# AOT ID: ['8_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_bitwise_and_bitwise_not_0 = async_compile.cpp_pybinding(['const bool*', 'const bool*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const bool* in_ptr0,
	                       const bool* in_ptr1,
	                       bool* out_ptr0)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = !tmp0;
	            auto tmp3 = decltype(tmp1)(tmp1 & tmp2);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp3;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1 = args
	    args.clear()
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    assert_size_stride(arg3_1, (2, ), (1, ))
	    assert_size_stride(arg4_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((0, ), (1, ), torch.float64)
	    aten.index_put_(arg1_1, [arg2_1], buf0, False)
	    del arg1_1
	    del arg2_1
	    del buf0
	    buf2 = empty_strided_cpu((2, ), (1, ), torch.bool)
	    cpp_fused_bitwise_and_bitwise_not_0(arg3_1, arg4_1, buf2)
	    del arg3_1
	    del arg4_1
	    return (buf2, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg3_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    arg4_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:44.085000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "ee92fceccd805622a2847d7fcd206c0c"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543164084838.0,
	"args": {
	"key": "fdakzmc6rvnpytuk7kzokgs44wuzalnryaq5ymojyaz2ife2qrnd",
	"components": [
	"[i5ethix7lgv7h6rjm2xxzqbxbbxoztf2ozcclb5fhhu2jtity5t] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    add = torch.ops.aten.add.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], add);  arg2_1 = add = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg3_1);  arg3_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(bitwise_not, arg4_1);  bitwise_not = arg4_1 = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2083055314,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:44.086000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "372878276dc9bde9b97a833704299616"}
	{"key": "fdakzmc6rvnpytuk7kzokgs44wuzalnryaq5ymojyaz2ife2qrnd", "components": ["[i5ethix7lgv7h6rjm2xxzqbxbbxoztf2ozcclb5fhhu2jtity5t] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1, arg3_1, arg4_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    add = torch.ops.aten.add.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], add);  arg2_1 = add = None\n    bitwise_not = torch.ops.aten.bitwise_not.default(arg3_1);  arg3_1 = None\n    bitwise_and = torch.ops.aten.bitwise_and.Tensor(bitwise_not, arg4_1);  bitwise_not = arg4_1 = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return (bitwise_and,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[3]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[4]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[5f52tnplvj3izwzofv4gqenvmdxwx2bth5tftlm3gdwtsxtg4l2] fx_kwargs[user_visible_outputs]: {'bitwise_and': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2083055314, "cache_state": "hit"}
V0401 21:32:44.087000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "f0099f573324c11f21e4033bbccc971e"}
	{
	"name": "inductor_compile",
	"ts": 1743543164087148.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.087000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "14b22ebd421528d9f7423024c2faf5d5"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543164087911.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.089000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "c05a9e412a5e070ec9c634b5cc6e7160"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543164089139.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.092000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "3abd2cd931e0415ac48631e3f2cfd6f3"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543164092393.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.093000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "afa110cfa7ac6184d09d6546327baa6e"}
	{
	"name": "backend_compile",
	"ts": 1743543164093279.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.094000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "db3737d7e8e7c1ad32efdfff535317d7"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543164094525.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.107000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "e536d8457a105e4ea42f4ed2c123944d"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['ub']), ___from_numpy(L['mask']), ___from_numpy(L['___stack0']), ___from_numpy(L['lb_finite']), ___from_numpy(L['ub_finite']))
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['lb_finite'], accessed_by=DictGetItemGuardAccessor(lb_finite)
	| | +- GuardManager: source=___from_numpy(L['lb_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['ub_finite'], accessed_by=DictGetItemGuardAccessor(ub_finite)
	| | +- GuardManager: source=___from_numpy(L['ub_finite']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub_finite']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub_finite']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:32:44.107000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "7af68a5f5fdffa3869c648d0909fea5e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164107732.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.108000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1, "has_payload": "b895ea6d584a004cf592dc9aae9f0cdd"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164108555.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 8,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.109000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "14/0", "frame_key": "28", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_583", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 583, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 10, "graph_input_count": 5, "start_time": 1743543163.9755821, "entire_frame_compile_time_s": 0.13207387924194336, "backend_compile_time_s": 0.056398868560791016, "inductor_compile_time_s": 0.01359868049621582, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True"], "dynamo_time_before_restart_s": 0.02853250503540039, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 14, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.111000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 580, "name": "_initialize_feasible", "filename": 6}, {"line": 580, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}, {"line": 583, "name": "torch_dynamo_resume_in__initialize_feasible_at_580", "filename": 6}, {"line": 586, "name": "torch_dynamo_resume_in__initialize_feasible_at_586", "filename": 6}]}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.111000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "24f7dd25de80613f658322f23e5696c2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164111817.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.112000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "631cb32ba2145bb9ed954b51aa06fe3a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164111817.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.115000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 41, "size": 0}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.116000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [0], "is_leaf": true, "stride": [0], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb6e6080>", "describer_id": 41}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.116000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 41, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.121000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 41, "size": 16}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.122000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb17c0>", "describer_id": 41}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.123000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 41, "id": 3, "source": "___from_numpy(L['p0'])"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.125000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 41, "size": 2}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.126000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb2c10>", "describer_id": 41}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.127000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 41, "id": 4, "source": "___from_numpy(L['mask'])"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.130000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_": [0], "l_p0_": [2], "l_mask_": [2], "wrapped_sub": [0]}}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "d38f650955beb6b8cb9a2d923160df4c"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_: "f64[0][0]cpu", L_p0_: "f64[2][1]cpu", L_mask_: "b8[2][1]cpu"):
	        l_stack0_ = L_stack0_
	        l_p0_ = L_p0_
	        l_mask_ = L_mask_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:586 in torch_dynamo_resume_in__initialize_feasible_at_586, code: p0[mask] = ub[mask] - 1
	        wrapped_sub: "f64[0][1]cpu" = torch__dynamo_utils_wrapped_sub(l_stack0_, 1);  l_stack0_ = None
	        wrapped___setitem__ = torch__dynamo_utils_wrapped___setitem__(l_p0_, l_mask_, wrapped_sub);  l_p0_ = l_mask_ = wrapped_sub = wrapped___setitem__ = None
	        return ()
	        
V0401 21:32:44.131000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "a8537cf186ce9f289565be4faeaaed54"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543164131881.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.133000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "0244e533c518f9ac74c6acb83847b133"}
	{
	"name": "backend_compile",
	"ts": 1743543164131881.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.138000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "0e691e21238b02eb809882b153da3883"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543164138032.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.157000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "d9ea633bb9b69eede4840ac85dee0aa4"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[0][0]cpu", arg1_1: "f64[2][1]cpu", arg2_1: "b8[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:586 in torch_dynamo_resume_in__initialize_feasible_at_586, code: p0[mask] = ub[mask] - 1
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        sub: "f64[0][1]cpu" = torch.ops.aten.sub.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        index_put: "f64[2][1]cpu" = torch.ops.aten.index_put.default(arg1_1, [arg2_1], sub);  arg2_1 = sub = None
	        copy_: "f64[2][1]cpu" = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None
	        return ()
	        
V0401 21:32:44.158000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "681504504a73015e7e6c150da62fb777"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543164157877.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.160000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "9c3bba4ba2e57872c2e40be04f27e3b5"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543164160645.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.161000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "5bc3f12d5888057e647ae06e0fbff88f"}
	{
	"name": "inductor_compile",
	"ts": 1743543164160645.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.168000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/dl/cdll33i4idcjni2tmji4jisqc6ixjbjq4dvuwjqsso6rc2nkcjso.py"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "4d267a0bf1958620c9e79ee78abd5af5"}
	# AOT ID: ['9_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((0, ), (1, ), torch.float64)
	    aten.index_put_(arg1_1, [arg2_1], buf0, False)
	    del arg1_1
	    del arg2_1
	    return ()
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((0, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.bool)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:44.169000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "3aca176ae08b3655e78e6bebf0796939"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543164169360.0,
	"args": {
	"key": "flvnpb3zork5pmpcx6lz2vwjpx7xbbbbsjvrnpgvsq7shmtxwpwv",
	"components": [
	"[o7vddygb3d2vcbxbyxulsvlugfb5xz7pq7kyyepwqevux7tdrrw] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], sub);  arg2_1 = sub = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 10248149,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:44.170000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "691c4d5a08a26b24e2ed30a10bf1d901"}
	{"key": "flvnpb3zork5pmpcx6lz2vwjpx7xbbbbsjvrnpgvsq7shmtxwpwv", "components": ["[o7vddygb3d2vcbxbyxulsvlugfb5xz7pq7kyyepwqevux7tdrrw] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    index_put = torch.ops.aten.index_put.default(arg1_1, [arg2_1], sub);  arg2_1 = sub = None\n    copy_ = torch.ops.aten.copy_.default(arg1_1, index_put);  arg1_1 = index_put = copy_ = None\n    return ()\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4pbrvaw4mpyunghzbvmybunsri6dv3k2rcki3ywo6kgx3thdfqg] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([0]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[yoqkkdfc724rhlfdcwqb2yk5xe36gaqs2isjd77cbktv5hjdwng] example_inputs[2]: TensorMetadata(dtype=torch.bool, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] fx_kwargs[user_visible_outputs]: {}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 10248149, "cache_state": "hit"}
V0401 21:32:44.171000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "f3c6f050287b886193f8667c18c35502"}
	{
	"name": "inductor_compile",
	"ts": 1743543164171622.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.172000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "60c799edf9e86966cf3d46ef1d2f885a"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543164172385.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.173000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "1b4821297c4b843e05103fa64a5afabc"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543164173769.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.178000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "bd9d0039dd3e39ee2e5121f67a361d09"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543164178186.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.179000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "4d5b0f9b7f09dd5cc037db1f76918bba"}
	{
	"name": "backend_compile",
	"ts": 1743543164179452.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.182000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "5eabfe47e241447f6d890ec340cc0b15"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543164182019.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.188000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "197f178dd85ba2f6d0e897a71c0f7119"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['mask']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['mask'], accessed_by=DictGetItemGuardAccessor(mask)
	| | +- GuardManager: source=___from_numpy(L['mask']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['mask']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['mask']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[0], stride=[0])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:32:44.189000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "f67f9a39e1d0cb4b64822ecd9a457e95"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164189097.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.190000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0, "has_payload": "ab9c5b9cc68ebabab37d45ee85a2794b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164189950.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 9,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.190000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "15/0", "frame_key": "29", "co_name": "torch_dynamo_resume_in__initialize_feasible_at_586", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 586, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 8, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 6, "graph_input_count": 3, "start_time": 1743543164.1118076, "entire_frame_compile_time_s": 0.07721710205078125, "backend_compile_time_s": 0.047506093978881836, "inductor_compile_time_s": 0.010886907577514648, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 15, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.193000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}]}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.193000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "1f9316a40af37a7480b5dae8add2f855"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164193743.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.194000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "5bada4739c9d39ca0240f80eb818dc0f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164193743.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.204000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 43, "size": 16}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.205000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb915810>", "describer_id": 43}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.205000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 43, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.208000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 43, "size": 16}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.209000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb915fe0>", "describer_id": 43}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.209000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 43, "id": 1, "source": "___from_numpy(L['lb'])"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.214000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 43, "size": 16}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.215000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb916800>", "describer_id": 43}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.215000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 43, "id": 4, "source": "___from_numpy(L['ub'])"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.225000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_lb_": [2], "l_ub_": [2], "wrapped_gt": [2], "wrapped_lt": [2], "wrapped_or_": [2], "bounded_problem": []}}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "411beb691e04107906795c088671a2fd"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_lb_: "f64[2][1]cpu", L_ub_: "f64[2][1]cpu"):
	        l_lb_ = L_lb_
	        l_ub_ = L_ub_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:916 in torch_dynamo_resume_in_curve_fit_at_914, code: bounded_problem = np.any((lb > -np.inf) | (ub < np.inf))
	        wrapped_gt: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_gt(l_lb_, -inf);  l_lb_ = None
	        wrapped_lt: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_lt(l_ub_, inf);  l_ub_ = None
	        wrapped_or_: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_or_(wrapped_gt, wrapped_lt);  wrapped_gt = wrapped_lt = None
	        bounded_problem: "b8[][]cpu" = torch__dynamo_utils_wrapped_any(wrapped_or_);  wrapped_or_ = None
	        return (bounded_problem,)
	        
V0401 21:32:44.226000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "f942edeb900f316d0fabca310b22e505"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543164226239.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.226000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "df85af2281ecb9b75eaa6f6e963aa1cb"}
	{
	"name": "backend_compile",
	"ts": 1743543164226239.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.230000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "9fffbd63055760f0a1db1e0b82eafefd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543164230272.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.252000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "7e31aaf4bda63f2fc5d38c9b85e4ea2b"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu", arg1_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:916 in torch_dynamo_resume_in_curve_fit_at_914, code: bounded_problem = np.any((lb > -np.inf) | (ub < np.inf))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        gt: "b8[2][1]cpu" = torch.ops.aten.gt.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        _tensor_constant1 = self._tensor_constant1
	        lift_fresh_copy_1: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None
	        lt: "b8[2][1]cpu" = torch.ops.aten.lt.Tensor(arg1_1, lift_fresh_copy_1);  arg1_1 = lift_fresh_copy_1 = None
	        bitwise_or: "b8[2][1]cpu" = torch.ops.aten.bitwise_or.Tensor(gt, lt);  gt = lt = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.default(bitwise_or);  bitwise_or = None
	        return (any_1,)
	        
V0401 21:32:44.254000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "6b29d28e1acde62a3cea44ee9afcac75"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543164253582.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.258000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "9426cdfab9189530ba07af60c551df22"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543164257983.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.258000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "01d3124908afb0f012d0b2a6fbc5bc09"}
	{
	"name": "inductor_compile",
	"ts": 1743543164257983.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.268000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/37/c37hwhbesycsk3sxucpus24q5zu2tfasgk7xqxqmtzvcuvpzuinc.py"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "b5f277ba0efd508927a9db1afd59840d"}
	# AOT ID: ['10_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_any_bitwise_or_gt_lift_fresh_lt_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       bool* out_ptr0)
	{
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                auto tmp3 = in_ptr1[static_cast<int64_t>(x0)];
	                auto tmp1 = -std::numeric_limits<double>::infinity();
	                auto tmp2 = tmp0 > tmp1;
	                auto tmp4 = std::numeric_limits<double>::infinity();
	                auto tmp5 = tmp3 < tmp4;
	                auto tmp6 = decltype(tmp2)(tmp2 | tmp5);
	                tmp_acc0 = tmp_acc0 || tmp6;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    cpp_fused_any_bitwise_or_gt_lift_fresh_lt_0(arg0_1, arg1_1, buf0)
	    del arg0_1
	    del arg1_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:44.270000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "7641a9611cc2c58d2c56a627d00210e6"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543164269876.8,
	"args": {
	"key": "fstzt65vvyck4b3j2hkcbkevgez364ihyfhur3iubyrvhyrcue4q",
	"components": [
	"[gkitalcxmcz37pk6n5r7uwhxdfvqwnlmaqgybrlsou6ct7yzmkj] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    gt = torch.ops.aten.gt.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default_1 = torch.ops.aten.full.default([], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Tensor(arg1_1, full_default_1);  arg1_1 = full_default_1 = None\n    bitwise_or = torch.ops.aten.bitwise_or.Tensor(gt, lt);  gt = lt = None\n    any_1 = torch.ops.aten.any.default(bitwise_or);  bitwise_or = None\n    return (any_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[s5yf3qhu2mzuc6huo2hj2x67z5dovjywy454rtpmcch3de7jidr] fx_kwargs[user_visible_outputs]: {'any_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 1980077558,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:44.271000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "5e802dc54dcf44d7268d46517ec0d964"}
	{"key": "fstzt65vvyck4b3j2hkcbkevgez364ihyfhur3iubyrvhyrcue4q", "components": ["[gkitalcxmcz37pk6n5r7uwhxdfvqwnlmaqgybrlsou6ct7yzmkj] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], -inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    gt = torch.ops.aten.gt.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    _tensor_constant1 = self._tensor_constant1;  _tensor_constant1 = None\n    full_default_1 = torch.ops.aten.full.default([], inf, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    lt = torch.ops.aten.lt.Tensor(arg1_1, full_default_1);  arg1_1 = full_default_1 = None\n    bitwise_or = torch.ops.aten.bitwise_or.Tensor(gt, lt);  gt = lt = None\n    any_1 = torch.ops.aten.any.default(bitwise_or);  bitwise_or = None\n    return (any_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[s5yf3qhu2mzuc6huo2hj2x67z5dovjywy454rtpmcch3de7jidr] fx_kwargs[user_visible_outputs]: {'any_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 1980077558, "cache_state": "hit"}
V0401 21:32:44.272000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "18936fd29515d434cd5b8a99b1fece08"}
	{
	"name": "inductor_compile",
	"ts": 1743543164272770.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.273000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "12ad05c8a46a1f30ea9db66cf352f817"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543164273778.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.275000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "bb4e3987fc664f64df5101f191f94d1c"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543164275284.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.280000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "e82a63b18cf3e68ed7fcd657d42b3b4f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543164280593.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.281000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "56ba64a4c74b035593dfd5c5d5d0d4cd"}
	{
	"name": "backend_compile",
	"ts": 1743543164281779.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.282000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "5ee2d459dc4b524be287de0c96f83e63"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543164282796.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.401000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "0e68992efb24239b48cacc1ad4e71197"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['method'], accessed_by=DictGetItemGuardAccessor(method)
	| | +- ID_MATCH: ___check_obj_id(L['method'], 111055818751712)               
	| +- GuardManager: source=L['lb'], accessed_by=DictGetItemGuardAccessor(lb)
	| | +- GuardManager: source=___from_numpy(L['lb']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['lb']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['lb']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['lb']), ___from_numpy(L['ub']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['ub'], accessed_by=DictGetItemGuardAccessor(ub)
	| | +- GuardManager: source=___from_numpy(L['ub']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ub']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ub']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].any, accessed_by=GetAttrGuardAccessor(any)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].any, 138005633277360)               
	| | | +- GuardManager: source=G['np'].inf, accessed_by=GetAttrGuardAccessor(inf)
	| | | | +- EQUALS_MATCH: G['np'].inf == inf                                          
	
V0401 21:32:44.402000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "544f9174c2f2eab515edac91752e7679"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164402649.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.403000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0, "has_payload": "cf801b1021228bf5126715935772a3b6"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164403554.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.404000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "16/0", "frame_key": "30", "co_name": "torch_dynamo_resume_in_curve_fit_at_914", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 914, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543164.1937337, "entire_frame_compile_time_s": 0.20883846282958984, "backend_compile_time_s": 0.05547475814819336, "inductor_compile_time_s": 0.014685869216918945, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 16, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.407000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}]}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.407000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "ce3c90dd75632c48d3795ef933042fe8"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164407658.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.408000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "f69fa6253d24a1d73c5cfe60c80bd7ae"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164407658.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.417000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 45, "size": 1}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.418000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 0, "dtype": "torch.bool", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb94a170>", "describer_id": 45}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.418000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 45, "id": 0, "source": "___from_numpy(L['bounded_problem'])"}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.557000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "d10a2e666d6a11f0cbf86fd87901a5b3"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['bounded_problem'], accessed_by=DictGetItemGuardAccessor(bounded_problem)
	| | +- GuardManager: source=___from_numpy(L['bounded_problem']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['bounded_problem']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.bool, device=None, requires_grad=False, size=[], stride=[])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['bounded_problem']), '_dynamo_dynamic_indices') == False
	
V0401 21:32:44.558000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "093cfb7808b145e98303392940f8bba2"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164558026.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.559000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0, "has_payload": "2b608943a0d12563a5547e3831d3dc7c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164559070.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.560000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "17/0", "frame_key": "31", "co_name": "torch_dynamo_resume_in_curve_fit_at_918", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 918, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 6, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543164.4076478, "entire_frame_compile_time_s": 0.15028691291809082, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 17, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.562000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}]}, "frame_id": 18, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.562000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 0, "has_payload": "a565502aa58d9db235c456fc6c71e253"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164562842.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.563000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 0, "has_payload": "04b4ed6328dad29b272650de8cc16c52"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164562842.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.580000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 47, "size": 2400}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.581000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbd1900>", "describer_id": 47}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.582000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 47, "id": 0, "source": "___from_numpy(L['ydata'])"}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.852000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1, "has_payload": "c3a34448f282e0889d3e93ac04643527"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['nan_policy'], accessed_by=DictGetItemGuardAccessor(nan_policy)
	| | +- ID_MATCH: ___check_obj_id(L['nan_policy'], 111055818751712)           
	| +- GuardManager: source=L['check_finite'], accessed_by=DictGetItemGuardAccessor(check_finite)
	| | +- ID_MATCH: ___check_obj_id(L['check_finite'], 111055818751712)         
	| +- GuardManager: source=L['ydata'], accessed_by=DictGetItemGuardAccessor(ydata)
	| | +- GuardManager: source=___from_numpy(L['ydata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ydata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ydata']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].asarray_chkfinite, accessed_by=GetAttrGuardAccessor(asarray_chkfinite)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].asarray_chkfinite, 138005630091488) 
	| | +- GuardManager: source=G['__builtins_dict___62'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___62)
	| | | +- GuardManager: source=G['__builtins_dict___62']['float'], accessed_by=DictGetItemGuardAccessor(float)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___62']['float'], 111055818722080)
	
V0401 21:32:44.853000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1, "has_payload": "efc14e34b0c955b254e0bcde76ffc6f1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164853083.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.854000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1, "has_payload": "e8adcfb42caa3795bc304c60c3e9f24d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164854085.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.855000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "18/0", "frame_key": "32", "co_name": "torch_dynamo_resume_in_curve_fit_at_923", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 923, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543164.562832, "entire_frame_compile_time_s": 0.2901468276977539, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Can't find numpy function <function asarray_chkfinite at 0x7d83f08f00e0> in torch._numpy.  Please file an issue to request support for this function."], "dynamo_time_before_restart_s": 0.0076770782470703125, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 18, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.858000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}]}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.859000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0, "has_payload": "b30a1efb203f02d042ecdd22443c4db2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543164859091.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.860000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0, "has_payload": "f73974299a44f5bdd11c7f7990b35a39"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543164859091.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:44.868000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 48, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.869000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbc3f3e0>", "describer_id": 48}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.870000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 48, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.873000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 48, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.873000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbdb95e0>", "describer_id": 48}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.874000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 48, "id": 1, "source": "___from_numpy(L['xdata'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:44.884000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 49, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.885000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb9440a0>", "describer_id": 49}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.885000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 49, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.888000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 49, "size": 2400}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.889000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbc2b0c0>", "describer_id": 49}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:44.889000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 49, "id": 1, "source": "___from_numpy(L['xdata'])"}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.014000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1, "has_payload": "e9510668671e8387b60bb74bdc6337e6"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['check_finite'], accessed_by=DictGetItemGuardAccessor(check_finite)
	| | +- ID_MATCH: ___check_obj_id(L['check_finite'], 111055818658720)         
	| +- GuardManager: source=L['xdata'], accessed_by=DictGetItemGuardAccessor(xdata)
	| | +- GuardManager: source=___from_numpy(L['xdata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['xdata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['xdata']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['xdata']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].ndarray, accessed_by=GetAttrGuardAccessor(ndarray)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ndarray, 138005714262272)           
	| | | +- GuardManager: source=G['np'].asarray_chkfinite, accessed_by=GetAttrGuardAccessor(asarray_chkfinite)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].asarray_chkfinite, 138005630091488) 
	| | +- GuardManager: source=G['__builtins_dict___65'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___65)
	| | | +- GuardManager: source=G['__builtins_dict___65']['list'], accessed_by=DictGetItemGuardAccessor(list)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['list'], 111055818730400)
	| | | +- GuardManager: source=G['__builtins_dict___65']['float'], accessed_by=DictGetItemGuardAccessor(float)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['float'], 111055818722080)
	| | | +- GuardManager: source=G['__builtins_dict___65']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['tuple'], 111055818760256)
	| | | +- GuardManager: source=G['__builtins_dict___65']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___65']['isinstance'], 138006094274832)
	
V0401 21:32:45.015000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1, "has_payload": "dad0faa154f5315d9c38f2b4b0b95cd7"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165015415.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.016000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1, "has_payload": "85f0383467fc9e8364b45c2e709801be"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165016311.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.017000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "19/0", "frame_key": "33", "co_name": "torch_dynamo_resume_in_curve_fit_at_932", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 932, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 15, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543164.8590808, "entire_frame_compile_time_s": 0.15623211860656738, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Can't find numpy function <function asarray_chkfinite at 0x7d83f08f00e0> in torch._numpy.  Please file an issue to request support for this function."], "dynamo_time_before_restart_s": 0.0161590576171875, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 19, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.020000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}]}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.020000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0, "has_payload": "dbdfd52f08e6680ca210cd006917ff78"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165020852.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.022000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0, "has_payload": "bbdb285e01941f84cc9d0f200126138e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165020852.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.031000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 50, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.032000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb2fd0>", "describer_id": 50}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.033000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 50, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.035000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 50, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.035000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbc17980>", "describer_id": 50}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.036000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 50, "id": 1, "source": "___from_numpy(L['ydata'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.048000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 51, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.049000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb76620>", "describer_id": 51}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.050000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 51, "id": 0, "source": "___from_numpy(L['___stack0'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.052000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 51, "size": 2400}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.053000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbb76030>", "describer_id": 51}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.053000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 51, "id": 1, "source": "___from_numpy(L['ydata'])"}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.122000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1, "has_payload": "3a786cab1201bc76a5286d93b64e502a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 138005303065888)           
	| +- GuardManager: source=L['sigma'], accessed_by=DictGetItemGuardAccessor(sigma)
	| | +- ID_MATCH: ___check_obj_id(L['sigma'], 111055818751712)                
	| +- GuardManager: source=L['check_finite'], accessed_by=DictGetItemGuardAccessor(check_finite)
	| | +- ID_MATCH: ___check_obj_id(L['check_finite'], 111055818658720)         
	| +- GuardManager: source=L['ydata'], accessed_by=DictGetItemGuardAccessor(ydata)
	| | +- GuardManager: source=___from_numpy(L['ydata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ydata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ydata']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['ydata']), ___from_numpy(L['___stack0']))
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=___from_numpy(L['___stack0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['_wrap_func'], accessed_by=DictGetItemGuardAccessor(_wrap_func)
	| | | +- GuardManager: source=G['_wrap_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_wrap_func'].__code__, 138005372313184)  
	| | +- GuardManager: source=G['_lightweight_memoizer'], accessed_by=DictGetItemGuardAccessor(_lightweight_memoizer)
	| | | +- GuardManager: source=G['_lightweight_memoizer'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_lightweight_memoizer'].__code__, 138005366732080)
	
V0401 21:32:45.124000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1, "has_payload": "51b391a7e46b4c30c41939b1d13040a2"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165124340.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.126000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1, "has_payload": "3b4133ff422d1e9205420a09874883e0"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165126443.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.128000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "20/0", "frame_key": "34", "co_name": "torch_dynamo_resume_in_curve_fit_at_940", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 940, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543165.0208418, "entire_frame_compile_time_s": 0.1034092903137207, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: setattr [<class 'torch._dynamo.variables.functions.NestedUserFunctionVariable'>, <class 'torch._dynamo.variables.constant.ConstantVariable'>, <class 'torch._dynamo.variables.constant.ConstantVariable'>] False"], "dynamo_time_before_restart_s": 0.017466306686401367, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 20, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.131000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 989, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}]}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.133000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0, "has_payload": "6914bdc5ac3c6265b0c281d0d71a8830"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165133652.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.134000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0, "has_payload": "7f6fd3f2484ab8844b46e7e3b67b95d3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165133652.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.144000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 52, "size": 2400}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.145000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbc29d60>", "describer_id": 52}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.145000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 52, "id": 0, "source": "___from_numpy(L['ydata'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.152000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 52, "size": 16}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.153000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb643840>", "describer_id": 52}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.154000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 52, "id": 1, "source": "___from_numpy(L['p0'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.180000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 53, "size": 2400}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.181000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbc9630>", "describer_id": 53}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.182000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 53, "id": 0, "source": "___from_numpy(L['ydata'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.186000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 53, "size": 16}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.187000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbcacb0>", "describer_id": 53}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.188000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 53, "id": 1, "source": "___from_numpy(L['p0'])"}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.281000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1, "has_payload": "a1ea574a4caeabd4e6439b562414493c"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['n'], accessed_by=DictGetItemGuardAccessor(n)
	| | +- EQUALS_MATCH: L['n'] == 2                                                 
	| +- GuardManager: source=L['jac'], accessed_by=DictGetItemGuardAccessor(jac)
	| | +- ID_MATCH: ___check_obj_id(L['jac'], 111055818751712)                  
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: not L['kwargs']                                             
	| +- GuardManager: source=L['method'], accessed_by=DictGetItemGuardAccessor(method)
	| | +- EQUALS_MATCH: L['method'] == 'lm'                                         
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- GuardManager: source=L['___stack0'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['___stack0'].__code__, 138005366804752)   
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['ydata']))
	| +- GuardManager: source=L['ydata'], accessed_by=DictGetItemGuardAccessor(ydata)
	| | +- GuardManager: source=___from_numpy(L['ydata']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['ydata']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['ydata']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['leastsq'], accessed_by=DictGetItemGuardAccessor(leastsq)
	| | | +- GuardManager: source=G['leastsq'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['leastsq'].__code__, 111056999990016)     
	| | +- GuardManager: source=G['__builtins_dict___71'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___71)
	| | | +- GuardManager: source=G['__builtins_dict___71']['callable'], accessed_by=DictGetItemGuardAccessor(callable)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___71']['callable'], 138006094273552)
	
V0401 21:32:45.282000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1, "has_payload": "7bf7e23a0caa3484cf212c541dfb6198"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165282178.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.283000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1, "has_payload": "cfdaa9a000cc687da21f40139982517a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165283275.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.284000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "21/0", "frame_key": "36", "co_name": "torch_dynamo_resume_in_curve_fit_at_989", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 989, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 15, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543165.1336424, "entire_frame_compile_time_s": 0.14842724800109863, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands"], "dynamo_time_before_restart_s": 0.030752897262573242, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 21, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.289000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}]}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.290000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0, "has_payload": "3b16768df65a3b4a30a91b613e4c90c1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165290688.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.291000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0, "has_payload": "2bb8ca79f993e8793153f97b17233c2a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165290688.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.301000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 54, "size": 16}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.302000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbb05a0>", "describer_id": 54}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.303000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 54, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 22, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.317000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 55, "size": 16}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.318000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb642990>", "describer_id": 55}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.319000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 55, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.325000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_x0_": [2], "wrapped_asarray": [2], "x0": [2]}}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "741c37af5591f03c34ee26b5e0d9e3bd"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_x0_: "f64[2][1]cpu"):
	        l_x0_ = L_x0_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:422 in leastsq, code: x0 = asarray(x0).flatten()
	        wrapped_asarray: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_asarray(l_x0_);  l_x0_ = None
	        x0: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_flatten(wrapped_asarray);  wrapped_asarray = None
	        return (x0,)
	        
V0401 21:32:45.326000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "60c1f3e2e695f32a3c62e637b2456546"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165326683.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.327000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "ab841415ed072290921f24300e17a69a"}
	{
	"name": "backend_compile",
	"ts": 1743543165326683.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.330000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "ea046f36eb655b2759365fcc004ac600"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165330361.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.340000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "7131d01c24ed02c36e4dd3a1bc5908c9"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	        return (arg0_1,)
	        
V0401 21:32:45.343000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "49d422caffd15497a83bfa5a3043d983"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165343414.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.348000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "ba5fe621962a2f13658b07c1aabd29d3"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165345507.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.350000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "46defcb7b3b5204cec6734544f9682c8"}
	{
	"name": "inductor_compile",
	"ts": 1743543165345507.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.355000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "ace49728a7c0a172bfd6a88b638bb750"}
	{
	"name": "inductor_compile",
	"ts": 1743543165355248.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.357000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "99b802aad735036dd55fa4f83980e02d"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165357260.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.358000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "6480dc5f909a30efe84fc27ad4e5faec"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165358502.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.363000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "3ebd998ab548bf5e1a8ad108f54a3c37"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165363716.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.364000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "d3ed92fc522fd403e6013c2e6ef76eb6"}
	{
	"name": "backend_compile",
	"ts": 1743543165364915.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.366000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "376af1b442aead376e8ca1e85f541d99"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165366024.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.405000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "594b1eab163731119c2a160be0b33ae3"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['args'], accessed_by=DictGetItemGuardAccessor(args)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 111055818760256)                
	| | +- LENGTH_CHECK: not L['args']                                               
	| +- GuardManager: source=L['func'], accessed_by=DictGetItemGuardAccessor(func)
	| | +- GuardManager: source=L['func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['func'].__code__, 138005366804752)        
	| +- GuardManager: source=L['x0'], accessed_by=DictGetItemGuardAccessor(x0)
	| | +- GuardManager: source=___from_numpy(L['x0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['x0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['x0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['asarray'], accessed_by=DictGetItemGuardAccessor(asarray)
	| | | +- ID_MATCH: ___check_obj_id(G['asarray'], 138006086609920)              
	| | +- GuardManager: source=G['_check_func'], accessed_by=DictGetItemGuardAccessor(_check_func)
	| | | +- GuardManager: source=G['_check_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_check_func'].__code__, 111056999968096) 
	| | +- GuardManager: source=G['__builtins_dict___74'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___74)
	| | | +- GuardManager: source=G['__builtins_dict___74']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___74']['len'], 138006094275152)
	| | | +- GuardManager: source=G['__builtins_dict___74']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___74']['tuple'], 111055818760256)
	| | | +- GuardManager: source=G['__builtins_dict___74']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___74']['isinstance'], 138006094274832)
	
V0401 21:32:45.406000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "e254d4695d0171dafa51c588a7190d24"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165406632.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.408000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1, "has_payload": "0b9fd6d8923a91d6b4e029c4236b2577"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165408595.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 10,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.409000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "22/0", "frame_key": "37", "co_name": "leastsq", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 292, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543165.290676, "entire_frame_compile_time_s": 0.11585617065429688, "backend_compile_time_s": 0.03816652297973633, "inductor_compile_time_s": 0.006564617156982422, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands"], "dynamo_time_before_restart_s": 0.01815176010131836, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 22, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.413000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 21, "name": "_check_func", "filename": 6}]}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.413000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0, "has_payload": "54640d1b574cb64403adfe469b6e729b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165413625.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.414000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0, "has_payload": "c5b9494f17083c2d187d46a335a0f0ad"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165413625.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.419000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 57, "size": 16}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.420000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbc29540>", "describer_id": 57}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.421000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 57, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.429000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 58, "size": 16}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.430000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb516d50>", "describer_id": 58}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.431000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 58, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.435000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_x0_": [2], "wrapped_getitem": [2]}}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "3d9625ce453d85332b40846605cfc418"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_x0_: "f64[2][1]cpu"):
	        l_x0_ = L_x0_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:23 in _check_func, code: res = atleast_1d(thefunc(*((x0[:numinputs],) + args)))
	        wrapped_getitem: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_getitem(l_x0_, slice(None, 2, None));  l_x0_ = None
	        return (wrapped_getitem,)
	        
V0401 21:32:45.436000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "e031e2114f003d901dbfa3a8aaf1b2a8"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165436556.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.437000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "5cb31d436fece5ad9d045db3ae67c65e"}
	{
	"name": "backend_compile",
	"ts": 1743543165436556.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.439000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "276f7aafad391fb69175a5ca31ba193c"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165439404.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.449000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "662fa58c3d349b3d2bc1776ae6494e47"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:23 in _check_func, code: res = atleast_1d(thefunc(*((x0[:numinputs],) + args)))
	        slice_1: "f64[2][1]cpu" = torch.ops.aten.slice.Tensor(arg0_1, 0, 0, 2);  arg0_1 = None
	        return (slice_1,)
	        
V0401 21:32:45.450000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "20ecc090d58f7611d380a74d68c6fba1"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165450019.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.451000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "8566f198f7db84465c95e745871154f0"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165451863.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.452000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "974d37e8b126c97bc1c6a892149610ea"}
	{
	"name": "inductor_compile",
	"ts": 1743543165451863.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.458000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/fp/cfp2ilt7vffar6bq4ic47nuai6tnrhuul3apzay3uqo3c4pkmd7t.py"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "ff0acf423232e489ae3de0b92d360976"}
	# AOT ID: ['12_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    return (arg0_1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:45.459000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "1b5cddf4d01f5b5b5b7829e26be8df77"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543165459399.5,
	"args": {
	"key": "fwkysxunwbmfh7xpdqnoc25mqewdv4fg4fgxhl63th4atggugobz",
	"components": [
	"[eotweswpn6tdut4xjsrwsmwo33n4g63uq2ujhpdsvi3xe4jmsf5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    slice_1 = torch.ops.aten.slice.Tensor(arg0_1, 0, 0, 2);  arg0_1 = None\n    return (slice_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[scxqngv652g7lmdzehboht3ccivqzlxyzcibzxvt52nw4kxiwuj] fx_kwargs[user_visible_outputs]: {'slice_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 5296711,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:45.460000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "a796028ed53933f94b4ed61bc15cb83f"}
	{"key": "fwkysxunwbmfh7xpdqnoc25mqewdv4fg4fgxhl63th4atggugobz", "components": ["[eotweswpn6tdut4xjsrwsmwo33n4g63uq2ujhpdsvi3xe4jmsf5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    slice_1 = torch.ops.aten.slice.Tensor(arg0_1, 0, 0, 2);  arg0_1 = None\n    return (slice_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[scxqngv652g7lmdzehboht3ccivqzlxyzcibzxvt52nw4kxiwuj] fx_kwargs[user_visible_outputs]: {'slice_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 5296711, "cache_state": "hit"}
V0401 21:32:45.462000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "176f44453a08301b061895cf1c7f0ba5"}
	{
	"name": "inductor_compile",
	"ts": 1743543165462032.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.462000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "4abac569df1c4f69829cdf16c721689c"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165462820.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.464000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "3ac877ba1a4daaeb38eb75b199fef714"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165463985.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.467000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "4e2303e6b210824a099484b4d5bd7cd5"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165467370.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.468000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "1cf8ebe19da36a0fbf69b961d4febf93"}
	{
	"name": "backend_compile",
	"ts": 1743543165468757.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.469000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "27e52babc09084111d3c7ef2d141d0bb"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165469620.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.479000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "b561eba758206372b65bc187b322fe34"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['args'], accessed_by=DictGetItemGuardAccessor(args)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 111055818760256)                
	| | +- LENGTH_CHECK: not L['args']                                               
	| +- GuardManager: source=L['thefunc'], accessed_by=DictGetItemGuardAccessor(thefunc)
	| | +- GuardManager: source=L['thefunc'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['thefunc'].__code__, 138005366804752)     
	| +- GuardManager: source=L['numinputs'], accessed_by=DictGetItemGuardAccessor(numinputs)
	| | +- EQUALS_MATCH: L['numinputs'] == 2                                         
	| +- GuardManager: source=L['x0'], accessed_by=DictGetItemGuardAccessor(x0)
	| | +- GuardManager: source=___from_numpy(L['x0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['x0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['x0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['atleast_1d'], accessed_by=DictGetItemGuardAccessor(atleast_1d)
	| | | +- ID_MATCH: ___check_obj_id(G['atleast_1d'], 138005632934448)           
	
V0401 21:32:45.480000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "ac2bc8adc6b818a60422900edcd690d5"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165480604.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.481000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1, "has_payload": "9b115e7ec3454529c0f0b27173742344"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165481362.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 11,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.482000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "23/0", "frame_key": "38", "co_name": "_check_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 21, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 10, "shape_env_guard_count": 0, "graph_op_count": 1, "graph_node_count": 3, "graph_input_count": 1, "start_time": 1743543165.4136136, "entire_frame_compile_time_s": 0.06668639183044434, "backend_compile_time_s": 0.032134056091308594, "inductor_compile_time_s": 0.01008915901184082, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Dynamic control flow is not supported at the moment. Please use functorch.experimental.control_flow.cond to explicitly capture the control flow. For more information about this error, see: https://pytorch.org/docs/main/generated/exportdb/index.html#cond-operands"], "dynamo_time_before_restart_s": 0.011202096939086914, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 23, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.484000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}]}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.485000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "083d2cd5947afe5d0b40365a116f5d88"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165485560.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.486000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "eb8c585bddfc447bb29c802f41a8d6fa"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165485560.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.489000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 60, "size": 16}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.490000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbba9fe0>", "describer_id": 60}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.491000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 60, "id": 0, "source": "___from_numpy(L['params'])"}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.495000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_params_": [2], "wrapped_eq": [2], "wrapped_all": []}}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "4f5440b3b1824eaaf02610b2c1eb2ae3"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_params_: "f64[2][1]cpu"):
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        wrapped_eq: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_eq(None, l_params_);  l_params_ = None
	        wrapped_all: "b8[][]cpu" = torch__dynamo_utils_wrapped_all(wrapped_eq);  wrapped_eq = None
	        return (wrapped_all,)
	        
V0401 21:32:45.496000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "f5cba9ba624d5467d260f3495f39c3fc"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165496516.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.497000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "2eb676805d806a07b11a017461649848"}
	{
	"name": "backend_compile",
	"ts": 1743543165496516.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.499000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "d47d490062ce9eba3ac245092f85685f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165499429.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.513000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "3ff372be4afe2733f214453ae3569ae7"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        full: "b8[2][1]cpu" = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False)
	        logical_not: "b8[2][1]cpu" = torch.ops.aten.logical_not.default(full);  full = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.dims(logical_not);  logical_not = None
	        logical_not_1: "b8[][]cpu" = torch.ops.aten.logical_not.default(any_1);  any_1 = None
	        return (logical_not_1,)
	        
V0401 21:32:45.514000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "d8af737f972a5d1b9c1a61cad134e893"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165513846.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.516000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "54b0823705a9d293c7e2228b4b6fdfb2"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165516627.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.517000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "29b0eca8339840552783bdd368070c43"}
	{
	"name": "inductor_compile",
	"ts": 1743543165516627.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.525000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/q5/cq5wfl2yqwi4le4rmfqq2y4pyn42e4qf7spssmca6py4ottabw2n.py"}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "2090f44d633c618d126ad013c3bd287a"}
	# AOT ID: ['13_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_all_0 = async_compile.cpp_pybinding(['bool*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(bool* in_out_ptr0)
	{
	    auto out_ptr0 = in_out_ptr0;
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = static_cast<bool>(true);
	                tmp_acc0 = tmp_acc0 || tmp0;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	    {
	        auto tmp0 = out_ptr0[static_cast<int64_t>(0L)];
	        auto tmp1 = !tmp0;
	        in_out_ptr0[static_cast<int64_t>(0L)] = tmp1;
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    buf1 = buf0; del buf0  # reuse
	    cpp_fused_all_0(buf1)
	    return (buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:45.526000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "d19d8660eac6bdd5d22356559c97f373"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543165526335.2,
	"args": {
	"key": "ff4kynrazp4b7vy6kbhgasuju7t34d7crvkb6eeokypc2is6exml",
	"components": [
	"[pf766mtcrjcjiazes3g7xrt2s7i6e7amn6isktw3bzfloau65xn] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False);  full = None\n    full_default = torch.ops.aten.full.default([2], True, dtype = torch.bool, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    any_1 = torch.ops.aten.any.dims(full_default);  full_default = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2241340438,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:45.527000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "b648851298b6a9bc59c02c7c954dc131"}
	{"key": "ff4kynrazp4b7vy6kbhgasuju7t34d7crvkb6eeokypc2is6exml", "components": ["[pf766mtcrjcjiazes3g7xrt2s7i6e7amn6isktw3bzfloau65xn] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full = torch.ops.aten.full.default([2], False, dtype = torch.bool, device = device(type='cpu'), pin_memory = False);  full = None\n    full_default = torch.ops.aten.full.default([2], True, dtype = torch.bool, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    any_1 = torch.ops.aten.any.dims(full_default);  full_default = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2241340438, "cache_state": "hit"}
V0401 21:32:45.528000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "cc4ca7ab5ea97acf7e168e24601bfa9c"}
	{
	"name": "inductor_compile",
	"ts": 1743543165528614.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.529000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "6edc118d0fdafa6a30171ce28e20e3a5"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165529366.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.530000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "e626b311b7b546718ab6d21bd7f58869"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165530552.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.533000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "d73831be5f12dd713fe77f8b9f86ade2"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165533597.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.534000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "d236a7b349bc4e1fb7d7d9ac9ae1881a"}
	{
	"name": "backend_compile",
	"ts": 1743543165534323.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.535000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "db6e6025e6a442d9ebecb75f37c537ea"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165535146.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.544000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "ef5ae195283cab7a51b94ee5afc5a0ac"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].last_params, 111055818751712)
	| | +- GuardManager: source=L['_memoized_func'].skip_lookup, accessed_by=GetAttrGuardAccessor(skip_lookup)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].skip_lookup, 111055818658752)
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].all, accessed_by=GetAttrGuardAccessor(all)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].all, 138005633278064)               
	
V0401 21:32:45.545000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "1a5ce66b5d0b571cda2f8541cdeda812"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165545272.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.546000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0, "has_payload": "80ff72f394e94fed593ebd991f96940a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165546129.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 12,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.547000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "24/0", "frame_key": "39", "co_name": "_memoized_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 515, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543165.4855173, "entire_frame_compile_time_s": 0.05961894989013672, "backend_compile_time_s": 0.0377199649810791, "inductor_compile_time_s": 0.011906623840332031, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 24, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.549000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "_check_func", "filename": 6}, {"line": 519, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}]}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.549000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0, "has_payload": "5debdcde4f53b53aee37d8587b211557"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165549842.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.550000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0, "has_payload": "805cab7e5878b04b9d4fd38196164e2c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165549842.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.554000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 62, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.554000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb79a120>", "describer_id": 62}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.555000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 62, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.557000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 62, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.558000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb9272a0>", "describer_id": 62}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.559000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 62, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.561000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 62, "size": 16}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.561000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbca260>", "describer_id": 62}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.562000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 62, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.576000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 63, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.577000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb90b980>", "describer_id": 63}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.578000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 63, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.580000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 63, "size": 2400}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.581000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb925b30>", "describer_id": 63}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.581000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 63, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.583000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 63, "size": 16}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.584000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbc2b7a0>", "describer_id": 63}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.585000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 63, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.595000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_f_closure_1_cell_contents": [300], "l_f_closure_2_cell_contents": [300], "l_params_": [2], "getitem": [], "getitem_1": [], "wrapped_mul": [], "wrapped_pow": [300], "wrapped_mul_1": [300], "wrapped_add": [300], "wrapped_truediv": [300], "val": [300], "wrapped_copy": [2]}}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "209f55592c558cee921ee7d582103b9b"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_f_closure_1_cell_contents: "f64[300][1]cpu", L_f_closure_2_cell_contents: "f64[300][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_f_closure_1_cell_contents = L_f_closure_1_cell_contents
	        l_f_closure_2_cell_contents = L_f_closure_2_cell_contents
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        getitem: "f64[][]cpu" = l_params_[0]
	        getitem_1: "f64[][]cpu" = l_params_[1]
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        wrapped_mul: "f64[][]cpu" = torch__dynamo_utils_wrapped_mul(2, getitem_1);  getitem_1 = None
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_f_closure_1_cell_contents, wrapped_mul);  l_f_closure_1_cell_contents = wrapped_mul = None
	        wrapped_mul_1: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_mul_1(getitem, wrapped_pow);  getitem = wrapped_pow = None
	        wrapped_add: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_add(1.0, wrapped_mul_1);  wrapped_mul_1 = None
	        wrapped_truediv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_truediv(1.0, wrapped_add);  wrapped_add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        val: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_sub(wrapped_truediv, l_f_closure_2_cell_contents);  wrapped_truediv = l_f_closure_2_cell_contents = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:527 in torch_dynamo_resume_in__memoized_func_at_519, code: _memoized_func.last_params = np.copy(params)
	        wrapped_copy: "f64[2][1]cpu" = torch__dynamo_utils_wrapped_copy(l_params_);  l_params_ = None
	        return (wrapped_copy, val)
	        
V0401 21:32:45.596000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "16d6f56f10605dae33f8d1d2c7e5c989"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165596339.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.597000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "d61308c8755905d3348e71f7cedd0852"}
	{
	"name": "backend_compile",
	"ts": 1743543165596339.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.601000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "2b771421a5be16a65a22e8f8782523fb"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165601608.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.630000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "6d87fd1e965b7dfb9d3b08028667c404"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[300][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 1)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        mul: "f64[][]cpu" = torch.ops.aten.mul.Tensor(lift_fresh_copy, select_1);  lift_fresh_copy = select_1 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None
	        div: "f64[300][1]cpu" = torch.ops.aten.div.Tensor(1.0, add);  add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        sub: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:527 in torch_dynamo_resume_in__memoized_func_at_519, code: _memoized_func.last_params = np.copy(params)
	        clone: "f64[2][1]cpu" = torch.ops.aten.clone.default(arg2_1);  arg2_1 = None
	        return (clone, sub)
	        
V0401 21:32:45.631000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "6d73b60d974fc63eaa87505c58f8e971"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165630685.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.634000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "a399577aef09a4e2cdbb54d3f3f33f0b"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165633959.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.634000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "08af7351dce8a9fef66e70c30f837257"}
	{
	"name": "inductor_compile",
	"ts": 1743543165633959.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.644000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/7r/c7roapbkgtvgf2d2szvit2awwmzo2or7qrswygzfvmio4bhhcs3b.py"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "bd645d3dd92d61184aba96a36e695974"}
	# AOT ID: ['14_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_clone_div_lift_fresh_mul_pow_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'const double*', 'double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       const double* in_ptr2,
	                       double* out_ptr0,
	                       double* out_ptr1)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            out_ptr0[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp13 = at::vec::VectorizedN<double,2>::loadu(in_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = at::vec::VectorizedN<double,2>(tmp4);
	            auto tmp6 = tmp1.pow(tmp5);
	            auto tmp7 = at::vec::VectorizedN<double,2>(tmp0);
	            auto tmp8 = tmp7 * tmp6;
	            auto tmp9 = static_cast<double>(1.0);
	            auto tmp10 = at::vec::VectorizedN<double,2>(tmp9);
	            auto tmp11 = tmp10 + tmp8;
	            auto tmp12 = tmp10 / tmp11;
	            auto tmp14 = tmp12 - tmp13;
	            tmp14.store(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = std::pow(tmp1, tmp4);
	            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
	            auto tmp7 = static_cast<double>(1.0);
	            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
	            auto tmp9 = tmp7 / tmp8;
	            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
	            out_ptr1[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (300, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((2, ), (1, ), torch.float64)
	    buf1 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_add_clone_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    del arg2_1
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:45.645000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "46c4e1557558604958410f9847ac7a2e"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543165645143.8,
	"args": {
	"key": "fwfwm3gcqnr4cvyzyoh2avpgdjkbl2zk7ymh4eijjhtpkoavhcvx",
	"components": [
	"[qflafsz2p4czhhersyocmxtxngfqw2jhm2baxmkqbkxhzskr6mz] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1)\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    clone = torch.ops.aten.clone.default(arg2_1);  arg2_1 = None\n    return (clone, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[36g36hx2xkznopwzdieqcx5gxtoradcuz4vsqu53gvtlrapu5aw] fx_kwargs[user_visible_outputs]: {'clone': None, 'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2031973205,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:45.646000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "399036bbb0b94f797a52c5daecbcb130"}
	{"key": "fwfwm3gcqnr4cvyzyoh2avpgdjkbl2zk7ymh4eijjhtpkoavhcvx", "components": ["[qflafsz2p4czhhersyocmxtxngfqw2jhm2baxmkqbkxhzskr6mz] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1)\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    clone = torch.ops.aten.clone.default(arg2_1);  arg2_1 = None\n    return (clone, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[36g36hx2xkznopwzdieqcx5gxtoradcuz4vsqu53gvtlrapu5aw] fx_kwargs[user_visible_outputs]: {'clone': None, 'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2031973205, "cache_state": "hit"}
V0401 21:32:45.647000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "e07ad07c66dd1d87cf564a3798f96eb7"}
	{
	"name": "inductor_compile",
	"ts": 1743543165647461.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.648000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "34622ba61f4a5d3127e105104c7a4701"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165648194.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.649000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "7fbce10eda2caf7ea600592b556a8f3d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165649362.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.652000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "d02286e6f8911e07dcc1e637de995bc5"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165652923.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.653000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "b80989be8641999e21925d3442976a53"}
	{
	"name": "backend_compile",
	"ts": 1743543165653701.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.654000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "baf29f5d0c03b845b787cf2c037065b0"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165654462.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.666000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "f5b4cd9436455d3a555b2ed103f3f50a"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 138005367243024)           
	| | +- GuardManager: source=L['f'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | +- GuardManager: source=L['f'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['f'].__closure__[0].cell_contents.__code__, 138005303065888)
	| | | +- GuardManager: source=L['f'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- GuardManager: source=L['f'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[1].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[1].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[1].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['f'].__closure__[1].cell_contents), ___from_numpy(L['f'].__closure__[2].cell_contents))
	| | | +- GuardManager: source=L['f'].__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- GuardManager: source=L['f'].__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[2].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[2].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[2].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].last_params, 111055818751712)
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].copy, accessed_by=GetAttrGuardAccessor(copy)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].copy, 138005630025584)              
	
V0401 21:32:45.667000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "1ab2b86fa191dfa4526522145a0f36f3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165667293.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.668000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1, "has_payload": "3ad97487ed9559deead8acc6b8164277"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165668145.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.669000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "25/0", "frame_key": "40", "co_name": "torch_dynamo_resume_in__memoized_func_at_519", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 519, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 14, "shape_env_guard_count": 0, "graph_op_count": 9, "graph_node_count": 13, "graph_input_count": 3, "start_time": 1743543165.549781, "entire_frame_compile_time_s": 0.11733150482177734, "backend_compile_time_s": 0.057297706604003906, "inductor_compile_time_s": 0.01342630386352539, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.022506237030029297, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 25, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.671000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "_check_func", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}, {"line": 527, "name": "torch_dynamo_resume_in__memoized_func_at_527", "filename": 6}]}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.671000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0, "has_payload": "ef10f026383c3c82b4045023d25c9dac"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165671877.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.672000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0, "has_payload": "2325ce33116a9a381fb7b592280e7fd0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165671877.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.676000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 65, "size": 2400}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.676000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb529ea0>", "describer_id": 65}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.677000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 65, "id": 0, "source": "___from_numpy(L['val'])"}, "frame_id": 26, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.681000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 66, "size": 2400}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.681000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5a7250>", "describer_id": 66}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.682000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 66, "id": 0, "source": "___from_numpy(L['val'])"}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.692000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1, "has_payload": "b6b845ac8273388b3cdb9b2a230dbb65"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| +- GuardManager: source=L['val'], accessed_by=DictGetItemGuardAccessor(val)
	| | +- GuardManager: source=___from_numpy(L['val']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['val']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['val']), '_dynamo_dynamic_indices') == False
	
V0401 21:32:45.693000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1, "has_payload": "689a358bb97314057880578a15ef1cc3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165693209.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.694000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1, "has_payload": "f12773218adb6722d3b5b63f4a10c0a1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165694061.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.695000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "26/0", "frame_key": "41", "co_name": "torch_dynamo_resume_in__memoized_func_at_527", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 527, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543165.671841, "entire_frame_compile_time_s": 0.021264076232910156, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.005614042282104492, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 26, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.696000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "_check_func", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}, {"line": 527, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}, {"line": 528, "name": "torch_dynamo_resume_in__memoized_func_at_528", "filename": 6}]}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.697000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "7b4e934ae226b0ced3b50607404eb73a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165697380.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.698000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "8d6ce7f6f1950982b30b4372ae61e606"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165697380.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.700000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 67, "size": 2400}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.701000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5285a0>", "describer_id": 67}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.702000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 67, "id": 0, "source": "___from_numpy(L['val'])"}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.704000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "b893f2cc10fbd95e7a4a66452d2859d9"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165704288.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.704000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0, "has_payload": "846e7b08e6cc7efee2a97292d72bfa61"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165704906.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.705000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "27/0", "frame_key": "42", "co_name": "torch_dynamo_resume_in__memoized_func_at_528", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 528, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543165.6973703, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.008390426635742188, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 27, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.707000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 23, "name": "torch_dynamo_resume_in__check_func_at_23", "filename": 6}]}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.708000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "f5baf36ebb6897f40cc04eaa1f537cdc"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165708460.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.709000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "948932296d3dae410647778c4c69c8ac"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165708460.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.712000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 68, "size": 2400}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.713000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb924780>", "describer_id": 68}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.714000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 68, "id": 0, "source": "___from_numpy(L['___stack1'])"}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.716000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "8c972903324158590dffb5cace59e4e0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165716709.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.717000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0, "has_payload": "42373594e9e9f41982a8b047347776da"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165717340.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.718000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "28/0", "frame_key": "43", "co_name": "torch_dynamo_resume_in__check_func_at_23", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 23, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543165.7084334, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "TODO: add support for ndarray.dtype", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "fail_user_frame_lineno": 38, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.009899377822875977, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 28, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.723000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}]}, "frame_id": 29, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.724000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 0, "has_payload": "3bc28db51f7260a8cbe0b0a7013f567a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165724139.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.725000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 0, "has_payload": "dc2efe49cf0581122bf7a9d331b4eeb1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165724139.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.738000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 70, "size": 16}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.739000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5eb7f0>", "describer_id": 70}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.741000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 70, "id": 0, "source": "___from_numpy(L['x0'])"}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.781000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1, "has_payload": "f2fb99174bf986f83732bb928d3dfcd1"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['n'], accessed_by=DictGetItemGuardAccessor(n)
	| | +- EQUALS_MATCH: L['n'] == 2                                                 
	| +- GuardManager: source=L['Dfun'], accessed_by=DictGetItemGuardAccessor(Dfun)
	| | +- ID_MATCH: ___check_obj_id(L['Dfun'], 111055818751712)                 
	| +- GuardManager: source=L['args'], accessed_by=DictGetItemGuardAccessor(args)
	| | +- TYPE_MATCH: ___check_type_id(L['args'], 111055818760256)                
	| | +- LENGTH_CHECK: not L['args']                                               
	| +- GuardManager: source=L['diag'], accessed_by=DictGetItemGuardAccessor(diag)
	| | +- ID_MATCH: ___check_obj_id(L['diag'], 111055818751712)                 
	| +- GuardManager: source=L['ftol'], accessed_by=DictGetItemGuardAccessor(ftol)
	| | +- EQUALS_MATCH: L['ftol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['func'], accessed_by=DictGetItemGuardAccessor(func)
	| | +- GuardManager: source=L['func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['func'].__code__, 138005366804752)        
	| +- GuardManager: source=L['gtol'], accessed_by=DictGetItemGuardAccessor(gtol)
	| | +- EQUALS_MATCH: L['gtol'] == 0.0                                            
	| +- GuardManager: source=L['xtol'], accessed_by=DictGetItemGuardAccessor(xtol)
	| | +- EQUALS_MATCH: L['xtol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['epsfcn'], accessed_by=DictGetItemGuardAccessor(epsfcn)
	| | +- ID_MATCH: ___check_obj_id(L['epsfcn'], 111055818751712)               
	| +- GuardManager: source=L['factor'], accessed_by=DictGetItemGuardAccessor(factor)
	| | +- EQUALS_MATCH: L['factor'] == 100                                          
	| +- GuardManager: source=L['maxfev'], accessed_by=DictGetItemGuardAccessor(maxfev)
	| | +- EQUALS_MATCH: L['maxfev'] == 0                                            
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 111055818760256)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 2                                    
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- TYPE_MATCH: ___check_type_id(L['___stack0'][0], 111055818760256)        
	| | | +- LENGTH_CHECK: len(L['___stack0'][0]) == 1                                 
	| | | +- GuardManager: source=L['___stack0'][0][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- EQUALS_MATCH: L['___stack0'][0][0] == 300                                 
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- ID_MATCH: ___check_obj_id(L['___stack0'][1], 138005714219040)         
	| +- GuardManager: source=L['full_output'], accessed_by=DictGetItemGuardAccessor(full_output)
	| | +- EQUALS_MATCH: L['full_output'] == 1                                       
	| +- GuardManager: source=L['x0'], accessed_by=DictGetItemGuardAccessor(x0)
	| | +- GuardManager: source=___from_numpy(L['x0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['x0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['x0']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['finfo'], accessed_by=DictGetItemGuardAccessor(finfo)
	| | | +- ID_MATCH: ___check_obj_id(G['finfo'], 111056941391040)                
	| | +- GuardManager: source=G['_minpack'], accessed_by=DictGetItemGuardAccessor(_minpack)
	| | | +- ID_MATCH: ___check_obj_id(G['_minpack'], 138005367158432)             
	| | | +- GuardManager: source=G['_minpack']._lmdif, accessed_by=GetAttrGuardAccessor(_lmdif)
	| | | | +- ID_MATCH: ___check_obj_id(G['_minpack']._lmdif, 138005367158752)      
	
V0401 21:32:45.782000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1, "has_payload": "bc71b62002794959173c4538e74db00d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165782834.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.783000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1, "has_payload": "cd5dfe8cc561e05803a417058bef9733"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165783663.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 13,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.784000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "29/0", "frame_key": "44", "co_name": "torch_dynamo_resume_in_leastsq_at_426", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 426, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 25, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543165.7241275, "entire_frame_compile_time_s": 0.05860447883605957, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Graph break due to unsupported builtin scipy.optimize._minpack._lmdif. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph."], "dynamo_time_before_restart_s": 0.006449460983276367, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 29, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:45.786000 13985 torch/_dynamo/guards.py:2817] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "d28cb01371a502b1d6e79dcda8d0a098"}
	[
	"24/0: ___check_obj_id(L['_memoized_func'].last_params, 111055818751712)"
	]
V0401 21:32:45.787000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}]}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.788000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "3ee52ee4ecf883cc9210b85be7b0f0d8"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165788426.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.789000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "1b64c639bfe5173e5172c772ac677023"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165788426.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.793000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 71, "size": 16}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.793000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb409fe0>", "describer_id": 71}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.794000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 71, "id": 0, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.796000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 71, "size": 16}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.797000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4099a0>", "describer_id": 71}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.798000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 71, "id": 1, "source": "___from_numpy(L['params'])"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.802000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_memoized_func_last_params": [2], "l_params_": [2], "wrapped_eq": [2], "wrapped_all": []}}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "73b6a6bc86473a0cac176805ec557312"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_memoized_func_last_params: "f64[2][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_memoized_func_last_params = L_memoized_func_last_params
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        wrapped_eq: "b8[2][1]cpu" = torch__dynamo_utils_wrapped_eq(l_memoized_func_last_params, l_params_);  l_memoized_func_last_params = l_params_ = None
	        wrapped_all: "b8[][]cpu" = torch__dynamo_utils_wrapped_all(wrapped_eq);  wrapped_eq = None
	        return (wrapped_all,)
	        
V0401 21:32:45.803000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "8a773da2b7f2e178abdcb4aa3fcb69ce"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165803613.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.804000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "2b51f9a58da2e0c9f824bc1b9af9ab06"}
	{
	"name": "backend_compile",
	"ts": 1743543165803613.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.806000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "1c44bb132049d8d30d78843a2609b2f4"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165806820.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.821000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "2f46f8cc4583d303690a2c0c213887cb"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu", arg1_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:519 in _memoized_func, code: if np.all(_memoized_func.last_params == params):
	        eq: "b8[2][1]cpu" = torch.ops.aten.eq.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None
	        logical_not: "b8[2][1]cpu" = torch.ops.aten.logical_not.default(eq);  eq = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.dims(logical_not);  logical_not = None
	        logical_not_1: "b8[][]cpu" = torch.ops.aten.logical_not.default(any_1);  any_1 = None
	        return (logical_not_1,)
	        
V0401 21:32:45.822000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "ffb8af4b87f333e023ddb72f50cc932c"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165822207.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.824000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "3815256f11cb4fe069d399abcc94f8c8"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165824232.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.824000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "012838f3d23acf2e629e2b5189d8c9b4"}
	{
	"name": "inductor_compile",
	"ts": 1743543165824232.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.833000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/7f/c7fumvbspyk4ft7v32ry3fkyy36pnlvdhpdaxqvwoyftvdbs2yv2.py"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "c34934ec506ade5679fe49b736ffadd6"}
	# AOT ID: ['15_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_all_eq_0 = async_compile.cpp_pybinding(['bool*', 'const double*', 'const double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(bool* in_out_ptr0,
	                       const double* in_ptr0,
	                       const double* in_ptr1)
	{
	    auto out_ptr0 = in_out_ptr0;
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	                auto tmp2 = tmp0 == tmp1;
	                auto tmp3 = !tmp2;
	                tmp_acc0 = tmp_acc0 || tmp3;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	    {
	        auto tmp0 = out_ptr0[static_cast<int64_t>(0L)];
	        auto tmp1 = !tmp0;
	        in_out_ptr0[static_cast<int64_t>(0L)] = tmp1;
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    buf1 = buf0; del buf0  # reuse
	    cpp_fused_all_eq_0(buf1, arg0_1, arg1_1)
	    del arg0_1
	    del arg1_1
	    return (buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:45.834000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "033661bc912e322cfc724b6ecc5c2f20"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543165833791.2,
	"args": {
	"key": "fz3tibsiysm6l7g7br74ma7iwd5qmdmol555vebgvnafgtakoxu7",
	"components": [
	"[cig7omdtbkjqq5aareag4of6n6f7qadmqzvdyodfxbrarlu5g7n] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    logical_not = torch.ops.aten.logical_not.default(eq);  eq = None\n    any_1 = torch.ops.aten.any.dims(logical_not);  logical_not = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2111348231,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:45.835000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "601a13ff23a9bec850b8cf421d221134"}
	{"key": "fz3tibsiysm6l7g7br74ma7iwd5qmdmol555vebgvnafgtakoxu7", "components": ["[cig7omdtbkjqq5aareag4of6n6f7qadmqzvdyodfxbrarlu5g7n] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    eq = torch.ops.aten.eq.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None\n    logical_not = torch.ops.aten.logical_not.default(eq);  eq = None\n    any_1 = torch.ops.aten.any.dims(logical_not);  logical_not = None\n    logical_not_1 = torch.ops.aten.logical_not.default(any_1);  any_1 = None\n    return (logical_not_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xtlzsr63uqouauuprr3alt7g7hkkt76a5pmomj2jwjjeyyckxqv] fx_kwargs[user_visible_outputs]: {'logical_not_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2111348231, "cache_state": "hit"}
V0401 21:32:45.836000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "518db60dc4970789ddaa2f0bbc09d173"}
	{
	"name": "inductor_compile",
	"ts": 1743543165836395.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.837000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "9d1b6021d0d2f8b7e6577b8061c0b82e"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165837065.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.838000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "aed56970597181475d329bc4850d6ce8"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165838335.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.841000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "a5d3507a1563a486f48373208ad92548"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165841832.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.842000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "448831555d93d76958e725ec7c1ca717"}
	{
	"name": "backend_compile",
	"ts": 1743543165842588.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.843000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "a99544d2950d886d165aeb175c1bb35a"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165843617.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.849000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "55a47ec521e7d728a26306e55003c1da"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| | +- GuardManager: source=L['_memoized_func'].skip_lookup, accessed_by=GetAttrGuardAccessor(skip_lookup)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].skip_lookup, 111055818658752)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- GuardManager: source=___from_numpy(L['_memoized_func'].last_params), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['_memoized_func'].last_params), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['_memoized_func'].last_params), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['_memoized_func'].last_params))
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].all, accessed_by=GetAttrGuardAccessor(all)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].all, 138005633278064)               
	
V0401 21:32:45.849000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "92837fb99eee54ca5ea808905d6970af"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165849915.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.850000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0, "has_payload": "679c0c461165ad8261af1b2f697577f5"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165850744.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.851000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "24/1", "frame_key": "45", "co_name": "_memoized_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 515, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 11, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 5, "graph_input_count": 2, "start_time": 1743543165.788398, "entire_frame_compile_time_s": 0.0614168643951416, "backend_compile_time_s": 0.03891491889953613, "inductor_compile_time_s": 0.01204061508178711, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 24, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.853000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 519, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}]}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.854000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "cd9106d329cd27ec856add9896017dd2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165854124.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.855000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "07c08b99cfb0906e87d320b57bb7c5aa"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165854124.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.857000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "109f57ff05e420b6965d0542f18fe36d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165857743.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.858000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0, "has_payload": "79c1f5a1f19cb28f854013d84c619994"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165858329.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.859000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "30/0", "frame_key": "46", "co_name": "torch_dynamo_resume_in__memoized_func_at_519", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 519, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543165.854115, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.005143165588378906, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 30, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.860000 13985 torch/_dynamo/guards.py:2817] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0, "has_payload": "51eb1396d9192df694f43373369a0661"}
	[
	"25/0: ___check_obj_id(L['_memoized_func'].last_params, 111055818751712)"
	]
V0401 21:32:45.862000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 519, "name": "torch_dynamo_resume_in__memoized_func_at_519", "filename": 6}]}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.862000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0, "has_payload": "6e0ef93f755122a1dff4ef60056b74db"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165862595.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.863000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0, "has_payload": "8dd505f4ed51e542822ec73a9f9e8c96"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165862595.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.866000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 74, "size": 16}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.867000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5f1680>", "describer_id": 74}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.867000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 74, "id": 0, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 25, "frame_compile_id": 1, "attempt": 0}
V0401 21:32:45.871000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 75, "size": 16}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:32:45.872000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb40a710>", "describer_id": 75}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:32:45.872000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 75, "id": 0, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:32:45.882000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1, "has_payload": "46c51dece66bad8cbfa2846acd747706"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- GuardManager: source=___from_numpy(L['_memoized_func'].last_params), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['_memoized_func'].last_params), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['_memoized_func'].last_params), '_dynamo_dynamic_indices') == False
	
V0401 21:32:45.883000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1, "has_payload": "b3d67f4dccdf25999484437a75de5b7b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165883174.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.884000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1, "has_payload": "21ca422abfdfab5fa5c724fa2f064a6c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165884020.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 14,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.885000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "25/1", "frame_key": "47", "co_name": "torch_dynamo_resume_in__memoized_func_at_519", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 519, "cache_size": 1, "accumulated_cache_size": 1, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543165.8625844, "entire_frame_compile_time_s": 0.02051520347595215, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Unknown fail_and_restart_analysis"], "dynamo_time_before_restart_s": 0.005443096160888672, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 25, "frame_compile_id": 1, "attempt": 1}
V0401 21:32:45.886000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}, {"line": 522, "name": "torch_dynamo_resume_in__memoized_func_at_522", "filename": 6}]}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.887000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "05df099ef71c28e5f66cc9052dab582a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165887211.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.888000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "00b9acf8cf1665b1c35db1f9ecd9481f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165887211.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.891000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 76, "size": 2400}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.892000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5f23a0>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.893000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.895000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 76, "size": 2400}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.895000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb528460>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.896000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.898000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 76, "size": 16}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.899000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb40a0d0>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.900000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.907000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 76, "size": 16}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.908000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5eb520>", "describer_id": 76}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.909000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 76, "id": 5, "source": "___from_numpy(L['_memoized_func'].last_params)"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.913000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_f_closure_1_cell_contents": [300], "l_f_closure_2_cell_contents": [300], "l_params_": [2], "getitem": [], "getitem_1": [], "wrapped_mul": [], "wrapped_pow": [300], "wrapped_mul_1": [300], "wrapped_add": [300], "wrapped_truediv": [300], "val": [300]}}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "97d252891cb86f7dc40ba7016106a293"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_f_closure_1_cell_contents: "f64[300][1]cpu", L_f_closure_2_cell_contents: "f64[300][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_f_closure_1_cell_contents = L_f_closure_1_cell_contents
	        l_f_closure_2_cell_contents = L_f_closure_2_cell_contents
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        getitem: "f64[][]cpu" = l_params_[0]
	        getitem_1: "f64[][]cpu" = l_params_[1];  l_params_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        wrapped_mul: "f64[][]cpu" = torch__dynamo_utils_wrapped_mul(2, getitem_1);  getitem_1 = None
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_f_closure_1_cell_contents, wrapped_mul);  l_f_closure_1_cell_contents = wrapped_mul = None
	        wrapped_mul_1: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_mul_1(getitem, wrapped_pow);  getitem = wrapped_pow = None
	        wrapped_add: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_add(1.0, wrapped_mul_1);  wrapped_mul_1 = None
	        wrapped_truediv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_truediv(1.0, wrapped_add);  wrapped_add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        val: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_sub(wrapped_truediv, l_f_closure_2_cell_contents);  wrapped_truediv = l_f_closure_2_cell_contents = None
	        return (val,)
	        
V0401 21:32:45.914000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "93793dc0ef9b545ef5a6f80240d4c331"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165914411.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.915000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "daf8441141561a5c9c45579f11655c17"}
	{
	"name": "backend_compile",
	"ts": 1743543165914411.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.919000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "dd6f831c1cb557bafc6c08367eb0c9af"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165919234.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.944000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "41cd24a03980b1c9303fa3bb07bbaf3a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[300][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        mul: "f64[][]cpu" = torch.ops.aten.mul.Tensor(lift_fresh_copy, select_1);  lift_fresh_copy = select_1 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None
	        div: "f64[300][1]cpu" = torch.ops.aten.div.Tensor(1.0, add);  add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        sub: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None
	        return (sub,)
	        
V0401 21:32:45.945000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "5bd145daf162e8943b119cd7fb3274c2"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165945333.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.948000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "8c7af4f08764464bc190724b8a9676c8"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165948201.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.948000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "ea24c390df64c6cca742a61a6407a1e4"}
	{
	"name": "inductor_compile",
	"ts": 1743543165948201.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.959000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/ar/carqk2ql6j3s35ha36vpi7bhf3u4fub6jcd75oip6pratc6wk5po.py"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "bbc4b287ccbb00bb12b7165fa99cb0c6"}
	# AOT ID: ['16_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_div_lift_fresh_mul_pow_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'const double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       const double* in_ptr2,
	                       double* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp13 = at::vec::VectorizedN<double,2>::loadu(in_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = at::vec::VectorizedN<double,2>(tmp4);
	            auto tmp6 = tmp1.pow(tmp5);
	            auto tmp7 = at::vec::VectorizedN<double,2>(tmp0);
	            auto tmp8 = tmp7 * tmp6;
	            auto tmp9 = static_cast<double>(1.0);
	            auto tmp10 = at::vec::VectorizedN<double,2>(tmp9);
	            auto tmp11 = tmp10 + tmp8;
	            auto tmp12 = tmp10 / tmp11;
	            auto tmp14 = tmp12 - tmp13;
	            tmp14.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = std::pow(tmp1, tmp4);
	            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
	            auto tmp7 = static_cast<double>(1.0);
	            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
	            auto tmp9 = tmp7 / tmp8;
	            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (300, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_add_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0)
	    del arg0_1
	    del arg1_1
	    del arg2_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:45.960000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "55b8ef9b4c6030b0f5e9b94ee1c12690"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543165960369.0,
	"args": {
	"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5",
	"components": [
	"[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2072073507,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:45.962000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "b2e1720821fdb1b98ae07236016837cf"}
	{"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5", "components": ["[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2072073507, "cache_state": "hit"}
V0401 21:32:45.963000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "0dee7bc0b28e8d4e975e45513610901c"}
	{
	"name": "inductor_compile",
	"ts": 1743543165963153.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.964000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "acd00dce54f00e02fc78c680101d68b6"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543165963952.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.965000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "31895dff3b211e2537408b0dec983299"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543165965247.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.968000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "17d2db130c1a2c60b2e9045884aef79c"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543165968298.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.969000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "a518348a33c2ea540949ba9f555354d8"}
	{
	"name": "backend_compile",
	"ts": 1743543165969115.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.970000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "edbc99e83533fdc52affb0ed66c40e63"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543165969924.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.976000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "c405663e9305d63b0ef5a940bb633ee5"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 138005367243024)           
	| | +- GuardManager: source=L['f'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | +- GuardManager: source=L['f'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['f'].__closure__[0].cell_contents.__code__, 138005303065888)
	| | | +- GuardManager: source=L['f'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- GuardManager: source=L['f'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[1].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[1].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[1].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['_memoized_func'].last_params), ___from_numpy(L['f'].__closure__[1].cell_contents), ___from_numpy(L['f'].__closure__[2].cell_contents))
	| | | +- GuardManager: source=L['f'].__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- GuardManager: source=L['f'].__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[2].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[2].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[2].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| | +- GuardManager: source=L['_memoized_func'].last_params, accessed_by=GetAttrGuardAccessor(last_params)
	| | | +- GuardManager: source=___from_numpy(L['_memoized_func'].last_params), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['_memoized_func'].last_params), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['_memoized_func'].last_params), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:32:45.977000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "d7463e638a3998cb877472bf5963f711"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165977488.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.978000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0, "has_payload": "4b97605cdf2748d9d9d3eb59fb613010"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165978354.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 15,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.979000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "31/0", "frame_key": "48", "co_name": "torch_dynamo_resume_in__memoized_func_at_522", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 522, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 8, "graph_node_count": 12, "graph_input_count": 3, "start_time": 1743543165.887201, "entire_frame_compile_time_s": 0.09021162986755371, "backend_compile_time_s": 0.05463767051696777, "inductor_compile_time_s": 0.01487278938293457, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 31, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:45.980000 13985 torch/_dynamo/guards.py:2817] {"artifact": {"name": "recompile_reasons", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "a17909eb69e090c62b88cf75141904de"}
	[
	"24/1: ___check_obj_id(L['_memoized_func'].skip_lookup, 111055818658752)",
	"24/0: ___check_obj_id(L['_memoized_func'].last_params, 111055818751712)"
	]
V0401 21:32:45.982000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 515, "name": "_memoized_func", "filename": 6}]}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.982000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "80484c5cd1a849fc731a4a0cdf4f1a06"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543165982808.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.983000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "9c669f25921aa9ade425b4a2d3f71da5"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543165982808.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:45.987000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 78, "size": 2400}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.987000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb40c730>", "describer_id": 78}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.988000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 78, "id": 0, "source": "___from_numpy(L['f'].__closure__[1].cell_contents)"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.990000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 78, "size": 2400}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.991000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5a5ae0>", "describer_id": 78}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.992000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 78, "id": 1, "source": "___from_numpy(L['f'].__closure__[2].cell_contents)"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.994000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 78, "size": 16}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.994000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cbbca0d0>", "describer_id": 78}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:45.995000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 78, "id": 2, "source": "___from_numpy(L['params'])"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:46.005000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_f_closure_1_cell_contents": [300], "l_f_closure_2_cell_contents": [300], "l_params_": [2], "getitem": [], "getitem_1": [], "wrapped_mul": [], "wrapped_pow": [300], "wrapped_mul_1": [300], "wrapped_add": [300], "wrapped_truediv": [300], "wrapped_sub": [300]}}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "b86e84ae184ef9563a10f3b1220b4abc"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_f_closure_1_cell_contents: "f64[300][1]cpu", L_f_closure_2_cell_contents: "f64[300][1]cpu", L_params_: "f64[2][1]cpu"):
	        l_f_closure_1_cell_contents = L_f_closure_1_cell_contents
	        l_f_closure_2_cell_contents = L_f_closure_2_cell_contents
	        l_params_ = L_params_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        getitem: "f64[][]cpu" = l_params_[0]
	        getitem_1: "f64[][]cpu" = l_params_[1];  l_params_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        wrapped_mul: "f64[][]cpu" = torch__dynamo_utils_wrapped_mul(2, getitem_1);  getitem_1 = None
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_f_closure_1_cell_contents, wrapped_mul);  l_f_closure_1_cell_contents = wrapped_mul = None
	        wrapped_mul_1: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_mul_1(getitem, wrapped_pow);  getitem = wrapped_pow = None
	        wrapped_add: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_add(1.0, wrapped_mul_1);  wrapped_mul_1 = None
	        wrapped_truediv: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_truediv(1.0, wrapped_add);  wrapped_add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        wrapped_sub: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_sub(wrapped_truediv, l_f_closure_2_cell_contents);  wrapped_truediv = l_f_closure_2_cell_contents = None
	        return (wrapped_sub,)
	        
V0401 21:32:46.006000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "2d3e172f295346ed88f1292c1f09d9c9"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166006415.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.007000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "55ba9246551733cdc97c056ebe3926be"}
	{
	"name": "backend_compile",
	"ts": 1743543166006415.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.011000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "53b5d3694627cf1dc21fdfe868e40350"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166011121.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.036000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "41cd24a03980b1c9303fa3bb07bbaf3a"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[300][1]cpu", arg1_1: "f64[300][1]cpu", arg2_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1401 in curve, code: return 1.0 / (1.0 + a * x ** (2 * b))
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        mul: "f64[][]cpu" = torch.ops.aten.mul.Tensor(lift_fresh_copy, select_1);  lift_fresh_copy = select_1 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None
	        mul_1: "f64[300][1]cpu" = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None
	        add: "f64[300][1]cpu" = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None
	        div: "f64[300][1]cpu" = torch.ops.aten.div.Tensor(1.0, add);  add = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:541 in func_wrapped, code: return func(xdata, *params) - ydata
	        sub: "f64[300][1]cpu" = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None
	        return (sub,)
	        
V0401 21:32:46.037000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "fd6387d33144083b3cdb91f3a9522b50"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166037110.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.040000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "dd212f042d88f5d90ab6d364ec5f8663"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166039940.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.040000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "dfe6e393ca947408e9430ecc720a6fc0"}
	{
	"name": "inductor_compile",
	"ts": 1743543166039940.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.047000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/ar/carqk2ql6j3s35ha36vpi7bhf3u4fub6jcd75oip6pratc6wk5po.py"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "bbc4b287ccbb00bb12b7165fa99cb0c6"}
	# AOT ID: ['16_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_div_lift_fresh_mul_pow_sub_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'const double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       const double* in_ptr2,
	                       double* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp13 = at::vec::VectorizedN<double,2>::loadu(in_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = at::vec::VectorizedN<double,2>(tmp4);
	            auto tmp6 = tmp1.pow(tmp5);
	            auto tmp7 = at::vec::VectorizedN<double,2>(tmp0);
	            auto tmp8 = tmp7 * tmp6;
	            auto tmp9 = static_cast<double>(1.0);
	            auto tmp10 = at::vec::VectorizedN<double,2>(tmp9);
	            auto tmp11 = tmp10 + tmp8;
	            auto tmp12 = tmp10 / tmp11;
	            auto tmp14 = tmp12 - tmp13;
	            tmp14.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp2 = in_ptr0[static_cast<int64_t>(1L)];
	            auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	            auto tmp3 = static_cast<double>(2.0);
	            auto tmp4 = decltype(tmp3)(tmp3 * tmp2);
	            auto tmp5 = std::pow(tmp1, tmp4);
	            auto tmp6 = decltype(tmp0)(tmp0 * tmp5);
	            auto tmp7 = static_cast<double>(1.0);
	            auto tmp8 = decltype(tmp7)(tmp7 + tmp6);
	            auto tmp9 = tmp7 / tmp8;
	            auto tmp11 = decltype(tmp9)(tmp9 - tmp10);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp11;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1, arg2_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (300, ), (1, ))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    assert_size_stride(arg2_1, (2, ), (1, ))
	    buf0 = empty_strided_cpu((300, ), (1, ), torch.float64)
	    cpp_fused_add_div_lift_fresh_mul_pow_sub_0(arg2_1, arg0_1, arg1_1, buf0)
	    del arg0_1
	    del arg1_1
	    del arg2_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    arg2_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1, arg2_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:46.048000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "6c424ffaf9199226e60ed5227b1c1151"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543166048463.2,
	"args": {
	"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5",
	"components": [
	"[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2072073507,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:46.049000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "b2e1720821fdb1b98ae07236016837cf"}
	{"key": "fgc2x4xut7zwoqbiprt425smdnlr34p3fpv4i4cczvj3hb5fjox5", "components": ["[6q6phnm7bwrxcryeuje6ck6deyivlcazx2j3qojb23ehg3lnoxv] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1, arg2_1):\n    select = torch.ops.aten.select.int(arg2_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg2_1, 0, 1);  arg2_1 = None\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    mul = torch.ops.aten.mul.Tensor(full_default, select_1);  full_default = select_1 = None\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg0_1, mul);  arg0_1 = mul = None\n    mul_1 = torch.ops.aten.mul.Tensor(select, pow_1);  select = pow_1 = None\n    add = torch.ops.aten.add.Tensor(1.0, mul_1);  mul_1 = None\n    div = torch.ops.aten.div.Tensor(1.0, add);  add = None\n    sub = torch.ops.aten.sub.Tensor(div, arg1_1);  div = arg1_1 = None\n    return (sub,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[2]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[iunpxy4ybsqsgwngjmvnfdt5zbijzizonmwezlqbmwxdjhrtnau] fx_kwargs[user_visible_outputs]: {'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2072073507, "cache_state": "hit"}
V0401 21:32:46.050000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "6d37e87dad132cf665e1f25d2101b7fa"}
	{
	"name": "inductor_compile",
	"ts": 1743543166050805.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.051000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "3225acf69e398f3f7c6385786692ea2e"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166051577.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.052000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "80a53ab92cfa15049c82f40ef30c4f6d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166052731.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.056000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "ec792863d9bf9aac08a761d239cd7bc2"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166056320.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.057000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "11500cfe08f4e2474f755620710e62ff"}
	{
	"name": "backend_compile",
	"ts": 1743543166057113.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.057000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "54097b17a34c4178c026cd1eb32f3b14"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166057904.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.064000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "1ac60bddb7a47da8a5d06f5ff6b99439"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['f'], accessed_by=DictGetItemGuardAccessor(f)
	| | +- GuardManager: source=L['f'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['f'].__code__, 138005367243024)           
	| | +- GuardManager: source=L['f'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | +- GuardManager: source=L['f'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=L['f'].__closure__[0].cell_contents.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(L['f'].__closure__[0].cell_contents.__code__, 138005303065888)
	| | | +- GuardManager: source=L['f'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- GuardManager: source=L['f'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[1].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[1].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[1].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['params']), ___from_numpy(L['f'].__closure__[1].cell_contents), ___from_numpy(L['f'].__closure__[2].cell_contents))
	| | | +- GuardManager: source=L['f'].__closure__[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- GuardManager: source=L['f'].__closure__[2].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | +- GuardManager: source=___from_numpy(L['f'].__closure__[2].cell_contents), accessed_by=PythonLambdaGuardAccessor
	| | | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['f'].__closure__[2].cell_contents), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | | +- NO_HASATTR: hasattr(___from_numpy(L['f'].__closure__[2].cell_contents), '_dynamo_dynamic_indices') == False
	| | | | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['_memoized_func'], accessed_by=DictGetItemGuardAccessor(_memoized_func)
	| | +- GuardManager: source=L['_memoized_func'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].__code__, 138005366804752)
	| | +- GuardManager: source=L['_memoized_func'].skip_lookup, accessed_by=GetAttrGuardAccessor(skip_lookup)
	| | | +- ID_MATCH: ___check_obj_id(L['_memoized_func'].skip_lookup, 111055818658720)
	| +- GuardManager: source=L['params'], accessed_by=DictGetItemGuardAccessor(params)
	| | +- GuardManager: source=___from_numpy(L['params']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['params']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['params']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	
V0401 21:32:46.065000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "d21af7302bc71189158d4b1103ce37df"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166065501.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.066000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0, "has_payload": "e1f2e5c4551a5b5b3955acaec6bbe8fb"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166066369.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 16,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.067000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "24/2", "frame_key": "49", "co_name": "_memoized_func", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 515, "cache_size": 2, "accumulated_cache_size": 2, "guard_count": 12, "shape_env_guard_count": 0, "graph_op_count": 8, "graph_node_count": 12, "graph_input_count": 3, "start_time": 1743543165.9827735, "entire_frame_compile_time_s": 0.08261990547180176, "backend_compile_time_s": 0.050631046295166016, "inductor_compile_time_s": 0.010790109634399414, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 24, "frame_compile_id": 2, "attempt": 0}
V0401 21:32:46.070000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}]}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.071000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0, "has_payload": "db4cdc478fbb0b585a55730413a16c9b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166071299.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.072000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0, "has_payload": "66bae5e159f6eef3b30a96f589a1be0e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166071299.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.080000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 80, "size": 8}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.081000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.int32", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5a4be0>", "describer_id": 80}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.082000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 80, "id": 0, "source": "___from_numpy(L['___stack0'][1]['ipvt'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.085000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 80, "size": 4800}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.086000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 300], "is_leaf": true, "stride": [300, 1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb5f1630>", "describer_id": 80}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.087000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 80, "id": 3, "source": "___from_numpy(L['___stack0'][1]['fjac'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.101000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 81, "size": 8}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.102000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.int32", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4b3c00>", "describer_id": 81}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.103000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 81, "id": 0, "source": "___from_numpy(L['___stack0'][1]['ipvt'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.106000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 81, "size": 4800}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.107000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 3, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 300], "is_leaf": true, "stride": [300, 1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4b3160>", "describer_id": 81}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.108000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 81, "id": 3, "source": "___from_numpy(L['___stack0'][1]['fjac'])"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.115000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_1_ipvt_": [2], "l_stack0_1_fjac_": [2, 300], "perm": [2], "wrapped_transpose": [300, 2], "wrapped_getitem": [2, 2], "r": [2, 2]}}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "3910dae55555ff32cfabebdc5a84883a"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_1_ipvt_: "i32[2][1]cpu", L_stack0_1_fjac_: "f64[2, 300][300, 1]cpu"):
	        l_stack0_1_ipvt_ = L_stack0_1_ipvt_
	        l_stack0_1_fjac_ = L_stack0_1_fjac_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:489 in torch_dynamo_resume_in_leastsq_at_439, code: perm = retval[1]['ipvt'] - 1
	        perm: "i32[2][1]cpu" = torch__dynamo_utils_wrapped_sub(l_stack0_1_ipvt_, 1);  l_stack0_1_ipvt_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:491 in torch_dynamo_resume_in_leastsq_at_439, code: r = triu(transpose(retval[1]['fjac'])[:n, :])
	        wrapped_transpose: "f64[300, 2][1, 300]cpu" = torch__dynamo_utils_wrapped_transpose(l_stack0_1_fjac_);  l_stack0_1_fjac_ = None
	        wrapped_getitem: "f64[2, 2][1, 300]cpu" = torch__dynamo_utils_wrapped_getitem(wrapped_transpose, (slice(None, 2, None), slice(None, None, None)));  wrapped_transpose = None
	        r: "f64[2, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_triu(wrapped_getitem);  wrapped_getitem = None
	        return (r, perm)
	        
V0401 21:32:46.116000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "36b7d304d4916e45aaabd11da04b9977"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166116080.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.116000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "36d6ab73eeb0f63dc0483c3578a96f51"}
	{
	"name": "backend_compile",
	"ts": 1743543166116080.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.120000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "ba6d87042a90f0dcb6656efe4e69395c"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166120103.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.149000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "5262070eaaa061788d0744a9ef045ba4"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i32[2][1]cpu", arg1_1: "f64[2, 300][300, 1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:489 in torch_dynamo_resume_in_leastsq_at_439, code: perm = retval[1]['ipvt'] - 1
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "i32[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        sub: "i32[2][1]cpu" = torch.ops.aten.sub.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:491 in torch_dynamo_resume_in_leastsq_at_439, code: r = triu(transpose(retval[1]['fjac'])[:n, :])
	        permute: "f64[300, 2][1, 300]cpu" = torch.ops.aten.permute.default(arg1_1, [1, 0]);  arg1_1 = None
	        slice_1: "f64[2, 2][1, 300]cpu" = torch.ops.aten.slice.Tensor(permute, 0, 0, 2);  permute = None
	        slice_2: "f64[2, 2][1, 300]cpu" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 9223372036854775807);  slice_1 = None
	        iota: "i64[2][1]cpu" = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)
	        unsqueeze: "i64[1, 2][2, 1]cpu" = torch.ops.aten.unsqueeze.default(iota, -2);  iota = None
	        iota_1: "i64[2][1]cpu" = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)
	        unsqueeze_1: "i64[2, 1][1, 1]cpu" = torch.ops.aten.unsqueeze.default(iota_1, -1);  iota_1 = None
	        sub_1: "i64[2, 2][2, 1]cpu" = torch.ops.aten.sub.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None
	        ge: "b8[2, 2][2, 1]cpu" = torch.ops.aten.ge.Scalar(sub_1, 0);  sub_1 = None
	        scalar_tensor: "f64[][]cpu" = torch.ops.aten.scalar_tensor.default(0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'))
	        where: "f64[2, 2][2, 1]cpu" = torch.ops.aten.where.self(ge, slice_2, scalar_tensor);  ge = slice_2 = scalar_tensor = None
	        return (where, sub)
	        
V0401 21:32:46.150000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "2f5f4dc0553b8e29d8b640b16b17db70"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166149712.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.153000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "32f2f96980d9c72bfe7c4aed95d86881"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166153587.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.154000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "9a48036acf4f3eab1007b2421f8e3af1"}
	{
	"name": "inductor_compile",
	"ts": 1743543166153587.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.164000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/yo/cyogko7nrwqotb23uabtpsudbm7n7svnlebxyaukni5ogmmgf3d6.py"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "763e92f5bb4ae5b626560b77f822ac49"}
	# AOT ID: ['18_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_lift_fresh_sub_triu_0 = async_compile.cpp_pybinding(['const double*', 'const int32_t*', 'double*', 'int32_t*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const int32_t* in_ptr1,
	                       double* out_ptr0,
	                       int32_t* out_ptr1)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            #pragma GCC ivdep
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(2L); x1+=static_cast<int64_t>(1L))
	            {
	                auto tmp4 = in_ptr0[static_cast<int64_t>(x0 + (300L*x1))];
	                auto tmp0 = x1 + ((-1L)*x0);
	                auto tmp1 = c10::convert<int64_t>(tmp0);
	                auto tmp2 = static_cast<int64_t>(0);
	                auto tmp3 = tmp1 >= tmp2;
	                auto tmp5 = static_cast<double>(0.0);
	                auto tmp6 = tmp3 ? tmp4 : tmp5;
	                out_ptr0[static_cast<int64_t>(x1 + (2L*x0))] = tmp6;
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr1[static_cast<int64_t>(x0)];
	            auto tmp1 = static_cast<int32_t>(1);
	            auto tmp2 = decltype(tmp0)(tmp0 - tmp1);
	            out_ptr1[static_cast<int64_t>(x0)] = tmp2;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    assert_size_stride(arg1_1, (2, 300), (300, 1))
	    buf0 = empty_strided_cpu((2, 2), (2, 1), torch.float64)
	    buf1 = empty_strided_cpu((2, ), (1, ), torch.int32)
	    cpp_fused_lift_fresh_sub_triu_0(arg1_1, arg0_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.int32)
	    arg1_1 = rand_strided((2, 300), (300, 1), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:46.165000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "de973e71386e9874ff6931d420c40acf"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543166165020.5,
	"args": {
	"key": "fkco7lv3m6ac6i5piarqgfxdmo6kdvocbjygzntmae4t5phjwwqd",
	"components": [
	"[zsxjvs4u2tzwgkiiod7qsglqnprvvu2zsf7dohtszkhod632hu4] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1, dtype = torch.int32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    permute = torch.ops.aten.permute.default(arg1_1, [1, 0]);  arg1_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(permute, 0, 0, 2);  permute = None\n    iota = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze = torch.ops.aten.unsqueeze.default(iota, -2);  iota = None\n    iota_1 = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(iota_1, -1);  iota_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None\n    ge = torch.ops.aten.ge.Scalar(sub_1, 0);  sub_1 = None\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    where = torch.ops.aten.where.self(ge, slice_1, full_default_1);  ge = slice_1 = full_default_1 = None\n    return (where, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[flokpmchmdzcwbxjrazdrm3ghpakwvxsz5d4vcsewg37j3zkzsb] example_inputs[0]: TensorMetadata(dtype=torch.int32, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[kprzcuvn6cyvzyepuwrnxonr6roucdchb5qz32l4ndpdlhe3fxi] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 300]), stride=(300, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[pqcdrbhudjrcl7i4c7ig4brfd4jva36vaoveljqxkf65opic7kb] fx_kwargs[user_visible_outputs]: {'where': None, 'sub': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 3458077117,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:46.166000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "970859a4ceed7b9bf90a338b83ab02a2"}
	{"key": "fkco7lv3m6ac6i5piarqgfxdmo6kdvocbjygzntmae4t5phjwwqd", "components": ["[zsxjvs4u2tzwgkiiod7qsglqnprvvu2zsf7dohtszkhod632hu4] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 1, dtype = torch.int32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    sub = torch.ops.aten.sub.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    permute = torch.ops.aten.permute.default(arg1_1, [1, 0]);  arg1_1 = None\n    slice_1 = torch.ops.aten.slice.Tensor(permute, 0, 0, 2);  permute = None\n    iota = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze = torch.ops.aten.unsqueeze.default(iota, -2);  iota = None\n    iota_1 = torch.ops.prims.iota.default(2, start = 0, step = 1, dtype = torch.int64, device = device(type='cpu'), requires_grad = False)\n    unsqueeze_1 = torch.ops.aten.unsqueeze.default(iota_1, -1);  iota_1 = None\n    sub_1 = torch.ops.aten.sub.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None\n    ge = torch.ops.aten.ge.Scalar(sub_1, 0);  sub_1 = None\n    full_default_1 = torch.ops.aten.full.default([], 0.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    where = torch.ops.aten.where.self(ge, slice_1, full_default_1);  ge = slice_1 = full_default_1 = None\n    return (where, sub)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[flokpmchmdzcwbxjrazdrm3ghpakwvxsz5d4vcsewg37j3zkzsb] example_inputs[0]: TensorMetadata(dtype=torch.int32, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[kprzcuvn6cyvzyepuwrnxonr6roucdchb5qz32l4ndpdlhe3fxi] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 300]), stride=(300, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[pqcdrbhudjrcl7i4c7ig4brfd4jva36vaoveljqxkf65opic7kb] fx_kwargs[user_visible_outputs]: {'where': None, 'sub': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 3458077117, "cache_state": "hit"}
V0401 21:32:46.167000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "b5e5b2b83fa733a50dfe4c2b6e170589"}
	{
	"name": "inductor_compile",
	"ts": 1743543166167367.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.168000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "56401a9f3b3920af1f888d8accfb314a"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166168142.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.169000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "4dba4da5f5c61e069b60ec5cb979cbd2"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166169285.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.172000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "4c357e8fc3654207ef31595a01deca90"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166172644.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.173000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "11bb522b8fa3834bd26c34e5b13abf80"}
	{
	"name": "backend_compile",
	"ts": 1743543166173383.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.174000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "8122a97e9d5aceb30dc8efd74cc423c7"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166174186.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.214000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "b77d3985837b72d3ac9d15cd3df3bed2"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['ftol'], accessed_by=DictGetItemGuardAccessor(ftol)
	| | +- EQUALS_MATCH: L['ftol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['gtol'], accessed_by=DictGetItemGuardAccessor(gtol)
	| | +- EQUALS_MATCH: L['gtol'] == 0.0                                            
	| +- GuardManager: source=L['xtol'], accessed_by=DictGetItemGuardAccessor(xtol)
	| | +- EQUALS_MATCH: L['xtol'] == 1.49012e-08                                    
	| +- GuardManager: source=L['maxfev'], accessed_by=DictGetItemGuardAccessor(maxfev)
	| | +- EQUALS_MATCH: L['maxfev'] == 600                                          
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 111055818760256)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 3                                    
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- DICT_LENGTH: len(L['___stack0'][1]) == 5                                 
	| | | +- GuardManager: source=L['___stack0'][1]['fvec'], accessed_by=DictGetItemGuardAccessor(fvec)
	| | | +- GuardManager: source=L['___stack0'][1]['nfev'], accessed_by=DictGetItemGuardAccessor(nfev)
	| | | +- GuardManager: source=L['___stack0'][1]['fjac'], accessed_by=DictGetItemGuardAccessor(fjac)
	| | | | +- GuardManager: source=___from_numpy(L['___stack0'][1]['fjac']), accessed_by=PythonLambdaGuardAccessor
	| | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]['fjac']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 300], stride=[300, 1])
	| | | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]['fjac']), '_dynamo_dynamic_indices') == False
	| | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][1]['fjac']), ___from_numpy(L['___stack0'][1]['ipvt']))
	| | | +- GuardManager: source=L['___stack0'][1]['ipvt'], accessed_by=DictGetItemGuardAccessor(ipvt)
	| | | | +- GuardManager: source=___from_numpy(L['___stack0'][1]['ipvt']), accessed_by=PythonLambdaGuardAccessor
	| | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]['ipvt']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int32, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]['ipvt']), '_dynamo_dynamic_indices') == False
	| | | | | +- NO_TENSOR_ALIASING
	| | | +- GuardManager: source=L['___stack0'][1]['qtf'], accessed_by=DictGetItemGuardAccessor(qtf)
	| | +- GuardManager: source=L['___stack0'][2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | +- EQUALS_MATCH: L['___stack0'][2] == 1                                      
	| +- GuardManager: source=L['full_output'], accessed_by=DictGetItemGuardAccessor(full_output)
	| | +- EQUALS_MATCH: L['full_output'] == 1                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['triu'], accessed_by=DictGetItemGuardAccessor(triu)
	| | | +- ID_MATCH: ___check_obj_id(G['triu'], 138005632111792)                 
	| | +- GuardManager: source=G['linalg'], accessed_by=DictGetItemGuardAccessor(linalg)
	| | | +- ID_MATCH: ___check_obj_id(G['linalg'], 138005513724656)               
	| | | +- GuardManager: source=G['linalg'].get_lapack_funcs, accessed_by=GetAttrGuardAccessor(get_lapack_funcs)
	| | | | +- GuardManager: source=G['linalg'].get_lapack_funcs.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['linalg'].get_lapack_funcs.__code__, 138005514362800)
	| | +- GuardManager: source=G['transpose'], accessed_by=DictGetItemGuardAccessor(transpose)
	| | | +- ID_MATCH: ___check_obj_id(G['transpose'], 138005633201712)            
	| | +- GuardManager: source=G['LEASTSQ_SUCCESS'], accessed_by=DictGetItemGuardAccessor(LEASTSQ_SUCCESS)
	| | | +- TYPE_MATCH: ___check_type_id(G['LEASTSQ_SUCCESS'], 111055818730400)     
	| | | +- LENGTH_CHECK: len(G['LEASTSQ_SUCCESS']) == 4                              
	| | | +- GuardManager: source=G['LEASTSQ_SUCCESS'][0], accessed_by=ListGetItemGuardAccessor(0)
	| | | | +- EQUALS_MATCH: G['LEASTSQ_SUCCESS'][0] == 1                                
	| | +- GuardManager: source=G['__builtins_dict___110'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___110)
	| | | +- GuardManager: source=G['__builtins_dict___110']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___110']['len'], 138006094275152)
	| | | +- GuardManager: source=G['__builtins_dict___110']['TypeError'], accessed_by=DictGetItemGuardAccessor(TypeError)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___110']['TypeError'], 111055818712544)
	| | | +- GuardManager: source=G['__builtins_dict___110']['ValueError'], accessed_by=DictGetItemGuardAccessor(ValueError)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___110']['ValueError'], 111055818694080)
	
V0401 21:32:46.215000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "8eefb367664ff537ed3a6d641e74003c"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166215415.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.216000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1, "has_payload": "d868341f6a75cea7e013f156cb95cfc2"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166216247.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.217000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "32/0", "frame_key": "50", "co_name": "torch_dynamo_resume_in_leastsq_at_439", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 439, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 25, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543166.0712674, "entire_frame_compile_time_s": 0.14404749870300293, "backend_compile_time_s": 0.0572361946105957, "inductor_compile_time_s": 0.013701915740966797, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["TODO: add support for ndarray.dtype"], "dynamo_time_before_restart_s": 0.02267742156982422, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 32, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.219000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", 7]}
V0401 21:32:46.220000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 384, "name": "getter", "filename": 7}]}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.221000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "c51dd5fd1ff378a95dd3fecb20d0e8e0"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166220999.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.222000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "fe8343c85fb5af59e8707c9a9afa8530"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166220999.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.225000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 83, "size": 32}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.226000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb927a70>", "describer_id": 83}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.227000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 83, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.229000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "ab3da5a953cdb3413349fb9f82a85323"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166229108.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.231000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0, "has_payload": "3af1e273791f919eaff8cd1187d1392c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166231014.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.232000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "33/0", "frame_key": "51", "co_name": "getter", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "co_firstlineno": 384, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543166.2209895, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "TODO: add support for ndarray.dtype", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "fail_user_frame_lineno": 389, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.011150836944580078, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 33, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.238000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/lapack.py", 8]}
V0401 21:32:46.240000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}, {"line": 884, "name": "get_lapack_funcs", "filename": 8}]}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.241000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0, "has_payload": "b97aed9e8ec57d3cf3999eb2e0ef038a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166241595.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.243000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0, "has_payload": "a60c340ea5f7b628c4f31e7fda6eae98"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166241595.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.265000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 84, "size": 32}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.267000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb40a7b0>", "describer_id": 84}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.268000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 84, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 34, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.283000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1, "has_payload": "e58dfa1b911d2f174b55ff2736325def"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['dtype'], accessed_by=DictGetItemGuardAccessor(dtype)
	| | +- ID_MATCH: ___check_obj_id(L['dtype'], 111055818751712)                
	| +- GuardManager: source=L['ilp64'], accessed_by=DictGetItemGuardAccessor(ilp64)
	| | +- ID_MATCH: ___check_obj_id(L['ilp64'], 111055818658752)                
	| +- GuardManager: source=L['names'], accessed_by=DictGetItemGuardAccessor(names)
	| | +- EQUALS_MATCH: L['names'] == 'trtri'                                       
	| +- GuardManager: source=L['arrays'], accessed_by=DictGetItemGuardAccessor(arrays)
	| | +- TYPE_MATCH: ___check_type_id(L['arrays'], 111055818760256)              
	| | +- LENGTH_CHECK: len(L['arrays']) == 1                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['_clapack'], accessed_by=DictGetItemGuardAccessor(_clapack)
	| | | +- ID_MATCH: ___check_obj_id(G['_clapack'], 111055818751712)             
	| | +- GuardManager: source=G['_flapack'], accessed_by=DictGetItemGuardAccessor(_flapack)
	| | | +- ID_MATCH: ___check_obj_id(G['_flapack'], 138005513726896)             
	| | +- GuardManager: source=G['_get_funcs'], accessed_by=DictGetItemGuardAccessor(_get_funcs)
	| | | +- GuardManager: source=G['_get_funcs'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_get_funcs'].__code__, 111056996729680)  
	| | +- GuardManager: source=G['_lapack_alias'], accessed_by=DictGetItemGuardAccessor(_lapack_alias)
	| | | +- DICT_LENGTH: len(G['_lapack_alias']) == 10                               
	| | | +- GuardManager: source=G['_lapack_alias']['corghr'], accessed_by=DictGetItemGuardAccessor(corghr)
	| | | +- GuardManager: source=G['_lapack_alias']['zorghr'], accessed_by=DictGetItemGuardAccessor(zorghr)
	| | | +- GuardManager: source=G['_lapack_alias']['corghr_lwork'], accessed_by=DictGetItemGuardAccessor(corghr_lwork)
	| | | +- GuardManager: source=G['_lapack_alias']['zorghr_lwork'], accessed_by=DictGetItemGuardAccessor(zorghr_lwork)
	| | | +- GuardManager: source=G['_lapack_alias']['corgqr'], accessed_by=DictGetItemGuardAccessor(corgqr)
	| | | +- GuardManager: source=G['_lapack_alias']['zorgqr'], accessed_by=DictGetItemGuardAccessor(zorgqr)
	| | | +- GuardManager: source=G['_lapack_alias']['cormqr'], accessed_by=DictGetItemGuardAccessor(cormqr)
	| | | +- GuardManager: source=G['_lapack_alias']['zormqr'], accessed_by=DictGetItemGuardAccessor(zormqr)
	| | | +- GuardManager: source=G['_lapack_alias']['corgrq'], accessed_by=DictGetItemGuardAccessor(corgrq)
	| | | +- GuardManager: source=G['_lapack_alias']['zorgrq'], accessed_by=DictGetItemGuardAccessor(zorgrq)
	| | +- GuardManager: source=G['__builtins_dict___115'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___115)
	| | | +- GuardManager: source=G['__builtins_dict___115']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___115']['str'], 111055818777536)
	| | | +- GuardManager: source=G['__builtins_dict___115']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___115']['isinstance'], 138006094274832)
	
V0401 21:32:46.284000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1, "has_payload": "a5833b1cbefb459a40ef27edf289394a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166284226.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.286000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1, "has_payload": "4d3cc8122c384a82a5fb9a8f7b0290a8"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166286166.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.287000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "34/0", "frame_key": "52", "co_name": "get_lapack_funcs", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/lapack.py", "co_firstlineno": 884, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 16, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543166.2415817, "entire_frame_compile_time_s": 0.042531728744506836, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["TODO: add support for ndarray.dtype"], "dynamo_time_before_restart_s": 0.026747465133666992, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 34, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.289000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}, {"line": 401, "name": "getter", "filename": 7}, {"line": 326, "name": "_get_funcs", "filename": 7}]}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.291000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0, "has_payload": "5483fb05725f21c3dabad4ce41aab108"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166290907.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.292000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0, "has_payload": "783dc4265cf06712f956b86068dfd2bc"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166290907.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.306000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 86, "size": 32}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.311000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4a03c0>", "describer_id": 86}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.312000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 86, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 35, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.321000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 1, "has_payload": "6bf2a3c3850f310934d69c6aef1ae160"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166321371.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.322000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 35, "frame_compile_id": 0, "attempt": 1, "has_payload": "fbfb45fc3f44563acf5d116d76abe5e1"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166322002.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.323000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "35/0", "frame_key": "53", "co_name": "_get_funcs", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "co_firstlineno": 326, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543166.2908955, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "reconstruct: NumpyDTypeVariable()", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "fail_user_frame_lineno": 346, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.03205561637878418, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 35, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.326000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 439, "name": "torch_dynamo_resume_in_leastsq_at_439", "filename": 6}, {"line": 401, "name": "getter", "filename": 7}, {"line": 884, "name": "get_lapack_funcs", "filename": 8}, {"line": 259, "name": "find_best_blas_type", "filename": 7}]}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.327000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "672e3c276a0233360c2fa29448ed49ec"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166327341.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.328000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "ccd80edce042865e72d42284bf181c46"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166327341.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.332000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 88, "size": 32}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.333000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb433b60>", "describer_id": 88}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.334000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 88, "id": 0, "source": "___from_numpy(L['arrays'][0])"}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.336000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "8dd008754749aac50ed9b04b7616ae04"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166336636.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.337000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0, "has_payload": "6fca09db3cde89ed2b4f6e6b80f2e66e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166337253.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.338000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "36/0", "frame_key": "54", "co_name": "find_best_blas_type", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "co_firstlineno": 259, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543166.3273306, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "TODO: add support for ndarray.dtype", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/linalg/blas.py", "fail_user_frame_lineno": 304, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.010826349258422852, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 36, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.341000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 292, "name": "leastsq", "filename": 6}, {"line": 426, "name": "torch_dynamo_resume_in_leastsq_at_426", "filename": 6}, {"line": 492, "name": "torch_dynamo_resume_in_leastsq_at_492", "filename": 6}]}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.342000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "e964b03ca17af2540707c992f19533ee"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166342153.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.343000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "4e746983e4430da3836509d5195c644f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166342153.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.348000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "5b359b1eb9771d1f9fdce4d72ad7f321"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166348799.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.349000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0, "has_payload": "3b4d6b7077b1c9a733a91520601d6f3c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166349404.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 17,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.350000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "37/0", "frame_key": "55", "co_name": "torch_dynamo_resume_in_leastsq_at_492", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 492, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543166.3421433, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": "Unsupported", "fail_reason": "call_method UserDefinedObjectVariable(fortran) __call__ [LazyVariableTracker()] {}", "fail_user_frame_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "fail_user_frame_lineno": 495, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.008177995681762695, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 37, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.354000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_1007", "filename": 6}]}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.355000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "13d823784f8b101d1baa7a91c87ef63e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166355328.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.356000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "382f0800994e98fda3911b305b762b4f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166355328.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.366000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 90, "size": 16}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.367000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4a15e0>", "describer_id": 90}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.368000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 90, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.370000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 90, "size": 32}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.371000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4b0c80>", "describer_id": 90}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.372000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 90, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.374000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 90, "size": 2400}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.375000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [300], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb9272a0>", "describer_id": 90}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.375000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 90, "id": 2, "source": "___from_numpy(L['___stack0'][2]['fvec'])"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.385000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_1_": [2, 2], "l_stack0_2_fvec_": [300], "wrapped_pow": [300], "cost": [], "wrapped_isnan": [2, 2], "wrapped_any": []}}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "ec1498e7abfbc0f1a7b0f6d45b769f35"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_1_: "f64[2, 2][2, 1]cpu", L_stack0_2_fvec_: "f64[300][1]cpu"):
	        l_stack0_1_ = L_stack0_1_
	        l_stack0_2_fvec_ = L_stack0_2_fvec_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1010 in torch_dynamo_resume_in_curve_fit_at_1007, code: cost = np.sum(infodict['fvec'] ** 2)
	        wrapped_pow: "f64[300][1]cpu" = torch__dynamo_utils_wrapped_pow(l_stack0_2_fvec_, 2);  l_stack0_2_fvec_ = None
	        cost: "f64[][]cpu" = torch__dynamo_utils_wrapped_sum(wrapped_pow);  wrapped_pow = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1040 in torch_dynamo_resume_in_curve_fit_at_1007, code: if pcov is None or np.isnan(pcov).any():
	        wrapped_isnan: "b8[2, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_isnan(l_stack0_1_);  l_stack0_1_ = None
	        wrapped_any: "b8[][]cpu" = torch__dynamo_utils_wrapped_any(wrapped_isnan);  wrapped_isnan = None
	        return (wrapped_any, cost)
	        
V0401 21:32:46.386000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "41a5eae46120159b301fbeb1177f2980"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166386860.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.387000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0238bdc9e0afcf03330f24c8c8aaa446"}
	{
	"name": "backend_compile",
	"ts": 1743543166386860.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.391000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "d03b45438489d1c20ca8a2fef29d97a4"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166391354.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.410000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "13f1d1972f80612f026a454817609c30"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2, 2][2, 1]cpu", arg1_1: "f64[300][1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1010 in torch_dynamo_resume_in_curve_fit_at_1007, code: cost = np.sum(infodict['fvec'] ** 2)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        pow_1: "f64[300][1]cpu" = torch.ops.aten.pow.Tensor_Tensor(arg1_1, lift_fresh_copy);  arg1_1 = lift_fresh_copy = None
	        sum_1: "f64[][]cpu" = torch.ops.aten.sum.default(pow_1);  pow_1 = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1040 in torch_dynamo_resume_in_curve_fit_at_1007, code: if pcov is None or np.isnan(pcov).any():
	        isnan: "b8[2, 2][2, 1]cpu" = torch.ops.aten.isnan.default(arg0_1);  arg0_1 = None
	        any_1: "b8[][]cpu" = torch.ops.aten.any.default(isnan);  isnan = None
	        return (any_1, sum_1)
	        
V0401 21:32:46.411000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "2ab2256d013f500f368b70fd0323b17d"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166410718.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.413000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "4bde795b66c532ed01a20f138b6e138e"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166413226.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.413000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "82fe04755821edd71d3172fa23307aa7"}
	{
	"name": "inductor_compile",
	"ts": 1743543166413226.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.423000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/br/cbrjwdf4b2s2oqv2gmwz6shtxlxqge65yufuoqox6zgfajmp4beb.py"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "af0d72c4394264d5a3e62f59fa58be39"}
	# AOT ID: ['19_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_any_isnan_lift_fresh_pow_sum_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'bool*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       bool* out_ptr0,
	                       double* out_ptr1)
	{
	    {
	        {
	            bool tmp_acc0 = 0;
	            at::vec::VecMask<float,1> tmp_acc0_vec = at::vec::VecMask<float,1>::from(0);
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(4L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                auto tmp1 = std::isnan(tmp0);
	                tmp_acc0 = tmp_acc0 || tmp1;
	            }
	            tmp_acc0 = tmp_acc0 || !tmp_acc0_vec.all_zero();
	            out_ptr0[static_cast<int64_t>(0L)] = static_cast<bool>(tmp_acc0);
	        }
	    }
	    {
	        {
	            double tmp_acc0 = 0;
	            at::vec::VectorizedN<double,2> tmp_acc0_vec = at::vec::VectorizedN<double,2>(0);
	            for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(296L); x0+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::VectorizedN<double,2>::loadu(in_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	                auto tmp1 = static_cast<double>(2.0);
	                auto tmp2 = at::vec::VectorizedN<double,2>(tmp1);
	                auto tmp3 = tmp0.pow(tmp2);
	                tmp_acc0_vec = tmp_acc0_vec + tmp3;
	            }
	            #pragma omp simd simdlen(4) 
	            for(int64_t x0=static_cast<int64_t>(296L); x0<static_cast<int64_t>(300L); x0+=static_cast<int64_t>(1L))
	            {
	                auto tmp0 = in_ptr1[static_cast<int64_t>(x0)];
	                auto tmp1 = static_cast<double>(2.0);
	                auto tmp2 = std::pow(tmp0, tmp1);
	                tmp_acc0 = tmp_acc0 + tmp2;
	            }
	            tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all<double, 2>([](at::vec::Vectorized<double>& x, at::vec::Vectorized<double>& y) { return x + y; }, tmp_acc0_vec);
	            out_ptr1[static_cast<int64_t>(0L)] = static_cast<double>(tmp_acc0);
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, 2), (2, 1))
	    assert_size_stride(arg1_1, (300, ), (1, ))
	    buf0 = empty_strided_cpu((), (), torch.bool)
	    buf1 = empty_strided_cpu((), (), torch.float64)
	    cpp_fused_any_isnan_lift_fresh_pow_sum_0(arg0_1, arg1_1, buf0, buf1)
	    del arg0_1
	    del arg1_1
	    return (buf0, buf1, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, 2), (2, 1), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((300, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:46.424000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "3998fa40bcaba1a7dcf2dd8f542ec79d"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543166423757.0,
	"args": {
	"key": "f7ibtjcuzkgnds5amxrn2zxytyljrywl7fsf2rj4ylhljku3i57r",
	"components": [
	"[z5xh4zriyhmmkzvbr6iu67ibftwitzm5a2nyu3b7i2tdayqbxk5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    sum_1 = torch.ops.aten.sum.default(pow_1);  pow_1 = None\n    isnan = torch.ops.aten.isnan.default(arg0_1);  arg0_1 = None\n    any_1 = torch.ops.aten.any.default(isnan);  isnan = None\n    return (any_1, sum_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[mw75reeo2vrojk7xzpdms2gvbmgb57pqrm6atjvidfizxwrnaab] fx_kwargs[user_visible_outputs]: {'any_1': None, 'sum_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2011997958,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:46.425000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "35c3ef5fa715b72e3e87076c33f90762"}
	{"key": "f7ibtjcuzkgnds5amxrn2zxytyljrywl7fsf2rj4ylhljku3i57r", "components": ["[z5xh4zriyhmmkzvbr6iu67ibftwitzm5a2nyu3b7i2tdayqbxk5] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 2.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    pow_1 = torch.ops.aten.pow.Tensor_Tensor(arg1_1, full_default);  arg1_1 = full_default = None\n    sum_1 = torch.ops.aten.sum.default(pow_1);  pow_1 = None\n    isnan = torch.ops.aten.isnan.default(arg0_1);  arg0_1 = None\n    any_1 = torch.ops.aten.any.default(isnan);  isnan = None\n    return (any_1, sum_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[qmpdiuwf2armx5jqensqnnzgdrrajjguaaezabublkwodn3zixf] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([300]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[mw75reeo2vrojk7xzpdms2gvbmgb57pqrm6atjvidfizxwrnaab] fx_kwargs[user_visible_outputs]: {'any_1': None, 'sum_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2011997958, "cache_state": "hit"}
V0401 21:32:46.426000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0b686b8afe0af7c15aea70644377221f"}
	{
	"name": "inductor_compile",
	"ts": 1743543166426133.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.426000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "af1ebb358639418449c21eaaba02d4bf"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166426914.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.428000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "b08285e4b09e43a63355f0bd26c6c52a"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166428066.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.431000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "96bbfcce49c666355d072d9b04bf8945"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166431704.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.432000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "5137311991ba5b03cb062203705cccb1"}
	{
	"name": "backend_compile",
	"ts": 1743543166432459.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.433000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "63c923092a353871d18c1c3a3e3dd57e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166433244.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.570000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0a3206f20f50cb80b43f5c4c007a65ec"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 111055818760256)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 5                                    
	| | +- GuardManager: source=L['___stack0'][2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | +- DICT_LENGTH: len(L['___stack0'][2]) == 5                                 
	| | | +- GuardManager: source=L['___stack0'][2]['fvec'], accessed_by=DictGetItemGuardAccessor(fvec)
	| | | | +- GuardManager: source=___from_numpy(L['___stack0'][2]['fvec']), accessed_by=PythonLambdaGuardAccessor
	| | | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][2]['fvec']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[300], stride=[1])
	| | | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][2]['fvec']), '_dynamo_dynamic_indices') == False
	| | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][0]), ___from_numpy(L['___stack0'][1]), ___from_numpy(L['___stack0'][2]['fvec']))
	| | | +- GuardManager: source=L['___stack0'][2]['nfev'], accessed_by=DictGetItemGuardAccessor(nfev)
	| | | +- GuardManager: source=L['___stack0'][2]['fjac'], accessed_by=DictGetItemGuardAccessor(fjac)
	| | | +- GuardManager: source=L['___stack0'][2]['ipvt'], accessed_by=DictGetItemGuardAccessor(ipvt)
	| | | +- GuardManager: source=L['___stack0'][2]['qtf'], accessed_by=DictGetItemGuardAccessor(qtf)
	| | +- GuardManager: source=L['___stack0'][3], accessed_by=TupleGetItemGuardAccessor(3)
	| | | +- EQUALS_MATCH: L['___stack0'][3] == 'Both actual and predicted relative reductions in the sum of squares\n  are at most 0.000000'
	| | +- GuardManager: source=L['___stack0'][4], accessed_by=TupleGetItemGuardAccessor(4)
	| | | +- EQUALS_MATCH: L['___stack0'][4] == 1                                      
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][0]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][0]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][0]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][1]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].sum, accessed_by=GetAttrGuardAccessor(sum)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].sum, 138005633276848)               
	| | | +- GuardManager: source=G['np'].isnan, accessed_by=GetAttrGuardAccessor(isnan)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].isnan, 138006087268928)             
	| | +- GuardManager: source=G['__builtins_dict___120'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___120)
	| | | +- GuardManager: source=G['__builtins_dict___120']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___120']['len'], 138006094275152)
	
V0401 21:32:46.571000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "88a8659109ee84bfa9926a28ffb7af09"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166571741.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.572000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0, "has_payload": "0f6b8e434bd43faab589cf780d157d19"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166572756.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 18,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.574000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "38/0", "frame_key": "56", "co_name": "torch_dynamo_resume_in_curve_fit_at_1007", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 1007, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 17, "shape_env_guard_count": 0, "graph_op_count": 4, "graph_node_count": 7, "graph_input_count": 2, "start_time": 1743543166.3553178, "entire_frame_compile_time_s": 0.21633696556091309, "backend_compile_time_s": 0.0455319881439209, "inductor_compile_time_s": 0.012828350067138672, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 38, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.577000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1406, "name": "torch_dynamo_resume_in_find_ab_params_at_1406", "filename": 4}, {"line": 591, "name": "curve_fit", "filename": 6}, {"line": 914, "name": "torch_dynamo_resume_in_curve_fit_at_914", "filename": 6}, {"line": 918, "name": "torch_dynamo_resume_in_curve_fit_at_918", "filename": 6}, {"line": 923, "name": "torch_dynamo_resume_in_curve_fit_at_923", "filename": 6}, {"line": 932, "name": "torch_dynamo_resume_in_curve_fit_at_932", "filename": 6}, {"line": 940, "name": "torch_dynamo_resume_in_curve_fit_at_940", "filename": 6}, {"line": 1007, "name": "torch_dynamo_resume_in_curve_fit_at_989", "filename": 6}, {"line": 1040, "name": "torch_dynamo_resume_in_curve_fit_at_1040", "filename": 6}]}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.578000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "300a318febe76a994d9ad6658c73537c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166577937.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.578000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "accc8368496e2aa5fbbed5080fa89adc"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166577937.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.587000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 92, "size": 16}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.588000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb3957c0>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.588000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 0, "source": "___from_numpy(L['p0'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.590000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 92, "size": 8}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.591000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb3960d0>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.592000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 1, "source": "___from_numpy(L['cost'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.596000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 92, "size": 32}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.597000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 4, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4a3ed0>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.597000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 4, "source": "___from_numpy(L['pcov'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.601000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 92, "size": 16}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.602000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb395540>", "describer_id": 92}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.603000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 92, "id": 6, "source": "___from_numpy(L['popt'])"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.606000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_cost_": [], "l_pcov_": [2, 2], "s_sq": [], "pcov": [2, 2]}}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "903a53807a5c78c4443f8bf908de0d35"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_cost_: "f64[][]cpu", L_pcov_: "f64[2, 2][2, 1]cpu"):
	        l_cost_ = L_cost_
	        l_pcov_ = L_pcov_
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1047 in torch_dynamo_resume_in_curve_fit_at_1040, code: s_sq = cost / (ysize - p0.size)
	        s_sq: "f64[][]cpu" = torch__dynamo_utils_wrapped_truediv(l_cost_, 298);  l_cost_ = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1048 in torch_dynamo_resume_in_curve_fit_at_1040, code: pcov = pcov * s_sq
	        pcov: "f64[2, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_mul(l_pcov_, s_sq);  l_pcov_ = s_sq = None
	        return (pcov,)
	        
V0401 21:32:46.607000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "ebce140504e6c868ebd42386f2e942b3"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166607285.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.607000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "b28878d77848b36d61e193257cf5411f"}
	{
	"name": "backend_compile",
	"ts": 1743543166607285.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.610000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "3c71a78972b35d701becbdc08bc4d376"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166610830.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.629000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "b081c5092cf61e9b056b5b26d88f5563"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[][]cpu", arg1_1: "f64[2, 2][2, 1]cpu"):
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1047 in torch_dynamo_resume_in_curve_fit_at_1040, code: s_sq = cost / (ysize - p0.size)
	        _tensor_constant0 = self._tensor_constant0
	        lift_fresh_copy: "f64[][]cpu" = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None
	        div: "f64[][]cpu" = torch.ops.aten.div.Tensor(arg0_1, lift_fresh_copy);  arg0_1 = lift_fresh_copy = None
	        
	         # File: /home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py:1048 in torch_dynamo_resume_in_curve_fit_at_1040, code: pcov = pcov * s_sq
	        mul: "f64[2, 2][2, 1]cpu" = torch.ops.aten.mul.Tensor(arg1_1, div);  arg1_1 = div = None
	        return (mul,)
	        
V0401 21:32:46.629000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "6ad5b601941a283cd864c7c67f2e3ef6"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166629703.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.632000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "8a68d6d8c35ad8d043e23d762f52ae86"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166632307.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.633000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "ee369867f2eb78a7907ef4fc88b32119"}
	{
	"name": "inductor_compile",
	"ts": 1743543166632307.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.641000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/ef/cefvveq36ljn5bkveegoxa3v65k3axdmf26w6c26pdgmhe4azohh.py"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "45a117617a23bdf409eb2c90a429944d"}
	# AOT ID: ['20_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_div_lift_fresh_mul_0 = async_compile.cpp_pybinding(['const double*', 'const double*', 'double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const double* in_ptr0,
	                       const double* in_ptr1,
	                       double* out_ptr0)
	{
	    {
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(4L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp1 = in_ptr1[static_cast<int64_t>(0L)];
	            auto tmp2 = static_cast<double>(0.003355704697986577);
	            auto tmp3 = decltype(tmp1)(tmp1 * tmp2);
	            auto tmp4 = decltype(tmp0)(tmp0 * tmp3);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp4;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, arg1_1 = args
	    args.clear()
	    assert_size_stride(arg0_1, (), ())
	    assert_size_stride(arg1_1, (2, 2), (2, 1))
	    buf0 = empty_strided_cpu((2, 2), (2, 1), torch.float64)
	    cpp_fused_div_lift_fresh_mul_0(arg1_1, arg0_1, buf0)
	    del arg0_1
	    del arg1_1
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((), (), device='cpu', dtype=torch.float64)
	    arg1_1 = rand_strided((2, 2), (2, 1), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1, arg1_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:46.642000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "a21041f75108f06206723b29a323f4a8"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543166642372.8,
	"args": {
	"key": "f3nrqjnlgotrkyjm7svtaxbecxqxi4ec6m2sabnfba4pztv6b2vx",
	"components": [
	"[jtmnjcpeee5hki7vjv7qi2sjjuqib4ym5xuyileqkmr3wq6gc2k] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 298.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    div = torch.ops.aten.div.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    mul = torch.ops.aten.mul.Tensor(arg1_1, div);  arg1_1 = div = None\n    return (mul,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[t75wnpkhdzho245k77fsy6jvriwrirovfy4byuuieeof5qil45t] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([]), stride=(), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xrrldqonl36w4z2az7sr3dnmawa4xjmy4qw7tjj6vilhmcl424y] fx_kwargs[user_visible_outputs]: {'mul': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 2038363573,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:46.643000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "c7140f0f970345d14787e8431a100d69"}
	{"key": "f3nrqjnlgotrkyjm7svtaxbecxqxi4ec6m2sabnfba4pztv6b2vx", "components": ["[jtmnjcpeee5hki7vjv7qi2sjjuqib4ym5xuyileqkmr3wq6gc2k] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1, arg1_1):\n    _tensor_constant0 = self._tensor_constant0;  _tensor_constant0 = None\n    full_default = torch.ops.aten.full.default([], 298.0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    div = torch.ops.aten.div.Tensor(arg0_1, full_default);  arg0_1 = full_default = None\n    mul = torch.ops.aten.mul.Tensor(arg1_1, div);  arg1_1 = div = None\n    return (mul,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[t75wnpkhdzho245k77fsy6jvriwrirovfy4byuuieeof5qil45t] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([]), stride=(), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[4boxwjpmja2r6koua7bvjcy7h2rdx32sgl3nkaygksjve73xurz] example_inputs[1]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2, 2]), stride=(2, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xrrldqonl36w4z2az7sr3dnmawa4xjmy4qw7tjj6vilhmcl424y] fx_kwargs[user_visible_outputs]: {'mul': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 2038363573, "cache_state": "hit"}
V0401 21:32:46.644000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "09c10da6cd197a228d37e3d1587f2ece"}
	{
	"name": "inductor_compile",
	"ts": 1743543166644806.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.645000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "0a89b6588cc2dd1820153716bf05756d"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166645512.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.646000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "a828f25bc822a065aefa80d4a2d7ec28"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166646702.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.649000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "628ef6bcd1b8f10e5a3899021db5f160"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166649736.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.650000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "98991f24d22f72cd5c6f329d6c4f0f0f"}
	{
	"name": "backend_compile",
	"ts": 1743543166650483.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.651000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "a15169e6c1f4f0f482e0b930a029c33f"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166651259.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.663000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "e1b385e667d29aa180fb3dc3bc4e8f9f"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['ysize'], accessed_by=DictGetItemGuardAccessor(ysize)
	| | +- EQUALS_MATCH: L['ysize'] == 300                                           
	| +- GuardManager: source=L['warn_cov'], accessed_by=DictGetItemGuardAccessor(warn_cov)
	| | +- ID_MATCH: ___check_obj_id(L['warn_cov'], 111055818658752)             
	| +- GuardManager: source=L['full_output'], accessed_by=DictGetItemGuardAccessor(full_output)
	| | +- ID_MATCH: ___check_obj_id(L['full_output'], 111055818658752)          
	| +- GuardManager: source=L['absolute_sigma'], accessed_by=DictGetItemGuardAccessor(absolute_sigma)
	| | +- ID_MATCH: ___check_obj_id(L['absolute_sigma'], 111055818658752)       
	| +- GuardManager: source=L['p0'], accessed_by=DictGetItemGuardAccessor(p0)
	| | +- GuardManager: source=___from_numpy(L['p0']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['p0']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['p0']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['p0']), ___from_numpy(L['cost']), ___from_numpy(L['pcov']), ___from_numpy(L['popt']))
	| +- GuardManager: source=L['cost'], accessed_by=DictGetItemGuardAccessor(cost)
	| | +- GuardManager: source=___from_numpy(L['cost']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['cost']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[], stride=[])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['cost']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['pcov'], accessed_by=DictGetItemGuardAccessor(pcov)
	| | +- GuardManager: source=___from_numpy(L['pcov']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['pcov']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['pcov']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['popt'], accessed_by=DictGetItemGuardAccessor(popt)
	| | +- GuardManager: source=___from_numpy(L['popt']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['popt']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['popt']), '_dynamo_dynamic_indices') == False
	| | | +- NO_TENSOR_ALIASING
	+- LAMBDA_GUARD: not __math_isnan(___from_numpy(L['cost']).item())             # _dynamo/output_graph.py:463 in init_ambient_guards
	
V0401 21:32:46.665000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "03cacd549e050d4d2f9268dc1aaa18ae"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166664500.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.666000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0, "has_payload": "f433d4d07219900f380c7932e22b1f86"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166666102.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 19,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.667000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "39/0", "frame_key": "57", "co_name": "torch_dynamo_resume_in_curve_fit_at_1040", "co_filename": "/home/codespace/.local/lib/python3.12/site-packages/scipy/optimize/_minpack_py.py", "co_firstlineno": 1040, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 13, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 5, "graph_input_count": 2, "start_time": 1743543166.5779097, "entire_frame_compile_time_s": 0.08646965026855469, "backend_compile_time_s": 0.04312729835510254, "inductor_compile_time_s": 0.012420177459716797, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 39, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.671000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1406, "name": "find_ab_params", "filename": 4}, {"line": 1407, "name": "torch_dynamo_resume_in_find_ab_params_at_1407", "filename": 4}]}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.672000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "3c92026c03dce6b56c580928a00d2cf0"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166672595.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.674000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "b4318b22d9afa3aed5348d78ff05a5d0"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166672595.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.678000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 94, "size": 16}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.680000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 1, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2], "is_leaf": true, "stride": [1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb3f0190>", "describer_id": 94}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.682000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 94, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.690000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 94, "size": 32}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.692000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [2, 2], "is_leaf": true, "stride": [2, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb34c370>", "describer_id": 94}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.694000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 94, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.707000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_stack0_0_": [2], "wrapped_getitem": [], "wrapped_getitem_1": []}}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "fa6a428f86ec82876592483fcaebf0b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_stack0_0_: "f64[2][1]cpu"):
	        l_stack0_0_ = L_stack0_0_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1408 in torch_dynamo_resume_in_find_ab_params_at_1407, code: return params[0], params[1]
	        wrapped_getitem: "f64[][]cpu" = torch__dynamo_utils_wrapped_getitem(l_stack0_0_, 0)
	        wrapped_getitem_1: "f64[][]cpu" = torch__dynamo_utils_wrapped_getitem_1(l_stack0_0_, 1);  l_stack0_0_ = None
	        return (wrapped_getitem, wrapped_getitem_1)
	        
V0401 21:32:46.709000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "f4b6c128d920ba8462b844d1dbbfe65b"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166709222.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.711000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "d0f4a4ad68eeff903ad4ea0b716a91f7"}
	{
	"name": "backend_compile",
	"ts": 1743543166709222.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.714000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "95f793ba920a2352612d388de8c3777f"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166714195.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.729000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "e1858c754268403596c82303239f4c07"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f64[2][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:1408 in torch_dynamo_resume_in_find_ab_params_at_1407, code: return params[0], params[1]
	        select: "f64[][]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0)
	        select_1: "f64[][]cpu" = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None
	        return (select, select_1)
	        
V0401 21:32:46.731000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "fe15e04c39af5aa2ccdecea8663df8cc"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166731110.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.734000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "309fdecbb3413b8b420b083200c8cb89"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166734708.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.735000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "7fedccb7359d56ddcbffb1a1d4dc31bf"}
	{
	"name": "inductor_compile",
	"ts": 1743543166734708.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.743000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/hd/chd37lcz4x3qev2qg5wjzrfa2lpkkpoajfmf7xru37hr2v44pi4e.py"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "9758e0955c95c26b1925bfad1b208517"}
	# AOT ID: ['21_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (2, ), (1, ))
	    return (reinterpret_tensor(arg0_1, (), (), 0), reinterpret_tensor(arg0_1, (), (), 1), )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((2, ), (1, ), device='cpu', dtype=torch.float64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:46.744000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "0e747607f279ce9ae85e7d5c564633e3"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543166743694.8,
	"args": {
	"key": "fxcvgvelixobhs5zr4mamq64nra6i4kgjlscfkoo2xu5evnibuhl",
	"components": [
	"[ippwpplt7o64l5zxxthx2ri2fxf6csf4dji7wiyj7rrmp2wqwkm] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None\n    return (select, select_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[zeb3repuwtz6sp4lhxsz2xnup5arzdbhbj4srmaa56mj2f7tat3] fx_kwargs[user_visible_outputs]: {'select': None, 'select_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 10609572,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:46.745000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "c60d09b01dae82d90865738efc24223e"}
	{"key": "fxcvgvelixobhs5zr4mamq64nra6i4kgjlscfkoo2xu5evnibuhl", "components": ["[ippwpplt7o64l5zxxthx2ri2fxf6csf4dji7wiyj7rrmp2wqwkm] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None\n    return (select, select_1)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[qohfdgrlpuhviaprev52o2nifcas6746pnpwbbgb4eykkj7zbx2] example_inputs[0]: TensorMetadata(dtype=torch.float64, shape=torch.Size([2]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[zeb3repuwtz6sp4lhxsz2xnup5arzdbhbj4srmaa56mj2f7tat3] fx_kwargs[user_visible_outputs]: {'select': None, 'select_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 10609572, "cache_state": "hit"}
V0401 21:32:46.746000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "d979d05ca4e6ebc4d92c6feac2d3d450"}
	{
	"name": "inductor_compile",
	"ts": 1743543166746416.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.747000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "c930bc364f9d29a5fcf7bd4edc0d2a17"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543166747109.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.748000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "7fe701d5443321030d6cf4f47527d9ae"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543166748487.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.753000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "878e16c7ed7c04b8cfd14f4c751b8038"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543166753350.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.754000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "95124fa0af3ccb41757858738b5766d2"}
	{
	"name": "backend_compile",
	"ts": 1743543166754159.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.755000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "4152c8d74ac0268d3224e5c3d9ba5cd1"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543166754925.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.759000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "f9651938ea9f7269b275239352f8b2d7"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 111055818760256)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 2                                    
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][0]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][0]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2], stride=[1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][0]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][0]), ___from_numpy(L['___stack0'][1]))
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][1]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[2, 2], stride=[2, 1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	
V0401 21:32:46.760000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "3d7ef341c7cdc0f04c39bd2ec050275f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166759882.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.760000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0, "has_payload": "cbf5a1fd901c48c200b3ec3f3317b2f7"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166760701.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.761000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "40/0", "frame_key": "58", "co_name": "torch_dynamo_resume_in_find_ab_params_at_1407", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1407, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 8, "shape_env_guard_count": 0, "graph_op_count": 2, "graph_node_count": 4, "graph_input_count": 1, "start_time": 1743543166.6725836, "entire_frame_compile_time_s": 0.08715391159057617, "backend_compile_time_s": 0.044870615005493164, "inductor_compile_time_s": 0.011628389358520508, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 40, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.764000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}]}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.765000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0, "has_payload": "d80d41861696a5762fbcce838761fcd5"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166765287.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.766000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0, "has_payload": "c780d7d58585f00f8ce23239d03a98e1"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166765287.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.782000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 96, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.784000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb2b3980>", "describer_id": 96}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.786000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 96, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.789000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 96, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.792000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb2b3fc0>", "describer_id": 96}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.795000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 96, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.814000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 96, "size": 40}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.815000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 2, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb4b14a0>", "describer_id": 96}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.816000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 96, "id": 2, "source": "___from_numpy(L['self']._raw_data)"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.838000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 97, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.840000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb2a3de0>", "describer_id": 97}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.843000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 97, "id": 0, "source": "___from_numpy(L['___stack0'][0])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.846000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 97, "size": 8}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.848000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 0, "dtype": "torch.float64", "device": "device(type='cpu')", "size": [], "is_leaf": true, "stride": [], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb2a37a0>", "describer_id": 97}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.851000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 97, "id": 1, "source": "___from_numpy(L['___stack0'][1])"}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.992000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1, "has_payload": "df0d553dbb9e02736361ed0fd11adfbf"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].init, accessed_by=GetAttrGuardAccessor(init)
	| | | +- EQUALS_MATCH: L['self'].init == 'spectral'                                
	| | +- GuardManager: source=L['self'].learning_rate, accessed_by=GetAttrGuardAccessor(learning_rate)
	| | | +- EQUALS_MATCH: L['self'].learning_rate == 1.0                              
	| | +- GuardManager: source=L['self'].precomputed_knn, accessed_by=GetAttrGuardAccessor(precomputed_knn)
	| | | +- TYPE_MATCH: ___check_type_id(L['self'].precomputed_knn, 111055818760256)
	| | | +- LENGTH_CHECK: len(L['self'].precomputed_knn) == 3                         
	| | | +- GuardManager: source=L['self'].precomputed_knn[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | +- ID_MATCH: ___check_obj_id(L['self'].precomputed_knn[0], 111055818751712)
	| | | +- GuardManager: source=L['self'].precomputed_knn[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | +- ID_MATCH: ___check_obj_id(L['self'].precomputed_knn[1], 111055818751712)
	| | | +- GuardManager: source=L['self'].precomputed_knn[2], accessed_by=TupleGetItemGuardAccessor(2)
	| | | | +- ID_MATCH: ___check_obj_id(L['self'].precomputed_knn[2], 111055818751712)
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- TYPE_MATCH: ___check_type_id(L['___stack0'], 111055818760256)           
	| | +- LENGTH_CHECK: len(L['___stack0']) == 2                                    
	| | +- GuardManager: source=L['___stack0'][0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][0]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][0]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[], stride=[])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][0]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING: check_no_aliasing(___from_numpy(L['___stack0'][0]), ___from_numpy(L['___stack0'][1]))
	| | +- GuardManager: source=L['___stack0'][1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | +- GuardManager: source=___from_numpy(L['___stack0'][1]), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['___stack0'][1]), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float64, device=None, requires_grad=False, size=[], stride=[])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['___stack0'][1]), '_dynamo_dynamic_indices') == False
	| | | | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].ndarray, accessed_by=GetAttrGuardAccessor(ndarray)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ndarray, 138005714262272)           
	| | +- GuardManager: source=G['__builtins_dict___129'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___129)
	| | | +- GuardManager: source=G['__builtins_dict___129']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___129']['len'], 138006094275152)
	| | | +- GuardManager: source=G['__builtins_dict___129']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___129']['isinstance'], 138006094274832)
	+- LAMBDA_GUARD: not __math_isnan(___from_numpy(L['___stack0'][0]).item())     # _dynamo/output_graph.py:463 in init_ambient_guards
	+- LAMBDA_GUARD: not __math_isnan(___from_numpy(L['___stack0'][1]).item())     # _dynamo/output_graph.py:463 in init_ambient_guards
	
V0401 21:32:46.993000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1, "has_payload": "c942d2d50f602c18b11f3cb8723c1bc2"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166993264.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.994000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1, "has_payload": "abe6d362563702b7b920d7cc5db6cb0f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166994148.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.995000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "41/0", "frame_key": "59", "co_name": "torch_dynamo_resume_in_fit_at_2383", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2383, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 19, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 4, "graph_input_count": 4, "start_time": 1743543166.7652771, "entire_frame_compile_time_s": 0.22789740562438965, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Graph break due to unsupported Python builtin _warnings.warn. Please file an issue on GitHub so the PyTorch team can add support for it. "], "dynamo_time_before_restart_s": 0.05629777908325195, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 41, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:46.998000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 1752, "name": "_validate_parameters", "filename": 4}]}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:46.998000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0, "has_payload": "0b2bfe80e3705320def43318e158030e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543166998667.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:46.999000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0, "has_payload": "e402d1b8adb41e224650d31932ba6d47"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543166998667.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.022000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 98, "size": 40}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.023000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb2c9b80>", "describer_id": 98}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.024000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 98, "id": 0, "source": "___from_numpy(L['self']._raw_data)"}, "frame_id": 42, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.061000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 99, "size": 40}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.062000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83cb34e8a0>", "describer_id": 99}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.063000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 99, "id": 0, "source": "___from_numpy(L['self']._raw_data)"}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.145000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1, "has_payload": "deafe27ebabbf59484c43918852c1415"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].init, accessed_by=GetAttrGuardAccessor(init)
	| | | +- EQUALS_MATCH: L['self'].init == 'spectral'                                
	| | +- GuardManager: source=L['self'].metric, accessed_by=GetAttrGuardAccessor(metric)
	| | | +- EQUALS_MATCH: L['self'].metric == 'euclidean'                             
	| | +- GuardManager: source=L['self'].n_jobs, accessed_by=GetAttrGuardAccessor(n_jobs)
	| | | +- EQUALS_MATCH: L['self'].n_jobs == -1                                      
	| | +- GuardManager: source=L['self'].spread, accessed_by=GetAttrGuardAccessor(spread)
	| | | +- EQUALS_MATCH: L['self'].spread == 1.0                                     
	| | +- GuardManager: source=L['self'].min_dist, accessed_by=GetAttrGuardAccessor(min_dist)
	| | | +- EQUALS_MATCH: L['self'].min_dist == 0.1                                   
	| | +- GuardManager: source=L['self'].n_epochs, accessed_by=GetAttrGuardAccessor(n_epochs)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].n_epochs, 111055818751712)        
	| | +- GuardManager: source=L['self'].metric_kwds, accessed_by=GetAttrGuardAccessor(metric_kwds)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].metric_kwds, 111055818751712)     
	| | +- GuardManager: source=L['self'].n_neighbors, accessed_by=GetAttrGuardAccessor(n_neighbors)
	| | | +- EQUALS_MATCH: L['self'].n_neighbors == 2                                  
	| | +- GuardManager: source=L['self'].n_components, accessed_by=GetAttrGuardAccessor(n_components)
	| | | +- EQUALS_MATCH: L['self'].n_components == 2                                 
	| | +- GuardManager: source=L['self'].random_state, accessed_by=GetAttrGuardAccessor(random_state)
	| | | +- EQUALS_MATCH: L['self'].random_state == 42                                
	| | +- GuardManager: source=L['self'].output_metric, accessed_by=GetAttrGuardAccessor(output_metric)
	| | | +- EQUALS_MATCH: L['self'].output_metric == 'euclidean'                      
	| | +- GuardManager: source=L['self']._initial_alpha, accessed_by=GetAttrGuardAccessor(_initial_alpha)
	| | | +- EQUALS_MATCH: L['self']._initial_alpha == 1.0                             
	| | +- GuardManager: source=L['self'].set_op_mix_ratio, accessed_by=GetAttrGuardAccessor(set_op_mix_ratio)
	| | | +- EQUALS_MATCH: L['self'].set_op_mix_ratio == 1.0                           
	| | +- GuardManager: source=L['self'].output_metric_kwds, accessed_by=GetAttrGuardAccessor(output_metric_kwds)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].output_metric_kwds, 111055818751712)
	| | +- GuardManager: source=L['self'].repulsion_strength, accessed_by=GetAttrGuardAccessor(repulsion_strength)
	| | | +- EQUALS_MATCH: L['self'].repulsion_strength == 1.0                         
	| | +- GuardManager: source=L['self'].target_metric_kwds, accessed_by=GetAttrGuardAccessor(target_metric_kwds)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].target_metric_kwds, 111055818751712)
	| | +- GuardManager: source=L['self'].target_n_neighbors, accessed_by=GetAttrGuardAccessor(target_n_neighbors)
	| | | +- EQUALS_MATCH: L['self'].target_n_neighbors == -1                          
	| | +- GuardManager: source=L['self'].negative_sample_rate, accessed_by=GetAttrGuardAccessor(negative_sample_rate)
	| | | +- EQUALS_MATCH: L['self'].negative_sample_rate == 5                         
	| | +- GuardManager: source=L['self']._raw_data, accessed_by=GetAttrGuardAccessor(_raw_data)
	| | | +- GuardManager: source=___from_numpy(L['self']._raw_data), accessed_by=PythonLambdaGuardAccessor
	| | | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['self']._raw_data), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | | +- NO_HASATTR: hasattr(___from_numpy(L['self']._raw_data), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].ndarray, accessed_by=GetAttrGuardAccessor(ndarray)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].ndarray, 138005714262272)           
	| | +- GuardManager: source=G['dist'], accessed_by=DictGetItemGuardAccessor(dist)
	| | | +- ID_MATCH: ___check_obj_id(G['dist'], 138005281706912)                 
	| | | +- GuardManager: source=G['dist'].named_distances, accessed_by=GetAttrGuardAccessor(named_distances)
	| | | | +- DICT_LENGTH: len(G['dist'].named_distances) == 39                        
	| | | | +- GuardManager: source=G['dist'].named_distances['euclidean'], accessed_by=DictGetItemGuardAccessor(euclidean)
	| | | | | +- TYPE_MATCH: ___check_type_id(G['dist'].named_distances['euclidean'], 111057023449744)
	| | | | +- GuardManager: source=G['dist'].named_distances['l2'], accessed_by=DictGetItemGuardAccessor(l2)
	| | | | +- GuardManager: source=G['dist'].named_distances['manhattan'], accessed_by=DictGetItemGuardAccessor(manhattan)
	| | | | +- GuardManager: source=G['dist'].named_distances['taxicab'], accessed_by=DictGetItemGuardAccessor(taxicab)
	| | | | +- GuardManager: source=G['dist'].named_distances['l1'], accessed_by=DictGetItemGuardAccessor(l1)
	| | | | +- GuardManager: source=G['dist'].named_distances['chebyshev'], accessed_by=DictGetItemGuardAccessor(chebyshev)
	| | | | +- GuardManager: source=G['dist'].named_distances['linfinity'], accessed_by=DictGetItemGuardAccessor(linfinity)
	| | | | +- GuardManager: source=G['dist'].named_distances['linfty'], accessed_by=DictGetItemGuardAccessor(linfty)
	| | | | +- GuardManager: source=G['dist'].named_distances['linf'], accessed_by=DictGetItemGuardAccessor(linf)
	| | | | +- GuardManager: source=G['dist'].named_distances['minkowski'], accessed_by=DictGetItemGuardAccessor(minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances['poincare'], accessed_by=DictGetItemGuardAccessor(poincare)
	| | | | +- GuardManager: source=G['dist'].named_distances['seuclidean'], accessed_by=DictGetItemGuardAccessor(seuclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances['standardised_euclidean'], accessed_by=DictGetItemGuardAccessor(standardised_euclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances['wminkowski'], accessed_by=DictGetItemGuardAccessor(wminkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances['weighted_minkowski'], accessed_by=DictGetItemGuardAccessor(weighted_minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances['mahalanobis'], accessed_by=DictGetItemGuardAccessor(mahalanobis)
	| | | | +- GuardManager: source=G['dist'].named_distances['canberra'], accessed_by=DictGetItemGuardAccessor(canberra)
	| | | | +- GuardManager: source=G['dist'].named_distances['cosine'], accessed_by=DictGetItemGuardAccessor(cosine)
	| | | | +- GuardManager: source=G['dist'].named_distances['correlation'], accessed_by=DictGetItemGuardAccessor(correlation)
	| | | | +- GuardManager: source=G['dist'].named_distances['hellinger'], accessed_by=DictGetItemGuardAccessor(hellinger)
	| | | | +- GuardManager: source=G['dist'].named_distances['haversine'], accessed_by=DictGetItemGuardAccessor(haversine)
	| | | | +- GuardManager: source=G['dist'].named_distances['braycurtis'], accessed_by=DictGetItemGuardAccessor(braycurtis)
	| | | | +- GuardManager: source=G['dist'].named_distances['ll_dirichlet'], accessed_by=DictGetItemGuardAccessor(ll_dirichlet)
	| | | | +- GuardManager: source=G['dist'].named_distances['symmetric_kl'], accessed_by=DictGetItemGuardAccessor(symmetric_kl)
	| | | | +- GuardManager: source=G['dist'].named_distances['hamming'], accessed_by=DictGetItemGuardAccessor(hamming)
	| | | | +- GuardManager: source=G['dist'].named_distances['jaccard'], accessed_by=DictGetItemGuardAccessor(jaccard)
	| | | | +- GuardManager: source=G['dist'].named_distances['dice'], accessed_by=DictGetItemGuardAccessor(dice)
	| | | | +- GuardManager: source=G['dist'].named_distances['matching'], accessed_by=DictGetItemGuardAccessor(matching)
	| | | | +- GuardManager: source=G['dist'].named_distances['kulsinski'], accessed_by=DictGetItemGuardAccessor(kulsinski)
	| | | | +- GuardManager: source=G['dist'].named_distances['rogerstanimoto'], accessed_by=DictGetItemGuardAccessor(rogerstanimoto)
	| | | | +- GuardManager: source=G['dist'].named_distances['russellrao'], accessed_by=DictGetItemGuardAccessor(russellrao)
	| | | | +- GuardManager: source=G['dist'].named_distances['sokalsneath'], accessed_by=DictGetItemGuardAccessor(sokalsneath)
	| | | | +- GuardManager: source=G['dist'].named_distances['sokalmichener'], accessed_by=DictGetItemGuardAccessor(sokalmichener)
	| | | | +- GuardManager: source=G['dist'].named_distances['yule'], accessed_by=DictGetItemGuardAccessor(yule)
	| | | | +- GuardManager: source=G['dist'].named_distances['categorical'], accessed_by=DictGetItemGuardAccessor(categorical)
	| | | | +- GuardManager: source=G['dist'].named_distances['ordinal'], accessed_by=DictGetItemGuardAccessor(ordinal)
	| | | | +- GuardManager: source=G['dist'].named_distances['hierarchical_categorical'], accessed_by=DictGetItemGuardAccessor(hierarchical_categorical)
	| | | | +- GuardManager: source=G['dist'].named_distances['count'], accessed_by=DictGetItemGuardAccessor(count)
	| | | | +- GuardManager: source=G['dist'].named_distances['string'], accessed_by=DictGetItemGuardAccessor(string)
	| | | +- GuardManager: source=G['dist'].named_distances_with_gradients, accessed_by=GetAttrGuardAccessor(named_distances_with_gradients)
	| | | | +- DICT_LENGTH: len(G['dist'].named_distances_with_gradients) == 26         
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['euclidean'], accessed_by=DictGetItemGuardAccessor(euclidean)
	| | | | | +- TYPE_MATCH: ___check_type_id(G['dist'].named_distances_with_gradients['euclidean'], 111057023449744)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['l2'], accessed_by=DictGetItemGuardAccessor(l2)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['manhattan'], accessed_by=DictGetItemGuardAccessor(manhattan)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['taxicab'], accessed_by=DictGetItemGuardAccessor(taxicab)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['l1'], accessed_by=DictGetItemGuardAccessor(l1)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['chebyshev'], accessed_by=DictGetItemGuardAccessor(chebyshev)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['linfinity'], accessed_by=DictGetItemGuardAccessor(linfinity)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['linfty'], accessed_by=DictGetItemGuardAccessor(linfty)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['linf'], accessed_by=DictGetItemGuardAccessor(linf)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['minkowski'], accessed_by=DictGetItemGuardAccessor(minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['seuclidean'], accessed_by=DictGetItemGuardAccessor(seuclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['standardised_euclidean'], accessed_by=DictGetItemGuardAccessor(standardised_euclidean)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['wminkowski'], accessed_by=DictGetItemGuardAccessor(wminkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['weighted_minkowski'], accessed_by=DictGetItemGuardAccessor(weighted_minkowski)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['mahalanobis'], accessed_by=DictGetItemGuardAccessor(mahalanobis)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['canberra'], accessed_by=DictGetItemGuardAccessor(canberra)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['cosine'], accessed_by=DictGetItemGuardAccessor(cosine)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['correlation'], accessed_by=DictGetItemGuardAccessor(correlation)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['hellinger'], accessed_by=DictGetItemGuardAccessor(hellinger)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['haversine'], accessed_by=DictGetItemGuardAccessor(haversine)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['braycurtis'], accessed_by=DictGetItemGuardAccessor(braycurtis)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['symmetric_kl'], accessed_by=DictGetItemGuardAccessor(symmetric_kl)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['spherical_gaussian_energy'], accessed_by=DictGetItemGuardAccessor(spherical_gaussian_energy)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['diagonal_gaussian_energy'], accessed_by=DictGetItemGuardAccessor(diagonal_gaussian_energy)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['gaussian_energy'], accessed_by=DictGetItemGuardAccessor(gaussian_energy)
	| | | | +- GuardManager: source=G['dist'].named_distances_with_gradients['hyperboloid'], accessed_by=DictGetItemGuardAccessor(hyperboloid)
	| | +- GuardManager: source=G['warn'], accessed_by=DictGetItemGuardAccessor(warn)
	| | | +- ID_MATCH: ___check_obj_id(G['warn'], 138006094349472)                 
	| | +- GuardManager: source=G['scipy'], accessed_by=DictGetItemGuardAccessor(scipy)
	| | | +- ID_MATCH: ___check_obj_id(G['scipy'], 138005521414752)                
	| | | +- GuardManager: source=G['scipy'].sparse, accessed_by=GetAttrGuardAccessor(sparse)
	| | | | +- ID_MATCH: ___check_obj_id(G['scipy'].sparse, 138005521411312)         
	| | | | +- GuardManager: source=G['scipy'].sparse.isspmatrix_csr, accessed_by=GetAttrGuardAccessor(isspmatrix_csr)
	| | | | | +- GuardManager: source=G['scipy'].sparse.isspmatrix_csr.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['scipy'].sparse.isspmatrix_csr.__code__, 138005512836544)
	| | +- GuardManager: source=G['__builtins_dict___132'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___132)
	| | | +- GuardManager: source=G['__builtins_dict___132']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['int'], 111055818732256)
	| | | +- GuardManager: source=G['__builtins_dict___132']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['str'], 111055818777536)
	| | | +- GuardManager: source=G['__builtins_dict___132']['list'], accessed_by=DictGetItemGuardAccessor(list)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['list'], 111055818730400)
	| | | +- GuardManager: source=G['__builtins_dict___132']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['tuple'], 111055818760256)
	| | | +- GuardManager: source=G['__builtins_dict___132']['callable'], accessed_by=DictGetItemGuardAccessor(callable)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['callable'], 138006094273552)
	| | | +- GuardManager: source=G['__builtins_dict___132']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___132']['isinstance'], 138006094274832)
	| | +- GuardManager: source=G['__import_scipy_dot_sparse_dot__csr'], accessed_by=DictGetItemGuardAccessor(__import_scipy_dot_sparse_dot__csr)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_sparse_dot__csr'], 138005513128512)
	| | | +- GuardManager: source=G['__import_scipy_dot_sparse_dot__csr'].csr_matrix, accessed_by=GetAttrGuardAccessor(csr_matrix)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_scipy_dot_sparse_dot__csr'].csr_matrix, 111056996325888)
	
V0401 21:32:47.146000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1, "has_payload": "86fb8f5ba91fcba8627de06e10ef998d"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167146519.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.147000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1, "has_payload": "dfaabccd5c39323164d872ce1046864d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167147388.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.148000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "42/0", "frame_key": "60", "co_name": "_validate_parameters", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1752, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 46, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 2, "graph_input_count": 2, "start_time": 1743543166.9986572, "entire_frame_compile_time_s": 0.14775514602661133, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["Graph break due to unsupported Python builtin _warnings.warn. Please file an issue on GitHub so the PyTorch team can add support for it. "], "dynamo_time_before_restart_s": 0.033907413482666016, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 42, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.151000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 1952, "name": "torch_dynamo_resume_in__validate_parameters_at_1952", "filename": 4}]}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.152000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "619838b708deba4ca337f5bdc15ef839"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167152401.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.153000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "fb79bcebdb740885081590214ed02003"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167152401.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.168000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "c8e6aa23c8235f6d3b4f338b442877c3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167168000.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.168000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0, "has_payload": "3c60fcc8840d0f597ec632b0b94206ba"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167168625.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.169000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "43/0", "frame_key": "61", "co_name": "torch_dynamo_resume_in__validate_parameters_at_1952", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 1952, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543167.152391, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.017111539840698242, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 43, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.172000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}]}, "frame_id": 44, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.173000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 0, "has_payload": "e1fe9033b2d713468920a481dd609890"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167173152.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.174000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 0, "has_payload": "ce9710c15409f4cfc5f437e61bdad985"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167173152.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.358000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1, "has_payload": "7f7b10573347cf60311ec7e82721792e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].verbose, accessed_by=GetAttrGuardAccessor(verbose)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].verbose, 111055818658752)         
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['numba'], accessed_by=DictGetItemGuardAccessor(numba)
	| | | +- ID_MATCH: ___check_obj_id(G['numba'], 138005296667584)                
	| | | +- GuardManager: source=G['numba'].get_num_threads, accessed_by=GetAttrGuardAccessor(get_num_threads)
	| | | | +- GuardManager: source=G['numba'].get_num_threads.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['numba'].get_num_threads.__code__, 138005173828192)
	
V0401 21:32:47.359000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1, "has_payload": "474b32207b8df2a9bfa8a4fe6b8bb17f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167359113.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.360000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1, "has_payload": "37e17f5072ce3c90f7bf4f70da8adbed"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167360022.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.361000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "44/0", "frame_key": "62", "co_name": "torch_dynamo_resume_in_fit_at_2408", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2408, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543167.1731417, "entire_frame_compile_time_s": 0.1858823299407959, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["BEFORE_WITH UserDefinedObjectVariable(RLock)"], "dynamo_time_before_restart_s": 0.031031370162963867, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 44, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.375000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2413, "name": "torch_dynamo_resume_in_fit_at_2413", "filename": 4}]}, "frame_id": 45, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.376000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 0, "has_payload": "6472fee73b2da0ac1fca5b8549284cdf"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167376264.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.377000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 0, "has_payload": "76c94e64ee1666506e7fb54d1bef852a"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167376264.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.683000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1, "has_payload": "6cd7f216ec9030fc2e3e1e309510487c"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].n_jobs, accessed_by=GetAttrGuardAccessor(n_jobs)
	| | | +- EQUALS_MATCH: L['self'].n_jobs == 1                                       
	| +- GuardManager: source=L['___stack0'], accessed_by=DictGetItemGuardAccessor(___stack0)
	| | +- EQUALS_MATCH: L['___stack0'] == 2                                         
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['numba'], accessed_by=DictGetItemGuardAccessor(numba)
	| | | +- ID_MATCH: ___check_obj_id(G['numba'], 138005296667584)                
	| | | +- GuardManager: source=G['numba'].set_num_threads, accessed_by=GetAttrGuardAccessor(set_num_threads)
	| | | | +- GuardManager: source=G['numba'].set_num_threads.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['numba'].set_num_threads.__code__, 138005167248592)
	
V0401 21:32:47.685000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1, "has_payload": "e13fdd66c98ca022a5825d14a0383717"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167685133.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.686000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1, "has_payload": "e5f75acf42e584b46745ca568179c912"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167686779.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.687000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "45/0", "frame_key": "89", "co_name": "torch_dynamo_resume_in_fit_at_2413", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2413, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 10, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543167.3762538, "entire_frame_compile_time_s": 0.3087635040283203, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["BEFORE_WITH UserDefinedObjectVariable(RLock)"], "dynamo_time_before_restart_s": 0.02094411849975586, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 45, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.692000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", 9]}
V0401 21:32:47.694000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 584, "name": "set_num_threads", "filename": 9}]}, "frame_id": 46, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.695000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 0, "has_payload": "2a4edf655a9d7771860254247492d9d9"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167695382.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.696000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 0, "has_payload": "7a97a5f041e0bf1d6ae7ca4e249e353e"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167695382.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.714000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1, "has_payload": "cc0653caf9bd58f826004a853c21dc48"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['_launch_threads'], accessed_by=DictGetItemGuardAccessor(_launch_threads)
	| | | +- GuardManager: source=G['_launch_threads'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_launch_threads'].__code__, 111057023510304)
	
V0401 21:32:47.715000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1, "has_payload": "ca0bf062cc17fe488d054ec1641f5468"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167715845.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.718000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1, "has_payload": "7e6634021e029e52ab49771a2f301cee"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167718723.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.721000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "46/0", "frame_key": "90", "co_name": "set_num_threads", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", "co_firstlineno": 584, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 6, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543167.6953695, "entire_frame_compile_time_s": 0.020357131958007812, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["BEFORE_WITH UserDefinedObjectVariable(RLock)"], "dynamo_time_before_restart_s": 0.011406898498535156, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 46, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.723000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 2413, "name": "torch_dynamo_resume_in_fit_at_2413", "filename": 4}, {"line": 607, "name": "torch_dynamo_resume_in_set_num_threads_at_607", "filename": 9}]}, "frame_id": 47, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.725000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 0, "has_payload": "e1b698f5d9f25abfeb52d9a69ed8df85"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167725135.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.726000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 0, "has_payload": "ec4af7a3d30cfcea53b651f8649c0fbe"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167725135.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.744000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1, "has_payload": "d505693aaa28c97422e412c6e50c906e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['n'], accessed_by=DictGetItemGuardAccessor(n)
	| | +- EQUALS_MATCH: L['n'] == 1                                                 
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].integer, accessed_by=GetAttrGuardAccessor(integer)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].integer, 138005714248832)           
	| | +- GuardManager: source=G['snt_check'], accessed_by=DictGetItemGuardAccessor(snt_check)
	| | | +- GuardManager: source=G['snt_check'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['snt_check'].__code__, 138005167410272)   
	| | | +- GuardManager: source=G['snt_check'].__closure__, accessed_by=GetAttrGuardAccessor(__closure__)
	| | | | +- GuardManager: source=G['snt_check'].__closure__[0], accessed_by=TupleGetItemGuardAccessor(0)
	| | | | | +- GuardManager: source=G['snt_check'].__closure__[0].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | | +- EQUALS_MATCH: G['snt_check'].__closure__[0].cell_contents == 2            
	| | | | +- GuardManager: source=G['snt_check'].__closure__[1], accessed_by=TupleGetItemGuardAccessor(1)
	| | | | | +- GuardManager: source=G['snt_check'].__closure__[1].cell_contents, accessed_by=GetAttrGuardAccessor(cell_contents)
	| | | | | | +- EQUALS_MATCH: G['snt_check'].__closure__[1].cell_contents == 'The number of threads must be between 1 and 2'
	| | +- GuardManager: source=G['_set_num_threads'], accessed_by=DictGetItemGuardAccessor(_set_num_threads)
	| | | +- TYPE_MATCH: ___check_type_id(G['_set_num_threads'], 111057059806880)    
	| | +- GuardManager: source=G['__builtins_dict___145'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___145)
	| | | +- GuardManager: source=G['__builtins_dict___145']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___145']['int'], 111055818732256)
	| | | +- GuardManager: source=G['__builtins_dict___145']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___145']['isinstance'], 138006094274832)
	
V0401 21:32:47.745000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1, "has_payload": "6cffc6fcc0443ca8929dcd346dbc8f00"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167745353.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.746000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1, "has_payload": "33918f7a007545b280d13be86d4b80c4"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167746300.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.747000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "47/0", "frame_key": "91", "co_name": "torch_dynamo_resume_in_set_num_threads_at_607", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", "co_firstlineno": 607, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 14, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743543167.725123, "entire_frame_compile_time_s": 0.020134449005126953, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["call_method UserDefinedObjectVariable(CFunctionType) __call__ [ConstantVariable()] {}"], "dynamo_time_before_restart_s": 0.005394935607910156, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 47, "frame_compile_id": 0, "attempt": 1}
V0401 21:32:47.749000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 2413, "name": "torch_dynamo_resume_in_fit_at_2413", "filename": 4}, {"line": 584, "name": "set_num_threads", "filename": 9}, {"line": 611, "name": "torch_dynamo_resume_in_set_num_threads_at_611", "filename": 9}]}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.751000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "f7857702c6dcebed3408ca1d1d3da1ad"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167750969.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.752000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "4615c938c877b9e672a04039012bdd95"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167750969.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.754000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "3433c1901b3022d7a25d4bba0f129cc5"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167754521.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.755000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0, "has_payload": "0608316e02219b54282b1ba2a38491be"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167755147.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 20,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.756000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "48/0", "frame_key": "92", "co_name": "torch_dynamo_resume_in_set_num_threads_at_611", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/numba/np/ufunc/parallel.py", "co_firstlineno": 611, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": null, "shape_env_guard_count": null, "graph_op_count": null, "graph_node_count": null, "graph_input_count": null, "start_time": 1743543167.750958, "entire_frame_compile_time_s": null, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.005069732666015625, "has_guarded_code": false, "possibly_missed_reinplacing_opportunities": null}, "frame_id": 48, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.759000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 42, "name": "torch_dynamo_resume_in_forward_refined_at_36", "filename": 1}, {"line": 2928, "name": "fit_transform", "filename": 4}, {"line": 2339, "name": "fit", "filename": 4}, {"line": 2372, "name": "torch_dynamo_resume_in_fit_at_2372", "filename": 4}, {"line": 2383, "name": "torch_dynamo_resume_in_fit_at_2383", "filename": 4}, {"line": 2408, "name": "torch_dynamo_resume_in_fit_at_2408", "filename": 4}, {"line": 2415, "name": "torch_dynamo_resume_in_fit_at_2415", "filename": 4}]}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.759000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "e24b4bbb24f61caf6826207e72755c9c"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167759581.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.760000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "62d6a0103d93d12444f15600952245c3"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167759581.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.776000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 110, "size": 40}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.777000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83c71042d0>", "describer_id": 110}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.778000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 110, "id": 0, "source": "___from_numpy(L['X'])"}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.789000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_x_": [1, 10], "wrapped_getitem": [1, 10], "wrapped_getitem_1": [1, 10], "wrapped_zeros": [1, 2]}}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "d9ad318e1de4396c6099639ca08a9152"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_X_: "f32[1, 10][10, 1]cpu"):
	        l_x_ = L_X_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2455 in torch_dynamo_resume_in_fit_at_2415, code: if X[index].shape[0] <= self.n_neighbors:
	        wrapped_getitem: "f32[1, 10][10, 1]cpu" = torch__dynamo_utils_wrapped_getitem(l_x_, [0]);  wrapped_getitem = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2456 in torch_dynamo_resume_in_fit_at_2415, code: if X[index].shape[0] == 1:
	        wrapped_getitem_1: "f32[1, 10][10, 1]cpu" = torch__dynamo_utils_wrapped_getitem_1(l_x_, [0]);  l_x_ = wrapped_getitem_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2457 in torch_dynamo_resume_in_fit_at_2415, code: self.embedding_ = np.zeros(
	        wrapped_zeros: "f64[1, 2][2, 1]cpu" = torch__dynamo_utils_wrapped_zeros((1, 2))
	        return (wrapped_zeros,)
	        
V0401 21:32:47.790000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "419c60121991c47faea916214f346910"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543167790516.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.791000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "4589b2720ad69ffd505577da0a837fd5"}
	{
	"name": "backend_compile",
	"ts": 1743543167790516.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.794000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "9c0f87f3ef502ecd26ad4a83160518fe"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543167794666.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.814000 13985 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "6387f5fe86d19ec1d312bda6f0a2f8fe"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "f32[1, 10][10, 1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py:2457 in torch_dynamo_resume_in_fit_at_2415, code: self.embedding_ = np.zeros(
	        full: "f64[1, 2][2, 1]cpu" = torch.ops.aten.full.default([1, 2], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        return (full,)
	        
V0401 21:32:47.815000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "1eb61d9abfd2143b3cee60d9399a8da4"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543167815523.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.818000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "e97fd2090697392a925577fb370e9793"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543167818859.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.819000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "69279e3b3bb2eeb81283aeeb964b0bc7"}
	{
	"name": "inductor_compile",
	"ts": 1743543167818859.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.829000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/k7/ck7jjpr25wynl4kevfr2zwjcxeiwq6gyvpjx34m6cruxgqovwf3b.py"}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "ff408293b4d8f9c3910e6fad6e48557c"}
	# AOT ID: ['22_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_zeros_0 = async_compile.cpp_pybinding(['double*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(double* out_ptr0)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(2L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp0 = static_cast<double>(0.0);
	            out_ptr0[static_cast<int64_t>(x0)] = tmp0;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    buf0 = empty_strided_cpu((1, 2), (2, 1), torch.float64)
	    cpp_fused_zeros_0(buf0)
	    return (buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.float32)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:47.830000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "9de1d03b16f172710c6df0d64ed41be7"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543167829990.5,
	"args": {
	"key": "fo2f6zvjs5lqkplvxo2e6xjnr4db3ilelj2si7dmgjrmk6ld3lvo",
	"components": [
	"[lvbow72o5gnv3mlsi4hjz24xm6wc4i75vwr4i7tkq5hcauuxywp] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full_default = torch.ops.aten.full.default([1, 2], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[2e74ctehigkd3ueulg6yyzt5nu3mdccgs6232onhxly2y7ldib7] example_inputs[0]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[rdcqaibaq4cmzf5ixiuy6tar4tfbmoziy7qrb5emggotlsoruhj] fx_kwargs[user_visible_outputs]: {'full_default': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 1970801553,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:47.831000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "68bac69f0561b20b5eb954f0397e5843"}
	{"key": "fo2f6zvjs5lqkplvxo2e6xjnr4db3ilelj2si7dmgjrmk6ld3lvo", "components": ["[lvbow72o5gnv3mlsi4hjz24xm6wc4i75vwr4i7tkq5hcauuxywp] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    full_default = torch.ops.aten.full.default([1, 2], 0, dtype = torch.float64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    return (full_default,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[2e74ctehigkd3ueulg6yyzt5nu3mdccgs6232onhxly2y7ldib7] example_inputs[0]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[rdcqaibaq4cmzf5ixiuy6tar4tfbmoziy7qrb5emggotlsoruhj] fx_kwargs[user_visible_outputs]: {'full_default': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 1970801553, "cache_state": "hit"}
V0401 21:32:47.832000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "e4d549a71fe2a3c7007feaa1bfff9cf6"}
	{
	"name": "inductor_compile",
	"ts": 1743543167832386.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.833000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "ae7f65b2c38c6d38836d0264536b1f9a"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543167833140.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.834000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "0084cf9962efa46c4e45708aeb407952"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543167834375.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.837000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "b642e99c452da1fc408cb2932ba840e3"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543167837718.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.838000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "185a32b626a9f746371a4f67f2970185"}
	{
	"name": "backend_compile",
	"ts": 1743543167838601.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.839000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "c03b7a9e719824e8e8746d587e49b092"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543167839856.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.845000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "ced64b59a107b5f1786494663a513c6e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057029776464)                
	| | +- GuardManager: source=L['self'].unique, accessed_by=GetAttrGuardAccessor(unique)
	| | | +- ID_MATCH: ___check_obj_id(L['self'].unique, 111055818658752)          
	| | +- GuardManager: source=L['self'].n_neighbors, accessed_by=GetAttrGuardAccessor(n_neighbors)
	| | | +- EQUALS_MATCH: L['self'].n_neighbors == 2                                  
	| | +- GuardManager: source=L['self'].n_components, accessed_by=GetAttrGuardAccessor(n_components)
	| | | +- EQUALS_MATCH: L['self'].n_components == 2                                 
	| +- GuardManager: source=L['X'], accessed_by=DictGetItemGuardAccessor(X)
	| | +- GuardManager: source=___from_numpy(L['X']), accessed_by=PythonLambdaGuardAccessor
	| | | +- TENSOR_MATCH: check_tensor(___from_numpy(L['X']), Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(___from_numpy(L['X']), '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['np'], accessed_by=DictGetItemGuardAccessor(np)
	| | | +- ID_MATCH: ___check_obj_id(G['np'], 138006086600640)                   
	| | | +- GuardManager: source=G['np'].zeros, accessed_by=GetAttrGuardAccessor(zeros)
	| | | | +- ID_MATCH: ___check_obj_id(G['np'].zeros, 138006086610480)             
	| | +- GuardManager: source=G['__builtins_dict___148'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___148)
	| | | +- GuardManager: source=G['__builtins_dict___148']['list'], accessed_by=DictGetItemGuardAccessor(list)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___148']['list'], 111055818730400)
	| | | +- GuardManager: source=G['__builtins_dict___148']['range'], accessed_by=DictGetItemGuardAccessor(range)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___148']['range'], 111055818753408)
	
V0401 21:32:47.846000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "b1a0c74ef5fb1c7d18d9453dbe2c4692"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167846332.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.847000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0, "has_payload": "1c41d6cd0dcd518f8cd343e6b6b9777b"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167847199.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 21,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.848000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "49/0", "frame_key": "93", "co_name": "torch_dynamo_resume_in_fit_at_2415", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/umap/umap_.py", "co_firstlineno": 2415, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 14, "shape_env_guard_count": 0, "graph_op_count": 3, "graph_node_count": 5, "graph_input_count": 1, "start_time": 1743543167.7595718, "entire_frame_compile_time_s": 0.08668804168701172, "backend_compile_time_s": 0.0480046272277832, "inductor_compile_time_s": 0.013441801071166992, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 49, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.854000 13985 torch/_logging/structured.py:22] {"str": ["/home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", 10]}
V0401 21:32:47.854000 13985 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 69, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 19, "name": "forward_refined", "filename": 1}, {"line": 34, "name": "torch_dynamo_resume_in_forward_refined_at_34", "filename": 1}, {"line": 35, "name": "torch_dynamo_resume_in_forward_refined_at_35", "filename": 1}, {"line": 1001, "name": "forward", "filename": 10}]}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.855000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "508644692ffafcc72f053a0cf5781d3f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543167855613.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.856000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "614f4f2192086a600621bc9233069a08"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543167855613.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:47.864000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 112, "size": 80}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.865000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d03938e0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:47.866000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 0, "source": "L['input_ids']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.176000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 112, "size": 4096}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.177000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "stride": [512, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d31199f0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.178000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 1, "source": "L['self']._modules['embeddings']._buffers['token_type_ids']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.187000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 112, "size": 4096}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.188000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d3547340>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.189000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "is_view": true, "stride": [512, 1], "storage": 2, "base": 6, "creation_meta": "CreationMeta.DEFAULT", "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7d83d3119950>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.190000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 5, "source": "L['self']._modules['embeddings']._buffers['position_ids']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.197000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 112, "size": 15627264}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.198000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [30522, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3152c60>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.199000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 8, "source": "L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.207000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 112, "size": 1024}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.208000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 9, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [2, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3153610>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.209000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 9, "source": "L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.216000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.216000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 11, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3150960>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.217000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 11, "source": "L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.224000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.225000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 12, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3152d50>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.225000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 12, "source": "L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.228000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 7, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.228000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 13, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 7, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3109040>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.229000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 13, "source": "L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.315000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 8, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.316000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 25, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 8, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3150dc0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.317000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 25, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.319000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 9, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.320000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 26, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 9, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3153570>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.321000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 26, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.340000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 10, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.341000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 36, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 10, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119a40>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.342000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 36, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.344000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 11, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.344000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 37, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 11, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3152fd0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.345000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 37, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.352000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 12, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.353000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 38, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 12, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119a90>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.353000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 38, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.356000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 13, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.357000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 39, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 13, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119ae0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.357000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 39, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.374000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 14, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.375000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 45, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 14, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d31531b0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.376000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 45, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.378000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 15, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.379000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 46, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 15, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3150460>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.380000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 46, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.388000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 16, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.389000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 47, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 16, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119c20>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.389000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 47, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.391000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 17, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.392000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 48, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 17, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119b30>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.393000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 48, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.409000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 18, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.409000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 52, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 18, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119cc0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.410000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 52, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.412000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 19, "describer_id": 112, "size": 2048}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.413000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 53, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 19, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119d10>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.414000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 53, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.428000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 20, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.429000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 61, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 20, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119c70>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.430000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 61, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.432000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 21, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.433000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 62, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 21, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3152a80>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.434000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 62, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.444000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 22, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.445000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 66, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 22, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119e00>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.445000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 66, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.447000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 23, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.448000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 67, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 23, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119db0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.449000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 67, "source": "L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.475000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 24, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.476000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 71, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 24, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119bd0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.477000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 71, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.479000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 25, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.480000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 72, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 25, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119d60>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.481000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 72, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.488000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 26, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.489000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 73, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 26, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119ea0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.489000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 73, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.491000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 27, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.492000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 74, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 27, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119f40>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.493000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 74, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.499000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 28, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.500000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 75, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 28, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119f90>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.501000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 75, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.503000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 29, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.504000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 76, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 29, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119fe0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.504000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 76, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.526000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 30, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.527000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 79, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 30, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a030>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.528000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 79, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.531000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 31, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.533000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 80, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 31, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a080>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.534000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 80, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.543000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 32, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.544000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 81, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 32, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a120>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.545000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 81, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.546000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 33, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.547000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 82, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 33, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a0d0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.548000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 82, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.559000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 34, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.560000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 86, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 34, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a210>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.561000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 86, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.562000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 35, "describer_id": 112, "size": 2048}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.563000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 87, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 35, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3119e50>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.564000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 87, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.572000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 36, "describer_id": 112, "size": 262144}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.572000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 88, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 36, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a1c0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.573000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 88, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.575000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 37, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.576000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 89, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 37, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a170>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.577000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 89, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.583000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 38, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.584000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 90, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 38, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a300>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.585000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 90, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.587000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 39, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.588000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 91, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 39, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d311a2b0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.588000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 91, "source": "L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.610000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 40, "describer_id": 112, "size": 65536}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.610000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 97, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 40, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3108fa0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.611000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 97, "source": "L['self']._modules['pooler']._modules['dense']._parameters['weight']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.614000 13985 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 41, "describer_id": 112, "size": 512}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.615000 13985 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 98, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 41, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7d83d3108ff0>", "describer_id": 112}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.615000 13985 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 112, "id": 98, "source": "L['self']._modules['pooler']._modules['dense']._parameters['bias']"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
V0401 21:32:48.646000 13985 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_input_ids_": [1, 10], "l_self_modules_embeddings_buffers_token_type_ids_": [1, 512], "l_self_modules_embeddings_buffers_position_ids_": [1, 512], "l_self_modules_embeddings_modules_word_embeddings_parameters_weight_": [30522, 128], "l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_": [2, 128], "l_self_modules_embeddings_modules_position_embeddings_parameters_weight_": [512, 128], "l_self_modules_embeddings_modules_layer_norm_parameters_weight_": [128], "l_self_modules_embeddings_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_": [512], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_": [128, 512], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_": [512], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_": [128, 512], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_": [128], "l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_": [128], "l_self_modules_pooler_modules_dense_parameters_weight_": [128, 128], "l_self_modules_pooler_modules_dense_parameters_bias_": [128], "buffered_token_type_ids": [1, 10], "buffered_token_type_ids_expanded": [1, 10], "position_ids": [1, 10], "inputs_embeds": [1, 10, 128], "token_type_embeddings": [1, 10, 128], "embeddings": [1, 10, 128], "position_embeddings": [1, 10, 128], "embeddings_1": [1, 10, 128], "embeddings_2": [1, 10, 128], "embeddings_3": [1, 10, 128], "attention_mask": [1, 10], "getitem_2": [1, 1, 1, 10], "expand_1": [1, 1, 10, 10], "expanded_mask": [1, 1, 10, 10], "inverted_mask": [1, 1, 10, 10], "to_1": [1, 1, 10, 10], "extended_attention_mask": [1, 1, 10, 10], "linear": [1, 10, 128], "x": [1, 10, 2, 64], "query_layer": [1, 2, 10, 64], "linear_1": [1, 10, 128], "x_1": [1, 10, 2, 64], "key_layer": [1, 2, 10, 64], "linear_2": [1, 10, 128], "x_2": [1, 10, 2, 64], "value_layer": [1, 2, 10, 64], "attn_output": [1, 2, 10, 64], "attn_output_1": [1, 10, 2, 64], "attn_output_2": [1, 10, 128], "hidden_states": [1, 10, 128], "hidden_states_1": [1, 10, 128], "add_1": [1, 10, 128], "hidden_states_2": [1, 10, 128], "hidden_states_3": [1, 10, 512], "hidden_states_4": [1, 10, 512], "hidden_states_5": [1, 10, 128], "hidden_states_6": [1, 10, 128], "add_2": [1, 10, 128], "hidden_states_7": [1, 10, 128], "linear_6": [1, 10, 128], "x_3": [1, 10, 2, 64], "query_layer_1": [1, 2, 10, 64], "linear_7": [1, 10, 128], "x_4": [1, 10, 2, 64], "key_layer_1": [1, 2, 10, 64], "linear_8": [1, 10, 128], "x_5": [1, 10, 2, 64], "value_layer_1": [1, 2, 10, 64], "attn_output_3": [1, 2, 10, 64], "attn_output_4": [1, 10, 2, 64], "attn_output_5": [1, 10, 128], "hidden_states_8": [1, 10, 128], "hidden_states_9": [1, 10, 128], "add_3": [1, 10, 128], "hidden_states_10": [1, 10, 128], "hidden_states_11": [1, 10, 512], "hidden_states_12": [1, 10, 512], "hidden_states_13": [1, 10, 128], "hidden_states_14": [1, 10, 128], "add_4": [1, 10, 128], "hidden_states_15": [1, 10, 128], "first_token_tensor": [1, 128], "pooled_output": [1, 128], "pooled_output_1": [1, 128]}}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "ab467e954c31af9f03b0e717a844571c"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_input_ids_: "i64[1, 10][10, 1]cpu", L_self_modules_embeddings_buffers_token_type_ids_: "i64[1, 512][512, 1]cpu", L_self_modules_embeddings_buffers_position_ids_: "i64[1, 512][512, 1]cpu", L_self_modules_embeddings_modules_word_embeddings_parameters_weight_: "f32[30522, 128][128, 1]cpu", L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_: "f32[2, 128][128, 1]cpu", L_self_modules_embeddings_modules_position_embeddings_parameters_weight_: "f32[512, 128][128, 1]cpu", L_self_modules_embeddings_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_embeddings_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", L_self_modules_pooler_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", L_self_modules_pooler_modules_dense_parameters_bias_: "f32[128][1]cpu"):
	        l_input_ids_ = L_input_ids_
	        l_self_modules_embeddings_buffers_token_type_ids_ = L_self_modules_embeddings_buffers_token_type_ids_
	        l_self_modules_embeddings_buffers_position_ids_ = L_self_modules_embeddings_buffers_position_ids_
	        l_self_modules_embeddings_modules_word_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_word_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_position_embeddings_parameters_weight_ = L_self_modules_embeddings_modules_position_embeddings_parameters_weight_
	        l_self_modules_embeddings_modules_layer_norm_parameters_weight_ = L_self_modules_embeddings_modules_LayerNorm_parameters_weight_
	        l_self_modules_embeddings_modules_layer_norm_parameters_bias_ = L_self_modules_embeddings_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_
	        l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_
	        l_self_modules_pooler_modules_dense_parameters_weight_ = L_self_modules_pooler_modules_dense_parameters_weight_
	        l_self_modules_pooler_modules_dense_parameters_bias_ = L_self_modules_pooler_modules_dense_parameters_bias_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        buffered_token_type_ids: "i64[1, 10][512, 1]cpu" = l_self_modules_embeddings_buffers_token_type_ids_[(slice(None, None, None), slice(None, 10, None))];  l_self_modules_embeddings_buffers_token_type_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        buffered_token_type_ids_expanded: "i64[1, 10][512, 1]cpu" = buffered_token_type_ids.expand(1, 10);  buffered_token_type_ids = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        position_ids: "i64[1, 10][512, 1]cpu" = l_self_modules_embeddings_buffers_position_ids_[(slice(None, None, None), slice(0, 10, None))];  l_self_modules_embeddings_buffers_position_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        inputs_embeds: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(l_input_ids_, l_self_modules_embeddings_modules_word_embeddings_parameters_weight_, 0, None, 2.0, False, False);  l_input_ids_ = l_self_modules_embeddings_modules_word_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        token_type_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(buffered_token_type_ids_expanded, l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_, None, None, 2.0, False, False);  buffered_token_type_ids_expanded = l_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = inputs_embeds + token_type_embeddings;  inputs_embeds = token_type_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        position_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(position_ids, l_self_modules_embeddings_modules_position_embeddings_parameters_weight_, None, None, 2.0, False, False);  position_ids = l_self_modules_embeddings_modules_position_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        embeddings += position_embeddings;  embeddings_1: "f32[1, 10, 128][1280, 128, 1]cpu" = embeddings;  embeddings = position_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        embeddings_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(embeddings_1, (128,), l_self_modules_embeddings_modules_layer_norm_parameters_weight_, l_self_modules_embeddings_modules_layer_norm_parameters_bias_, 1e-12);  embeddings_1 = l_self_modules_embeddings_modules_layer_norm_parameters_weight_ = l_self_modules_embeddings_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        embeddings_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(embeddings_2, 0.1, False, False);  embeddings_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        attention_mask: "f32[1, 10][10, 1]cpu" = torch.ones((1, 10), device = device(type='cpu'))
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        getitem_2: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = attention_mask[(slice(None, None, None), None, None, slice(None, None, None))];  attention_mask = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = getitem_2.expand(1, 1, 10, 10);  getitem_2 = None
	        expanded_mask: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = expand_1.to(torch.float32);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        inverted_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = 1.0 - expanded_mask;  expanded_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        to_1: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.to(torch.bool)
	        extended_attention_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.masked_fill(to_1, -3.4028234663852886e+38);  inverted_mask = to_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear.view((1, 10, 2, 64));  linear = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x.permute(0, 2, 1, 3);  x = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_1.view((1, 10, 2, 64));  linear_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_1.permute(0, 2, 1, 3);  x_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_2.view((1, 10, 2, 64));  linear_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_2.permute(0, 2, 1, 3);  x_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer, key_layer, value_layer, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer = key_layer = value_layer = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output.transpose(1, 2);  attn_output = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_2: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_1.reshape(1, 10, 128);  attn_output_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_2, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_2 = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states, 0.1, False, False);  hidden_states = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_1 + embeddings_3;  hidden_states_1 = embeddings_3 = None
	        hidden_states_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_1, (128,), l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_1 = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_2, l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_3);  hidden_states_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_4, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_);  hidden_states_4 = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_5, 0.1, False, False);  hidden_states_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_2: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_6 + hidden_states_2;  hidden_states_6 = hidden_states_2 = None
	        hidden_states_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_2, (128,), l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_2 = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_3: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_6.view((1, 10, 2, 64));  linear_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_3.permute(0, 2, 1, 3);  x_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_7.view((1, 10, 2, 64));  linear_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_4.permute(0, 2, 1, 3);  x_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_8.view((1, 10, 2, 64));  linear_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_5.permute(0, 2, 1, 3);  x_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer_1, key_layer_1, value_layer_1, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer_1 = key_layer_1 = value_layer_1 = extended_attention_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output_3.transpose(1, 2);  attn_output_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_5: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_4.reshape(1, 10, 128);  attn_output_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_5, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_5 = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_8, 0.1, False, False);  hidden_states_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_9 + hidden_states_7;  hidden_states_9 = hidden_states_7 = None
	        hidden_states_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_3, (128,), l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_3 = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_10, l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_);  l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_11);  hidden_states_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_12, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_);  hidden_states_12 = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_13, 0.1, False, False);  hidden_states_13 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_14 + hidden_states_10;  hidden_states_14 = hidden_states_10 = None
	        hidden_states_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_4, (128,), l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_, l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_4 = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = l_self_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        first_token_tensor: "f32[1, 128][1280, 1]cpu" = hidden_states_15[(slice(None, None, None), 0)]
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        pooled_output: "f32[1, 128][128, 1]cpu" = torch._C._nn.linear(first_token_tensor, l_self_modules_pooler_modules_dense_parameters_weight_, l_self_modules_pooler_modules_dense_parameters_bias_);  first_token_tensor = l_self_modules_pooler_modules_dense_parameters_weight_ = l_self_modules_pooler_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        pooled_output_1: "f32[1, 128][128, 1]cpu" = torch.tanh(pooled_output);  pooled_output = None
	        return (hidden_states_15, pooled_output_1)
	        
V0401 21:32:48.647000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "12c878320c20a4293e99634c7da53d6e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543168647890.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:48.648000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "ca0a2de08a9581b8b6ff7f08f67706c0"}
	{
	"name": "backend_compile",
	"ts": 1743543168647890.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:48.685000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "c79f64da44faa122540395bb67e36d37"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543168685742.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.360000 13985 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:352] {"aot_joint_graph": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcb09d2e1a88d319c9f911a929a3e77d"}
	class joint_helper(torch.nn.Module):
	    def forward(self, primals, tangents):
	        primals_1: "i64[1, 10][10, 1]cpu"; primals_2: "i64[1, 512][512, 1]cpu"; primals_3: "i64[1, 512][512, 1]cpu"; primals_4: "f32[30522, 128][128, 1]cpu"; primals_5: "f32[2, 128][128, 1]cpu"; primals_6: "f32[512, 128][128, 1]cpu"; primals_7: "f32[128][1]cpu"; primals_8: "f32[128][1]cpu"; primals_9: "f32[128, 128][1, 128]cpu"; primals_10: "f32[128][1]cpu"; primals_11: "f32[128, 128][1, 128]cpu"; primals_12: "f32[128][1]cpu"; primals_13: "f32[128, 128][1, 128]cpu"; primals_14: "f32[128][1]cpu"; primals_15: "f32[128, 128][1, 128]cpu"; primals_16: "f32[128][1]cpu"; primals_17: "f32[128][1]cpu"; primals_18: "f32[128][1]cpu"; primals_19: "f32[512, 128][1, 512]cpu"; primals_20: "f32[512][1]cpu"; primals_21: "f32[128, 512][1, 128]cpu"; primals_22: "f32[128][1]cpu"; primals_23: "f32[128][1]cpu"; primals_24: "f32[128][1]cpu"; primals_25: "f32[128, 128][1, 128]cpu"; primals_26: "f32[128][1]cpu"; primals_27: "f32[128, 128][1, 128]cpu"; primals_28: "f32[128][1]cpu"; primals_29: "f32[128, 128][1, 128]cpu"; primals_30: "f32[128][1]cpu"; primals_31: "f32[128, 128][1, 128]cpu"; primals_32: "f32[128][1]cpu"; primals_33: "f32[128][1]cpu"; primals_34: "f32[128][1]cpu"; primals_35: "f32[512, 128][1, 512]cpu"; primals_36: "f32[512][1]cpu"; primals_37: "f32[128, 512][1, 128]cpu"; primals_38: "f32[128][1]cpu"; primals_39: "f32[128][1]cpu"; primals_40: "f32[128][1]cpu"; primals_41: "f32[128, 128][1, 128]cpu"; primals_42: "f32[128][1]cpu"; tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu"; tangents_2: "f32[1, 128][128, 1]cpu"; 
	    
	        primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, tangents_1, tangents_2, = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_1: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 0, 0, 9223372036854775807);  primals_2 = None
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 10);  slice_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_3: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 0, 0, 9223372036854775807);  primals_3 = None
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_3, 1, 0, 10);  slice_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1)
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7);  mul = None
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        clone: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(add_3);  add_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        full: "f32[1, 10][10, 1]cpu" = torch.ops.aten.full.default([1, 10], 1, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        slice_5: "f32[1, 10][10, 1]cpu" = torch.ops.aten.slice.Tensor(full, 0, 0, 9223372036854775807);  full = None
	        unsqueeze: "f32[1, 1, 10][10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(slice_5, 1);  slice_5 = None
	        unsqueeze_1: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
	        slice_6: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.slice.Tensor(unsqueeze_1, 3, 0, 9223372036854775807);  unsqueeze_1 = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = torch.ops.aten.expand.default(slice_6, [1, 1, 10, 10]);  slice_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        sub_1: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.sub.Tensor(1.0, expand_1);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        convert_element_type: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.prims.convert_element_type.default(sub_1, torch.bool)
	        scalar_tensor: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(-3.4028234663852886e+38, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.where.self(convert_element_type, scalar_tensor, sub_1);  convert_element_type = scalar_tensor = sub_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view_3, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view_6, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = where)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        alias: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_2)
	        alias_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias);  alias = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3]);  getitem_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_11);  view_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_1, clone);  clone_1 = clone = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5)
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17);  mul_2 = None
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_15);  view_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_2, add_6);  clone_2 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7)
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23);  mul_7 = None
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_19: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_19, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_22, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = where)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        alias_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_8)
	        alias_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_2);  alias_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3]);  getitem_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_27);  view_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_3, add_10);  clone_3 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11)
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33);  mul_9 = None
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_31);  view_31 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_4, add_13);  clone_4 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13)
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39);  mul_14 = None
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        slice_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice.Tensor(add_17, 0, 0, 9223372036854775807)
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(slice_7, 1, 0);  slice_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        alias_4: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(tanh)
	        alias_5: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_4);  alias_4 = None
	        alias_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_5);  alias_5 = None
	        alias_7: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_6);  alias_6 = None
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(alias_7, alias_7);  alias_7 = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_1, mm, 1, 0);  full_1 = mm = None
	        full_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        slice_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice_scatter.default(full_2, select_scatter, 0, 0, 9223372036854775807);  full_2 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, slice_scatter);  tangents_1 = slice_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_7, rsqrt_4);  sub_7 = None
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_18);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_18, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_18);  mul_18 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_2: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_25);  mul_25 = None
	        add_19: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_2, 1);  erf_2 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_19, 0.5);  add_19 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_32: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_10, rsqrt_3);  sub_10 = None
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_32);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_32, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_32);  mul_32 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_3);  alias_3 = None
	        alias_9: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_8);  alias_8 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, alias_9, getitem_9, 0.0, False, attn_mask = where);  permute_33 = permute_11 = permute_13 = permute_15 = alias_9 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_22, [1, 0]);  view_22 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44);  permute_36 = None
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        permute_40: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_19, [1, 0]);  view_19 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_40, view_48);  permute_40 = None
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        permute_44: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_44, view_52);  permute_44 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_39: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_13, rsqrt_2);  sub_13 = None
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_39);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_39, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_39);  mul_39 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_46: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_46);  mul_46 = None
	        add_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_3, 1);  erf_3 = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_25, 0.5);  add_25 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_16: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_53: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_16, rsqrt_1);  sub_16 = None
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_53);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_53, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_53);  mul_53 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_10: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_1);  alias_1 = None
	        alias_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_10);  alias_10 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, alias_11, getitem_3, 0.0, False, attn_mask = where);  permute_55 = permute_1 = permute_3 = permute_5 = alias_11 = getitem_3 = where = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_6, [1, 0]);  view_6 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66);  permute_58 = None
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        permute_62: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_3, [1, 0]);  view_3 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_62, view_70);  permute_62 = None
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        permute_66: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_66, view_74);  permute_66 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        sub_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_19, rsqrt);  sub_19 = None
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul_60);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_60, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul_60);  mul_60 = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        scalar_tensor_1: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, scalar_tensor_1, mul_65);  unsqueeze_2 = scalar_tensor_1 = None
	        full_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_3, [slice_4], where_1, True);  full_3 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        scalar_tensor_2: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, scalar_tensor_2, mul_65);  unsqueeze_3 = scalar_tensor_2 = None
	        full_4: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_4, [expand], where_2, True);  full_4 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        scalar_tensor_3: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, scalar_tensor_3, mul_65);  unsqueeze_4 = scalar_tensor_3 = mul_65 = None
	        full_5: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_5, [primals_1], where_3, True);  full_5 = primals_1 = where_3 = None
	        return pytree.tree_unflatten([add_17, tanh, None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32], self._out_spec)
	        
V0401 21:32:49.812000 13985 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:545] {"aot_forward_graph": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "79ae68c5ee14a8aca5626a97bbc2e0b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_2: "i64[1, 512][512, 1]cpu", primals_3: "i64[1, 512][512, 1]cpu", primals_4: "f32[30522, 128][128, 1]cpu", primals_5: "f32[2, 128][128, 1]cpu", primals_6: "f32[512, 128][128, 1]cpu", primals_7: "f32[128][1]cpu", primals_8: "f32[128][1]cpu", primals_9: "f32[128, 128][1, 128]cpu", primals_10: "f32[128][1]cpu", primals_11: "f32[128, 128][1, 128]cpu", primals_12: "f32[128][1]cpu", primals_13: "f32[128, 128][1, 128]cpu", primals_14: "f32[128][1]cpu", primals_15: "f32[128, 128][1, 128]cpu", primals_16: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_18: "f32[128][1]cpu", primals_19: "f32[512, 128][1, 512]cpu", primals_20: "f32[512][1]cpu", primals_21: "f32[128, 512][1, 128]cpu", primals_22: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_24: "f32[128][1]cpu", primals_25: "f32[128, 128][1, 128]cpu", primals_26: "f32[128][1]cpu", primals_27: "f32[128, 128][1, 128]cpu", primals_28: "f32[128][1]cpu", primals_29: "f32[128, 128][1, 128]cpu", primals_30: "f32[128][1]cpu", primals_31: "f32[128, 128][1, 128]cpu", primals_32: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_34: "f32[128][1]cpu", primals_35: "f32[512, 128][1, 512]cpu", primals_36: "f32[512][1]cpu", primals_37: "f32[128, 512][1, 128]cpu", primals_38: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", primals_40: "f32[128][1]cpu", primals_41: "f32[128, 128][1, 128]cpu", primals_42: "f32[128][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_3, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17)
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23)
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33)
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39)
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(add_17, 1, 0)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)
	        
V0401 21:32:49.824000 13985 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] {"aot_backward_graph": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "8ef2f550890c1bc6143556bd01aa3cc0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_7: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", expand: "i64[1, 10][512, 1]cpu", slice_4: "i64[1, 10][512, 1]cpu", mul: "f32[1, 10, 128][1280, 128, 1]cpu", full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu", permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_3: "f32[1, 2, 10][20, 1, 2]cpu", mul_2: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_4: "f32[10, 512][512, 1]cpu", mul_7: "f32[1, 10, 128][1280, 128, 1]cpu", permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_9: "f32[1, 2, 10][20, 1, 2]cpu", mul_9: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_10: "f32[10, 512][512, 1]cpu", mul_14: "f32[1, 10, 128][1280, 128, 1]cpu", tanh: "f32[1, 128][128, 1]cpu", permute_21: "f32[128, 128][1, 128]cpu", permute_22: "f32[128, 1][1, 1280]cpu", div: "f32[1, 10, 1][10, 1, 1]cpu", permute_24: "f32[128, 512][1, 128]cpu", permute_25: "f32[512, 10][1, 512]cpu", permute_27: "f32[512, 128][1, 512]cpu", permute_28: "f32[128, 10][1, 128]cpu", div_1: "f32[1, 10, 1][10, 1, 1]cpu", permute_30: "f32[128, 128][1, 128]cpu", permute_35: "f32[128, 128][1, 128]cpu", permute_36: "f32[128, 10][1, 128]cpu", permute_39: "f32[128, 128][1, 128]cpu", permute_43: "f32[128, 128][1, 128]cpu", div_2: "f32[1, 10, 1][10, 1, 1]cpu", permute_46: "f32[128, 512][1, 128]cpu", permute_47: "f32[512, 10][1, 512]cpu", permute_49: "f32[512, 128][1, 512]cpu", permute_50: "f32[128, 10][1, 128]cpu", div_3: "f32[1, 10, 1][10, 1, 1]cpu", permute_52: "f32[128, 128][1, 128]cpu", permute_57: "f32[128, 128][1, 128]cpu", permute_58: "f32[128, 10][1, 128]cpu", permute_61: "f32[128, 128][1, 128]cpu", permute_65: "f32[128, 128][1, 128]cpu", div_4: "f32[1, 10, 1][10, 1, 1]cpu", tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu", tangents_2: "f32[1, 128][128, 1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tanh, tanh);  tanh = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_default_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_default_1, mm, 1, 0);  full_default_1 = mm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, select_scatter);  tangents_1 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_14);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_14);  mul_14 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_14, 0.5);  add_14 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_9);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_9);  mul_9 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, getitem_8, getitem_9, 0.0, False, attn_mask = full_default);  permute_33 = permute_11 = permute_13 = permute_15 = getitem_8 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44)
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_48)
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_52);  permute_36 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_7);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_7);  mul_7 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_7, 0.5);  add_7 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_2);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_2);  mul_2 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, getitem_2, getitem_3, 0.0, False, attn_mask = full_default);  permute_55 = permute_1 = permute_3 = permute_5 = getitem_2 = getitem_3 = full_default = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66)
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_70)
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_74);  permute_58 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul);  mul = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        full_default_3: "f32[][]cpu" = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, full_default_3, mul_65);  unsqueeze_2 = None
	        full_default_4: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_4, [slice_4], where_1, True);  full_default_4 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, full_default_3, mul_65);  unsqueeze_3 = None
	        full_default_6: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_6, [expand], where_2, True);  full_default_6 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, full_default_3, mul_65);  unsqueeze_4 = full_default_3 = mul_65 = None
	        full_default_8: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_8, [primals_1], where_3, True);  full_default_8 = primals_1 = where_3 = None
	        return (None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32)
	        
V0401 21:32:49.825000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "4264659374e47c8af42445d4d8bf5fc5"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543169825396.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.827000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "71903cd31d38d13f5428b53336909341"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543169826962.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.828000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "f1688560bc4367a451bb579057ea0985"}
	{
	"name": "inductor_compile",
	"ts": 1743543169826962.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.873000 13985 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/wj/cwj2yvfe4p4qqpw45iwdct6oixfgysw425lsdrk75mhovzer24kt.py"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "27c0d546112e14e158896e97040f6d61"}
	# AOT ID: ['23_forward']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0 = async_compile.cpp_pybinding(['const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       const float* in_ptr1,
	                       const int64_t* in_ptr2,
	                       const float* in_ptr3,
	                       const int64_t* in_ptr4,
	                       const float* in_ptr5,
	                       const float* in_ptr6,
	                       const float* in_ptr7,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4,
	                       float* out_ptr5,
	                       float* out_ptr6)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                    auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	                    auto tmp21 = in_ptr4[static_cast<int64_t>(x0)];
	                    auto tmp1 = 30522L;
	                    auto tmp2 = c10::convert<int64_t>(tmp1);
	                    auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
	                    auto tmp4 = tmp0 < 0;
	                    auto tmp5 = tmp4 ? tmp3 : tmp0;
	                    auto tmp6 = tmp5;
	                    auto tmp7 = c10::convert<int64_t>(tmp6);
	                    TORCH_CHECK((0 <= tmp7) & (tmp7 < 30522L), "index out of bounds: 0 <= tmp7 < 30522L");
	                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*tmp5)), static_cast<int64_t>(8));
	                    auto tmp11 = 2L;
	                    auto tmp12 = c10::convert<int64_t>(tmp11);
	                    auto tmp13 = decltype(tmp10)(tmp10 + tmp12);
	                    auto tmp14 = tmp10 < 0;
	                    auto tmp15 = tmp14 ? tmp13 : tmp10;
	                    auto tmp16 = tmp15;
	                    auto tmp17 = c10::convert<int64_t>(tmp16);
	                    TORCH_CHECK((0 <= tmp17) & (tmp17 < 2L), "index out of bounds: 0 <= tmp17 < 2L");
	                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1 + (128L*tmp15)), static_cast<int64_t>(8));
	                    auto tmp20 = tmp9 + tmp19;
	                    auto tmp22 = 512L;
	                    auto tmp23 = c10::convert<int64_t>(tmp22);
	                    auto tmp24 = decltype(tmp21)(tmp21 + tmp23);
	                    auto tmp25 = tmp21 < 0;
	                    auto tmp26 = tmp25 ? tmp24 : tmp21;
	                    auto tmp27 = tmp26;
	                    auto tmp28 = c10::convert<int64_t>(tmp27);
	                    TORCH_CHECK((0 <= tmp28) & (tmp28 < 512L), "index out of bounds: 0 <= tmp28 < 512L");
	                    auto tmp30 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x1 + (128L*tmp26)), static_cast<int64_t>(8));
	                    auto tmp31 = tmp20 + tmp30;
	                    tmp31.store(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)));
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp31, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr2[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp4 = out_ptr2[static_cast<int64_t>(x0)];
	                auto tmp12 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = at::vec::Vectorized<float>(tmp1);
	                auto tmp3 = tmp0 - tmp2;
	                auto tmp5 = static_cast<float>(128.0);
	                auto tmp6 = tmp4 / tmp5;
	                auto tmp7 = static_cast<float>(1e-12);
	                auto tmp8 = decltype(tmp6)(tmp6 + tmp7);
	                auto tmp9 = 1 / std::sqrt(tmp8);
	                auto tmp10 = at::vec::Vectorized<float>(tmp9);
	                auto tmp11 = tmp3 * tmp10;
	                auto tmp13 = tmp11 * tmp12;
	                auto tmp15 = tmp13 + tmp14;
	                tmp11.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp15.store(out_ptr4 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(96L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(96L); x0<static_cast<int64_t>(100L); x0+=static_cast<int64_t>(4L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0), static_cast<int64_t>(4L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_1 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_2 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_3 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_4 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_5 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_6 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_tanh_7 = async_compile.cpp_pybinding(['float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(float* in_out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(128L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = decltype(tmp0)(2) / (decltype(tmp0)(1) + (decltype(tmp0)(-2) * tmp0).exp()) - decltype(tmp0)(1);
	            tmp1.store(in_out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42 = args
	    args.clear()
	    assert_size_stride(primals_1, (1, 10), (10, 1))
	    assert_size_stride(primals_2, (1, 512), (512, 1))
	    assert_size_stride(primals_3, (1, 512), (512, 1))
	    assert_size_stride(primals_4, (30522, 128), (128, 1))
	    assert_size_stride(primals_5, (2, 128), (128, 1))
	    assert_size_stride(primals_6, (512, 128), (128, 1))
	    assert_size_stride(primals_7, (128, ), (1, ))
	    assert_size_stride(primals_8, (128, ), (1, ))
	    assert_size_stride(primals_9, (128, 128), (1, 128))
	    assert_size_stride(primals_10, (128, ), (1, ))
	    assert_size_stride(primals_11, (128, 128), (1, 128))
	    assert_size_stride(primals_12, (128, ), (1, ))
	    assert_size_stride(primals_13, (128, 128), (1, 128))
	    assert_size_stride(primals_14, (128, ), (1, ))
	    assert_size_stride(primals_15, (128, 128), (1, 128))
	    assert_size_stride(primals_16, (128, ), (1, ))
	    assert_size_stride(primals_17, (128, ), (1, ))
	    assert_size_stride(primals_18, (128, ), (1, ))
	    assert_size_stride(primals_19, (512, 128), (1, 512))
	    assert_size_stride(primals_20, (512, ), (1, ))
	    assert_size_stride(primals_21, (128, 512), (1, 128))
	    assert_size_stride(primals_22, (128, ), (1, ))
	    assert_size_stride(primals_23, (128, ), (1, ))
	    assert_size_stride(primals_24, (128, ), (1, ))
	    assert_size_stride(primals_25, (128, 128), (1, 128))
	    assert_size_stride(primals_26, (128, ), (1, ))
	    assert_size_stride(primals_27, (128, 128), (1, 128))
	    assert_size_stride(primals_28, (128, ), (1, ))
	    assert_size_stride(primals_29, (128, 128), (1, 128))
	    assert_size_stride(primals_30, (128, ), (1, ))
	    assert_size_stride(primals_31, (128, 128), (1, 128))
	    assert_size_stride(primals_32, (128, ), (1, ))
	    assert_size_stride(primals_33, (128, ), (1, ))
	    assert_size_stride(primals_34, (128, ), (1, ))
	    assert_size_stride(primals_35, (512, 128), (1, 512))
	    assert_size_stride(primals_36, (512, ), (1, ))
	    assert_size_stride(primals_37, (128, 512), (1, 128))
	    assert_size_stride(primals_38, (128, ), (1, ))
	    assert_size_stride(primals_39, (128, ), (1, ))
	    assert_size_stride(primals_40, (128, ), (1, ))
	    assert_size_stride(primals_41, (128, 128), (1, 128))
	    assert_size_stride(primals_42, (128, ), (1, ))
	    buf0 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf1 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf2 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf4 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf6 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf53 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    buf5 = empty_strided_cpu((1, 1, 10, 10), (100, 100, 10, 1), torch.float32)
	    cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0(primals_1, primals_4, primals_2, primals_5, primals_3, primals_6, primals_7, primals_8, buf0, buf1, buf2, buf4, buf6, buf53, buf5)
	    del primals_4
	    del primals_5
	    del primals_6
	    del primals_8
	    buf7 = reinterpret_tensor(buf0, (10, 128), (128, 1), 0); del buf0  # reuse
	    # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_10, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_9, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf7)
	    del primals_10
	    buf8 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_1], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_12, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_11, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf8)
	    del primals_12
	    buf9 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_14, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_13, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf9)
	    del primals_14
	    # Topologically Sorted Source Nodes: [attn_output], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf10 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf11 = buf10[0]
	    buf12 = buf10[1]
	    del buf10
	    buf13 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_16, reinterpret_tensor(buf11, (10, 128), (128, 1), 0), reinterpret_tensor(primals_15, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf13)
	    del primals_16
	    buf14 = buf2; del buf2  # reuse
	    buf15 = buf1; del buf1  # reuse
	    buf17 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf18 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf52 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_1(buf13, buf6, primals_17, primals_18, buf14, buf15, buf17, buf18, buf52)
	    del primals_18
	    buf19 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_3], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_20, reinterpret_tensor(buf18, (10, 128), (128, 1), 0), reinterpret_tensor(primals_19, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf19)
	    del primals_20
	    buf20 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_2(buf19, buf20)
	    buf21 = buf13; del buf13  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_5], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_22, reinterpret_tensor(buf20, (10, 512), (512, 1), 0), reinterpret_tensor(primals_21, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf21)
	    del primals_22
	    buf22 = buf15; del buf15  # reuse
	    buf23 = buf14; del buf14  # reuse
	    buf25 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf26 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf51 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_3(buf21, buf18, primals_23, primals_24, buf22, buf23, buf25, buf26, buf51)
	    del primals_24
	    buf27 = buf21; del buf21  # reuse
	    # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_26, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_25, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf27)
	    del primals_26
	    buf28 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_7], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_28, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_27, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf28)
	    del primals_28
	    buf29 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_30, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_29, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf29)
	    del primals_30
	    # Topologically Sorted Source Nodes: [attn_output_3], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf30 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf31 = buf30[0]
	    buf32 = buf30[1]
	    del buf30
	    buf33 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_32, reinterpret_tensor(buf31, (10, 128), (128, 1), 0), reinterpret_tensor(primals_31, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf33)
	    del primals_32
	    buf34 = buf23; del buf23  # reuse
	    buf35 = buf22; del buf22  # reuse
	    buf37 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf38 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf50 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_4(buf33, buf26, primals_33, primals_34, buf34, buf35, buf37, buf38, buf50)
	    del primals_34
	    buf39 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_11], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_36, reinterpret_tensor(buf38, (10, 128), (128, 1), 0), reinterpret_tensor(primals_35, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf39)
	    del primals_36
	    buf40 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_5(buf39, buf40)
	    buf41 = buf33; del buf33  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_13], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_38, reinterpret_tensor(buf40, (10, 512), (512, 1), 0), reinterpret_tensor(primals_37, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf41)
	    del primals_38
	    buf42 = buf35; del buf35  # reuse
	    buf43 = buf34; del buf34  # reuse
	    buf45 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf46 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf49 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_6(buf41, buf38, primals_39, primals_40, buf42, buf43, buf45, buf46, buf49)
	    del buf41
	    del buf42
	    del buf43
	    del primals_40
	    buf47 = empty_strided_cpu((1, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [pooled_output], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_42, reinterpret_tensor(buf46, (1, 128), (128, 1), 0), reinterpret_tensor(primals_41, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf47)
	    del primals_42
	    buf48 = buf47; del buf47  # reuse
	    cpp_fused_tanh_7(buf48)
	    return (buf46, buf48, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, reinterpret_tensor(primals_2, (1, 10), (512, 1), 0), reinterpret_tensor(primals_3, (1, 10), (512, 1), 0), buf4, buf5, reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf11, buf12, buf17, buf19, buf25, reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf31, buf32, buf37, buf39, buf45, buf48, primals_41, reinterpret_tensor(buf46, (128, 1), (1, 1280), 0), buf49, primals_37, reinterpret_tensor(buf40, (512, 10), (1, 512), 0), primals_35, reinterpret_tensor(buf38, (128, 10), (1, 128), 0), buf50, primals_31, primals_29, reinterpret_tensor(buf26, (128, 10), (1, 128), 0), primals_27, primals_25, buf51, primals_21, reinterpret_tensor(buf20, (512, 10), (1, 512), 0), primals_19, reinterpret_tensor(buf18, (128, 10), (1, 128), 0), buf52, primals_15, primals_13, reinterpret_tensor(buf6, (128, 10), (1, 128), 0), primals_11, primals_9, buf53, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    primals_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    primals_2 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_3 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_4 = rand_strided((30522, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_5 = rand_strided((2, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_6 = rand_strided((512, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_7 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_8 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_9 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_10 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_11 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_12 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_13 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_14 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_15 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_16 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_17 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_18 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_19 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_20 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_21 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_22 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_23 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_24 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_25 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_26 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_27 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_28 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_29 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_30 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_31 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_32 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_33 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_34 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_35 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_36 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_37 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_38 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_39 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_40 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_41 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_42 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0401 21:32:49.875000 13985 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "2bb08aa4e65937ad61115dab1cfc641c"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743543169874740.8,
	"args": {
	"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a",
	"components": [
	"[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]",
	"[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 9358179354,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0401 21:32:49.876000 13985 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "e79f0f8d777e763e920651daa30b6af1"}
	{"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a", "components": ["[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]", "[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 9358179354, "cache_state": "hit"}
V0401 21:32:49.879000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "a2135d8cf4c986603f5e746f9322a59b"}
	{
	"name": "inductor_compile",
	"ts": 1743543169878989.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.879000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "63a30bb350a128a46eaea2996e05c869"}
	{
	"name": "compile_fx_inner",
	"ts": 1743543169879607.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.880000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "8b16cab8e2e1a34b8169f390d18f3b91"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743543169880852.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.884000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "a74f1996ca085c47deba0eab1267b7fd"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743543169884505.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.885000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "57837325b191e85644fbbc2a0c8d6392"}
	{
	"name": "backend_compile",
	"ts": 1743543169885447.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:49.886000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "b5107464b9ca07c0b7b0c60192e122cb"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743543169886186.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:50.089000 13985 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "6a39edf24874c69ca1b7d0aafd3fbab1"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | +- TYPE_MATCH: ___check_type_id(L['self'], 111057051038704)                
	| | +- GuardManager: source=L['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | +- GuardManager: source=L['self'].config, accessed_by=DictGetItemGuardAccessor(config)
	| | | | +- TYPE_MATCH: ___check_type_id(L['self'].config, 111057046026224)         
	| | | | +- GuardManager: source=L['self'].config.is_decoder, accessed_by=GetAttrGuardAccessor(is_decoder)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.is_decoder, 111055818658752)
	| | | | +- GuardManager: source=L['self'].config.use_return_dict, accessed_by=GetAttrGuardAccessor(use_return_dict)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.use_return_dict, 111055818658720)
	| | | | +- GuardManager: source=L['self'].config.num_hidden_layers, accessed_by=GetAttrGuardAccessor(num_hidden_layers)
	| | | | | +- EQUALS_MATCH: L['self'].config.num_hidden_layers == 2                     
	| | | | +- GuardManager: source=L['self'].config.output_attentions, accessed_by=GetAttrGuardAccessor(output_attentions)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.output_attentions, 111055818658752)
	| | | | +- GuardManager: source=L['self'].config.output_hidden_states, accessed_by=GetAttrGuardAccessor(output_hidden_states)
	| | | | | +- ID_MATCH: ___check_obj_id(L['self'].config.output_hidden_states, 111055818658752)
	| | | +- GuardManager: source=L['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | +- DICT_LENGTH: len(L['self']._modules) == 3                                
	| | | | +- GuardManager: source=L['self']._modules['embeddings'], accessed_by=DictGetItemGuardAccessor(embeddings)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings'], 111057050251056)
	| | | | | +- GuardManager: source=L['self']._modules['embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers, accessed_by=DictGetItemGuardAccessor(_buffers)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._buffers) == 2         
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._buffers['position_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['input_ids'], L['self']._modules['embeddings']._buffers['position_ids'], L['self']._modules['embeddings']._buffers['token_type_ids'], L['self']._modules['pooler']._modules['dense']._parameters['bias'], L['self']._modules['pooler']._modules['dense']._parameters['weight'], L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'])
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._buffers['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._buffers['token_type_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules) == 5         
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'], accessed_by=DictGetItemGuardAccessor(word_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['word_embeddings'], 111056951365232)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['word_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].sparse, 111055818658752)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].max_norm, 111055818751712)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['word_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['word_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['word_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[30522, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['word_embeddings'].padding_idx == 0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, 111055818658752)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'], accessed_by=DictGetItemGuardAccessor(position_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['position_embeddings'], 111056951365232)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['position_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].sparse, 111055818658752)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].max_norm, 111055818751712)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['position_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['position_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['position_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].padding_idx, 111055818751712)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, 111055818658752)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'], accessed_by=DictGetItemGuardAccessor(token_type_embeddings)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['token_type_embeddings'], 111056951365232)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['token_type_embeddings'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].sparse, 111055818658752)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].max_norm, 111055818751712)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['token_type_embeddings'].norm_type == 2.0
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters) == 1
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[2, 128], stride=[128, 1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].padding_idx, 111055818751712)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, 111055818658752)
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['LayerNorm'], 111056950804992)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['LayerNorm'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['embeddings']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['embeddings']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape, 111055818760256)
	| | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['embeddings']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['embeddings']._modules['dropout'], 111056948550784)
	| | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['embeddings']._modules['dropout'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings']._modules['dropout'].p == 0.1
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['dropout'].inplace, 111055818658752)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['embeddings']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['embeddings']._modules['dropout'].training, 111055818658752)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._parameters            
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['embeddings']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._backward_hooks        
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['embeddings']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['embeddings']._backward_pre_hooks    
	| | | | | | +- GuardManager: source=L['self']._modules['embeddings'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | +- EQUALS_MATCH: L['self']._modules['embeddings'].position_embedding_type == 'absolute'
	| | | | +- GuardManager: source=L['self']._modules['encoder'], accessed_by=DictGetItemGuardAccessor(encoder)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder'], 111056988489696)
	| | | | | +- GuardManager: source=L['self']._modules['encoder'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules) == 1            
	| | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer'], accessed_by=DictGetItemGuardAccessor(layer)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer'], 111056949413008)
	| | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']) == 2   
	| | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DictGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | +- KeyValueManager pair at index=0
	| | | | | | | | | | | +- KeyManager: GuardManager: source=list(L['self']._modules['encoder']._modules['layer']._modules.keys())[0]
	| | | | | | | | | | | | +- EQUALS_MATCH: list(L['self']._modules['encoder']._modules['layer']._modules.keys())[0] == '0'
	| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0'], 111057050756640)
	| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0'].__dict__)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules) == 3
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'], 111057050725792)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], 111057050672880)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], 111057050674656)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], 111056950804992)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 111055818760256)
	| | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], 111056948550784)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, 111055818658752)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], 111055818751712)
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], 111057050727568)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], 111056949993488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], 111057050063840)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, 138005629074096)
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'], 111057050754864)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], 111056949993488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], 111056950804992)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, 111055818760256)
	| | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], 111056948550784)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, 111055818658752)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['0'].is_decoder, 111055818658752)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._parameters
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._backward_hooks
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward == 0
	| | | | | | | | | | +- KeyValueManager pair at index=1
	| | | | | | | | | | | +- KeyManager: GuardManager: source=list(L['self']._modules['encoder']._modules['layer']._modules.keys())[1]
	| | | | | | | | | | | | +- EQUALS_MATCH: list(L['self']._modules['encoder']._modules['layer']._modules.keys())[1] == '1'
	| | | | | | | | | | | +- ValueManager: GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1'], 111057050756640)
	| | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1'].__dict__)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules) == 3
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'], 111057050725792)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], 111057050672880)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], 111057050674656)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], 111056949993488)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], 111056950804992)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 111055818760256)
	| | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], 111056948550784)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, 111055818658752)
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], 111055818751712)
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], 111057050727568)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], 111056949993488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], 111057050063840)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, 138005629074096)
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'], 111057050754864)
	| | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], 111056949993488)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], 111056950804992)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, 111055818760256)
	| | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], 111056948550784)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, 111055818658752)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, 111055818658752)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder']._modules['layer']._modules['1'].is_decoder, 111055818658752)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._parameters
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._backward_hooks
	| | | | | | | | | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks
	| | | | | | | | | | | | | +- GuardManager: source=L['self']._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | +- EQUALS_MATCH: L['self']._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward == 0
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._parameters               
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._backward_hooks           
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['encoder']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['encoder']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['encoder']._backward_pre_hooks       
	| | | | | | +- GuardManager: source=L['self']._modules['encoder'].gradient_checkpointing, accessed_by=DictGetItemGuardAccessor(gradient_checkpointing)
	| | | | | | | +- ID_MATCH: ___check_obj_id(L['self']._modules['encoder'].gradient_checkpointing, 111055818658752)
	| | | | +- GuardManager: source=L['self']._modules['pooler'], accessed_by=DictGetItemGuardAccessor(pooler)
	| | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler'], 111056988491472)
	| | | | | +- GuardManager: source=L['self']._modules['pooler'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | +- DICT_LENGTH: len(L['self']._modules['pooler']._modules) == 2             
	| | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler']._modules['dense'], 111056949993488)
	| | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler']._modules['dense'].__dict__)
	| | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | +- DICT_LENGTH: len(L['self']._modules['pooler']._modules['dense']._parameters) == 2
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['pooler']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | +- TENSOR_MATCH: check_tensor(L['self']._modules['pooler']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['activation'], accessed_by=DictGetItemGuardAccessor(activation)
	| | | | | | | | +- TYPE_MATCH: ___check_type_id(L['self']._modules['pooler']._modules['activation'], 111056949702112)
	| | | | | | | | +- GuardManager: source=L['self']._modules['pooler']._modules['activation'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', L['self']._modules['pooler']._modules['activation'].__dict__)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._parameters                
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['pooler']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._backward_hooks            
	| | | | | | +- DictSubclassGuardManager: source=L['self']._modules['pooler']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | +- GuardManager: source=L['self']._modules['pooler']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | +- DICT_LENGTH: not L['self']._modules['pooler']._backward_pre_hooks        
	| | | +- GuardManager: source=L['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | +- DICT_LENGTH: not L['self']._parameters                                   
	| | | +- GuardManager: source=L['self'].attn_implementation, accessed_by=DictGetItemGuardAccessor(attn_implementation)
	| | | | +- EQUALS_MATCH: L['self'].attn_implementation == 'sdpa'                     
	| | | +- GuardManager: source=L['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | +- EQUALS_MATCH: L['self'].position_embedding_type == 'absolute'             
	| +- GuardManager: source=L['head_mask'], accessed_by=DictGetItemGuardAccessor(head_mask)
	| | +- ID_MATCH: ___check_obj_id(L['head_mask'], 111055818751712)            
	| +- GuardManager: source=L['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['input_ids'], '_dynamo_dynamic_indices') == False 
	| | +- NO_TENSOR_ALIASING
	| +- GuardManager: source=L['return_dict'], accessed_by=DictGetItemGuardAccessor(return_dict)
	| | +- ID_MATCH: ___check_obj_id(L['return_dict'], 111055818751712)          
	| +- GuardManager: source=L['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | +- ID_MATCH: ___check_obj_id(L['position_ids'], 111055818751712)         
	| +- GuardManager: source=L['inputs_embeds'], accessed_by=DictGetItemGuardAccessor(inputs_embeds)
	| | +- ID_MATCH: ___check_obj_id(L['inputs_embeds'], 111055818751712)        
	| +- GuardManager: source=L['attention_mask'], accessed_by=DictGetItemGuardAccessor(attention_mask)
	| | +- ID_MATCH: ___check_obj_id(L['attention_mask'], 111055818751712)       
	| +- GuardManager: source=L['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | +- ID_MATCH: ___check_obj_id(L['token_type_ids'], 111055818751712)       
	| +- GuardManager: source=L['past_key_values'], accessed_by=DictGetItemGuardAccessor(past_key_values)
	| | +- ID_MATCH: ___check_obj_id(L['past_key_values'], 111055818751712)      
	| +- GuardManager: source=L['output_attentions'], accessed_by=DictGetItemGuardAccessor(output_attentions)
	| | +- ID_MATCH: ___check_obj_id(L['output_attentions'], 111055818751712)    
	| +- GuardManager: source=L['output_hidden_states'], accessed_by=DictGetItemGuardAccessor(output_hidden_states)
	| | +- ID_MATCH: ___check_obj_id(L['output_hidden_states'], 111055818751712) 
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__import_torch'], accessed_by=DictGetItemGuardAccessor(__import_torch)
	| | | +- GuardManager: source=G['__import_torch'].fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx, 138005605510064)    
	| | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | | +- GuardManager: source=G['__import_torch'].fx.Proxy, accessed_by=GetAttrGuardAccessor(Proxy)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx.Proxy, 111056956451792)
	| | | +- GuardManager: source=G['__import_torch'].compiler, accessed_by=GetAttrGuardAccessor(compiler)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler, 138005588529840)
	| | | | +- GuardManager: source=G['__import_torch'].compiler.is_compiling, accessed_by=GetAttrGuardAccessor(is_compiling)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler.is_compiling, 138005588920416)
	| | +- GuardManager: source=G['apply_chunking_to_forward'], accessed_by=DictGetItemGuardAccessor(apply_chunking_to_forward)
	| | | +- GuardManager: source=G['apply_chunking_to_forward'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['apply_chunking_to_forward'].__code__, 111056993199824)
	| | +- GuardManager: source=G['__builtins_dict___150'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___150)
	| | | +- GuardManager: source=G['__builtins_dict___150']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['int'], 111055818732256)
	| | | +- GuardManager: source=G['__builtins_dict___150']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['len'], 138006094275152)
	| | | +- GuardManager: source=G['__builtins_dict___150']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['str'], 111055818777536)
	| | | +- GuardManager: source=G['__builtins_dict___150']['dict'], accessed_by=DictGetItemGuardAccessor(dict)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['dict'], 111055818737888)
	| | | +- GuardManager: source=G['__builtins_dict___150']['iter'], accessed_by=DictGetItemGuardAccessor(iter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['iter'], 138006094274992)
	| | | +- GuardManager: source=G['__builtins_dict___150']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['tuple'], 111055818760256)
	| | | +- GuardManager: source=G['__builtins_dict___150']['hasattr'], accessed_by=DictGetItemGuardAccessor(hasattr)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['hasattr'], 138006094274432)
	| | | +- GuardManager: source=G['__builtins_dict___150']['enumerate'], accessed_by=DictGetItemGuardAccessor(enumerate)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['enumerate'], 111055818680736)
	| | | +- GuardManager: source=G['__builtins_dict___150']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___150']['isinstance'], 138006094274832)
	| | +- GuardManager: source=G['_prepare_4d_attention_mask_for_sdpa'], accessed_by=DictGetItemGuardAccessor(_prepare_4d_attention_mask_for_sdpa)
	| | | +- GuardManager: source=G['_prepare_4d_attention_mask_for_sdpa'].__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | +- ID_MATCH: ___check_obj_id(G['_prepare_4d_attention_mask_for_sdpa'].__code__, 138005137764912)
	| | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_pytorch_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'], 138005523104768)
	| | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect, accessed_by=GetAttrGuardAccessor(inspect)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect, 138006093226336)
	| | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature, accessed_by=GetAttrGuardAccessor(signature)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, 138006091046704)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'], 138005138004368)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch, 138006092370688)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['torch']
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn, accessed_by=GetAttrGuardAccessor(nn)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.nn, 138005626326048)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn.functional, accessed_by=GetAttrGuardAccessor(functional)
	| | | | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit, accessed_by=GetAttrGuardAccessor(jit)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit, 138005612721344)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, accessed_by=GetAttrGuardAccessor(is_tracing)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, 138005611461536)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.bool, accessed_by=GetAttrGuardAccessor(bool)
	| | | | | +- EQUALS_MATCH: G['__import_transformers_dot_modeling_utils'].torch.bool == torch.bool
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.ones, accessed_by=GetAttrGuardAccessor(ones)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.ones, 138006086442480)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.tanh, accessed_by=GetAttrGuardAccessor(tanh)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.tanh, 138006086504896)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.finfo, accessed_by=GetAttrGuardAccessor(finfo)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.finfo, 138006083535136)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy, accessed_by=GetAttrGuardAccessor(is_torch_fx_proxy)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, 138005543296656)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, 138005543724864)
	| | +- GuardManager: source=G['BaseModelOutputWithPastAndCrossAttentions'], accessed_by=DictGetItemGuardAccessor(BaseModelOutputWithPastAndCrossAttentions)
	| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPastAndCrossAttentions'], 111056993072192)
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_generic'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_generic)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_generic'], 138005540034880)
	| | +- GuardManager: source=G['BaseModelOutputWithPoolingAndCrossAttentions'], accessed_by=DictGetItemGuardAccessor(BaseModelOutputWithPoolingAndCrossAttentions)
	| | | +- ID_MATCH: ___check_obj_id(G['BaseModelOutputWithPoolingAndCrossAttentions'], 111056993094832)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_linear)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 138005617454320)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_module)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 138005626331648)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_sparse)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'], 138005615029328)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, 138005617454480)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, accessed_by=GetAttrGuardAccessor(linear)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, 138005629075216)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, accessed_by=GetAttrGuardAccessor(dropout)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, 138005615458112)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, accessed_by=GetAttrGuardAccessor(embedding)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, 138005615544896)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, 138005615545856)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, accessed_by=GetAttrGuardAccessor(scaled_dot_product_attention)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, 138005629126992)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_dropout)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_dropout'], 138005614333200)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_container)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'], 138005614058992)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_activation)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_activation'], 138005616045856)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_import_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'], 138005543643520)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_available, accessed_by=GetAttrGuardAccessor(_torch_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_available, 111055818658720)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available, accessed_by=GetAttrGuardAccessor(is_torch_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, 138005541710656)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, accessed_by=GetAttrGuardAccessor(_torch_fx_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, 111055818658720)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available, accessed_by=GetAttrGuardAccessor(is_torch_fx_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, 138005541713568)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_attn_mask_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'], 138005138008208)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, accessed_by=GetAttrGuardAccessor(AttentionMaskConverter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, 111057050223296)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask, accessed_by=GetAttrGuardAccessor(_expand_mask)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, 138005137763888)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, 138005543724864)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_normalization)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 138005614450048)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | +- GuardManager: source=G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot__dynamo_dot_polyfills_dot_builtins)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], 138005551329536)
	| | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor(torch)
	| | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['torch']
	
V0401 21:32:50.090000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "a8f4ed105b93eda87afb08114eadc704"}
	{
	"name": "entire_frame_compile",
	"ts": 1743543170090793.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:50.091000 13985 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0, "has_payload": "05e42a263e00d46099fac38108363b68"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743543170091605.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 22,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0401 21:32:50.092000 13985 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "50/0", "frame_key": "95", "co_name": "forward", "co_filename": "/home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py", "co_firstlineno": 1001, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 642, "shape_env_guard_count": 0, "graph_op_count": 64, "graph_node_count": 107, "graph_input_count": 42, "start_time": 1743543167.855603, "entire_frame_compile_time_s": 2.2350986003875732, "backend_compile_time_s": 1.2374792098999023, "inductor_compile_time_s": 0.0519411563873291, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 50, "frame_compile_id": 0, "attempt": 0}
