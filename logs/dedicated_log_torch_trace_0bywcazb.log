V0331 22:38:51.337000 25844 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py", 0]}
V0331 22:38:51.338000 25844 torch/_logging/structured.py:22] {"str": ["/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", 1]}
V0331 22:38:51.339000 25844 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", 2]}
V0331 22:38:51.339000 25844 torch/_logging/structured.py:22] {"str": ["/home/codespace/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", 3]}
V0331 22:38:51.340000 25844 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 49, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 16, "name": "forward_refined", "filename": 1}]}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:51.341000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "da7f7d71ea039164e4dbdd7bd161c600"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460731340822.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.341000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0, "has_payload": "59a88a006cabd1d88231be262a4bcc1b"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460731340822.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.361000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 0, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:51.362000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c010579d1d0>", "describer_id": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:51.362000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 0, "id": 0, "source": "L['kwargs']['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:51.371000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 1, "size": 80}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:51.372000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c010579d1d0>", "describer_id": 1}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:51.373000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 1, "id": 0, "source": "L['kwargs']['input_ids']"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:51.387000 25844 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_kwargs_input_ids_": [1, 10], "modified_input_ids": [1, 10], "getitem": [], "iadd": [], "getitem_1": []}}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "f2869f4fd8e7bcc47199bffd268bb50a"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_kwargs_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_kwargs_input_ids_ = L_kwargs_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:24 in forward_refined, code: modified_input_ids = input_ids.clone()
	        modified_input_ids: "i64[1, 10][10, 1]cpu" = l_kwargs_input_ids_.clone()
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:28 in forward_refined, code: modified_input_ids[0, 0] += seq_length
	        getitem: "i64[][]cpu" = modified_input_ids[(0, 0)]
	        getitem += 10;  iadd: "i64[][]cpu" = getitem;  getitem = None
	        modified_input_ids[(0, 0)] = iadd;  setitem = modified_input_ids;  iadd = setitem = None
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:31 in forward_refined, code: print(f"Original first element: {input_ids[0, 0]}")
	        getitem_1: "i64[][]cpu" = l_kwargs_input_ids_[(0, 0)];  l_kwargs_input_ids_ = None
	        return (getitem_1, modified_input_ids)
	        
V0331 22:38:51.388000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "663587b862f8a97949e7603f52fbd294"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743460731388337.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.389000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "0c7591552325994734753d8c35c4cf48"}
	{
	"name": "backend_compile",
	"ts": 1743460731388337.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.397000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "1447fca45fef8c84d2a2b326ce20d080"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743460731397518.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.438000 25844 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "f1726177f013a619a489a9f338578363"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:24 in forward_refined, code: modified_input_ids = input_ids.clone()
	        clone: "i64[1, 10][10, 1]cpu" = torch.ops.aten.clone.default(arg0_1)
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:28 in forward_refined, code: modified_input_ids[0, 0] += seq_length
	        select: "i64[10][1]cpu" = torch.ops.aten.select.int(clone, 0, 0)
	        select_1: "i64[][]cpu" = torch.ops.aten.select.int(select, 0, 0);  select = None
	        add: "i64[][]cpu" = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None
	        select_2: "i64[10][1]cpu" = torch.ops.aten.select.int(clone, 0, 0)
	        select_scatter: "i64[10][1]cpu" = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None
	        select_scatter_1: "i64[1, 10][10, 1]cpu" = torch.ops.aten.select_scatter.default(clone, select_scatter, 0, 0);  clone = select_scatter = None
	        select_3: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_4: "i64[][]cpu" = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None
	        select_7: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_8: "i64[][]cpu" = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = None
	        copy: "i64[][]cpu" = torch.ops.aten.copy.default(select_8, select_4);  select_8 = select_4 = None
	        select_9: "i64[10][1]cpu" = torch.ops.aten.select.int(select_scatter_1, 0, 0)
	        select_scatter_2: "i64[10][1]cpu" = torch.ops.aten.select_scatter.default(select_9, copy, 0, 0);  select_9 = copy = None
	        select_scatter_3: "i64[1, 10][10, 1]cpu" = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:31 in forward_refined, code: print(f"Original first element: {input_ids[0, 0]}")
	        select_12: "i64[10][1]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None
	        select_13: "i64[][]cpu" = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None
	        return (select_13, select_scatter_3)
	        
V0331 22:38:51.439000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "94a850b66695d94e40174a3ea4dfa365"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743460731438864.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.581000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "0e3cd325ac1af9f397e3ee92fdfe380f"}
	{
	"name": "compile_fx_inner",
	"ts": 1743460731581148.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:51.582000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "6aeb33d562ed4557580d01aecf068e45"}
	{
	"name": "inductor_compile",
	"ts": 1743460731581148.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.120000 25844 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/za/cza42ezs6wdnqo3b4nlw4kwua42vqcv5gso47esdzicghfon3frt.py"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "b03204725a32a1e8cfe9a86df64c4b5d"}
	# AOT ID: ['0_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_0 = async_compile.cpp_pybinding(['const int64_t*', 'int64_t*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       int64_t* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp7 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp12 = at::vec::VectorizedN<int64_t,2>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp0 = static_cast<int32_t>(0);
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = x0;
	            auto tmp3 = c10::convert<int32_t>(tmp2);
	            auto tmp4 = at::vec::Vectorized<int32_t>::arange(tmp3, 1);
	            auto tmp5 = at::vec::Vectorized<int32_t>(tmp0);
	            auto tmp6 = at::vec::VecMask<int32_t,1>(tmp4 == tmp5);
	            auto tmp8 = static_cast<int64_t>(10);
	            auto tmp9 = decltype(tmp7)(tmp7 + tmp8);
	            auto tmp10 = tmp1 ? tmp9 : tmp7;
	            auto tmp11 = tmp1 ? tmp10 : tmp7;
	            auto tmp13 = at::vec::VectorizedN<int64_t,2>(tmp9);
	            auto tmp14 = decltype(tmp13)::blendv(tmp12, tmp13, tmp6.template cast<int64_t,2>());
	            auto tmp15 = at::vec::VecMask<float,1>::from(tmp1);
	            auto tmp16 = decltype(tmp14)::blendv(tmp12, tmp14, tmp15.template cast<int64_t,2>());
	            auto tmp17 = at::vec::VectorizedN<int64_t,2>(tmp11);
	            auto tmp18 = decltype(tmp17)::blendv(tmp16, tmp17, tmp6.template cast<int64_t,2>());
	            auto tmp19 = decltype(tmp18)::blendv(tmp16, tmp18, tmp15.template cast<int64_t,2>());
	            tmp19.store(out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	        }
	        #pragma omp simd simdlen(4) 
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            auto tmp5 = in_ptr0[static_cast<int64_t>(0L)];
	            auto tmp10 = in_ptr0[static_cast<int64_t>(x0)];
	            auto tmp0 = static_cast<int32_t>(0);
	            auto tmp1 = tmp0 == tmp0;
	            auto tmp2 = x0;
	            auto tmp3 = c10::convert<int32_t>(tmp2);
	            auto tmp4 = tmp3 == tmp0;
	            auto tmp6 = static_cast<int64_t>(10);
	            auto tmp7 = decltype(tmp5)(tmp5 + tmp6);
	            auto tmp8 = tmp1 ? tmp7 : tmp5;
	            auto tmp9 = tmp1 ? tmp8 : tmp5;
	            auto tmp11 = tmp4 ? tmp7 : tmp10;
	            auto tmp12 = tmp1 ? tmp11 : tmp10;
	            auto tmp13 = tmp4 ? tmp9 : tmp12;
	            auto tmp14 = tmp1 ? tmp13 : tmp12;
	            out_ptr0[static_cast<int64_t>(x0)] = tmp14;
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    buf0 = empty_strided_cpu((1, 10), (10, 1), torch.int64)
	    cpp_fused_add_0(arg0_1, buf0)
	    return (reinterpret_tensor(arg0_1, (), (), 0), buf0, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0331 22:38:54.122000 25844 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "8abb832ee12885f3e867e8166b0f8860"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743460734121667.8,
	"args": {
	"key": "f45yeswqixng4eyeijdmgdg6qxts7wnacm33wctqnuimy5akgqsg",
	"components": [
	"[lhff6jmwhay6uafbrkejb2az4bylpedd2xot6tiu6smleylsdao] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    add = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None\n    select_2 = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_scatter = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None\n    select_scatter_1 = torch.ops.aten.select_scatter.default(arg0_1, select_scatter, 0, 0);  select_scatter = None\n    select_3 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_4 = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None\n    select_7 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_8 = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = select_8 = None\n    select_9 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_scatter_2 = torch.ops.aten.select_scatter.default(select_9, select_4, 0, 0);  select_9 = select_4 = None\n    select_scatter_3 = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None\n    select_12 = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_13 = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None\n    return (select_13, select_scatter_3)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[xakmu6hsswqogysgn56movvhqlw4wodj3bhszmkotgxxv3ro4uw] fx_kwargs[user_visible_outputs]: {'select_13': None, 'select_scatter_3': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 4371851192,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0331 22:38:54.123000 25844 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "9658b675071d12dd577ddc8c675ffe10"}
	{"key": "f45yeswqixng4eyeijdmgdg6qxts7wnacm33wctqnuimy5akgqsg", "components": ["[lhff6jmwhay6uafbrkejb2az4bylpedd2xot6tiu6smleylsdao] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    add = torch.ops.aten.add.Tensor(select_1, 10);  select_1 = None\n    select_2 = torch.ops.aten.select.int(arg0_1, 0, 0)\n    select_scatter = torch.ops.aten.select_scatter.default(select_2, add, 0, 0);  select_2 = add = None\n    select_scatter_1 = torch.ops.aten.select_scatter.default(arg0_1, select_scatter, 0, 0);  select_scatter = None\n    select_3 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_4 = torch.ops.aten.select.int(select_3, 0, 0);  select_3 = None\n    select_7 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_8 = torch.ops.aten.select.int(select_7, 0, 0);  select_7 = select_8 = None\n    select_9 = torch.ops.aten.select.int(select_scatter_1, 0, 0)\n    select_scatter_2 = torch.ops.aten.select_scatter.default(select_9, select_4, 0, 0);  select_9 = select_4 = None\n    select_scatter_3 = torch.ops.aten.select_scatter.default(select_scatter_1, select_scatter_2, 0, 0);  select_scatter_1 = select_scatter_2 = None\n    select_12 = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_13 = torch.ops.aten.select.int(select_12, 0, 0);  select_12 = None\n    return (select_13, select_scatter_3)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[xakmu6hsswqogysgn56movvhqlw4wodj3bhszmkotgxxv3ro4uw] fx_kwargs[user_visible_outputs]: {'select_13': None, 'select_scatter_3': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 4371851192, "cache_state": "hit"}
V0331 22:38:54.124000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "563a32450d283395e604e83af7791a12"}
	{
	"name": "inductor_compile",
	"ts": 1743460734124189.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.124000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "cf2ce297ca2624eecfa66d6a2c53a3a5"}
	{
	"name": "compile_fx_inner",
	"ts": 1743460734124794.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.125000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "8a52518e68eedc9246198fce686151da"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743460734125859.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.128000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "fb8942791a099fb3876e80ae782e89c1"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743460734128902.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.129000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "c104b763f1009385d24de7e069b53dee"}
	{
	"name": "backend_compile",
	"ts": 1743460734129728.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.130000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "059b894ce663528fa9fcb7550e11b3d8"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743460734130345.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.138000 25844 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "e40f7e11ee033c291d7402ce6045fd7e"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: len(L['kwargs']) == 1                                       
	| | +- GuardManager: source=L['kwargs']['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| | | +- TENSOR_MATCH: check_tensor(L['kwargs']['input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | | +- NO_HASATTR: hasattr(L['kwargs']['input_ids'], '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___1'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___1)
	| | | +- GuardManager: source=G['__builtins_dict___1']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___1']['print'], 136343830586656)
	
V0331 22:38:54.138000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "f61d064bc7f6d1e69ec67f04d38ff244"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460734138781.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.139000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1, "has_payload": "67479a375b4d5936bc9f05d76a227c5a"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460734139404.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 1,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.140000 25844 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "0/0", "frame_key": "1", "co_name": "forward_refined", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 16, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 9, "shape_env_guard_count": 0, "graph_op_count": 5, "graph_node_count": 7, "graph_input_count": 1, "start_time": 1743460731.3408003, "entire_frame_compile_time_s": 2.7977004051208496, "backend_compile_time_s": 2.7413015365600586, "inductor_compile_time_s": 2.542750835418701, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.misc.StringFormatVariable'>] False"], "dynamo_time_before_restart_s": 0.02768540382385254, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 0, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:54.142000 25844 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 49, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 31, "name": "torch_dynamo_resume_in_forward_refined_at_31", "filename": 1}]}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.142000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0, "has_payload": "0e6fb38ebac150f848de6b5046a3cc1e"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460734142580.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.143000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0, "has_payload": "c89de855fabd6cf7a35938ae3a3a71ed"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460734142580.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.145000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 5, "size": 80}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.146000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c00d0573de0>", "describer_id": 5}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.147000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 5, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.151000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 6, "size": 80}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:54.152000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c00d0573de0>", "describer_id": 6}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:54.152000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 6, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:54.156000 25844 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_modified_input_ids_": [1, 10], "getitem": []}}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "b4345f739ac7591023b1dc302c403c0d"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_modified_input_ids_: "i64[1, 10][10, 1]cpu"):
	        l_modified_input_ids_ = L_modified_input_ids_
	        
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:32 in torch_dynamo_resume_in_forward_refined_at_31, code: print(f"Modified first element: {modified_input_ids[0, 0]}")
	        getitem: "i64[][]cpu" = l_modified_input_ids_[(0, 0)];  l_modified_input_ids_ = None
	        return (getitem,)
	        
V0331 22:38:54.157000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "ba61bd82f2a9996722d904000e81b4e6"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743460734156961.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.157000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "cb08a9a050a865019b94d4bf58ef0c7f"}
	{
	"name": "backend_compile",
	"ts": 1743460734156961.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.159000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "96970a05afa931e6ca3527d9fa3dcc29"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743460734159416.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.169000 25844 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:215] {"aot_forward_graph": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "0df0696c4d0ea524e9c778fcc6ae4747"}
	class <lambda>(torch.nn.Module):
	    def forward(self, arg0_1: "i64[1, 10][10, 1]cpu"):
	         # File: /workspaces/HPML-Project/pull_model_run_dynamo_explain.py:32 in torch_dynamo_resume_in_forward_refined_at_31, code: print(f"Modified first element: {modified_input_ids[0, 0]}")
	        select: "i64[10][1]cpu" = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None
	        select_1: "i64[][]cpu" = torch.ops.aten.select.int(select, 0, 0);  select = None
	        return (select_1,)
	        
V0331 22:38:54.170000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "6bed4c45ef867a53d63913b58ad2af24"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743460734170460.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.172000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "5cd281768364b76294ba00489decfc65"}
	{
	"name": "compile_fx_inner",
	"ts": 1743460734172057.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.173000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "fd6b6bcc8b1b17722a3ec03445d408cd"}
	{
	"name": "inductor_compile",
	"ts": 1743460734172057.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.181000 25844 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/mf/cmfwsynimsavisgwplg33qd33nmpeiz6yigdbqzhgwumgq5l7im3.py"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "02aa93543631a1582a9db906672174f8"}
	# AOT ID: ['1_inference']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    arg0_1, = args
	    args.clear()
	    assert_size_stride(arg0_1, (1, 10), (10, 1))
	    return (reinterpret_tensor(arg0_1, (), (), 0), )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    arg0_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    fn = lambda: call([arg0_1])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0331 22:38:54.182000 25844 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "489d13f90c3b05c51327f1b30a86f3d8"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743460734181945.0,
	"args": {
	"key": "fjjuflzqe3xa3bki3hrdezh2yb7fcvpr5a7vabgq2eqgcfqqmqpa",
	"components": [
	"[fl2wa3duqskceg3a4tsvilaaejxeh5hx5joo6yg7wnyjgjtwpfr] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    return (select_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []",
	"[vnytv4vvduj2micgs6fvhtgyftmyf4tv24dcsrt3c2rpsdyaevy] fx_kwargs[user_visible_outputs]: {'select_1': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 20056714,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0331 22:38:54.183000 25844 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "4ebe86be6d2b4cc8c8574abeab4093c1"}
	{"key": "fjjuflzqe3xa3bki3hrdezh2yb7fcvpr5a7vabgq2eqgcfqqmqpa", "components": ["[fl2wa3duqskceg3a4tsvilaaejxeh5hx5joo6yg7wnyjgjtwpfr] gm: <lambda>()\n\n\n\ndef forward(self, arg0_1):\n    select = torch.ops.aten.select.int(arg0_1, 0, 0);  arg0_1 = None\n    select_1 = torch.ops.aten.select.int(select, 0, 0);  select = None\n    return (select_1,)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_inference]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []", "[vnytv4vvduj2micgs6fvhtgyftmyf4tv24dcsrt3c2rpsdyaevy] fx_kwargs[user_visible_outputs]: {'select_1': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 20056714, "cache_state": "hit"}
V0331 22:38:54.183000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "faebb83385df7ff1d3e3d507d598ba6e"}
	{
	"name": "inductor_compile",
	"ts": 1743460734183894.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.184000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "fa0febaed7f7a6e181e9ad1e6ca195d8"}
	{
	"name": "compile_fx_inner",
	"ts": 1743460734184521.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.185000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "837f2007227db1ab65f45e26d002c0b9"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743460734185449.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.188000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "e5b4205f7d8a69c229a5fdeb849de991"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743460734188363.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.189000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "b0fe9a19218518808bba9373484fe90d"}
	{
	"name": "backend_compile",
	"ts": 1743460734189157.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.189000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "c478971e78a13b4258e4c34620a58ed7"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743460734189748.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.198000 25844 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "065dec8f62119674419e78170bb2cef0"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['modified_input_ids'], accessed_by=DictGetItemGuardAccessor(modified_input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['modified_input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['modified_input_ids'], '_dynamo_dynamic_indices') == False
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___5'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___5)
	| | | +- GuardManager: source=G['__builtins_dict___5']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___5']['print'], 136343830586656)
	
V0331 22:38:54.199000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "d6c8389262cd9c5b7839fe08ae842c0f"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460734199727.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.200000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1, "has_payload": "6f7b7a5eb050267e91ddac6d3ab35f22"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460734200366.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.201000 25844 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "1/0", "frame_key": "2", "co_name": "torch_dynamo_resume_in_forward_refined_at_31", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 31, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 1, "graph_node_count": 3, "graph_input_count": 1, "start_time": 1743460734.1425686, "entire_frame_compile_time_s": 0.05707049369812012, "backend_compile_time_s": 0.03213787078857422, "inductor_compile_time_s": 0.011745691299438477, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.misc.StringFormatVariable'>] False"], "dynamo_time_before_restart_s": 0.0058994293212890625, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 1, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:54.202000 25844 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 49, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 16, "name": "forward_refined", "filename": 1}, {"line": 32, "name": "torch_dynamo_resume_in_forward_refined_at_32", "filename": 1}]}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.203000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0, "has_payload": "0a2c506450eac8a804de635e1ea80b8d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460734203084.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.203000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 0, "has_payload": "b22a2fd5a9bb1ebc03f76f072a894aa4"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460734203084.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.216000 25844 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "72de124411978e39af3c4e6a619e6bbd"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['seq_length'], accessed_by=DictGetItemGuardAccessor(seq_length)
	| | +- EQUALS_MATCH: L['seq_length'] == 10                                       
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['__builtins_dict___9'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___9)
	| | | +- GuardManager: source=G['__builtins_dict___9']['print'], accessed_by=DictGetItemGuardAccessor(print)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___9']['print'], 136343830586656)
	
V0331 22:38:54.217000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "e092c7a768e9a47d6344653c304c5988"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460734217587.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.218000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1, "has_payload": "030c0e4ab7604ac80bd47e9ae45e1f36"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460734218229.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 2,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.219000 25844 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "2/0", "frame_key": "3", "co_name": "torch_dynamo_resume_in_forward_refined_at_32", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 32, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 7, "shape_env_guard_count": 0, "graph_op_count": 0, "graph_node_count": 0, "graph_input_count": 0, "start_time": 1743460734.203074, "entire_frame_compile_time_s": 0.014417171478271484, "backend_compile_time_s": null, "inductor_compile_time_s": null, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": ["builtin: print [<class 'torch._dynamo.variables.constant.ConstantVariable'>] False"], "dynamo_time_before_restart_s": 0.0019414424896240234, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 2, "frame_compile_id": 0, "attempt": 1}
V0331 22:38:54.220000 25844 torch/_dynamo/convert_frame.py:894] {"dynamo_start": {"stack": [{"line": 49, "name": "<module>", "filename": 1}, {"line": 465, "name": "_fn", "filename": 2}, {"line": 1736, "name": "_wrapped_call_impl", "filename": 3}, {"line": 1747, "name": "_call_impl", "filename": 3}, {"line": 16, "name": "forward_refined", "filename": 1}, {"line": 31, "name": "torch_dynamo_resume_in_forward_refined_at_31", "filename": 1}, {"line": 33, "name": "torch_dynamo_resume_in_forward_refined_at_33", "filename": 1}]}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.220000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "7643d8f7fbe1007c18f9c1db7c620b0d"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460734220767.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.221000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "b3e77493df01065276e2d4a445967f29"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460734220767.5,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.232000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 0, "describer_id": 10, "size": 80}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.233000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 0, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 10], "is_leaf": true, "stride": [10, 1], "storage": 0, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c00d0573de0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.234000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 0, "source": "L['modified_input_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.512000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 1, "describer_id": 10, "size": 4096}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.515000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 1, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "stride": [512, 1], "storage": 1, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c00d37f1180>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.516000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 1, "source": "G['model']._orig_mod._modules['embeddings']._buffers['token_type_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.524000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 2, "describer_id": 10, "size": 4096}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.525000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 6, "ndim": 1, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "stride": [1], "storage": 2, "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c00d683b6b0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.526000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 5, "ndim": 2, "dtype": "torch.int64", "device": "device(type='cpu')", "size": [1, 512], "is_leaf": true, "is_view": true, "stride": [512, 1], "storage": 2, "base": 6, "creation_meta": "CreationMeta.DEFAULT", "view_func": "<built-in method _view_func_unsafe of Tensor object at 0x7c00d37e0870>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.527000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 5, "source": "G['model']._orig_mod._modules['embeddings']._buffers['position_ids']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.532000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 3, "describer_id": 10, "size": 15627264}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.533000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 8, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [30522, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 3, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d3ff49b0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.533000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 8, "source": "G['model']._orig_mod._modules['embeddings']._modules['word_embeddings']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.542000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 4, "describer_id": 10, "size": 1024}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.542000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 9, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [2, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 4, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d381ab20>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.543000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 9, "source": "G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.550000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 5, "describer_id": 10, "size": 262144}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.551000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 11, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [128, 1], "storage": 5, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d3818aa0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.551000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 11, "source": "G['model']._orig_mod._modules['embeddings']._modules['position_embeddings']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.558000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 6, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.559000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 12, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 6, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d3818f50>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.559000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 12, "source": "G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.561000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 7, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.562000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 13, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 7, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37e08c0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.562000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 13, "source": "G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.616000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 8, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.616000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 25, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 8, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d381ac10>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.617000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 25, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.619000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 9, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.619000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 26, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 9, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d381a490>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.620000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 26, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.636000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 10, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.637000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 36, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 10, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d3fe2530>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.637000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 36, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.639000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 11, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.639000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 37, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 11, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d381ad50>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.640000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 37, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.646000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 12, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.647000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 38, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 12, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f0910>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.648000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 38, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.649000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 13, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.650000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 39, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 13, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1220>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.651000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 39, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.665000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 14, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.666000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 45, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 14, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d381a300>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.667000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 45, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.668000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 15, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.669000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 46, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 15, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d38180f0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.670000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 46, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.677000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 16, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.677000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 47, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 16, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1360>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.678000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 47, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.679000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 17, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.680000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 48, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 17, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1270>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.681000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 48, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.696000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 18, "describer_id": 10, "size": 262144}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.697000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 52, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 18, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1400>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.698000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 52, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.699000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 19, "describer_id": 10, "size": 2048}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.700000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 53, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 19, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1310>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.701000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 53, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.716000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 20, "describer_id": 10, "size": 262144}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.717000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 61, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 20, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f13b0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.717000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 61, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.719000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 21, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.720000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 62, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 21, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d381a120>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.720000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 62, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.729000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 22, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.730000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 66, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 22, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f14f0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.731000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 66, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.732000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 23, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.733000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 67, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 23, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f14a0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.734000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 67, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.749000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 24, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.750000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 71, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 24, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f12c0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.751000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 71, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.752000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 25, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.753000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 72, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 25, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1450>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.753000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 72, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.760000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 26, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.761000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 73, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 26, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1590>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.761000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 73, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.763000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 27, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.764000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 74, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 27, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1630>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.764000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 74, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.770000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 28, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.771000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 75, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 28, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1680>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.771000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 75, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.773000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 29, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.774000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 76, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 29, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f16d0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.774000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 76, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.787000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 30, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.788000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 79, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 30, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1720>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.788000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 79, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.790000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 31, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.791000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 80, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 31, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1770>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.791000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 80, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.798000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 32, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.799000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 81, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 32, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1810>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.799000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 81, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.801000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 33, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.802000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 82, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 33, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f17c0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.802000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 82, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.813000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 34, "describer_id": 10, "size": 262144}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.814000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 86, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 512], "storage": 34, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1900>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.815000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 86, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.816000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 35, "describer_id": 10, "size": 2048}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.817000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 87, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 35, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1540>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.817000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 87, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.825000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 36, "describer_id": 10, "size": 262144}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.825000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 88, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 512], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 36, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f18b0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.826000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 88, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.828000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 37, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.828000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 89, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 37, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f1860>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.829000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 89, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.835000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 38, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.836000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 90, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 38, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f19f0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.837000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 90, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.838000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 39, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.839000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 91, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 39, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37f19a0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.840000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 91, "source": "G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.862000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 40, "describer_id": 10, "size": 65536}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.863000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 97, "ndim": 2, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128, 128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1, 128], "storage": 40, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37e3430>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.864000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 97, "source": "G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['weight']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.865000 25844 torch/_subclasses/meta_utils.py:204] {"describe_storage": {"id": 41, "describer_id": 10, "size": 512}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.866000 25844 torch/_subclasses/meta_utils.py:417] {"describe_tensor": {"id": 98, "ndim": 1, "dtype": "torch.float32", "device": "device(type='cpu')", "size": [128], "is_leaf": true, "requires_grad": true, "is_parameter": true, "stride": [1], "storage": 41, "view_func": "<built-in method _view_func_unsafe of Parameter object at 0x7c00d37e07d0>", "describer_id": 10}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.867000 25844 torch/_subclasses/meta_utils.py:1640] {"describe_source": {"describer_id": 10, "id": 98, "source": "G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['bias']"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
V0331 22:38:54.898000 25844 torch/_dynamo/output_graph.py:1346] {"dynamo_output_graph": {"sizes": {"l_modified_input_ids_": [1, 10], "g_model_orig_mod_modules_embeddings_buffers_token_type_ids_": [1, 512], "g_model_orig_mod_modules_embeddings_buffers_position_ids_": [1, 512], "g_model_orig_mod_modules_embeddings_modules_word_embeddings_parameters_weight_": [30522, 128], "g_model_orig_mod_modules_embeddings_modules_token_type_embeddings_parameters_weight_": [2, 128], "g_model_orig_mod_modules_embeddings_modules_position_embeddings_parameters_weight_": [512, 128], "g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_weight_": [128], "g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_": [512], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_": [128, 512], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_": [128, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_": [512, 128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_": [512], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_": [128, 512], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_": [128], "g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_": [128], "g_model_orig_mod_modules_pooler_modules_dense_parameters_weight_": [128, 128], "g_model_orig_mod_modules_pooler_modules_dense_parameters_bias_": [128], "buffered_token_type_ids": [1, 10], "buffered_token_type_ids_expanded": [1, 10], "position_ids": [1, 10], "inputs_embeds": [1, 10, 128], "token_type_embeddings": [1, 10, 128], "embeddings": [1, 10, 128], "position_embeddings": [1, 10, 128], "embeddings_1": [1, 10, 128], "embeddings_2": [1, 10, 128], "embeddings_3": [1, 10, 128], "attention_mask": [1, 10], "getitem_2": [1, 1, 1, 10], "expand_1": [1, 1, 10, 10], "expanded_mask": [1, 1, 10, 10], "inverted_mask": [1, 1, 10, 10], "to_1": [1, 1, 10, 10], "extended_attention_mask": [1, 1, 10, 10], "linear": [1, 10, 128], "x": [1, 10, 2, 64], "query_layer": [1, 2, 10, 64], "linear_1": [1, 10, 128], "x_1": [1, 10, 2, 64], "key_layer": [1, 2, 10, 64], "linear_2": [1, 10, 128], "x_2": [1, 10, 2, 64], "value_layer": [1, 2, 10, 64], "attn_output": [1, 2, 10, 64], "attn_output_1": [1, 10, 2, 64], "attn_output_2": [1, 10, 128], "hidden_states": [1, 10, 128], "hidden_states_1": [1, 10, 128], "add_1": [1, 10, 128], "hidden_states_2": [1, 10, 128], "hidden_states_3": [1, 10, 512], "hidden_states_4": [1, 10, 512], "hidden_states_5": [1, 10, 128], "hidden_states_6": [1, 10, 128], "add_2": [1, 10, 128], "hidden_states_7": [1, 10, 128], "linear_6": [1, 10, 128], "x_3": [1, 10, 2, 64], "query_layer_1": [1, 2, 10, 64], "linear_7": [1, 10, 128], "x_4": [1, 10, 2, 64], "key_layer_1": [1, 2, 10, 64], "linear_8": [1, 10, 128], "x_5": [1, 10, 2, 64], "value_layer_1": [1, 2, 10, 64], "attn_output_3": [1, 2, 10, 64], "attn_output_4": [1, 10, 2, 64], "attn_output_5": [1, 10, 128], "hidden_states_8": [1, 10, 128], "hidden_states_9": [1, 10, 128], "add_3": [1, 10, 128], "hidden_states_10": [1, 10, 128], "hidden_states_11": [1, 10, 512], "hidden_states_12": [1, 10, 512], "hidden_states_13": [1, 10, 128], "hidden_states_14": [1, 10, 128], "add_4": [1, 10, 128], "hidden_states_15": [1, 10, 128], "first_token_tensor": [1, 128], "pooled_output": [1, 128], "pooled_output_1": [1, 128]}}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "14baacdb75361e64d4a798bcf73818b6"}
	class GraphModule(torch.nn.Module):
	    def forward(self, L_modified_input_ids_: "i64[1, 10][10, 1]cpu", G_model_orig_mod_modules_embeddings_buffers_token_type_ids_: "i64[1, 512][512, 1]cpu", G_model_orig_mod_modules_embeddings_buffers_position_ids_: "i64[1, 512][512, 1]cpu", G_model_orig_mod_modules_embeddings_modules_word_embeddings_parameters_weight_: "f32[30522, 128][128, 1]cpu", G_model_orig_mod_modules_embeddings_modules_token_type_embeddings_parameters_weight_: "f32[2, 128][128, 1]cpu", G_model_orig_mod_modules_embeddings_modules_position_embeddings_parameters_weight_: "f32[512, 128][128, 1]cpu", G_model_orig_mod_modules_embeddings_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", G_model_orig_mod_modules_embeddings_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_: "f32[512, 128][1, 512]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_: "f32[512][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_: "f32[128, 512][1, 128]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_: "f32[128][1]cpu", G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_: "f32[128][1]cpu", G_model_orig_mod_modules_pooler_modules_dense_parameters_weight_: "f32[128, 128][1, 128]cpu", G_model_orig_mod_modules_pooler_modules_dense_parameters_bias_: "f32[128][1]cpu"):
	        l_modified_input_ids_ = L_modified_input_ids_
	        g_model_orig_mod_modules_embeddings_buffers_token_type_ids_ = G_model_orig_mod_modules_embeddings_buffers_token_type_ids_
	        g_model_orig_mod_modules_embeddings_buffers_position_ids_ = G_model_orig_mod_modules_embeddings_buffers_position_ids_
	        g_model_orig_mod_modules_embeddings_modules_word_embeddings_parameters_weight_ = G_model_orig_mod_modules_embeddings_modules_word_embeddings_parameters_weight_
	        g_model_orig_mod_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = G_model_orig_mod_modules_embeddings_modules_token_type_embeddings_parameters_weight_
	        g_model_orig_mod_modules_embeddings_modules_position_embeddings_parameters_weight_ = G_model_orig_mod_modules_embeddings_modules_position_embeddings_parameters_weight_
	        g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_weight_ = G_model_orig_mod_modules_embeddings_modules_LayerNorm_parameters_weight_
	        g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_bias_ = G_model_orig_mod_modules_embeddings_modules_LayerNorm_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_
	        g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = G_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_
	        g_model_orig_mod_modules_pooler_modules_dense_parameters_weight_ = G_model_orig_mod_modules_pooler_modules_dense_parameters_weight_
	        g_model_orig_mod_modules_pooler_modules_dense_parameters_bias_ = G_model_orig_mod_modules_pooler_modules_dense_parameters_bias_
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        buffered_token_type_ids: "i64[1, 10][512, 1]cpu" = g_model_orig_mod_modules_embeddings_buffers_token_type_ids_[(slice(None, None, None), slice(None, 10, None))];  g_model_orig_mod_modules_embeddings_buffers_token_type_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        buffered_token_type_ids_expanded: "i64[1, 10][512, 1]cpu" = buffered_token_type_ids.expand(1, 10);  buffered_token_type_ids = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        position_ids: "i64[1, 10][512, 1]cpu" = g_model_orig_mod_modules_embeddings_buffers_position_ids_[(slice(None, None, None), slice(0, 10, None))];  g_model_orig_mod_modules_embeddings_buffers_position_ids_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        inputs_embeds: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(l_modified_input_ids_, g_model_orig_mod_modules_embeddings_modules_word_embeddings_parameters_weight_, 0, None, 2.0, False, False);  l_modified_input_ids_ = g_model_orig_mod_modules_embeddings_modules_word_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        token_type_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(buffered_token_type_ids_expanded, g_model_orig_mod_modules_embeddings_modules_token_type_embeddings_parameters_weight_, None, None, 2.0, False, False);  buffered_token_type_ids_expanded = g_model_orig_mod_modules_embeddings_modules_token_type_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = inputs_embeds + token_type_embeddings;  inputs_embeds = token_type_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        position_embeddings: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.embedding(position_ids, g_model_orig_mod_modules_embeddings_modules_position_embeddings_parameters_weight_, None, None, 2.0, False, False);  position_ids = g_model_orig_mod_modules_embeddings_modules_position_embeddings_parameters_weight_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        embeddings += position_embeddings;  embeddings_1: "f32[1, 10, 128][1280, 128, 1]cpu" = embeddings;  embeddings = position_embeddings = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        embeddings_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(embeddings_1, (128,), g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_weight_, g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_bias_, 1e-12);  embeddings_1 = g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_weight_ = g_model_orig_mod_modules_embeddings_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        embeddings_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(embeddings_2, 0.1, False, False);  embeddings_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        attention_mask: "f32[1, 10][10, 1]cpu" = torch.ones((1, 10), device = device(type='cpu'))
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        getitem_2: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = attention_mask[(slice(None, None, None), None, None, slice(None, None, None))];  attention_mask = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = getitem_2.expand(1, 1, 10, 10);  getitem_2 = None
	        expanded_mask: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = expand_1.to(torch.float32);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        inverted_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = 1.0 - expanded_mask;  expanded_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        to_1: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.to(torch.bool)
	        extended_attention_mask: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = inverted_mask.masked_fill(to_1, -3.4028234663852886e+38);  inverted_mask = to_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear.view((1, 10, 2, 64));  linear = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x.permute(0, 2, 1, 3);  x = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_1.view((1, 10, 2, 64));  linear_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_1.permute(0, 2, 1, 3);  x_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(embeddings_3, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_2.view((1, 10, 2, 64));  linear_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_2.permute(0, 2, 1, 3);  x_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer, key_layer, value_layer, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer = key_layer = value_layer = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_1: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output.transpose(1, 2);  attn_output = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_2: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_1.reshape(1, 10, 128);  attn_output_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_2, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_2 = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states, 0.1, False, False);  hidden_states = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_1 + embeddings_3;  hidden_states_1 = embeddings_3 = None
	        hidden_states_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_1, (128,), g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_1 = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_2, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_3);  hidden_states_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_4, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_);  hidden_states_4 = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_5, 0.1, False, False);  hidden_states_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_2: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_6 + hidden_states_2;  hidden_states_6 = hidden_states_2 = None
	        hidden_states_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_2, (128,), g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_2 = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_0_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        linear_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_3: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_6.view((1, 10, 2, 64));  linear_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        query_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_3.permute(0, 2, 1, 3);  x_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        linear_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_7.view((1, 10, 2, 64));  linear_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        key_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_4.permute(0, 2, 1, 3);  x_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        linear_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_7, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        x_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = linear_8.view((1, 10, 2, 64));  linear_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        value_layer_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = x_5.permute(0, 2, 1, 3);  x_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        attn_output_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch._C._nn.scaled_dot_product_attention(query_layer_1, key_layer_1, value_layer_1, attn_mask = extended_attention_mask, dropout_p = 0.0, is_causal = False);  query_layer_1 = key_layer_1 = value_layer_1 = extended_attention_mask = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        attn_output_4: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = attn_output_3.transpose(1, 2);  attn_output_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        attn_output_5: "f32[1, 10, 128][1280, 128, 1]cpu" = attn_output_4.reshape(1, 10, 128);  attn_output_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(attn_output_5, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_);  attn_output_5 = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_8, 0.1, False, False);  hidden_states_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_9 + hidden_states_7;  hidden_states_9 = hidden_states_7 = None
	        hidden_states_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_3, (128,), g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_3 = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.linear(hidden_states_10, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_);  g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        hidden_states_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch._C._nn.gelu(hidden_states_11);  hidden_states_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        hidden_states_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch._C._nn.linear(hidden_states_12, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_);  hidden_states_12 = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        hidden_states_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.dropout(hidden_states_13, 0.1, False, False);  hidden_states_13 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = hidden_states_14 + hidden_states_10;  hidden_states_14 = hidden_states_10 = None
	        hidden_states_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.nn.functional.layer_norm(add_4, (128,), g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_, g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_, 1e-12);  add_4 = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_weight_ = g_model_orig_mod_modules_encoder_modules_layer_modules_1_modules_output_modules_layer_norm_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        first_token_tensor: "f32[1, 128][1280, 1]cpu" = hidden_states_15[(slice(None, None, None), 0)]
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        pooled_output: "f32[1, 128][128, 1]cpu" = torch._C._nn.linear(first_token_tensor, g_model_orig_mod_modules_pooler_modules_dense_parameters_weight_, g_model_orig_mod_modules_pooler_modules_dense_parameters_bias_);  first_token_tensor = g_model_orig_mod_modules_pooler_modules_dense_parameters_weight_ = g_model_orig_mod_modules_pooler_modules_dense_parameters_bias_ = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        pooled_output_1: "f32[1, 128][128, 1]cpu" = torch.tanh(pooled_output);  pooled_output = None
	        return (hidden_states_15, pooled_output_1)
	        
V0331 22:38:54.899000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "5c8de7906bd712ba2ceb55f35e6268ee"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743460734899629.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.900000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "b61f0e0f795ed8a4e99e33e5720a1c88"}
	{
	"name": "backend_compile",
	"ts": 1743460734899629.8,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:54.937000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "f236f2d3b09e5bf6daae07e056d18df1"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743460734937382.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:55.817000 25844 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:352] {"aot_joint_graph": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "dcb09d2e1a88d319c9f911a929a3e77d"}
	class joint_helper(torch.nn.Module):
	    def forward(self, primals, tangents):
	        primals_1: "i64[1, 10][10, 1]cpu"; primals_2: "i64[1, 512][512, 1]cpu"; primals_3: "i64[1, 512][512, 1]cpu"; primals_4: "f32[30522, 128][128, 1]cpu"; primals_5: "f32[2, 128][128, 1]cpu"; primals_6: "f32[512, 128][128, 1]cpu"; primals_7: "f32[128][1]cpu"; primals_8: "f32[128][1]cpu"; primals_9: "f32[128, 128][1, 128]cpu"; primals_10: "f32[128][1]cpu"; primals_11: "f32[128, 128][1, 128]cpu"; primals_12: "f32[128][1]cpu"; primals_13: "f32[128, 128][1, 128]cpu"; primals_14: "f32[128][1]cpu"; primals_15: "f32[128, 128][1, 128]cpu"; primals_16: "f32[128][1]cpu"; primals_17: "f32[128][1]cpu"; primals_18: "f32[128][1]cpu"; primals_19: "f32[512, 128][1, 512]cpu"; primals_20: "f32[512][1]cpu"; primals_21: "f32[128, 512][1, 128]cpu"; primals_22: "f32[128][1]cpu"; primals_23: "f32[128][1]cpu"; primals_24: "f32[128][1]cpu"; primals_25: "f32[128, 128][1, 128]cpu"; primals_26: "f32[128][1]cpu"; primals_27: "f32[128, 128][1, 128]cpu"; primals_28: "f32[128][1]cpu"; primals_29: "f32[128, 128][1, 128]cpu"; primals_30: "f32[128][1]cpu"; primals_31: "f32[128, 128][1, 128]cpu"; primals_32: "f32[128][1]cpu"; primals_33: "f32[128][1]cpu"; primals_34: "f32[128][1]cpu"; primals_35: "f32[512, 128][1, 512]cpu"; primals_36: "f32[512][1]cpu"; primals_37: "f32[128, 512][1, 128]cpu"; primals_38: "f32[128][1]cpu"; primals_39: "f32[128][1]cpu"; primals_40: "f32[128][1]cpu"; primals_41: "f32[128, 128][1, 128]cpu"; primals_42: "f32[128][1]cpu"; tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu"; tangents_2: "f32[1, 128][128, 1]cpu"; 
	    
	        primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, tangents_1, tangents_2, = fx_pytree.tree_flatten_spec([primals, tangents], self._in_spec)
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_1: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 0, 0, 9223372036854775807);  primals_2 = None
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 10);  slice_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_3: "i64[1, 512][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 0, 0, 9223372036854775807);  primals_3 = None
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(slice_3, 1, 0, 10);  slice_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1)
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7);  mul = None
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:219 in forward, code: embeddings = self.dropout(embeddings)
	        clone: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(add_3);  add_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1087 in forward, code: attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)
	        full: "f32[1, 10][10, 1]cpu" = torch.ops.aten.full.default([1, 10], 1, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:188 in _expand_mask, code: expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)
	        slice_5: "f32[1, 10][10, 1]cpu" = torch.ops.aten.slice.Tensor(full, 0, 0, 9223372036854775807);  full = None
	        unsqueeze: "f32[1, 1, 10][10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(slice_5, 1);  slice_5 = None
	        unsqueeze_1: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None
	        slice_6: "f32[1, 1, 1, 10][10, 10, 10, 1]cpu" = torch.ops.aten.slice.Tensor(unsqueeze_1, 3, 0, 9223372036854775807);  unsqueeze_1 = None
	        expand_1: "f32[1, 1, 10, 10][10, 10, 0, 1]cpu" = torch.ops.aten.expand.default(slice_6, [1, 1, 10, 10]);  slice_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:190 in _expand_mask, code: inverted_mask = 1.0 - expanded_mask
	        sub_1: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.sub.Tensor(1.0, expand_1);  expand_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        convert_element_type: "b8[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.prims.convert_element_type.default(sub_1, torch.bool)
	        scalar_tensor: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(-3.4028234663852886e+38, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.where.self(convert_element_type, scalar_tensor, sub_1);  convert_element_type = scalar_tensor = sub_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view_3, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(clone, [10, 128])
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view_6, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = where)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        alias: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_2)
	        alias_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias);  alias = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3]);  getitem_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_11);  view_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_1, clone);  clone_1 = clone = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5)
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17);  mul_2 = None
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_15);  view_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_2, add_6);  clone_2 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7)
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23);  mul_7 = None
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_19: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_19, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_22, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = where)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        alias_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(getitem_8)
	        alias_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_2);  alias_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3]);  getitem_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:467 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_27);  view_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_3, add_10);  clone_3 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11)
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33);  mul_9 = None
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:553 in forward, code: hidden_states = self.dropout(hidden_states)
	        clone_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.clone.default(view_31);  view_31 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(clone_4, add_13);  clone_4 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13)
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39);  mul_14 = None
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        slice_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice.Tensor(add_17, 0, 0, 9223372036854775807)
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(slice_7, 1, 0);  slice_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        alias_4: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(tanh)
	        alias_5: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_4);  alias_4 = None
	        alias_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_5);  alias_5 = None
	        alias_7: "f32[1, 128][128, 1]cpu" = torch.ops.aten.alias.default(alias_6);  alias_6 = None
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(alias_7, alias_7);  alias_7 = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_1, mm, 1, 0);  full_1 = mm = None
	        full_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        slice_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.slice_scatter.default(full_2, select_scatter, 0, 0, 9223372036854775807);  full_2 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, slice_scatter);  tangents_1 = slice_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_7, rsqrt_4);  sub_7 = None
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_18);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_18, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_18);  mul_18 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_2: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_25);  mul_25 = None
	        add_19: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_2, 1);  erf_2 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_19, 0.5);  add_19 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_32: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_10, rsqrt_3);  sub_10 = None
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_32);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_32, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_32);  mul_32 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_3);  alias_3 = None
	        alias_9: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_8);  alias_8 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, alias_9, getitem_9, 0.0, False, attn_mask = where);  permute_33 = permute_11 = permute_13 = permute_15 = alias_9 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_22, [1, 0]);  view_22 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44);  permute_36 = None
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        permute_40: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_19, [1, 0]);  view_19 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_40, view_48);  permute_40 = None
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        permute_44: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_44, view_52);  permute_44 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_39: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_13, rsqrt_2);  sub_13 = None
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_39);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_39, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_39);  mul_39 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_46: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf_3: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_46);  mul_46 = None
	        add_25: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_3, 1);  erf_3 = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_25, 0.5);  add_25 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        sub_16: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_53: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_16, rsqrt_1);  sub_16 = None
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_53);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_53, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_53);  mul_53 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        alias_10: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_1);  alias_1 = None
	        alias_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.alias.default(alias_10);  alias_10 = None
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, alias_11, getitem_3, 0.0, False, attn_mask = where);  permute_55 = permute_1 = permute_3 = permute_5 = alias_11 = getitem_3 = where = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_6, [1, 0]);  view_6 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66);  permute_58 = None
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        permute_62: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_3, [1, 0]);  view_3 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_62, view_70);  permute_62 = None
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        permute_66: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_66, view_74);  permute_66 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        sub_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_19, rsqrt);  sub_19 = None
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul_60);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_60, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul_60);  mul_60 = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        scalar_tensor_1: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, scalar_tensor_1, mul_65);  unsqueeze_2 = scalar_tensor_1 = None
	        full_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_3, [slice_4], where_1, True);  full_3 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        scalar_tensor_2: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, scalar_tensor_2, mul_65);  unsqueeze_3 = scalar_tensor_2 = None
	        full_4: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_4, [expand], where_2, True);  full_4 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        scalar_tensor_3: "f32[][]cpu" = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, scalar_tensor_3, mul_65);  unsqueeze_4 = scalar_tensor_3 = mul_65 = None
	        full_5: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_5, [primals_1], where_3, True);  full_5 = primals_1 = where_3 = None
	        return pytree.tree_unflatten([add_17, tanh, None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32], self._out_spec)
	        
V0331 22:38:56.296000 25844 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:545] {"aot_forward_graph": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "79ae68c5ee14a8aca5626a97bbc2e0b0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_2: "i64[1, 512][512, 1]cpu", primals_3: "i64[1, 512][512, 1]cpu", primals_4: "f32[30522, 128][128, 1]cpu", primals_5: "f32[2, 128][128, 1]cpu", primals_6: "f32[512, 128][128, 1]cpu", primals_7: "f32[128][1]cpu", primals_8: "f32[128][1]cpu", primals_9: "f32[128, 128][1, 128]cpu", primals_10: "f32[128][1]cpu", primals_11: "f32[128, 128][1, 128]cpu", primals_12: "f32[128][1]cpu", primals_13: "f32[128, 128][1, 128]cpu", primals_14: "f32[128][1]cpu", primals_15: "f32[128, 128][1, 128]cpu", primals_16: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_18: "f32[128][1]cpu", primals_19: "f32[512, 128][1, 512]cpu", primals_20: "f32[512][1]cpu", primals_21: "f32[128, 512][1, 128]cpu", primals_22: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_24: "f32[128][1]cpu", primals_25: "f32[128, 128][1, 128]cpu", primals_26: "f32[128][1]cpu", primals_27: "f32[128, 128][1, 128]cpu", primals_28: "f32[128][1]cpu", primals_29: "f32[128, 128][1, 128]cpu", primals_30: "f32[128][1]cpu", primals_31: "f32[128, 128][1, 128]cpu", primals_32: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_34: "f32[128][1]cpu", primals_35: "f32[512, 128][1, 512]cpu", primals_36: "f32[512][1]cpu", primals_37: "f32[128, 512][1, 128]cpu", primals_38: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", primals_40: "f32[128][1]cpu", primals_41: "f32[128, 128][1, 128]cpu", primals_42: "f32[128][1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1072 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]
	        slice_2: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1073 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
	        expand: "i64[1, 10][512, 1]cpu" = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:197 in forward, code: position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]
	        slice_4: "i64[1, 10][512, 1]cpu" = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        embedding: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        embedding_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:214 in forward, code: embeddings = inputs_embeds + token_type_embeddings
	        add: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        embedding_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:217 in forward, code: embeddings += position_embeddings
	        add_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)
	        getitem: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[0]
	        getitem_1: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean[1];  var_mean = None
	        add_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None
	        rsqrt: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_2);  add_2 = None
	        sub: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None
	        mul: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None
	        mul_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, primals_7)
	        add_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:192 in _expand_mask, code: return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)
	        full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu" = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_3, [10, 128])
	        permute: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None
	        addmm: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None
	        view_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_2: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_2: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None
	        addmm_1: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None
	        view_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_5: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_4: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None
	        addmm_2: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None
	        view_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_8: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)
	        getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu[0]
	        getitem_3: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None
	        addmm_3: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None
	        view_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None
	        var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)
	        getitem_4: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[0]
	        getitem_5: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_1[1];  var_mean_1 = None
	        add_5: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None
	        rsqrt_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_5);  add_5 = None
	        sub_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None
	        mul_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None
	        mul_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, primals_17)
	        add_6: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_6, [10, 128])
	        permute_8: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None
	        addmm_4: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_4: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.5)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_6: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None
	        permute_9: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None
	        addmm_5: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None
	        view_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None
	        var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)
	        getitem_6: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[0]
	        getitem_7: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_2[1];  var_mean_2 = None
	        add_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None
	        rsqrt_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
	        sub_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None
	        mul_7: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None
	        mul_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, primals_23)
	        add_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_10, [10, 128])
	        permute_10: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None
	        addmm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None
	        view_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_18: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_12: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None
	        addmm_7: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None
	        view_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_21: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_14: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None
	        addmm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None
	        view_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_24: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)
	        getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[0]
	        getitem_9: "f32[1, 2, 10][20, 1, 2]cpu" = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_17: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None
	        addmm_9: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None
	        view_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None
	        var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)
	        getitem_10: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[0]
	        getitem_11: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_3[1];  var_mean_3 = None
	        add_12: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None
	        rsqrt_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_12);  add_12 = None
	        sub_4: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None
	        mul_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None
	        mul_10: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, primals_33)
	        add_13: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_28: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(add_13, [10, 128])
	        permute_18: "f32[128, 512][512, 1]cpu" = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None
	        addmm_10: "f32[10, 512][512, 1]cpu" = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_11: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.5)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_30: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None
	        permute_19: "f32[512, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None
	        addmm_11: "f32[10, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None
	        view_31: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        add_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None
	        var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)
	        getitem_12: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[0]
	        getitem_13: "f32[1, 10, 1][10, 1, 1]cpu" = var_mean_4[1];  var_mean_4 = None
	        add_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None
	        rsqrt_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.rsqrt.default(add_16);  add_16 = None
	        sub_5: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None
	        mul_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None
	        mul_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, primals_39)
	        add_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        select: "f32[1, 128][1280, 1]cpu" = torch.ops.aten.select.int(add_17, 1, 0)
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_20: "f32[128, 128][128, 1]cpu" = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None
	        addmm_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        tanh: "f32[1, 128][128, 1]cpu" = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        permute_21: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None
	        permute_22: "f32[128, 1][1, 1280]cpu" = torch.ops.aten.permute.default(select, [1, 0]);  select = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_24: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
	        permute_25: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_27: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
	        permute_28: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_1: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_30: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_35: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None
	        permute_36: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_39: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_43: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_46: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
	        permute_47: "f32[512, 10][1, 512]cpu" = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_49: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
	        permute_50: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        div_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        permute_52: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        permute_57: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None
	        permute_58: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view, [1, 0]);  view = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        permute_61: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        permute_65: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        div_4: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None
	        return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)
	        
V0331 22:38:56.307000 25844 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] {"aot_backward_graph": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "8ef2f550890c1bc6143556bd01aa3cc0"}
	class GraphModule(torch.nn.Module):
	    def forward(self, primals_1: "i64[1, 10][10, 1]cpu", primals_7: "f32[128][1]cpu", primals_17: "f32[128][1]cpu", primals_23: "f32[128][1]cpu", primals_33: "f32[128][1]cpu", primals_39: "f32[128][1]cpu", expand: "i64[1, 10][512, 1]cpu", slice_4: "i64[1, 10][512, 1]cpu", mul: "f32[1, 10, 128][1280, 128, 1]cpu", full_default: "f32[1, 1, 10, 10][100, 100, 10, 1]cpu", permute_1: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_3: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_5: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_2: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_3: "f32[1, 2, 10][20, 1, 2]cpu", mul_2: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_4: "f32[10, 512][512, 1]cpu", mul_7: "f32[1, 10, 128][1280, 128, 1]cpu", permute_11: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_13: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", permute_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_8: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu", getitem_9: "f32[1, 2, 10][20, 1, 2]cpu", mul_9: "f32[1, 10, 128][1280, 128, 1]cpu", addmm_10: "f32[10, 512][512, 1]cpu", mul_14: "f32[1, 10, 128][1280, 128, 1]cpu", tanh: "f32[1, 128][128, 1]cpu", permute_21: "f32[128, 128][1, 128]cpu", permute_22: "f32[128, 1][1, 1280]cpu", div: "f32[1, 10, 1][10, 1, 1]cpu", permute_24: "f32[128, 512][1, 128]cpu", permute_25: "f32[512, 10][1, 512]cpu", permute_27: "f32[512, 128][1, 512]cpu", permute_28: "f32[128, 10][1, 128]cpu", div_1: "f32[1, 10, 1][10, 1, 1]cpu", permute_30: "f32[128, 128][1, 128]cpu", permute_35: "f32[128, 128][1, 128]cpu", permute_36: "f32[128, 10][1, 128]cpu", permute_39: "f32[128, 128][1, 128]cpu", permute_43: "f32[128, 128][1, 128]cpu", div_2: "f32[1, 10, 1][10, 1, 1]cpu", permute_46: "f32[128, 512][1, 128]cpu", permute_47: "f32[512, 10][1, 512]cpu", permute_49: "f32[512, 128][1, 512]cpu", permute_50: "f32[128, 10][1, 128]cpu", div_3: "f32[1, 10, 1][10, 1, 1]cpu", permute_52: "f32[128, 128][1, 128]cpu", permute_57: "f32[128, 128][1, 128]cpu", permute_58: "f32[128, 10][1, 128]cpu", permute_61: "f32[128, 128][1, 128]cpu", permute_65: "f32[128, 128][1, 128]cpu", div_4: "f32[1, 10, 1][10, 1, 1]cpu", tangents_1: "f32[1, 10, 128][1280, 128, 1]cpu", tangents_2: "f32[1, 128][128, 1]cpu"):
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:748 in forward, code: pooled_output = self.activation(pooled_output)
	        mul_16: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tanh, tanh);  tanh = None
	        sub_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sub.Tensor(1, mul_16);  mul_16 = None
	        mul_17: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mul.Tensor(tangents_2, sub_6);  tangents_2 = sub_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:747 in forward, code: pooled_output = self.dense(first_token_tensor)
	        mm: "f32[1, 128][128, 1]cpu" = torch.ops.aten.mm.default(mul_17, permute_21);  permute_21 = None
	        mm_1: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_22, mul_17);  permute_22 = None
	        sum_1: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_17, [0], True);  mul_17 = None
	        view_32: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_1, [128]);  sum_1 = None
	        permute_23: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        full_default_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.full.default([1, 10, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        select_scatter: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.select_scatter.default(full_default_1, mm, 1, 0);  full_default_1 = mm = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:746 in forward, code: first_token_tensor = hidden_states[:, 0]
	        add_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(tangents_1, select_scatter);  tangents_1 = select_scatter = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_19: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, primals_39);  primals_39 = None
	        mul_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, 128)
	        sum_2: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_19, [2], True)
	        mul_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_19, mul_14);  mul_19 = None
	        sum_3: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_21, [2], True);  mul_21 = None
	        mul_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_14, sum_3);  sum_3 = None
	        sub_8: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_20, sum_2);  mul_20 = sum_2 = None
	        sub_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_8, mul_22);  sub_8 = mul_22 = None
	        mul_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div, sub_9);  div = sub_9 = None
	        mul_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_18, mul_14);  mul_14 = None
	        sum_4: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_24, [0, 1]);  mul_24 = None
	        sum_5: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_18, [0, 1]);  add_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_33: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_23, [10, 128])
	        mm_2: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_33, permute_24);  permute_24 = None
	        mm_3: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_25, view_33);  permute_25 = None
	        sum_6: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_33, [0], True);  view_33 = None
	        view_34: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_6, [128]);  sum_6 = None
	        permute_26: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_3, [1, 0]);  mm_3 = None
	        view_35: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_2, [1, 10, 512]);  mm_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_10, [1, 10, 512]);  addmm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_12: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476)
	        erf_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_12);  mul_12 = None
	        add_14: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None
	        mul_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_14, 0.5);  add_14 = None
	        mul_27: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, view_29)
	        mul_28: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_27, -0.5);  mul_27 = None
	        exp: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_28);  mul_28 = None
	        mul_29: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp, 0.3989422804014327);  exp = None
	        mul_30: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_29, mul_29);  view_29 = mul_29 = None
	        add_20: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_26, mul_30);  mul_26 = mul_30 = None
	        mul_31: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_35, add_20);  view_35 = add_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_36: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_31, [10, 512]);  mul_31 = None
	        mm_4: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_36, permute_27);  permute_27 = None
	        mm_5: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_28, view_36);  permute_28 = None
	        sum_7: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_36, [0], True);  view_36 = None
	        view_37: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_7, [512]);  sum_7 = None
	        permute_29: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_5, [1, 0]);  mm_5 = None
	        view_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_4, [1, 10, 128]);  mm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_23, view_38);  mul_23 = view_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_33: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, primals_33);  primals_33 = None
	        mul_34: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, 128)
	        sum_8: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_33, [2], True)
	        mul_35: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_33, mul_9);  mul_33 = None
	        sum_9: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_35, [2], True);  mul_35 = None
	        mul_36: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_9, sum_9);  sum_9 = None
	        sub_11: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_34, sum_8);  mul_34 = sum_8 = None
	        sub_12: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_11, mul_36);  sub_11 = mul_36 = None
	        mul_37: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_1, sub_12);  div_1 = sub_12 = None
	        mul_38: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_21, mul_9);  mul_9 = None
	        sum_10: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_38, [0, 1]);  mul_38 = None
	        sum_11: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_21, [0, 1]);  add_21 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_39: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_37, [10, 128])
	        mm_6: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_39, permute_30);  permute_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_16: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_25: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_26: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None
	        permute_31: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_26, [1, 0]);  view_26 = None
	        mm_7: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_31, view_39);  permute_31 = None
	        sum_12: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_39, [0], True);  view_39 = None
	        view_40: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_12, [128]);  sum_12 = None
	        permute_32: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_7, [1, 0]);  mm_7 = None
	        view_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_6, [1, 10, 128]);  mm_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_41, [1, 10, 2, 64]);  view_41 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_33: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_42, [0, 2, 1, 3]);  view_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_33, permute_11, permute_13, permute_15, getitem_8, getitem_9, 0.0, False, attn_mask = full_default);  permute_33 = permute_11 = permute_13 = permute_15 = getitem_8 = getitem_9 = None
	        getitem_14: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[0]
	        getitem_15: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[1]
	        getitem_16: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward[2];  _scaled_dot_product_flash_attention_for_cpu_backward = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_34: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_16, [0, 2, 1, 3]);  getitem_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_34, [1, 10, 128]);  permute_34 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_44: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_43, [10, 128]);  view_43 = None
	        mm_8: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_44, permute_35);  permute_35 = None
	        mm_9: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_44)
	        sum_13: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_44, [0], True);  view_44 = None
	        view_45: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_13, [128]);  sum_13 = None
	        permute_37: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_9, [1, 0]);  mm_9 = None
	        view_46: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_8, [1, 10, 128]);  mm_8 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_22: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_37, view_46);  mul_37 = view_46 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_38: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3]);  getitem_15 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_47: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_38, [1, 10, 128]);  permute_38 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_48: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_47, [10, 128]);  view_47 = None
	        mm_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_48, permute_39);  permute_39 = None
	        mm_11: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_48)
	        sum_14: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_48, [0], True);  view_48 = None
	        view_49: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_14, [128]);  sum_14 = None
	        permute_41: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_11, [1, 0]);  mm_11 = None
	        view_50: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_10, [1, 10, 128]);  mm_10 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_23: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_22, view_50);  add_22 = view_50 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_42: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_51: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_42, [1, 10, 128]);  permute_42 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_52: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_51, [10, 128]);  view_51 = None
	        mm_12: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_52, permute_43);  permute_43 = None
	        mm_13: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_36, view_52);  permute_36 = None
	        sum_15: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_52, [0], True);  view_52 = None
	        view_53: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_15, [128]);  sum_15 = None
	        permute_45: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_13, [1, 0]);  mm_13 = None
	        view_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_12, [1, 10, 128]);  mm_12 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_24: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_23, view_54);  add_23 = view_54 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:554 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_40: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, primals_23);  primals_23 = None
	        mul_41: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, 128)
	        sum_16: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_40, [2], True)
	        mul_42: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_40, mul_7);  mul_40 = None
	        sum_17: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_42, [2], True);  mul_42 = None
	        mul_43: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_7, sum_17);  sum_17 = None
	        sub_14: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_41, sum_16);  mul_41 = sum_16 = None
	        sub_15: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_14, mul_43);  sub_14 = mul_43 = None
	        mul_44: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_2, sub_15);  div_2 = sub_15 = None
	        mul_45: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_24, mul_7);  mul_7 = None
	        sum_18: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_45, [0, 1]);  mul_45 = None
	        sum_19: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_24, [0, 1]);  add_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:552 in forward, code: hidden_states = self.dense(hidden_states)
	        view_55: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_44, [10, 128])
	        mm_14: "f32[10, 512][512, 1]cpu" = torch.ops.aten.mm.default(view_55, permute_46);  permute_46 = None
	        mm_15: "f32[512, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_47, view_55);  permute_47 = None
	        sum_20: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_55, [0], True);  view_55 = None
	        view_56: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_20, [128]);  sum_20 = None
	        permute_48: "f32[128, 512][1, 128]cpu" = torch.ops.aten.permute.default(mm_15, [1, 0]);  mm_15 = None
	        view_57: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(mm_14, [1, 10, 512]);  mm_14 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_13: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.view.default(addmm_4, [1, 10, 512]);  addmm_4 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/activations.py:78 in forward, code: return self.act(input)
	        mul_5: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476)
	        erf: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.erf.default(mul_5);  mul_5 = None
	        add_7: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(erf, 1);  erf = None
	        mul_47: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(add_7, 0.5);  add_7 = None
	        mul_48: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, view_13)
	        mul_49: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(mul_48, -0.5);  mul_48 = None
	        exp_1: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.exp.default(mul_49);  mul_49 = None
	        mul_50: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None
	        mul_51: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_13, mul_50);  view_13 = mul_50 = None
	        add_26: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.add.Tensor(mul_47, mul_51);  mul_47 = mul_51 = None
	        mul_52: "f32[1, 10, 512][5120, 512, 1]cpu" = torch.ops.aten.mul.Tensor(view_57, add_26);  view_57 = add_26 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        view_58: "f32[10, 512][512, 1]cpu" = torch.ops.aten.view.default(mul_52, [10, 512]);  mul_52 = None
	        mm_16: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_58, permute_49);  permute_49 = None
	        mm_17: "f32[128, 512][512, 1]cpu" = torch.ops.aten.mm.default(permute_50, view_58);  permute_50 = None
	        sum_21: "f32[1, 512][512, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_58, [0], True);  view_58 = None
	        view_59: "f32[512][1]cpu" = torch.ops.aten.view.default(sum_21, [512]);  sum_21 = None
	        permute_51: "f32[512, 128][1, 512]cpu" = torch.ops.aten.permute.default(mm_17, [1, 0]);  mm_17 = None
	        view_60: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_16, [1, 10, 128]);  mm_16 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539 in forward, code: hidden_states = self.dense(hidden_states)
	        add_27: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_44, view_60);  mul_44 = view_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:468 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)
	        mul_54: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, primals_17);  primals_17 = None
	        mul_55: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, 128)
	        sum_22: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_54, [2], True)
	        mul_56: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_54, mul_2);  mul_54 = None
	        sum_23: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_56, [2], True);  mul_56 = None
	        mul_57: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_2, sum_23);  sum_23 = None
	        sub_17: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_55, sum_22);  mul_55 = sum_22 = None
	        sub_18: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_17, mul_57);  sub_17 = mul_57 = None
	        mul_58: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_3, sub_18);  div_3 = sub_18 = None
	        mul_59: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_27, mul_2);  mul_2 = None
	        sum_24: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_59, [0, 1]);  mul_59 = None
	        sum_25: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_27, [0, 1]);  add_27 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_61: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(mul_58, [10, 128])
	        mm_18: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_61, permute_52);  permute_52 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_6: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_9: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:466 in forward, code: hidden_states = self.dense(hidden_states)
	        view_10: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None
	        permute_53: "f32[128, 10][1, 128]cpu" = torch.ops.aten.permute.default(view_10, [1, 0]);  view_10 = None
	        mm_19: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_53, view_61);  permute_53 = None
	        sum_26: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_61, [0], True);  view_61 = None
	        view_62: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_26, [128]);  sum_26 = None
	        permute_54: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_19, [1, 0]);  mm_19 = None
	        view_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_18, [1, 10, 128]);  mm_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:450 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)
	        view_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.view.default(view_63, [1, 10, 2, 64]);  view_63 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:449 in forward, code: attn_output = attn_output.transpose(1, 2)
	        permute_55: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(
	        _scaled_dot_product_flash_attention_for_cpu_backward_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu_backward.default(permute_55, permute_1, permute_3, permute_5, getitem_2, getitem_3, 0.0, False, attn_mask = full_default);  permute_55 = permute_1 = permute_3 = permute_5 = getitem_2 = getitem_3 = full_default = None
	        getitem_17: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[0]
	        getitem_18: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[1]
	        getitem_19: "f32[1, 2, 10, 64][1280, 64, 128, 1]cpu" = _scaled_dot_product_flash_attention_for_cpu_backward_1[2];  _scaled_dot_product_flash_attention_for_cpu_backward_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_56: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_19, [0, 2, 1, 3]);  getitem_19 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_56, [1, 10, 128]);  permute_56 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        view_66: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_65, [10, 128]);  view_65 = None
	        mm_20: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_66, permute_57);  permute_57 = None
	        mm_21: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_66)
	        sum_27: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_66, [0], True);  view_66 = None
	        view_67: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_27, [128]);  sum_27 = None
	        permute_59: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_21, [1, 0]);  mm_21 = None
	        view_68: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_20, [1, 10, 128]);  mm_20 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:409 in forward, code: value_layer = self.transpose_for_scores(self.value(current_states))
	        add_28: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(mul_58, view_68);  mul_58 = view_68 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_60: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_18, [0, 2, 1, 3]);  getitem_18 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_69: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_60, [1, 10, 128]);  permute_60 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        view_70: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_69, [10, 128]);  view_69 = None
	        mm_22: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_70, permute_61);  permute_61 = None
	        mm_23: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_70)
	        sum_28: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_70, [0], True);  view_70 = None
	        view_71: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_28, [128]);  sum_28 = None
	        permute_63: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_23, [1, 0]);  mm_23 = None
	        view_72: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_22, [1, 10, 128]);  mm_22 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:408 in forward, code: key_layer = self.transpose_for_scores(self.key(current_states))
	        add_29: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_28, view_72);  add_28 = view_72 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:253 in transpose_for_scores, code: return x.permute(0, 2, 1, 3)
	        permute_64: "f32[1, 10, 2, 64][1280, 128, 64, 1]cpu" = torch.ops.aten.permute.default(getitem_17, [0, 2, 1, 3]);  getitem_17 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:252 in transpose_for_scores, code: x = x.view(new_x_shape)
	        view_73: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(permute_64, [1, 10, 128]);  permute_64 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        view_74: "f32[10, 128][128, 1]cpu" = torch.ops.aten.view.default(view_73, [10, 128]);  view_73 = None
	        mm_24: "f32[10, 128][128, 1]cpu" = torch.ops.aten.mm.default(view_74, permute_65);  permute_65 = None
	        mm_25: "f32[128, 128][128, 1]cpu" = torch.ops.aten.mm.default(permute_58, view_74);  permute_58 = None
	        sum_29: "f32[1, 128][128, 1]cpu" = torch.ops.aten.sum.dim_IntList(view_74, [0], True);  view_74 = None
	        view_75: "f32[128][1]cpu" = torch.ops.aten.view.default(sum_29, [128]);  sum_29 = None
	        permute_67: "f32[128, 128][1, 128]cpu" = torch.ops.aten.permute.default(mm_25, [1, 0]);  mm_25 = None
	        view_76: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.view.default(mm_24, [1, 10, 128]);  mm_24 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:395 in forward, code: query_layer = self.transpose_for_scores(self.query(hidden_states))
	        add_30: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.add.Tensor(add_29, view_76);  add_29 = view_76 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:218 in forward, code: embeddings = self.LayerNorm(embeddings)
	        mul_61: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, primals_7);  primals_7 = None
	        mul_62: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, 128)
	        sum_30: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_61, [2], True)
	        mul_63: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul_61, mul);  mul_61 = None
	        sum_31: "f32[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.sum.dim_IntList(mul_63, [2], True);  mul_63 = None
	        mul_64: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(mul, sum_31);  sum_31 = None
	        sub_20: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(mul_62, sum_30);  mul_62 = sum_30 = None
	        sub_21: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.sub.Tensor(sub_20, mul_64);  sub_20 = mul_64 = None
	        mul_65: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(div_4, sub_21);  div_4 = sub_21 = None
	        mul_66: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.mul.Tensor(add_30, mul);  mul = None
	        sum_32: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(mul_66, [0, 1]);  mul_66 = None
	        sum_33: "f32[128][1]cpu" = torch.ops.aten.sum.dim_IntList(add_30, [0, 1]);  add_30 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:216 in forward, code: position_embeddings = self.position_embeddings(position_ids)
	        eq: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(slice_4, -1)
	        unsqueeze_2: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq, -1);  eq = None
	        full_default_3: "f32[][]cpu" = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        where_1: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_2, full_default_3, mul_65);  unsqueeze_2 = None
	        full_default_4: "f32[512, 128][128, 1]cpu" = torch.ops.aten.full.default([512, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put: "f32[512, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_4, [slice_4], where_1, True);  full_default_4 = slice_4 = where_1 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:212 in forward, code: token_type_embeddings = self.token_type_embeddings(token_type_ids)
	        eq_1: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(expand, -1)
	        unsqueeze_3: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_1, -1);  eq_1 = None
	        where_2: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_3, full_default_3, mul_65);  unsqueeze_3 = None
	        full_default_6: "f32[2, 128][128, 1]cpu" = torch.ops.aten.full.default([2, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_1: "f32[2, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_6, [expand], where_2, True);  full_default_6 = expand = where_2 = None
	        
	         # File: /home/codespace/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211 in forward, code: inputs_embeds = self.word_embeddings(input_ids)
	        eq_2: "b8[1, 10][10, 1]cpu" = torch.ops.aten.eq.Scalar(primals_1, 0)
	        unsqueeze_4: "b8[1, 10, 1][10, 1, 1]cpu" = torch.ops.aten.unsqueeze.default(eq_2, -1);  eq_2 = None
	        where_3: "f32[1, 10, 128][1280, 128, 1]cpu" = torch.ops.aten.where.self(unsqueeze_4, full_default_3, mul_65);  unsqueeze_4 = full_default_3 = mul_65 = None
	        full_default_8: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.full.default([30522, 128], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)
	        index_put_2: "f32[30522, 128][128, 1]cpu" = torch.ops.aten.index_put.default(full_default_8, [primals_1], where_3, True);  full_default_8 = primals_1 = where_3 = None
	        return (None, None, None, index_put_2, index_put_1, index_put, sum_32, sum_33, permute_67, view_75, permute_63, view_71, permute_59, view_67, permute_54, view_62, sum_24, sum_25, permute_51, view_59, permute_48, view_56, sum_18, sum_19, permute_45, view_53, permute_41, view_49, permute_37, view_45, permute_32, view_40, sum_10, sum_11, permute_29, view_37, permute_26, view_34, sum_4, sum_5, permute_23, view_32)
	        
V0331 22:38:56.308000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "a38774735d0876ff4c0537f8857699d2"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743460736307841.0,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.309000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "89b5afefd0df1b8a5634daadd7d04a3e"}
	{
	"name": "compile_fx_inner",
	"ts": 1743460736308994.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.309000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "369663566dcad3f7c5ef385fc1b0c10f"}
	{
	"name": "inductor_compile",
	"ts": 1743460736308994.2,
	"args": null,
	"ph": "B",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.363000 25844 torch/_inductor/codecache.py:1132] {"inductor_output_code": {"filename": "/tmp/torchinductor_codespace/kb/ckb7rafd2axgx3svqabknxiadoamlwfrjac5wn435h7nnf25khqd.py"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "d41660e2a5bd76f896de5d8724a7cc08"}
	# AOT ID: ['0_forward']
	from ctypes import c_void_p, c_long, c_int
	import torch
	import math
	import random
	import os
	import tempfile
	from math import inf, nan
	from torch._inductor.hooks import run_intermediate_hooks
	from torch._inductor.utils import maybe_profile
	from torch._inductor.codegen.memory_planning import _align as align
	from torch import device, empty_strided
	from torch._inductor.async_compile import AsyncCompile
	from torch._inductor.select_algorithm import extern_kernels
	from torch._inductor.codegen.multi_kernel import MultiKernelCall
	
	aten = torch.ops.aten
	inductor_ops = torch.ops.inductor
	_quantized = torch.ops._quantized
	assert_size_stride = torch._C._dynamo.guards.assert_size_stride
	empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
	empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
	empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
	reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
	alloc_from_pool = torch.ops.inductor._alloc_from_pool
	async_compile = AsyncCompile()
	
	
	cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0 = async_compile.cpp_pybinding(['const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const int64_t*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const int64_t* in_ptr0,
	                       const float* in_ptr1,
	                       const int64_t* in_ptr2,
	                       const float* in_ptr3,
	                       const int64_t* in_ptr4,
	                       const float* in_ptr5,
	                       const float* in_ptr6,
	                       const float* in_ptr7,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4,
	                       float* out_ptr5,
	                       float* out_ptr6)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = in_ptr0[static_cast<int64_t>(x0)];
	                    auto tmp10 = in_ptr2[static_cast<int64_t>(x0)];
	                    auto tmp21 = in_ptr4[static_cast<int64_t>(x0)];
	                    auto tmp1 = 30522L;
	                    auto tmp2 = c10::convert<int64_t>(tmp1);
	                    auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
	                    auto tmp4 = tmp0 < 0;
	                    auto tmp5 = tmp4 ? tmp3 : tmp0;
	                    auto tmp6 = tmp5;
	                    auto tmp7 = c10::convert<int64_t>(tmp6);
	                    TORCH_CHECK((0 <= tmp7) & (tmp7 < 30522L), "index out of bounds: 0 <= tmp7 < 30522L");
	                    auto tmp9 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*tmp5)), static_cast<int64_t>(8));
	                    auto tmp11 = 2L;
	                    auto tmp12 = c10::convert<int64_t>(tmp11);
	                    auto tmp13 = decltype(tmp10)(tmp10 + tmp12);
	                    auto tmp14 = tmp10 < 0;
	                    auto tmp15 = tmp14 ? tmp13 : tmp10;
	                    auto tmp16 = tmp15;
	                    auto tmp17 = c10::convert<int64_t>(tmp16);
	                    TORCH_CHECK((0 <= tmp17) & (tmp17 < 2L), "index out of bounds: 0 <= tmp17 < 2L");
	                    auto tmp19 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1 + (128L*tmp15)), static_cast<int64_t>(8));
	                    auto tmp20 = tmp9 + tmp19;
	                    auto tmp22 = 512L;
	                    auto tmp23 = c10::convert<int64_t>(tmp22);
	                    auto tmp24 = decltype(tmp21)(tmp21 + tmp23);
	                    auto tmp25 = tmp21 < 0;
	                    auto tmp26 = tmp25 ? tmp24 : tmp21;
	                    auto tmp27 = tmp26;
	                    auto tmp28 = c10::convert<int64_t>(tmp27);
	                    TORCH_CHECK((0 <= tmp28) & (tmp28 < 512L), "index out of bounds: 0 <= tmp28 < 512L");
	                    auto tmp30 = at::vec::Vectorized<float>::loadu(in_ptr5 + static_cast<int64_t>(x1 + (128L*tmp26)), static_cast<int64_t>(8));
	                    auto tmp31 = tmp20 + tmp30;
	                    tmp31.store(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)));
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp31, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr2[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp4 = out_ptr2[static_cast<int64_t>(x0)];
	                auto tmp12 = at::vec::Vectorized<float>::loadu(in_ptr6 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr7 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = at::vec::Vectorized<float>(tmp1);
	                auto tmp3 = tmp0 - tmp2;
	                auto tmp5 = static_cast<float>(128.0);
	                auto tmp6 = tmp4 / tmp5;
	                auto tmp7 = static_cast<float>(1e-12);
	                auto tmp8 = decltype(tmp6)(tmp6 + tmp7);
	                auto tmp9 = 1 / std::sqrt(tmp8);
	                auto tmp10 = at::vec::Vectorized<float>(tmp9);
	                auto tmp11 = tmp3 * tmp10;
	                auto tmp13 = tmp11 * tmp12;
	                auto tmp15 = tmp13 + tmp14;
	                tmp11.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp15.store(out_ptr4 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr2 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr5 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(96L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(96L); x0<static_cast<int64_t>(100L); x0+=static_cast<int64_t>(4L))
	        {
	            auto tmp0 = static_cast<float>(0.0);
	            auto tmp1 = at::vec::Vectorized<float>(tmp0);
	            tmp1.store(out_ptr6 + static_cast<int64_t>(x0), static_cast<int64_t>(4L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_1 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_2 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_3 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_4 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_gelu_5 = async_compile.cpp_pybinding(['const float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       float* out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(5120L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(0.5);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 * tmp2;
	            auto tmp4 = static_cast<float>(0.7071067811865476);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp0 * tmp5;
	            auto tmp7 = tmp6.erf();
	            auto tmp8 = static_cast<float>(1.0);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 + tmp9;
	            auto tmp11 = tmp3 * tmp10;
	            tmp11.store(out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	cpp_fused_add_native_layer_norm_native_layer_norm_backward_6 = async_compile.cpp_pybinding(['const float*', 'const float*', 'const float*', 'const float*', 'float*', 'float*', 'float*', 'float*', 'float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(const float* in_ptr0,
	                       const float* in_ptr1,
	                       const float* in_ptr2,
	                       const float* in_ptr3,
	                       float* out_ptr0,
	                       float* out_ptr1,
	                       float* out_ptr2,
	                       float* out_ptr3,
	                       float* out_ptr4)
	{
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            {
	                Welford<float> tmp_acc0 = Welford<float>();
	                Welford<at::vec::Vectorized<float>> tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                Welford<at::vec::Vectorized<float>> masked_tmp_acc0_vec = Welford<at::vec::Vectorized<float>>();
	                static WeightRecp<at::vec::Vectorized<float>> wrecps0(static_cast<int64_t>(16L));
	                for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	                {
	                    auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                    auto tmp2 = tmp0 + tmp1;
	                    tmp_acc0_vec = welford_combine(tmp_acc0_vec, tmp2, &wrecps0);
	                }
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(masked_tmp_acc0_vec));
	                tmp_acc0 = welford_combine(tmp_acc0, welford_vec_reduce_all(tmp_acc0_vec));
	                out_ptr0[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.mean);
	                out_ptr1[static_cast<int64_t>(x0)] = static_cast<float>(tmp_acc0.m2);
	            }
	        }
	    }
	    {
	        #pragma GCC ivdep
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(1L))
	        {
	            for(int64_t x1=static_cast<int64_t>(0L); x1<static_cast<int64_t>(128L); x1+=static_cast<int64_t>(8L))
	            {
	                auto tmp0 = at::vec::Vectorized<float>::loadu(in_ptr0 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp1 = at::vec::Vectorized<float>::loadu(in_ptr1 + static_cast<int64_t>(x1 + (128L*x0)), static_cast<int64_t>(8));
	                auto tmp3 = out_ptr0[static_cast<int64_t>(x0)];
	                auto tmp6 = out_ptr1[static_cast<int64_t>(x0)];
	                auto tmp14 = at::vec::Vectorized<float>::loadu(in_ptr2 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp16 = at::vec::Vectorized<float>::loadu(in_ptr3 + static_cast<int64_t>(x1), static_cast<int64_t>(8));
	                auto tmp2 = tmp0 + tmp1;
	                auto tmp4 = at::vec::Vectorized<float>(tmp3);
	                auto tmp5 = tmp2 - tmp4;
	                auto tmp7 = static_cast<float>(128.0);
	                auto tmp8 = tmp6 / tmp7;
	                auto tmp9 = static_cast<float>(1e-12);
	                auto tmp10 = decltype(tmp8)(tmp8 + tmp9);
	                auto tmp11 = 1 / std::sqrt(tmp10);
	                auto tmp12 = at::vec::Vectorized<float>(tmp11);
	                auto tmp13 = tmp5 * tmp12;
	                auto tmp15 = tmp13 * tmp14;
	                auto tmp17 = tmp15 + tmp16;
	                tmp13.store(out_ptr2 + static_cast<int64_t>(x1 + (128L*x0)));
	                tmp17.store(out_ptr3 + static_cast<int64_t>(x1 + (128L*x0)));
	            }
	        }
	    }
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(8L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0));
	        }
	        for(int64_t x0=static_cast<int64_t>(8L); x0<static_cast<int64_t>(10L); x0+=static_cast<int64_t>(2L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(out_ptr1 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	            auto tmp1 = static_cast<float>(128.0);
	            auto tmp2 = at::vec::Vectorized<float>(tmp1);
	            auto tmp3 = tmp0 / tmp2;
	            auto tmp4 = static_cast<float>(1e-12);
	            auto tmp5 = at::vec::Vectorized<float>(tmp4);
	            auto tmp6 = tmp3 + tmp5;
	            auto tmp7 = tmp6.rsqrt();
	            auto tmp8 = static_cast<float>(0.0078125);
	            auto tmp9 = at::vec::Vectorized<float>(tmp8);
	            auto tmp10 = tmp7 * tmp9;
	            tmp10.store(out_ptr4 + static_cast<int64_t>(x0), static_cast<int64_t>(2L));
	        }
	    }
	}
	''')
	
	
	cpp_fused_tanh_7 = async_compile.cpp_pybinding(['float*'], '''
	#include "/tmp/torchinductor_codespace/vu/cvuvp4i7roujum4xemrfwnb3t4c5t3r3mihr4b7iegh6tcqvdg43.h"
	extern "C"  void kernel(float* in_out_ptr0)
	{
	    {
	        for(int64_t x0=static_cast<int64_t>(0L); x0<static_cast<int64_t>(128L); x0+=static_cast<int64_t>(8L))
	        {
	            auto tmp0 = at::vec::Vectorized<float>::loadu(in_out_ptr0 + static_cast<int64_t>(x0), static_cast<int64_t>(8));
	            auto tmp1 = decltype(tmp0)(2) / (decltype(tmp0)(1) + (decltype(tmp0)(-2) * tmp0).exp()) - decltype(tmp0)(1);
	            tmp1.store(in_out_ptr0 + static_cast<int64_t>(x0));
	        }
	    }
	}
	''')
	
	
	async_compile.wait(globals())
	del async_compile
	
	def call(args):
	    primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42 = args
	    args.clear()
	    assert_size_stride(primals_1, (1, 10), (10, 1))
	    assert_size_stride(primals_2, (1, 512), (512, 1))
	    assert_size_stride(primals_3, (1, 512), (512, 1))
	    assert_size_stride(primals_4, (30522, 128), (128, 1))
	    assert_size_stride(primals_5, (2, 128), (128, 1))
	    assert_size_stride(primals_6, (512, 128), (128, 1))
	    assert_size_stride(primals_7, (128, ), (1, ))
	    assert_size_stride(primals_8, (128, ), (1, ))
	    assert_size_stride(primals_9, (128, 128), (1, 128))
	    assert_size_stride(primals_10, (128, ), (1, ))
	    assert_size_stride(primals_11, (128, 128), (1, 128))
	    assert_size_stride(primals_12, (128, ), (1, ))
	    assert_size_stride(primals_13, (128, 128), (1, 128))
	    assert_size_stride(primals_14, (128, ), (1, ))
	    assert_size_stride(primals_15, (128, 128), (1, 128))
	    assert_size_stride(primals_16, (128, ), (1, ))
	    assert_size_stride(primals_17, (128, ), (1, ))
	    assert_size_stride(primals_18, (128, ), (1, ))
	    assert_size_stride(primals_19, (512, 128), (1, 512))
	    assert_size_stride(primals_20, (512, ), (1, ))
	    assert_size_stride(primals_21, (128, 512), (1, 128))
	    assert_size_stride(primals_22, (128, ), (1, ))
	    assert_size_stride(primals_23, (128, ), (1, ))
	    assert_size_stride(primals_24, (128, ), (1, ))
	    assert_size_stride(primals_25, (128, 128), (1, 128))
	    assert_size_stride(primals_26, (128, ), (1, ))
	    assert_size_stride(primals_27, (128, 128), (1, 128))
	    assert_size_stride(primals_28, (128, ), (1, ))
	    assert_size_stride(primals_29, (128, 128), (1, 128))
	    assert_size_stride(primals_30, (128, ), (1, ))
	    assert_size_stride(primals_31, (128, 128), (1, 128))
	    assert_size_stride(primals_32, (128, ), (1, ))
	    assert_size_stride(primals_33, (128, ), (1, ))
	    assert_size_stride(primals_34, (128, ), (1, ))
	    assert_size_stride(primals_35, (512, 128), (1, 512))
	    assert_size_stride(primals_36, (512, ), (1, ))
	    assert_size_stride(primals_37, (128, 512), (1, 128))
	    assert_size_stride(primals_38, (128, ), (1, ))
	    assert_size_stride(primals_39, (128, ), (1, ))
	    assert_size_stride(primals_40, (128, ), (1, ))
	    assert_size_stride(primals_41, (128, 128), (1, 128))
	    assert_size_stride(primals_42, (128, ), (1, ))
	    buf0 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf1 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf2 = empty_strided_cpu((1, 10, 1), (10, 1, 10), torch.float32)
	    buf4 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf6 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf53 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    buf5 = empty_strided_cpu((1, 1, 10, 10), (100, 100, 10, 1), torch.float32)
	    cpp_fused_add_embedding_masked_fill_native_layer_norm_native_layer_norm_backward_0(primals_1, primals_4, primals_2, primals_5, primals_3, primals_6, primals_7, primals_8, buf0, buf1, buf2, buf4, buf6, buf53, buf5)
	    del primals_4
	    del primals_5
	    del primals_6
	    del primals_8
	    buf7 = reinterpret_tensor(buf0, (10, 128), (128, 1), 0); del buf0  # reuse
	    # Topologically Sorted Source Nodes: [linear], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_10, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_9, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf7)
	    del primals_10
	    buf8 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_1], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_12, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_11, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf8)
	    del primals_12
	    buf9 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_2], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_14, reinterpret_tensor(buf6, (10, 128), (128, 1), 0), reinterpret_tensor(primals_13, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf9)
	    del primals_14
	    # Topologically Sorted Source Nodes: [attn_output], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf10 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf11 = buf10[0]
	    buf12 = buf10[1]
	    del buf10
	    buf13 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_16, reinterpret_tensor(buf11, (10, 128), (128, 1), 0), reinterpret_tensor(primals_15, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf13)
	    del primals_16
	    buf14 = buf2; del buf2  # reuse
	    buf15 = buf1; del buf1  # reuse
	    buf17 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf18 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf52 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_1(buf13, buf6, primals_17, primals_18, buf14, buf15, buf17, buf18, buf52)
	    del primals_18
	    buf19 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_3], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_20, reinterpret_tensor(buf18, (10, 128), (128, 1), 0), reinterpret_tensor(primals_19, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf19)
	    del primals_20
	    buf20 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_2(buf19, buf20)
	    buf21 = buf13; del buf13  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_5], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_22, reinterpret_tensor(buf20, (10, 512), (512, 1), 0), reinterpret_tensor(primals_21, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf21)
	    del primals_22
	    buf22 = buf15; del buf15  # reuse
	    buf23 = buf14; del buf14  # reuse
	    buf25 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf26 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf51 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_3(buf21, buf18, primals_23, primals_24, buf22, buf23, buf25, buf26, buf51)
	    del primals_24
	    buf27 = buf21; del buf21  # reuse
	    # Topologically Sorted Source Nodes: [linear_6], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_26, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_25, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf27)
	    del primals_26
	    buf28 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_7], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_28, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_27, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf28)
	    del primals_28
	    buf29 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [linear_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_30, reinterpret_tensor(buf26, (10, 128), (128, 1), 0), reinterpret_tensor(primals_29, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf29)
	    del primals_30
	    # Topologically Sorted Source Nodes: [attn_output_3], Original ATen: [aten._scaled_dot_product_flash_attention_for_cpu]
	    buf30 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), attn_mask=buf5)
	    buf31 = buf30[0]
	    buf32 = buf30[1]
	    del buf30
	    buf33 = empty_strided_cpu((10, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_8], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_32, reinterpret_tensor(buf31, (10, 128), (128, 1), 0), reinterpret_tensor(primals_31, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf33)
	    del primals_32
	    buf34 = buf23; del buf23  # reuse
	    buf35 = buf22; del buf22  # reuse
	    buf37 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf38 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf50 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_4(buf33, buf26, primals_33, primals_34, buf34, buf35, buf37, buf38, buf50)
	    del primals_34
	    buf39 = empty_strided_cpu((10, 512), (512, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [hidden_states_11], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_36, reinterpret_tensor(buf38, (10, 128), (128, 1), 0), reinterpret_tensor(primals_35, (128, 512), (512, 1), 0), alpha=1, beta=1, out=buf39)
	    del primals_36
	    buf40 = empty_strided_cpu((1, 10, 512), (5120, 512, 1), torch.float32)
	    cpp_fused_gelu_5(buf39, buf40)
	    buf41 = buf33; del buf33  # reuse
	    # Topologically Sorted Source Nodes: [hidden_states_13], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_38, reinterpret_tensor(buf40, (10, 512), (512, 1), 0), reinterpret_tensor(primals_37, (512, 128), (128, 1), 0), alpha=1, beta=1, out=buf41)
	    del primals_38
	    buf42 = buf35; del buf35  # reuse
	    buf43 = buf34; del buf34  # reuse
	    buf45 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf46 = empty_strided_cpu((1, 10, 128), (1280, 128, 1), torch.float32)
	    buf49 = empty_strided_cpu((1, 10, 1), (10, 1, 1), torch.float32)
	    cpp_fused_add_native_layer_norm_native_layer_norm_backward_6(buf41, buf38, primals_39, primals_40, buf42, buf43, buf45, buf46, buf49)
	    del buf41
	    del buf42
	    del buf43
	    del primals_40
	    buf47 = empty_strided_cpu((1, 128), (128, 1), torch.float32)
	    # Topologically Sorted Source Nodes: [pooled_output], Original ATen: [aten.addmm]
	    extern_kernels.addmm(primals_42, reinterpret_tensor(buf46, (1, 128), (128, 1), 0), reinterpret_tensor(primals_41, (128, 128), (128, 1), 0), alpha=1, beta=1, out=buf47)
	    del primals_42
	    buf48 = buf47; del buf47  # reuse
	    cpp_fused_tanh_7(buf48)
	    return (buf46, buf48, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, reinterpret_tensor(primals_2, (1, 10), (512, 1), 0), reinterpret_tensor(primals_3, (1, 10), (512, 1), 0), buf4, buf5, reinterpret_tensor(buf7, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf8, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf9, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf11, buf12, buf17, buf19, buf25, reinterpret_tensor(buf27, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf28, (1, 2, 10, 64), (1280, 64, 128, 1), 0), reinterpret_tensor(buf29, (1, 2, 10, 64), (1280, 64, 128, 1), 0), buf31, buf32, buf37, buf39, buf45, buf48, primals_41, reinterpret_tensor(buf46, (128, 1), (1, 1280), 0), buf49, primals_37, reinterpret_tensor(buf40, (512, 10), (1, 512), 0), primals_35, reinterpret_tensor(buf38, (128, 10), (1, 128), 0), buf50, primals_31, primals_29, reinterpret_tensor(buf26, (128, 10), (1, 128), 0), primals_27, primals_25, buf51, primals_21, reinterpret_tensor(buf20, (512, 10), (1, 512), 0), primals_19, reinterpret_tensor(buf18, (128, 10), (1, 128), 0), buf52, primals_15, primals_13, reinterpret_tensor(buf6, (128, 10), (1, 128), 0), primals_11, primals_9, buf53, )
	
	
	def benchmark_compiled_module(times=10, repeat=10):
	    from torch._dynamo.testing import rand_strided
	    from torch._inductor.utils import print_performance
	    primals_1 = rand_strided((1, 10), (10, 1), device='cpu', dtype=torch.int64)
	    primals_2 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_3 = rand_strided((1, 512), (512, 1), device='cpu', dtype=torch.int64)
	    primals_4 = rand_strided((30522, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_5 = rand_strided((2, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_6 = rand_strided((512, 128), (128, 1), device='cpu', dtype=torch.float32)
	    primals_7 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_8 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_9 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_10 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_11 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_12 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_13 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_14 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_15 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_16 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_17 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_18 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_19 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_20 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_21 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_22 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_23 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_24 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_25 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_26 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_27 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_28 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_29 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_30 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_31 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_32 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_33 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_34 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_35 = rand_strided((512, 128), (1, 512), device='cpu', dtype=torch.float32)
	    primals_36 = rand_strided((512, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_37 = rand_strided((128, 512), (1, 128), device='cpu', dtype=torch.float32)
	    primals_38 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_39 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_40 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    primals_41 = rand_strided((128, 128), (1, 128), device='cpu', dtype=torch.float32)
	    primals_42 = rand_strided((128, ), (1, ), device='cpu', dtype=torch.float32)
	    fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42])
	    return print_performance(fn, times=times, repeat=repeat)
	
	
	if __name__ == "__main__":
	    from torch._inductor.wrapper_benchmark import compiled_module_main
	    compiled_module_main('None', benchmark_compiled_module)
	
V0331 22:38:56.364000 25844 torch/_dynamo/utils.py:985] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "0bf1986c9f1e32125c426143112d00b7"}
	{
	"name": "fx_graph_cache_hit",
	"ts": 1743460736364097.5,
	"args": {
	"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a",
	"components": [
	"[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`",
	"[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False",
	"[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None",
	"[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]",
	"[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}",
	"[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)",
	"[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)",
	"[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>",
	"[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False",
	"[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT",
	"[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True",
	"[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False",
	"[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16",
	"[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None",
	"[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False",
	"[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None",
	"[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None",
	"[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None",
	"[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton",
	"[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False",
	"[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None",
	"[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False",
	"[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False",
	"[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False",
	"[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019",
	"[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True",
	"[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25",
	"[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True",
	"[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10",
	"[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False",
	"[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False",
	"[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP",
	"[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False",
	"[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0",
	"[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0",
	"[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0",
	"[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1",
	"[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False",
	"[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates",
	"[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128",
	"[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None",
	"[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None",
	"[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None",
	"[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8",
	"[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30",
	"[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False",
	"[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True",
	"[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None",
	"[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']",
	"[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True",
	"[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False",
	"[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False",
	"[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False",
	"[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None",
	"[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2",
	"[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256",
	"[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True",
	"[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False",
	"[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192",
	"[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False",
	"[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False",
	"[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False",
	"[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"
	],
	"time_saved_ns": 13851574116,
	"cache_state": "hit"
	},
	"ph": "i",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0,
	"s": "p"
	}
V0331 22:38:56.365000 25844 torch/_inductor/codecache.py:1379] {"artifact": {"name": "fx_graph_cache_hash", "encoding": "json"}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "b9cb65574f54c08cd81fa88e9ac50a7a"}
	{"key": "f2n5mjttbhdjklypxr5to5xysa53cwa2zbx7j2lkkyzsyczhxb3a", "components": ["[ca5xyjg3gbzsz3do62tbo43ybszu7esfoztdtjllggt62qvjwbn] gm: GraphModule()\n\n\n\ndef forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42):\n    slice_2 = torch.ops.aten.slice.Tensor(primals_2, 1, 0, 10);  primals_2 = None\n    expand = torch.ops.aten.expand.default(slice_2, [1, 10]);  slice_2 = None\n    slice_4 = torch.ops.aten.slice.Tensor(primals_3, 1, 0, 10);  primals_3 = None\n    embedding = torch.ops.aten.embedding.default(primals_4, primals_1, 0);  primals_4 = None\n    embedding_1 = torch.ops.aten.embedding.default(primals_5, expand);  primals_5 = None\n    add = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n    embedding_2 = torch.ops.aten.embedding.default(primals_6, slice_4);  primals_6 = None\n    add_1 = torch.ops.aten.add.Tensor(add, embedding_2);  add = embedding_2 = None\n    var_mean = torch.ops.aten.var_mean.correction(add_1, [2], correction = 0, keepdim = True)\n    getitem = var_mean[0]\n    getitem_1 = var_mean[1];  var_mean = None\n    add_2 = torch.ops.aten.add.Tensor(getitem, 1e-12);  getitem = None\n    rsqrt = torch.ops.aten.rsqrt.default(add_2);  add_2 = None\n    sub = torch.ops.aten.sub.Tensor(add_1, getitem_1);  add_1 = getitem_1 = None\n    mul = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n    mul_1 = torch.ops.aten.mul.Tensor(mul, primals_7)\n    add_3 = torch.ops.aten.add.Tensor(mul_1, primals_8);  mul_1 = primals_8 = None\n    full_default = torch.ops.aten.full.default([1, 1, 10, 10], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n    view = torch.ops.aten.view.default(add_3, [10, 128])\n    permute = torch.ops.aten.permute.default(primals_9, [1, 0]);  primals_9 = None\n    addmm = torch.ops.aten.addmm.default(primals_10, view, permute);  primals_10 = None\n    view_1 = torch.ops.aten.view.default(addmm, [1, 10, 128]);  addmm = None\n    view_2 = torch.ops.aten.view.default(view_1, [1, 10, 2, 64]);  view_1 = None\n    permute_1 = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n    permute_2 = torch.ops.aten.permute.default(primals_11, [1, 0]);  primals_11 = None\n    addmm_1 = torch.ops.aten.addmm.default(primals_12, view, permute_2);  primals_12 = None\n    view_4 = torch.ops.aten.view.default(addmm_1, [1, 10, 128]);  addmm_1 = None\n    view_5 = torch.ops.aten.view.default(view_4, [1, 10, 2, 64]);  view_4 = None\n    permute_3 = torch.ops.aten.permute.default(view_5, [0, 2, 1, 3]);  view_5 = None\n    permute_4 = torch.ops.aten.permute.default(primals_13, [1, 0]);  primals_13 = None\n    addmm_2 = torch.ops.aten.addmm.default(primals_14, view, permute_4);  primals_14 = None\n    view_7 = torch.ops.aten.view.default(addmm_2, [1, 10, 128]);  addmm_2 = None\n    view_8 = torch.ops.aten.view.default(view_7, [1, 10, 2, 64]);  view_7 = None\n    permute_5 = torch.ops.aten.permute.default(view_8, [0, 2, 1, 3]);  view_8 = None\n    _scaled_dot_product_flash_attention_for_cpu = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_1, permute_3, permute_5, attn_mask = full_default)\n    getitem_2 = _scaled_dot_product_flash_attention_for_cpu[0]\n    getitem_3 = _scaled_dot_product_flash_attention_for_cpu[1];  _scaled_dot_product_flash_attention_for_cpu = None\n    permute_6 = torch.ops.aten.permute.default(getitem_2, [0, 2, 1, 3])\n    view_9 = torch.ops.aten.view.default(permute_6, [1, 10, 128]);  permute_6 = None\n    view_10 = torch.ops.aten.view.default(view_9, [10, 128]);  view_9 = None\n    permute_7 = torch.ops.aten.permute.default(primals_15, [1, 0]);  primals_15 = None\n    addmm_3 = torch.ops.aten.addmm.default(primals_16, view_10, permute_7);  primals_16 = view_10 = None\n    view_11 = torch.ops.aten.view.default(addmm_3, [1, 10, 128]);  addmm_3 = None\n    add_4 = torch.ops.aten.add.Tensor(view_11, add_3);  view_11 = add_3 = None\n    var_mean_1 = torch.ops.aten.var_mean.correction(add_4, [2], correction = 0, keepdim = True)\n    getitem_4 = var_mean_1[0]\n    getitem_5 = var_mean_1[1];  var_mean_1 = None\n    add_5 = torch.ops.aten.add.Tensor(getitem_4, 1e-12);  getitem_4 = None\n    rsqrt_1 = torch.ops.aten.rsqrt.default(add_5);  add_5 = None\n    sub_2 = torch.ops.aten.sub.Tensor(add_4, getitem_5);  add_4 = getitem_5 = None\n    mul_2 = torch.ops.aten.mul.Tensor(sub_2, rsqrt_1);  sub_2 = None\n    mul_3 = torch.ops.aten.mul.Tensor(mul_2, primals_17)\n    add_6 = torch.ops.aten.add.Tensor(mul_3, primals_18);  mul_3 = primals_18 = None\n    view_12 = torch.ops.aten.view.default(add_6, [10, 128])\n    permute_8 = torch.ops.aten.permute.default(primals_19, [1, 0]);  primals_19 = None\n    addmm_4 = torch.ops.aten.addmm.default(primals_20, view_12, permute_8);  primals_20 = None\n    view_13 = torch.ops.aten.view.default(addmm_4, [1, 10, 512])\n    mul_4 = torch.ops.aten.mul.Tensor(view_13, 0.5)\n    mul_5 = torch.ops.aten.mul.Tensor(view_13, 0.7071067811865476);  view_13 = None\n    erf = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n    add_7 = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n    mul_6 = torch.ops.aten.mul.Tensor(mul_4, add_7);  mul_4 = add_7 = None\n    view_14 = torch.ops.aten.view.default(mul_6, [10, 512]);  mul_6 = None\n    permute_9 = torch.ops.aten.permute.default(primals_21, [1, 0]);  primals_21 = None\n    addmm_5 = torch.ops.aten.addmm.default(primals_22, view_14, permute_9);  primals_22 = None\n    view_15 = torch.ops.aten.view.default(addmm_5, [1, 10, 128]);  addmm_5 = None\n    add_8 = torch.ops.aten.add.Tensor(view_15, add_6);  view_15 = add_6 = None\n    var_mean_2 = torch.ops.aten.var_mean.correction(add_8, [2], correction = 0, keepdim = True)\n    getitem_6 = var_mean_2[0]\n    getitem_7 = var_mean_2[1];  var_mean_2 = None\n    add_9 = torch.ops.aten.add.Tensor(getitem_6, 1e-12);  getitem_6 = None\n    rsqrt_2 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None\n    sub_3 = torch.ops.aten.sub.Tensor(add_8, getitem_7);  add_8 = getitem_7 = None\n    mul_7 = torch.ops.aten.mul.Tensor(sub_3, rsqrt_2);  sub_3 = None\n    mul_8 = torch.ops.aten.mul.Tensor(mul_7, primals_23)\n    add_10 = torch.ops.aten.add.Tensor(mul_8, primals_24);  mul_8 = primals_24 = None\n    view_16 = torch.ops.aten.view.default(add_10, [10, 128])\n    permute_10 = torch.ops.aten.permute.default(primals_25, [1, 0]);  primals_25 = None\n    addmm_6 = torch.ops.aten.addmm.default(primals_26, view_16, permute_10);  primals_26 = None\n    view_17 = torch.ops.aten.view.default(addmm_6, [1, 10, 128]);  addmm_6 = None\n    view_18 = torch.ops.aten.view.default(view_17, [1, 10, 2, 64]);  view_17 = None\n    permute_11 = torch.ops.aten.permute.default(view_18, [0, 2, 1, 3]);  view_18 = None\n    permute_12 = torch.ops.aten.permute.default(primals_27, [1, 0]);  primals_27 = None\n    addmm_7 = torch.ops.aten.addmm.default(primals_28, view_16, permute_12);  primals_28 = None\n    view_20 = torch.ops.aten.view.default(addmm_7, [1, 10, 128]);  addmm_7 = None\n    view_21 = torch.ops.aten.view.default(view_20, [1, 10, 2, 64]);  view_20 = None\n    permute_13 = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n    permute_14 = torch.ops.aten.permute.default(primals_29, [1, 0]);  primals_29 = None\n    addmm_8 = torch.ops.aten.addmm.default(primals_30, view_16, permute_14);  primals_30 = None\n    view_23 = torch.ops.aten.view.default(addmm_8, [1, 10, 128]);  addmm_8 = None\n    view_24 = torch.ops.aten.view.default(view_23, [1, 10, 2, 64]);  view_23 = None\n    permute_15 = torch.ops.aten.permute.default(view_24, [0, 2, 1, 3]);  view_24 = None\n    _scaled_dot_product_flash_attention_for_cpu_1 = torch.ops.aten._scaled_dot_product_flash_attention_for_cpu.default(permute_11, permute_13, permute_15, attn_mask = full_default)\n    getitem_8 = _scaled_dot_product_flash_attention_for_cpu_1[0]\n    getitem_9 = _scaled_dot_product_flash_attention_for_cpu_1[1];  _scaled_dot_product_flash_attention_for_cpu_1 = None\n    permute_16 = torch.ops.aten.permute.default(getitem_8, [0, 2, 1, 3])\n    view_25 = torch.ops.aten.view.default(permute_16, [1, 10, 128]);  permute_16 = None\n    view_26 = torch.ops.aten.view.default(view_25, [10, 128]);  view_25 = None\n    permute_17 = torch.ops.aten.permute.default(primals_31, [1, 0]);  primals_31 = None\n    addmm_9 = torch.ops.aten.addmm.default(primals_32, view_26, permute_17);  primals_32 = view_26 = None\n    view_27 = torch.ops.aten.view.default(addmm_9, [1, 10, 128]);  addmm_9 = None\n    add_11 = torch.ops.aten.add.Tensor(view_27, add_10);  view_27 = add_10 = None\n    var_mean_3 = torch.ops.aten.var_mean.correction(add_11, [2], correction = 0, keepdim = True)\n    getitem_10 = var_mean_3[0]\n    getitem_11 = var_mean_3[1];  var_mean_3 = None\n    add_12 = torch.ops.aten.add.Tensor(getitem_10, 1e-12);  getitem_10 = None\n    rsqrt_3 = torch.ops.aten.rsqrt.default(add_12);  add_12 = None\n    sub_4 = torch.ops.aten.sub.Tensor(add_11, getitem_11);  add_11 = getitem_11 = None\n    mul_9 = torch.ops.aten.mul.Tensor(sub_4, rsqrt_3);  sub_4 = None\n    mul_10 = torch.ops.aten.mul.Tensor(mul_9, primals_33)\n    add_13 = torch.ops.aten.add.Tensor(mul_10, primals_34);  mul_10 = primals_34 = None\n    view_28 = torch.ops.aten.view.default(add_13, [10, 128])\n    permute_18 = torch.ops.aten.permute.default(primals_35, [1, 0]);  primals_35 = None\n    addmm_10 = torch.ops.aten.addmm.default(primals_36, view_28, permute_18);  primals_36 = None\n    view_29 = torch.ops.aten.view.default(addmm_10, [1, 10, 512])\n    mul_11 = torch.ops.aten.mul.Tensor(view_29, 0.5)\n    mul_12 = torch.ops.aten.mul.Tensor(view_29, 0.7071067811865476);  view_29 = None\n    erf_1 = torch.ops.aten.erf.default(mul_12);  mul_12 = None\n    add_14 = torch.ops.aten.add.Tensor(erf_1, 1);  erf_1 = None\n    mul_13 = torch.ops.aten.mul.Tensor(mul_11, add_14);  mul_11 = add_14 = None\n    view_30 = torch.ops.aten.view.default(mul_13, [10, 512]);  mul_13 = None\n    permute_19 = torch.ops.aten.permute.default(primals_37, [1, 0]);  primals_37 = None\n    addmm_11 = torch.ops.aten.addmm.default(primals_38, view_30, permute_19);  primals_38 = None\n    view_31 = torch.ops.aten.view.default(addmm_11, [1, 10, 128]);  addmm_11 = None\n    add_15 = torch.ops.aten.add.Tensor(view_31, add_13);  view_31 = add_13 = None\n    var_mean_4 = torch.ops.aten.var_mean.correction(add_15, [2], correction = 0, keepdim = True)\n    getitem_12 = var_mean_4[0]\n    getitem_13 = var_mean_4[1];  var_mean_4 = None\n    add_16 = torch.ops.aten.add.Tensor(getitem_12, 1e-12);  getitem_12 = None\n    rsqrt_4 = torch.ops.aten.rsqrt.default(add_16);  add_16 = None\n    sub_5 = torch.ops.aten.sub.Tensor(add_15, getitem_13);  add_15 = getitem_13 = None\n    mul_14 = torch.ops.aten.mul.Tensor(sub_5, rsqrt_4);  sub_5 = None\n    mul_15 = torch.ops.aten.mul.Tensor(mul_14, primals_39)\n    add_17 = torch.ops.aten.add.Tensor(mul_15, primals_40);  mul_15 = primals_40 = None\n    select = torch.ops.aten.select.int(add_17, 1, 0)\n    permute_20 = torch.ops.aten.permute.default(primals_41, [1, 0]);  primals_41 = None\n    addmm_12 = torch.ops.aten.addmm.default(primals_42, select, permute_20);  primals_42 = None\n    tanh = torch.ops.aten.tanh.default(addmm_12);  addmm_12 = None\n    permute_21 = torch.ops.aten.permute.default(permute_20, [1, 0]);  permute_20 = None\n    permute_22 = torch.ops.aten.permute.default(select, [1, 0]);  select = None\n    div = torch.ops.aten.div.Tensor(rsqrt_4, 128);  rsqrt_4 = None\n    permute_24 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None\n    permute_25 = torch.ops.aten.permute.default(view_30, [1, 0]);  view_30 = None\n    permute_27 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None\n    permute_28 = torch.ops.aten.permute.default(view_28, [1, 0]);  view_28 = None\n    div_1 = torch.ops.aten.div.Tensor(rsqrt_3, 128);  rsqrt_3 = None\n    permute_30 = torch.ops.aten.permute.default(permute_17, [1, 0]);  permute_17 = None\n    permute_35 = torch.ops.aten.permute.default(permute_14, [1, 0]);  permute_14 = None\n    permute_36 = torch.ops.aten.permute.default(view_16, [1, 0]);  view_16 = None\n    permute_39 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None\n    permute_43 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None\n    div_2 = torch.ops.aten.div.Tensor(rsqrt_2, 128);  rsqrt_2 = None\n    permute_46 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None\n    permute_47 = torch.ops.aten.permute.default(view_14, [1, 0]);  view_14 = None\n    permute_49 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None\n    permute_50 = torch.ops.aten.permute.default(view_12, [1, 0]);  view_12 = None\n    div_3 = torch.ops.aten.div.Tensor(rsqrt_1, 128);  rsqrt_1 = None\n    permute_52 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None\n    permute_57 = torch.ops.aten.permute.default(permute_4, [1, 0]);  permute_4 = None\n    permute_58 = torch.ops.aten.permute.default(view, [1, 0]);  view = None\n    permute_61 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None\n    permute_65 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n    div_4 = torch.ops.aten.div.Tensor(rsqrt, 128);  rsqrt = None\n    return (add_17, tanh, primals_1, primals_7, primals_17, primals_23, primals_33, primals_39, expand, slice_4, mul, full_default, permute_1, permute_3, permute_5, getitem_2, getitem_3, mul_2, addmm_4, mul_7, permute_11, permute_13, permute_15, getitem_8, getitem_9, mul_9, addmm_10, mul_14, tanh, permute_21, permute_22, div, permute_24, permute_25, permute_27, permute_28, div_1, permute_30, permute_35, permute_36, permute_39, permute_43, div_2, permute_46, permute_47, permute_49, permute_50, div_3, permute_52, permute_57, permute_58, permute_61, permute_65, div_4)\n    \n# To see more debug info, please use `graph_module.print_readable()`", "[aonqu3i753flyuomemr75xtzvegaw2q6ake46zjzro4t2erejyl] example_inputs[0]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 10]), stride=(10, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[1]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[lpazqx5r4lyinoum2wvlmcbsoc3tmch37lwix3jls7bgkhrghko] example_inputs[2]: TensorMetadata(dtype=torch.int64, shape=torch.Size([1, 512]), stride=(512, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[ntcrldqdseqpo5aqow53pvj6lg5pbwx43rpmytw2xxhlef2yvrg] example_inputs[3]: TensorMetadata(dtype=torch.float32, shape=torch.Size([30522, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[xjebjsdwh7t75xbr44j2mtdtzs7jutvrxfkcy62w5z4busb5jih] example_inputs[4]: TensorMetadata(dtype=torch.float32, shape=torch.Size([2, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[rpzphxv7udek74lts2oqp6f7t2526gjgqdaxdagbh6g4pdkmgxm] example_inputs[5]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(128, 1), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[6]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[7]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[8]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[9]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[10]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[11]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[12]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[13]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[14]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[15]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[16]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[17]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[18]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[19]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[20]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[21]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[22]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[23]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[24]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[25]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[26]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[27]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[28]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[29]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[30]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[31]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[32]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[33]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[eiplombieub3mcksymqnczvevh6qlbioweoddtb5krj6aslsbn4] example_inputs[34]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512, 128]), stride=(1, 512), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[n5i7on7th3ob5ofk4pakwsazdtmpqnruqi2zudkjmg3omvyniki] example_inputs[35]: TensorMetadata(dtype=torch.float32, shape=torch.Size([512]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[54bfynaitko7evztyzezhxp7smwjlliqwszvllihitjxcej4ivz] example_inputs[36]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 512]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[37]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[38]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[39]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[c2kd2w6p62pg3rikvqog3ne6zznajngckvxwzwmn2zb5i4zx3gq] example_inputs[40]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128, 128]), stride=(1, 128), device=device(type='cpu'), layout=torch.strided, memory_format=None, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[52sxdjfikb24cemlsuyeoduuo4uu3oppje6asg2ermkgehjupji] example_inputs[41]: TensorMetadata(dtype=torch.float32, shape=torch.Size([128]), stride=(1,), device=device(type='cpu'), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[aot_mode]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False", "[xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None", "[hf6szflddgll5xonlclhiouvpgf5qbutyjirws5ihm3h6g4nzco] fx_kwargs[static_input_idxs]: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]", "[zcpzudcpirohulo52z7lfhjrp3bgeq2xuqfgfyj3au63j6mberl] fx_kwargs[user_visible_outputs]: {'add_17': None, 'tanh': None}", "[du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)", "[qiptf2633zubseuei4bkisoq3not35l6lud6p23p4qmcsxiw2uq] cuda_matmul_settings: (False, True, True)", "[euia4x65hsc6y5ske7h7hmltbkudc55se2v2ibwesmk5u7lvt5b] torch_version: <bytes>", "[ou2myrupfm7jqj7zhckhwr35g4s7cslkzawm6jrbi4dt72allir] system_info[hash]: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[abi_compatible]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[allow_stack_allocation]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_dump_consts_bin]: False", "[ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: ", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: ", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT", "[jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_fallback_to_aten]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[autotune_local_cache]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[autotune_remote_cache]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True", "[b4ha3ravs3qv237q65hpfqegbnoww7tf2ahcbu2i7xo6te5spqs] inductor_config[c_shim_version]: 2", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernel_foreach_dynamic_shapes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False", "[c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_floating_point_contract_flag]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16", "[g7rrnbg5yonzux3cfj5ovre5lob3ayda7qcfpxjvtwmiz4uicii] inductor_config[cpp.min_chunk_size]: 4096", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None", "[sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False", "[bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None", "[tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None", "[lwkz5chtpji756gurqw4foijfi7zfgljtnn5nmnvdi2skpt4mgh] inductor_config[cuda.cutlass_op_denylist_regex]: pingpong", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.generate_test_runner]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None", "[caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton", "[vzzema5ityqj2wepdmkulue7q5pcevdr5h27oxxutf35d4tjume] inductor_config[custom_op_default_layout_constraint]: flexible_layout", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[developer_warnings]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_auto_functionalized_v2]: False", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: ", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False", "[lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_disable_caches]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[fx_graph_cache]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[fx_graph_remote_cache]: None", "[zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False", "[ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False", "[wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False", "[k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019", "[svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True", "[5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25", "[yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_nightly_or_source]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[joint_custom_pre_pass]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True", "[j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10", "[4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[loop_ordering_after_fusion]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False", "[uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False", "[2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP", "[jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False", "[bh33ranllcgilhgmgr3qvygzxjm6isq5iexnfm3zx6fnr2zwlp2] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 1.0", "[iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0", "[pwoh5aypf4fxbntdvwt67rppxorqos6xr3w7qzeun6kblbfg2ga] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 2.0", "[aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1", "[jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False", "[x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates", "[v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128", "[dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_post_pass]: None", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[post_grad_custom_pre_pass]: None", "[4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None", "[gtkv35cxmtt6tr556buxi277a67g25mjojnv32dc4bjvc7bwscw] inductor_config[pre_grad_fusion_options]: {'batch_linear': {}, 'batch_linear_lhs': {}, 'batch_layernorm': {}, 'batch_tanh': {}, 'batch_relu': {}, 'batch_sigmoid': {}}", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None", "[v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: ", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8", "[rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30", "[lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False", "[ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True", "[h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None", "[oartxnko2l7d67tzwwm2otcumaut3n4wwcfgz3o377hmcveu5ft] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx940', 'gfx941', 'gfx942']", "[klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_at_compile_time]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True", "[tuax46wac7rfv2trf5gcps6vleo3cq44lbnrdxtprvo3ljjaddj] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 50", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False", "[ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False", "[yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False", "[tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None", "[pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[triton.max_tiles]: 2", "[fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256", "[vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True", "[ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_kernel_names]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False", "[wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192", "[yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_minimal_arrayref_interface]: False", "[cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False", "[esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False", "[hofygoznqmna6yvgsc6itdddi4hxftssgegh6wquixg2yng3a3z] inductor_config[worker_start_method]: subprocess"], "time_saved_ns": 13851574116, "cache_state": "hit"}
V0331 22:38:56.367000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "6c4585dcda5213424d5fbb2c0241ccc7"}
	{
	"name": "inductor_compile",
	"ts": 1743460736367526.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.368000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "a905fd5d4c0b53a3819eb0c8bc3daf66"}
	{
	"name": "compile_fx_inner",
	"ts": 1743460736368133.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.369000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "cafcf4e5c50af85359f00601d070e613"}
	{
	"name": "compile_fx.<locals>.fw_compiler_base",
	"ts": 1743460736369131.2,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.372000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "fdc5f8285fb595a7a821c77a605739ac"}
	{
	"name": "create_aot_dispatcher_function",
	"ts": 1743460736372634.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.373000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "f78f7c081ce58aad5b2eaace7fdf05e4"}
	{
	"name": "backend_compile",
	"ts": 1743460736373558.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.374000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "9d624825c9153a9e71e2fa65e45f055e"}
	{
	"name": "OutputGraph.call_user_compiler",
	"ts": 1743460736374156.0,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.577000 25844 torch/_dynamo/guards.py:2277] {"dynamo_cpp_guards_str": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "8951fa8744ece376fa1c4d7459c70639"}
	
	TREE_GUARD_MANAGER:
	+- RootGuardManager
	| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards
	| +- GLOBAL_STATE: ___check_global_state()
	| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
	| +- GuardManager: source=L['kwargs'], accessed_by=DictGetItemGuardAccessor(kwargs)
	| | +- DICT_LENGTH: len(L['kwargs']) == 1                                       
	| | +- GuardManager: source=L['kwargs']['input_ids'], accessed_by=DictGetItemGuardAccessor(input_ids)
	| +- GuardManager: source=L['modified_input_ids'], accessed_by=DictGetItemGuardAccessor(modified_input_ids)
	| | +- TENSOR_MATCH: check_tensor(L['modified_input_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 10], stride=[10, 1])
	| | +- NO_HASATTR: hasattr(L['modified_input_ids'], '_dynamo_dynamic_indices') == False
	| | +- NO_TENSOR_ALIASING: check_no_aliasing(L['modified_input_ids'], G['model']._orig_mod._modules['embeddings']._buffers['position_ids'], G['model']._orig_mod._modules['embeddings']._buffers['token_type_ids'], G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['bias'], G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['weight'], G['model']._orig_mod._modules['embeddings']._modules['word_embeddings']._parameters['weight'], G['model']._orig_mod._modules['embeddings']._modules['position_embeddings']._parameters['weight'], G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'])
	| +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor
	| | +- GuardManager: source=G['model'], accessed_by=DictGetItemGuardAccessor(model)
	| | | +- TYPE_MATCH: ___check_type_id(G['model'], 100279822702720)               
	| | | +- GuardManager: source=G['model']._orig_mod, accessed_by=GetAttrGuardAccessor(_orig_mod)
	| | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod, 100279863582720)     
	| | | | +- GuardManager: source=G['model']._orig_mod.__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | +- GuardManager: source=G['model']._orig_mod.original_forward, accessed_by=DictGetItemGuardAccessor(original_forward)
	| | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[1], accessed_by=GetItemGuardAccessor(1)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[1], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[2], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[3], accessed_by=GetItemGuardAccessor(3)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[3], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[4], accessed_by=GetItemGuardAccessor(4)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[4], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[5], accessed_by=GetItemGuardAccessor(5)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[5], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[8], accessed_by=GetItemGuardAccessor(8)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[8], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[10], accessed_by=GetItemGuardAccessor(10)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[10], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[11], accessed_by=GetItemGuardAccessor(11)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[11], 100279619366624)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod.original_forward.__defaults__[12], accessed_by=GetItemGuardAccessor(12)
	| | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.original_forward.__defaults__[12], 100279619366624)
	| | | | | +- GuardManager: source=G['model']._orig_mod.config, accessed_by=DictGetItemGuardAccessor(config)
	| | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod.config, 100279858374320)
	| | | | | | +- GuardManager: source=G['model']._orig_mod.config.is_decoder, accessed_by=GetAttrGuardAccessor(is_decoder)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.config.is_decoder, 100279619273664)
	| | | | | | +- GuardManager: source=G['model']._orig_mod.config.use_return_dict, accessed_by=GetAttrGuardAccessor(use_return_dict)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.config.use_return_dict, 100279619273632)
	| | | | | | +- GuardManager: source=G['model']._orig_mod.config.num_hidden_layers, accessed_by=GetAttrGuardAccessor(num_hidden_layers)
	| | | | | | | +- EQUALS_MATCH: G['model']._orig_mod.config.num_hidden_layers == 2          
	| | | | | | +- GuardManager: source=G['model']._orig_mod.config.output_attentions, accessed_by=GetAttrGuardAccessor(output_attentions)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.config.output_attentions, 100279619273664)
	| | | | | | +- GuardManager: source=G['model']._orig_mod.config.output_hidden_states, accessed_by=GetAttrGuardAccessor(output_hidden_states)
	| | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod.config.output_hidden_states, 100279619273664)
	| | | | | +- GuardManager: source=G['model']._orig_mod._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules) == 3                     
	| | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings'], accessed_by=DictGetItemGuardAccessor(embeddings)
	| | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings'], 100279862802720)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['embeddings'].__dict__)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._buffers, accessed_by=DictGetItemGuardAccessor(_buffers)
	| | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['embeddings']._buffers) == 2
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._buffers['position_ids'], accessed_by=DictGetItemGuardAccessor(position_ids)
	| | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._buffers['position_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._buffers['token_type_ids'], accessed_by=DictGetItemGuardAccessor(token_type_ids)
	| | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._buffers['token_type_ids'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.int64, device=None, requires_grad=False, size=[1, 512], stride=[512, 1])
	| | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['embeddings']._modules) == 5
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'], accessed_by=DictGetItemGuardAccessor(word_embeddings)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'], 100279793066112)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].__dict__)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].sparse, 100279619273664)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].max_norm, 100279619366624)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].norm_type == 2.0
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['embeddings']._modules['word_embeddings']._parameters) == 1
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._modules['word_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[30522, 128], stride=[128, 1])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].padding_idx == 0
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['word_embeddings'].scale_grad_by_freq, 100279619273664)
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'], accessed_by=DictGetItemGuardAccessor(position_embeddings)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'], 100279793066112)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].__dict__)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].sparse, 100279619273664)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].max_norm, 100279619366624)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].norm_type == 2.0
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings']._parameters) == 1
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[128, 1])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].padding_idx, 100279619366624)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['position_embeddings'].scale_grad_by_freq, 100279619273664)
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'], accessed_by=DictGetItemGuardAccessor(token_type_embeddings)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'], 100279793066112)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].__dict__)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].sparse, accessed_by=DictGetItemGuardAccessor(sparse)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].sparse, 100279619273664)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].max_norm, accessed_by=DictGetItemGuardAccessor(max_norm)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].max_norm, 100279619366624)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].norm_type, accessed_by=DictGetItemGuardAccessor(norm_type)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].norm_type == 2.0
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings']._parameters) == 1
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[2, 128], stride=[128, 1])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].padding_idx, accessed_by=DictGetItemGuardAccessor(padding_idx)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].padding_idx, 100279619366624)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, accessed_by=DictGetItemGuardAccessor(scale_grad_by_freq)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['token_type_embeddings'].scale_grad_by_freq, 100279619273664)
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'], 100279792544784)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['embeddings']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].normalized_shape, 100279619375168)
	| | | | | | | | | | | | +- LENGTH_CHECK: len(G['model']._orig_mod._modules['embeddings']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['embeddings']._modules['dropout'], 100279792133872)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['embeddings']._modules['dropout'].__dict__)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings']._modules['dropout'].p == 0.1
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['dropout'].inplace, 100279619273664)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['embeddings']._modules['dropout'].training, 100279619273664)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['embeddings']._parameters 
	| | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['embeddings']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['embeddings']._backward_hooks
	| | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['embeddings']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['embeddings']._backward_pre_hooks
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['embeddings'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['embeddings'].position_embedding_type == 'absolute'
	| | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder'], accessed_by=DictGetItemGuardAccessor(encoder)
	| | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder'], 100279863565168)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder'].__dict__)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules) == 1 
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer'], accessed_by=DictGetItemGuardAccessor(layer)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer'], 100279791156528)
	| | | | | | | | | | +- LENGTH_CHECK: len(G['model']._orig_mod._modules['encoder']._modules['layer']) == 2
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DictGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | +- KeyValueManager pair at index=0
	| | | | | | | | | | | | | +- KeyManager: GuardManager: source=list(G['model']._orig_mod._modules['encoder']._modules['layer']._modules.keys())[0]
	| | | | | | | | | | | | | | +- EQUALS_MATCH: list(G['model']._orig_mod._modules['encoder']._modules['layer']._modules.keys())[0] == '0'
	| | | | | | | | | | | | | +- ValueManager: GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']
	| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'], 100279863330864)
	| | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'].__dict__)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules) == 3
	| | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'], 100279863299168)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'], 100279863246896)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].training, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].is_decoder, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].require_contiguous_qkv, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'], 100279863248672)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'], 100279792544784)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 100279619375168)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'], 100279792133872)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].inplace, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._modules['dropout'].training, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['attention'].__class__.forward.__defaults__[2], 100279619366624)
	| | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'], 100279863300944)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'], 100279862894032)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn'].act, 136343330457376)
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output'], 100279863329088)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'], 100279792544784)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape, 100279619375168)
	| | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'], 100279792133872)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].inplace, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._modules['dropout'].training, 100279619273664)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'].is_decoder, 100279619273664)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._parameters
	| | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._backward_hooks
	| | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['0'].chunk_size_feed_forward == 0
	| | | | | | | | | | | | +- KeyValueManager pair at index=1
	| | | | | | | | | | | | | +- KeyManager: GuardManager: source=list(G['model']._orig_mod._modules['encoder']._modules['layer']._modules.keys())[1]
	| | | | | | | | | | | | | | +- EQUALS_MATCH: list(G['model']._orig_mod._modules['encoder']._modules['layer']._modules.keys())[1] == '1'
	| | | | | | | | | | | | | +- ValueManager: GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']
	| | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'], 100279863330864)
	| | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'].__dict__)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules) == 3
	| | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'], accessed_by=DictGetItemGuardAccessor(attention)
	| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'], 100279863299168)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__dict__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules) == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], accessed_by=DictGetItemGuardAccessor(self)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'], 100279863246896)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules) == 4
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], accessed_by=DictGetItemGuardAccessor(query)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['query']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], accessed_by=DictGetItemGuardAccessor(key)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['key']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], accessed_by=DictGetItemGuardAccessor(value)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['value']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].training, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].is_decoder, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._parameters
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size, accessed_by=DictGetItemGuardAccessor(all_head_size)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].all_head_size == 128
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_hooks
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size, accessed_by=DictGetItemGuardAccessor(attention_head_size)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].attention_head_size == 64
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads, accessed_by=DictGetItemGuardAccessor(num_attention_heads)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].num_attention_heads == 2
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, accessed_by=DictGetItemGuardAccessor(require_contiguous_qkv)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].require_contiguous_qkv, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['self'].position_embedding_type == 'absolute'
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'], 100279863248672)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'], 100279792544784)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape, 100279619375168)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'], 100279792133872)
	| | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].inplace, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._modules['dropout'].training, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._parameters
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_hooks
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__, accessed_by=GetAttrGuardAccessor(__class__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=GetAttrGuardAccessor(forward)
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward, accessed_by=FuncDefaultsGuardAccessor
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], accessed_by=GetItemGuardAccessor(2)
	| | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['attention'].__class__.forward.__defaults__[2], 100279619366624)
	| | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], accessed_by=DictGetItemGuardAccessor(intermediate)
	| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'], 100279863300944)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate'].__dict__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules) == 2
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512, 128], stride=[1, 512])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[512], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], accessed_by=DictGetItemGuardAccessor(intermediate_act_fn)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'], 100279862894032)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, accessed_by=DictGetItemGuardAccessor(act)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn'].act, 136343330457376)
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_hooks
	| | | | | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._modules['intermediate_act_fn']._backward_pre_hooks
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._parameters
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_hooks
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['intermediate']._backward_pre_hooks
	| | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output'], accessed_by=DictGetItemGuardAccessor(output)
	| | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output'], 100279863329088)
	| | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output'].__dict__)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules) == 3
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'], 100279791765424)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 512], stride=[1, 128])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], accessed_by=DictGetItemGuardAccessor(LayerNorm)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'], 100279792544784)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps, accessed_by=DictGetItemGuardAccessor(eps)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].eps == 1e-12
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters) == 2
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, accessed_by=DictGetItemGuardAccessor(normalized_shape)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape == (128,)
	| | | | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape, 100279619375168)
	| | | | | | | | | | | | | | | | | | | | | | +- LENGTH_CHECK: len(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['LayerNorm'].normalized_shape) == 1
	| | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], accessed_by=DictGetItemGuardAccessor(dropout)
	| | | | | | | | | | | | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'], 100279792133872)
	| | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].__dict__)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p, accessed_by=DictGetItemGuardAccessor(p)
	| | | | | | | | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].p == 0.1
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, accessed_by=DictGetItemGuardAccessor(inplace)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].inplace, 100279619273664)
	| | | | | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, accessed_by=DictGetItemGuardAccessor(training)
	| | | | | | | | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._modules['dropout'].training, 100279619273664)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._parameters
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_hooks
	| | | | | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._modules['output']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'].is_decoder, accessed_by=DictGetItemGuardAccessor(is_decoder)
	| | | | | | | | | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'].is_decoder, 100279619273664)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._parameters
	| | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._backward_hooks
	| | | | | | | | | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1']._backward_pre_hooks
	| | | | | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward, accessed_by=DictGetItemGuardAccessor(chunk_size_feed_forward)
	| | | | | | | | | | | | | | | | +- EQUALS_MATCH: G['model']._orig_mod._modules['encoder']._modules['layer']._modules['1'].chunk_size_feed_forward == 0
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._parameters    
	| | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._backward_hooks
	| | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['encoder']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['encoder']._backward_pre_hooks
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['encoder'].gradient_checkpointing, accessed_by=DictGetItemGuardAccessor(gradient_checkpointing)
	| | | | | | | | | +- ID_MATCH: ___check_obj_id(G['model']._orig_mod._modules['encoder'].gradient_checkpointing, 100279619273664)
	| | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler'], accessed_by=DictGetItemGuardAccessor(pooler)
	| | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['pooler'], 100279863566944)
	| | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['pooler'].__dict__)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules, accessed_by=DictGetItemGuardAccessor(_modules)
	| | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['pooler']._modules) == 2  
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['dense'], accessed_by=DictGetItemGuardAccessor(dense)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['pooler']._modules['dense'], 100279791765424)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['dense'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['pooler']._modules['dense'].__dict__)
	| | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['dense']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | | | | +- DICT_LENGTH: len(G['model']._orig_mod._modules['pooler']._modules['dense']._parameters) == 2
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['weight'], accessed_by=DictGetItemGuardAccessor(weight)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['weight'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128, 128], stride=[1, 128])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['bias'], accessed_by=DictGetItemGuardAccessor(bias)
	| | | | | | | | | | | | | +- TENSOR_MATCH: check_tensor(G['model']._orig_mod._modules['pooler']._modules['dense']._parameters['bias'], Parameter, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=True, size=[128], stride=[1])
	| | | | | | | | | | | | | +- NO_TENSOR_ALIASING
	| | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['activation'], accessed_by=DictGetItemGuardAccessor(activation)
	| | | | | | | | | | +- TYPE_MATCH: ___check_type_id(G['model']._orig_mod._modules['pooler']._modules['activation'], 100279791367600)
	| | | | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._modules['activation'].__dict__, accessed_by=GetGenericDictGuardAccessor
	| | | | | | | | | | | +- DICT_CONTAINS: not ___dict_contains('forward', G['model']._orig_mod._modules['pooler']._modules['activation'].__dict__)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['pooler']._parameters     
	| | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['pooler']._forward_hooks, accessed_by=DictGetItemGuardAccessor(_forward_hooks)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._backward_hooks, accessed_by=DictGetItemGuardAccessor(_backward_hooks)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['pooler']._backward_hooks 
	| | | | | | | | +- DictSubclassGuardManager: source=G['model']._orig_mod._modules['pooler']._forward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_forward_pre_hooks)
	| | | | | | | | +- GuardManager: source=G['model']._orig_mod._modules['pooler']._backward_pre_hooks, accessed_by=DictGetItemGuardAccessor(_backward_pre_hooks)
	| | | | | | | | | +- DICT_LENGTH: not G['model']._orig_mod._modules['pooler']._backward_pre_hooks
	| | | | | +- GuardManager: source=G['model']._orig_mod._parameters, accessed_by=DictGetItemGuardAccessor(_parameters)
	| | | | | | +- DICT_LENGTH: not G['model']._orig_mod._parameters                        
	| | | | | +- GuardManager: source=G['model']._orig_mod.attn_implementation, accessed_by=DictGetItemGuardAccessor(attn_implementation)
	| | | | | | +- EQUALS_MATCH: G['model']._orig_mod.attn_implementation == 'sdpa'          
	| | | | | +- GuardManager: source=G['model']._orig_mod.position_embedding_type, accessed_by=DictGetItemGuardAccessor(position_embedding_type)
	| | | | | | +- EQUALS_MATCH: G['model']._orig_mod.position_embedding_type == 'absolute'  
	| | +- GuardManager: source=G['__import_torch'], accessed_by=DictGetItemGuardAccessor(__import_torch)
	| | | +- GuardManager: source=G['__import_torch'].fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx, 136343307909568)    
	| | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | | +- GuardManager: source=G['__import_torch'].fx.Proxy, accessed_by=GetAttrGuardAccessor(Proxy)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].fx.Proxy, 100279798193376)
	| | | +- GuardManager: source=G['__import_torch'].compiler, accessed_by=GetAttrGuardAccessor(compiler)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler, 136343292731424)
	| | | | +- GuardManager: source=G['__import_torch'].compiler.is_compiling, accessed_by=GetAttrGuardAccessor(is_compiling)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch'].compiler.is_compiling, 136343291080960)
	| | +- GuardManager: source=G['__builtins_dict___11'], accessed_by=DictGetItemGuardAccessor(__builtins_dict___11)
	| | | +- GuardManager: source=G['__builtins_dict___11']['int'], accessed_by=DictGetItemGuardAccessor(int)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['int'], 100279619347168)
	| | | +- GuardManager: source=G['__builtins_dict___11']['len'], accessed_by=DictGetItemGuardAccessor(len)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['len'], 136343830585936)
	| | | +- GuardManager: source=G['__builtins_dict___11']['str'], accessed_by=DictGetItemGuardAccessor(str)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['str'], 100279619392448)
	| | | +- GuardManager: source=G['__builtins_dict___11']['dict'], accessed_by=DictGetItemGuardAccessor(dict)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['dict'], 100279619352800)
	| | | +- GuardManager: source=G['__builtins_dict___11']['iter'], accessed_by=DictGetItemGuardAccessor(iter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['iter'], 136343830585776)
	| | | +- GuardManager: source=G['__builtins_dict___11']['tuple'], accessed_by=DictGetItemGuardAccessor(tuple)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['tuple'], 100279619375168)
	| | | +- GuardManager: source=G['__builtins_dict___11']['hasattr'], accessed_by=DictGetItemGuardAccessor(hasattr)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['hasattr'], 136343830585216)
	| | | +- GuardManager: source=G['__builtins_dict___11']['enumerate'], accessed_by=DictGetItemGuardAccessor(enumerate)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['enumerate'], 100279619295648)
	| | | +- GuardManager: source=G['__builtins_dict___11']['isinstance'], accessed_by=DictGetItemGuardAccessor(isinstance)
	| | | | +- ID_MATCH: ___check_obj_id(G['__builtins_dict___11']['isinstance'], 136343830585616)
	| | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_pytorch_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'], 136343225815088)
	| | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect, accessed_by=GetAttrGuardAccessor(inspect)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect, 136343829520656)
	| | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature, accessed_by=GetAttrGuardAccessor(signature)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_pytorch_utils'].inspect.signature.__code__, 136343827357488)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'], 136342992792016)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch, 136343828681312)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].torch
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn, accessed_by=GetAttrGuardAccessor(nn)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.nn, 136343327840256)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.nn.functional, accessed_by=GetAttrGuardAccessor(functional)
	| | | | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit, accessed_by=GetAttrGuardAccessor(jit)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit, 136343315284672)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, accessed_by=GetAttrGuardAccessor(is_tracing)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.jit.is_tracing, 136343313933440)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.bool, accessed_by=GetAttrGuardAccessor(bool)
	| | | | | +- EQUALS_MATCH: G['__import_transformers_dot_modeling_utils'].torch.bool == torch.bool
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.ones, accessed_by=GetAttrGuardAccessor(ones)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.ones, 136343822736720)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.tanh, accessed_by=GetAttrGuardAccessor(tanh)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.tanh, 136343822799136)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.finfo, accessed_by=GetAttrGuardAccessor(finfo)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].torch.finfo, 136343819845920)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].torch.fx, accessed_by=GetAttrGuardAccessor(fx)
	| | | | | +- OBJECT_ALIASING: G['__import_torch'].fx is G['__import_transformers_dot_modeling_utils'].torch.fx
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy, accessed_by=GetAttrGuardAccessor(is_torch_fx_proxy)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torch_fx_proxy.__code__, 136343245890032)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_utils'].is_torchdynamo_compiling.__code__, 136343246382112)
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_generic'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_generic)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_generic'], 136343242712272)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_linear)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_linear'], 136343319886352)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_linear'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_module)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_module'], 136343327845856)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_forward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, accessed_by=GetAttrGuardAccessor(_global_backward_pre_hooks)
	| | | | +- DICT_LENGTH: not G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_sparse)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'], 136343317412608)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F, 136343319886512)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_linear'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_transformers_dot_modeling_utils'].torch.nn.functional
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, accessed_by=GetAttrGuardAccessor(linear)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.linear, 136343330458496)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, accessed_by=GetAttrGuardAccessor(dropout)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.dropout, 136343317995552)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, accessed_by=GetAttrGuardAccessor(embedding)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.embedding, 136343318000352)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, accessed_by=GetAttrGuardAccessor(layer_norm)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.layer_norm, 136343318001312)
	| | | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, accessed_by=GetAttrGuardAccessor(scaled_dot_product_attention)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_sparse'].F.scaled_dot_product_attention, 136343330461056)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_dropout)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_dropout'], 136343316749248)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_dropout'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_dropout'].F
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_container'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_container)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_container'], 136343318572192)
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_activation)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_activation'], 136343318511056)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_activation'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_torch_dot_nn_dot_modules_dot_activation'].torch
	| | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_utils_dot_import_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'], 136343246302528)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_available, accessed_by=GetAttrGuardAccessor(_torch_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_available, 100279619273632)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available, accessed_by=GetAttrGuardAccessor(is_torch_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_available.__code__, 136343246449888)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, accessed_by=GetAttrGuardAccessor(_torch_fx_available)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils']._torch_fx_available, 100279619273632)
	| | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available, accessed_by=GetAttrGuardAccessor(is_torch_fx_available)
	| | | | +- GuardManager: source=G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_utils_dot_import_utils'].is_torch_fx_available.__code__, 136343246452800)
	| | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_modeling_attn_mask_utils)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'], 136342992787136)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, accessed_by=GetAttrGuardAccessor(AttentionMaskConverter)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter, 100279862773856)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask, accessed_by=GetAttrGuardAccessor(_expand_mask)
	| | | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].AttentionMaskConverter._expand_mask.__code__, 136342992593456)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling, accessed_by=GetAttrGuardAccessor(is_torchdynamo_compiling)
	| | | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_modeling_attn_mask_utils'].is_torchdynamo_compiling.__code__, 136343246382112)
	| | | +- GuardManager: source=G['__import_transformers_dot_modeling_attn_mask_utils'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_modeling_attn_mask_utils'].torch
	| | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot_nn_dot_modules_dot_normalization)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot_nn_dot_modules_dot_normalization'], 136343316849712)
	| | | +- GuardManager: source=G['__import_torch_dot_nn_dot_modules_dot_normalization'].F, accessed_by=GetAttrGuardAccessor(F)
	| | | | +- OBJECT_ALIASING: G['__import_torch_dot_nn_dot_modules_dot_sparse'].F is G['__import_torch_dot_nn_dot_modules_dot_normalization'].F
	| | +- GuardManager: source=G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], accessed_by=DictGetItemGuardAccessor(__import_torch_dot__dynamo_dot_polyfills_dot_builtins)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_torch_dot__dynamo_dot_polyfills_dot_builtins'], 136343254037936)
	| | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'], accessed_by=DictGetItemGuardAccessor(__import_transformers_dot_models_dot_bert_dot_modeling_bert)
	| | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'], 136342992659344)
	| | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].apply_chunking_to_forward, accessed_by=GetAttrGuardAccessor(apply_chunking_to_forward)
	| | | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].apply_chunking_to_forward.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].apply_chunking_to_forward.__code__, 100279835012192)
	| | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert']._prepare_4d_attention_mask_for_sdpa, accessed_by=GetAttrGuardAccessor(_prepare_4d_attention_mask_for_sdpa)
	| | | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert']._prepare_4d_attention_mask_for_sdpa.__code__, accessed_by=GetAttrGuardAccessor(__code__)
	| | | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_models_dot_bert_dot_modeling_bert']._prepare_4d_attention_mask_for_sdpa.__code__, 136342992594480)
	| | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].BaseModelOutputWithPastAndCrossAttentions, accessed_by=GetAttrGuardAccessor(BaseModelOutputWithPastAndCrossAttentions)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].BaseModelOutputWithPastAndCrossAttentions, 100279834829984)
	| | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].BaseModelOutputWithPoolingAndCrossAttentions, accessed_by=GetAttrGuardAccessor(BaseModelOutputWithPoolingAndCrossAttentions)
	| | | | +- ID_MATCH: ___check_obj_id(G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].BaseModelOutputWithPoolingAndCrossAttentions, 100279834825872)
	| | | +- GuardManager: source=G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].torch, accessed_by=GetAttrGuardAccessor(torch)
	| | | | +- OBJECT_ALIASING: G['__import_transformers_dot_modeling_utils'].torch is G['__import_transformers_dot_models_dot_bert_dot_modeling_bert'].torch
	
V0331 22:38:56.579000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "184cdf1686b8a15e401bf24e1a80cf01"}
	{
	"name": "entire_frame_compile",
	"ts": 1743460736579574.5,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.580000 25844 torch/_dynamo/utils.py:953] {"chromium_event": {}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0, "has_payload": "e59b2aff097fe10c36b68ff3516dfa2f"}
	{
	"name": "_compile.compile_inner",
	"ts": 1743460736580221.8,
	"args": {
	"cache_stats": {
	"fxgraph_cache_hit": 3,
	"fxgraph_cache_miss": 0,
	"fxgraph_cache_bypass": 0
	}
	},
	"ph": "E",
	"cat": "dynamo_timed",
	"tid": 0,
	"pid": 0
	}
V0331 22:38:56.581000 25844 torch/_dynamo/utils.py:810] {"compilation_metrics": {"compile_id": "3/0", "frame_key": "4", "co_name": "torch_dynamo_resume_in_forward_refined_at_33", "co_filename": "/workspaces/HPML-Project/pull_model_run_dynamo_explain.py", "co_firstlineno": 33, "cache_size": 0, "accumulated_cache_size": 0, "guard_count": 646, "shape_env_guard_count": 0, "graph_op_count": 64, "graph_node_count": 107, "graph_input_count": 42, "start_time": 1743460734.220757, "entire_frame_compile_time_s": 2.35870361328125, "backend_compile_time_s": 1.473862648010254, "inductor_compile_time_s": 0.05842471122741699, "code_gen_time_s": null, "fail_type": null, "fail_reason": null, "fail_user_frame_filename": null, "fail_user_frame_lineno": null, "non_compliant_ops": [], "compliant_custom_ops": [], "restart_reasons": [], "dynamo_time_before_restart_s": 0.0, "has_guarded_code": true, "possibly_missed_reinplacing_opportunities": 0}, "frame_id": 3, "frame_compile_id": 0, "attempt": 0}
